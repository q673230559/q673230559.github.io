[{"title":"Markdown效果预览","url":"/2017_01_01_markdown_use/","content":"概要&amp;emsp;&amp;emsp;小书匠是一款专为markdown写作而设计的编辑器。\n//首行空两格&amp;emsp;&amp;emsp;\n\n主要功能\n专为markdown写作设计的文档编辑器，让用户心无旁骛的进行创作。//加粗**专为markdown写作设计的文档编辑器**\n多种编辑模式。单栏编辑，双栏编辑，三栏编辑，全屏写作，全屏阅读…想怎么切换，就怎么切换，就是这样随心所欲。\n多种编辑器实现。codemirror编辑器（提供vim,emacs按键，行专注等），ace编辑器（提供vim，emacs按键绑定，显示行号），轻量编辑器，CJK竖排编辑器\n多种主题选择。包括编辑器主题，预览区代码高亮主题，及预览区用户自定义css。\n丰富的语法支持。不仅提供了常用的commanmarkdown语法，还提供了许多有用的扩展语法，比如&#x3D;&#x3D;Latex公式&#x3D;&#x3D;，&#x3D;&#x3D;表格&#x3D;&#x3D;, &#x3D;&#x3D;目录&#x3D;&#x3D;， &#x3D;&#x3D;脚注&#x3D;&#x3D;, &#x3D;&#x3D;视频&#x3D;&#x3D;, &#x3D;&#x3D;音频&#x3D;&#x3D;, &#x3D;&#x3D;附件&#x3D;&#x3D;, &#x3D;&#x3D;checklist&#x3D;&#x3D;, &#x3D;&#x3D;流程图&#x3D;&#x3D;等。更多语法可查看&lt;小书匠语法使用手册&gt;\n代码块文字格式语法。语法可查看&lt;小书匠语法使用手册&gt;\n第三方同步。&#x3D;&#x3D;浏览器存储&#x3D;&#x3D;, &#x3D;&#x3D;本地文件系统存储&#x3D;&#x3D;, &#x3D;&#x3D;dropbox&#x3D;&#x3D;, &#x3D;&#x3D;evernote&#x3D;&#x3D;, &#x3D;&#x3D;印象笔记&#x3D;&#x3D;,&#x3D;&#x3D;有道笔记&#x3D;&#x3D;, &#x3D;&#x3D;为知笔记&#x3D;&#x3D;, &#x3D;&#x3D;github&#x3D;&#x3D;等多种存储方案，保证了用户数据的安全，也让用户在存储方案上有了更多的选择。\n支持evernote，印象笔记。提供双向操作，可以将文章保存到evernote&#x2F;印象笔记上，也可以从evernote&#x2F;印象笔记上导入数据。同时提供标签，附件，图片，待办等相关处理。\n强大的文件管理功能。文件信息，标签，附件，音频，视频，图片管理。\n发布功能。 支持将文章发布到博客平台上。\n邮件发送功能。\nsourceMap对照功能。方便在源markdown文件和生成的html文件上进行比较，特别适合markdown初学者使用，了解每一个markdown解析产生的结果，也适用于文章后期的校对上。\nppt。\nppt跨屏演示\npdf预览\ntypewriter scrolling\nautocomplete 和 snippets 功能\n\n离线版下载地址http://soft.xiaoshujiang.com\nWEB版访问地址http://markdown.xiaoshujiang.com\n元数据使用说明语法开关元数据项，可以到设置面板里的语法扩展标签页下查看对应的元数据标识．在元数据里true时，表示当前文档强制打开该语法，false时表示强制关闭该语法．如果没有对应的元数据，则使用全局设置里的语法开关.\npreview_previewType元数据，可用的值为normal和presentation．用于文章在打开时，控制是否需要系统切换对应的预览界面．如果文章里没有该项元数据，或者元数据值不正确，则系统默认使用normal预览界面．该元数据仅控制文章打开时初始化的界面，用户依然可以通过按钮在不同预览界面间切换．\n浏览器存储系统对创建的文章，都会在浏览器存储上进行保存。包括像evernote&#x2F;印象笔记&#x2F;github&#x2F;dropbox等导入的文章，也都会保存一份副本，并创建一个标识，表示跟哪些第三方存储关联。\n标题，标签文章标题的处理规则：如果文章内存在元数据title，则系统自动使用元数据内的title做为标题。如果文章未使用到元数据功能，用户可以通过维护文章信息按钮，修改标题。标签tags的规则也跟标题一样。\n附件文章使用./做为附件的引用标识。对于图片，音频，视频，附件等链接的处理，系统只处理以./开头的链接，并转换成附件真实的地址进行显示。用户可以通过工具栏的插入图片，插入音频，插入视频，插入附件等按钮上传附件。\nevernote&#x2F;印象笔记小书匠编辑器提供对evernote&#x2F;印象笔记的支持，下面的使用说明默认用户已经完成了evernote&#x2F;印象笔记的绑定操作，并将当前的工作平台切换到evernote&#x2F;印象笔记下。\n新建通过新建按钮后，创建的文章将自动关联到evernote&#x2F;印象笔记上(注:这里仅仅是在文章上创建一个关联的标识，只有当用户保存后，才能在服务器上查看到新的笔记)\n打开点击笔记，系统将自动把笔记导入，并将当前文章切换为导入的笔记内容。导入的文章自动与evernote&#x2F;印象笔记上的笔记关联，下次再点击该笔记时，将直接从浏览器存储上打开。用户可以通过切换存储平台浏览器存储，来删除该缓存的文件。导入的笔记如果本地没有缓存，系统将对服务器上的笔记进行判断，如果笔记是通过小书匠编辑器进行保存，并且文章在保存后没有被操作过，则系统自动使用保存时附带的markdown附件做为文章内容，重新导入。如果笔记已经被修改，或者笔记不是通过小书匠编辑器进行保存的，系统将自动将文章转换成markdown格式。\n保存对于新创建的文章，用户可以直接保存ctrl+s，系统将弹出一个选择笔记本的窗口，确认后，系统将保存当前文章到evernote&#x2F;印象笔记上。（在弹出窗口上选择笔记本时，如果用户选择了笔记，系统将覆盖该笔记）\n对于已经存在的文章，但还没有保存到evernote&#x2F;印象笔记，用户可以通过另存为ctrl+shift+s将当前文章保存到evernote&#x2F;印象笔记上。\n不管是保存，还是另存为，保存成功后，系统都将自动对当前文章与evernote&#x2F;印象笔记上的笔记进行关联。下次保存时ctrl+s系统将自动同步保存到evernote&#x2F;印象笔记上。\n删除系统不提供删除操作，用户需要自己到evernote&#x2F;印象笔记端删除，如果本地缓存了笔记，可以通过浏览器存储删除缓存。\n重命名直接修改元数据title，如果文章内未使用元数据功能，可通过浏览器存储里的修改文章信息进行修改\n标签管理系统自动通过每篇文章的元数据tags提取为笔记的标签。\n附件管理打开时，系统自动将笔记上的附件导入到文章对应的附件管理器上。保存时，系统将根据文章内对附件的引用，将附件保存到服务器上。这里的引用包括音频，视频，附件，图片。如果文章内使用到了流程图，序列图，公式，统计图等，系统将会把这些内容转换成图片进行保存。由于evernote&#x2F;印象笔记在部分终端不提供视频，音频的支持，查看保存的文章时，对应的音频，视频将以附件的形式存储。\n待办事项目前系统仅同步了待办事项。\ngithub&#x2F;dropbox新建参考evernote/印象笔记的新建\n打开参考evernote/印象笔记的打开不同的是，github&#x2F;dropbox只能打开扩展名为html，markdown，md，mkd以及无扩展名的文件。\n保存参考evernote/印象笔记的保存不同的是，github&#x2F;dropbox保存时，仅保存了markdown文章本身，并不会将markdown转换成html进行保存，也不会处理附件相关的内容。对于新文章的保存，github&#x2F;dropbox存储需要用户指定文件名及存储的位置。\n删除系统不提供删除操作\n重命名系统不提供重命名操作，只能通过另存为ctrl+shift+s，保存成新的文件。\n本地文件系统存储本地文件系统存储仅在离线版提供支持。\n新建参考evernote/印象笔记的新建\n打开参考github/dropbox的打开不同的是，本地文件系统存储在打开文件时，将会自动关联文章内的附件引用标识./，自动抓取同级目录下对应的附件资源。\n保存参考github/dropbox的保存不同的是，本地文件系统存储在保存时，不仅保存了markdown文章，还会处理附件相关的内容，将附件保存到同级目录下，请确保附件的名称不要重复，防止数据被覆盖丢失。\n删除右击相应的文章可进行删除操作\n重命名右击相应的文章可进行重命名操作\n发布小书匠编辑器离线版提供文章发布功能，用户可以将自己的文章发布到博客系统上。发布功能实现了博客的metaweblogAPI（newPost, editPost, newMediaObject）。使用该发布功能，需要博客系统提供对应的api接口，系统将转换成html的文章和图片自动提交到博客系统上。\n配置发布示例：博客链接地址：比如http://www.cnblogs.com/[用户名]/用户名：用户在该博客上的用户名密码：用户在该博客上的密码\n测试通过的博客地址：博客园：http://www.cnblogs.com/[用户名]/开源中国：http://my.oschina.net/[用户名]/blog\n邮件发送小书匠编辑器提供邮件发送功能，系统将对当前文章转换成html格式后进行发送，并对图片，视频等文件以附件的形式进行发送。\n导出小书匠编辑器提供多种格式的导出文件功能。&#x3D;&#x3D;html&#x3D;&#x3D;,&#x3D;&#x3D;markdown&#x3D;&#x3D;,&#x3D;&#x3D;html(inlinestyle)&#x3D;&#x3D;,&#x3D;&#x3D;word&#x3D;&#x3D;,&#x3D;&#x3D;zip&#x3D;&#x3D;,&#x3D;&#x3D;pdf&#x3D;&#x3D;。\nzip导出： 该导出将导出文章的所有信息，包括markdown,html,markdown文章内引用的所有附件，公式，流程图等对应的图片文件，以及方便再次导入时需要的标识数据文件。\npdf导出：目前pdf导出只能在chrome版浏览器上使用。\n导入小书匠编辑器提供markdown, html, zip三种导入功能，并且实现了文本文件直接拖动导入功能。\nzip导入：导入的zip文件必需是由小书匠编辑器导出的文件。\n其他web版实现了图片直接粘贴功能，用户不仅可以拖动图片上传，还可以直接复制粘贴图片。\n","categories":["其他资料"],"tags":["Markdown","小书匠"]},{"title":"Markdown文件规范","url":"/2017_01_01_mdfile_standard/","content":"Markdown是一种可以使用普通文本编辑器编辑的标记语言，通过简单的标记语法，可以自动生成具有一定样式的文本。markdown语法简单明了，学习容易，而且功能比纯文本要强，因此很多人用他来写博客，比如WordPress和大型的CMS如Joomla、Drupal等都支持markdown。除此之外markdown还用于github中README.md用于编写说明文档。\n\n\n文件头格式规范---title: 诫子书date: 2017-04-15 16:20:00updated: 2017-04-15 16:20:00comments: falsetags: [励志]categories: 文言permalink: to_sondescription: xx---\ntitle\n文章标题\n\ndate\n文件编写日期\n\nupdated\n更新时间\n\ncomments\n是否开启评论true or false\n\ntags\ntomcat\nnginx\njava\nmarkdown\njs\najax\nhtml5\n前端\n青春\n励志\n读书\n激情\n…\n\ncategories\n文言\n美文\n诗歌\n文档\n技术\n摄影\n小说\n…\n\ndescription\n文章概述，如果不为空，则预览的时候显示后标签后面的内容（作用和正文中的分隔符作用差不多）\n\n正文格式规范&gt; &amp;emsp;&amp;emsp;其实非常喜欢这...# 标题一## 标题二### 标题三    XXXXXXXX## 标题二.1\n\n说明\n我们用引用符号&gt; 来规范文本格式，作为摘要部分，一般情况下，摘要要大于150个字，因为摘要的前150个字用于作为首页摘要简讯\n斜体*摘要：*注明摘要部分开始，这不是必需，而是规范。\n\n","categories":["其他资料"],"tags":["Markdown"]},{"title":"爱的深沉","url":"/2017_01_15_oak/","content":"第一篇：今天下午在言谈之中，忽然想起一首诗——舒婷的《致橡树》，致橡树 读后感。虽然这不是一首纯粹描述爱情的诗句，但是许多人却从中看出了爱情该有的态度。记得以前最喜欢其中的一句“我必须是你近旁的一株木棉，做为树的形象和你站在一起。”正是这种努力成长为树的信念，让我一度动容。自古以来，女性的形象似乎就被设定为了柔情似水、若柳扶风，长久以来受到压迫的旧社会的妇女也习惯了依附男人而生。拥有与失去似乎向来不是由女性向导，而只是被动地承受。\n也许真的存在那种耐心极好的男人，那就是极品了，不是你我轻易能够遇到的。男人的确喜欢温柔的女人，但是温柔不是软弱无力、不是悲泣啼哭，温柔的女人也可以拥有一个坚毅的灵魂。泪水也许会换来男人一时的柔情，但总怕终有一天，这个曾经给予你温暖的手也会因为疲倦而无力地垂下。我想我是不愿当这棵菟丝花的，那样只能努力地依附大树而生，贪婪地榨取大树的精力来得到生存，让大树的躯干无法得到伸展。我愿意用我的智慧来经营我的感情和生活，将自己塑造成一个温柔的女人和一个并肩的战友，拥有自己独特的和煦而坚定的微笑。当欣赏江山如画的时候，我愿意化为一汪春水，为这副风景增添一抹丽色;当遭遇风浪袭人的时候，我亦可以和你一起迎风而上 ，而不是委屈地退缩害怕、逃离。\n第二篇：《致橡树》是我非常喜欢的一首诗，记得上大学的时候，我把这首诗写在了日记里，对诗中的每一句都曾仔细的斟酌和品味，后来常常把它默记在心里。随着年龄的增长，对诗中所体现的那种至高无上的爱情更是感受至深。近几天，我在看央视播放的电视剧《相思树》，当这首诗被男女主人公深情朗诵的时候，让我又一次产生了强烈的思想共鸣，也让我想起了很多的往事，往事不可追，但却永远珍藏在内心深处，还有往事中的他伴我在记忆的空间里飞呀飞……\n致橡树舒婷我如果爱你——绝不像攀援的凌霄花，借你的高枝炫耀自己；我如果爱你——绝不学痴情的鸟儿，为绿荫重复单调的歌曲；也不止像泉源，常年送来清凉的慰藉；也不止像险峰，增加你的高度，衬托你的威仪。甚至日光，甚至春雨。不，这些都还不够！我必须是你近旁的一株木棉，作为树的形象和你站在一起。根，紧握在地下；叶，相触在云里。每一阵风过，我们都互相致意，但没有人，听懂我们的言语。你有你的铜枝铁干，像刀，像剑，也像戟；我有我红硕的花朵，像沉重的叹息，又像英勇的火炬。我们分担寒潮、风雷、霹雳；我们共享雾霭、流岚、虹霓。仿佛永远分离，却又终身相依。这才是伟大的爱情，坚贞就在这里：爱——不仅爱你伟岸的身躯，也爱你坚持的位置，足下的土地。\n","categories":["哲学思考"],"tags":["爱情","致橡树","舒婷","情书"]},{"title":"Youth(青春)","url":"/2017_01_06_youth/","content":"塞缪尔·厄儿曼既不是诗人，也不是作家，他一生就只写了这一首散文诗，而且是在他七十余岁高龄时写下来自勉的。后来偶然间由朋友不经意传出，立即受到了许多人喜爱，他们纷纷将其作为自己的人生格言，挂在墙上、放入衣兜、置入心灵深出，伴随自己一生，共同沐浴风雨阳光。塞缪尔·厄儿曼虽然已经去世快两个世纪了，但是他的这首《青春》仍然不减当年风采，依旧拥有震撼人心的力度，如诗如画的优美和深邃隽永的哲理。 青春是美好的，花样般的年华，白里透红的桃面，樱桃般的丹唇，弱柳扶风般的柔膝；勇敢的锐气，远大的理想，炽热的感情，青春是人一生中最美好的季节。\n青春塞缪尔\n青春不是年华，而是心境；青春不是桃面、丹唇、柔膝，而是深沉的意志，恢宏的想象，炙热的恋情；青春是生命的深泉在涌流。 \n青春气贯长虹，勇锐盖过怯弱，进取压倒苟安。如此锐气，二十后生而有之，六旬男子则更多见。年岁有加，并非垂老，理想丢弃，方堕暮年。 \n岁月悠悠，衰微只及肌肤；热忱抛却，颓废必致灵魂。忧烦，惶恐，丧失自信，定使心灵扭曲，意气如灰。 \n无论年届花甲，拟或二八芳龄，心中皆有生命之欢乐，奇迹之诱惑，孩童般天真久盛不衰。人人心中皆有一台天线，只要你从天上人间接受美好、希望、欢乐、勇气和力量的信号，你就青春永驻，风华常存。 \n一旦天线下降，锐气便被冰雪覆盖，玩世不恭、自暴自弃油然而生，即使年方二十，实已垂垂老矣；然则只要树起天线，捕捉乐观信号，你就有望在八十高龄告别尘寰时仍觉年轻。\nYOUTHSamuel Ullman \nYouth is not a time of life; it is a state of mind; it is not a matter of rosy cheeks, red lips and supple knees; it is a matter of the will, a quality of the imagination, a vigor of the emotions; it is the freshness of the deep springs of life. \nYouth means a tempera-mental predominance of courage over timidity, of the appetite for adventure over the love of ease. This often exists in a man of 60 more than a boy of 20.　Nobody grows old merely by a number of years.　We grow old by deserting our ideals. \nYears may wrinkle the skin, but to give up enthusiasm wrinkles the soul. Worry, fear, self-distrust bows the heart and turns the spring back to dust. \nWhether 60 or 16, there is in every human being’s heart the lure of wonder, the unfailing childlike appetite of what’s next and the joy of the game of living.　In the center of your heart and my heart there is a wireless station: so long as it receives messages of beauty, hope, cheer, courage and power from men and from the Infinite, so long are you young. \nWhen the aerials are down, and your spirit is covered with snows of cynicism and the ice of pessimism, then you are grown old, even at 20, but as long as your aerials are up, to catch waves of optimism, there is hope you may die young at 80.\n","categories":["哲学思考"],"tags":["励志","青春","塞缪尔","Youth"]},{"title":"以书为伴","url":"/2017_01_07_book/","content":"通常看一个读些什么书就可知道他的为人，就像看他同什么人交往就可知道他的为人一样，因为有人以人为伴，也有人以书为伴。无论是书友还是朋友，我们都应该以最好的为伴。\n好书就像是你最好的朋友。它始终不渝，过去如此，现在如此，将来也永远不变。它是最有耐心，最令人愉悦的伴侣。在我们穷愁潦倒，临危遭难时，它也不会抛弃我们，对我们总是一如既往地亲切。在我们年轻时，好书陶冶我们的性情，增长我们的知识；到我们年老时，它又给我们以慰藉和勉励。\n人们常常因为喜欢同一本书而结为知已，就像有时两个人因为敬慕同一个人而成为朋友一样。有句古谚说道：&quot;爱屋及屋。&quot;其实&quot;爱我及书&quot;这句话蕴涵更多的哲理。书是更为真诚而高尚的情谊纽带。人们可以通过共同喜爱的作家沟通思想，交流感情，彼此息息相通，并与自己喜欢的作家思想相通，情感相融。\n好书常如最精美的宝器，珍藏着人生的思想的精华，因为人生的境界主要就在于其思想的境界。因此，最好的书是金玉良言和崇高思想的宝库，这些良言和思想若铭记于心并多加珍视，就会成为我们忠实的伴侣和永恒的慰藉。\n书籍具有不朽的本质，是为人类努力创造的最为持久的成果。寺庙会倒坍，神像会朽烂，而书却经久长存。对于伟大的思想来说，时间是无关紧要的。多年前初次闪现于作者脑海的伟大思想今日依然清新如故。时间惟一的作用是淘汰不好的作品，因为只有真正的佳作才能经世长存。\n书籍介绍我们与最优秀的人为伍，使我们置身于历代伟人巨匠之间，如闻其声，如观其行，如见其人，同他们情感交融，悲喜与共，感同身受。我们觉得自己仿佛在作者所描绘的舞台上和他们一起粉墨登场。\n即使在人世间，伟大杰出的人物也永生不来。他们的精神被载入书册，传于四海。书是人生至今仍在聆听的智慧之声，永远充满着活力。\n","categories":["哲学思考"],"tags":["读书"]},{"title":"阿里巴巴Java开发手册","url":"/2017_02_16_java_help_doc/","content":"2017年开春之际，诚意献上重磅大礼：阿里巴巴Java开发手册，首次公开阿里官方Java代码规范标准。这套Java统一规范标准将有助于提高行业编码规范化水平，帮助行业人员提高开发质量和效率、大大降低代码维护成本。你是否曾因Java代码规范版本纷杂而无所适从？\n你是否想过代码规范能将系统故障率降低20%？\n你是否曾因团队代码风格迥异而协同困难？\n你是否正在review一些原本可以避免的故障？\n\n\n你是否无法确定自己的代码足够健壮？ \n码出高效，码出质量！相比C++代码规范业界已经达成共识，Java代码规范业界比较混乱，我们期待这次发布的Java代码规范能够给业界带来一个标准，促使整体行业代码规范水平得到提高，最终能够帮助企业和开发者提升代码质量和降低代码故障率。\n阿里出品，质量保证！阿里Java技术团队一手打造出Dubbo、JStorm、Fastjson等诸多流行开源框架，部分已成为Apache基金会孵化项目；\n阿里在Java后端领域支撑起全球访问量最大的服务器集群；\nJava代码构建的阿里双11业务系统订单处理能力达到17.5万笔&#x2F;秒；\n到目前已累计数亿行高并发、高稳定性的最佳Java代码实践；\n……\n此次首度公开的Java开发手册正是出自这样的团队，近万名阿里Java技术精英的经验总结，并经历了多次大规模一线实战检验及完善，铸就了这本高含金量的阿里Java开发手册。该手册以Java开发者为中心视角，划分为编程规约、异常日志规约、MYSQL规约、工程规约、安全规约五大块，再根据内容特征，细分成若干二级子目录。根据约束力强弱和故障敏感性，规约依次分为强制、推荐、参考三大类。此套规范不仅能让代码一目了然， 更有助于加强团队分工与合作、真正提升效率。 \n无规矩不成方圆 无规范不能协作众所周知，制订交通法规表面上是要限制行车权，实际上是保障公众的人身安全。试想如果没有限速，没有红绿灯，没有规定靠右行驶，谁还敢上路行驶。 \n同理，对软件来说，适当的规范和标准绝不是消灭代码内容的创造性、优雅性，而是限制过度个性化，以一种普遍认可的方式一起做事，降低故障率，提升协作效率。开发手册详细列举如何开发更加高效，更加容错，更加有协作性，力求知其然，更知其不然，结合正反例，提高代码质量。比如，异常日志处理时的各种不规范行为；集合转换的各种坑；创建线程池出现的等待队列OOM等。 \n阿里技术资深大咖联袂推荐阿里高级研究员多隆：工程师对于代码，一定要“精益求精”，不论从性能，还是简洁优雅，都要具备“精益求精”的工匠精神，认真打磨自己的作品。 \n阿里研究员毕玄：一个优秀的工程师和一个普通工程师的区别，不是现在满天飞的架构图，他的功底就是体现在他写的每一行代码上。 \n阿里研究员玄难：代码是软件工程里面的产品设计、系统架构设计等工作的最后承载体，代码的质量决定了一切工作的成败。 \n阿里巴巴B2B事业群CTO李纯：好的软件产品离不开工程师高质量的代码及相互间顺畅的沟通与合作。简单，适用的代码规约背后所传递的是技术上的追求卓越、协同合作的精神，是每个技术团队不可缺失的重要利器。 \n阿里研究员、HipHop作者：赵海平（花名：福贝）：程序员是创造个性化作品的艺术家，但同时也是需要团队合作的工种。个性化应尽量表现在代码效率和算法方面，牺牲小我，成就大我。 \n拥抱规范，远离伤害！\n开发的同学们赶紧行动起来，遵守代码规范，你好，我好，大家好！ \n下载链接： http://pan.baidu.com/s/1o8bLJSm 密码: w9vw\n","categories":["开发手册"],"tags":["Java","阿里"]},{"title":"经典诫子书","url":"/2017_04_15_to_son/","content":"其实非常喜欢这篇文章，推荐给亲⊙o记得第一次读到这篇文章的时候在初中，当时很励志，以此鞭策自己，如今看来任然可以作为终身的信条O(∩_∩)O&#x2F;年轻一定要奋斗，严格要求自己，宁静致远，这样不会再年老的时候发出“悲守穷庐，将复何及”的感叹！而且要树立终身学习的观念，寻找适合自己的学习方法，每个人的学习能力存在差异可能不容易改变，但是时间的累积会让你获得意想不到的收获 ~ 朋友们加油吧。\n\n\n原文诸葛亮夫君子之行，静以修身，俭以养德。非淡泊无以明志，非宁静无以致远。夫学须静也，才须学也。非学无以广才，非志无以成学。淫慢则不能励精，险躁则不能治性。年与时驰，意与日去，遂成枯落，多不接世。悲守穷庐，将复何及？\n\n最喜欢“宁静致远”。\n\n创作背景这篇文章当作于蜀汉建兴十二年（元234年），是诸葛亮晚年写给他八岁的儿子诸葛瞻的一封家书。诸葛亮一生为国，鞠躬尽瘁，死而后已。他为了蜀汉国家事业日夜操劳，顾不上亲自教育儿子，于是写下这篇书信告诫诸葛瞻。\n作品鉴赏古代家训，大都浓缩了作者毕生的生活经历、人生体验和学术思想等方面内容，不仅他的子孙从中获益颇多，就是今人读来也大有可借鉴之处。三国时蜀汉丞相诸葛亮被后人誉为“智慧之化身”，他的《诫子书》也可谓是一篇充满智慧之语的家训，是古代家训中的名作。文章阐述修身养性、治学做人的深刻道理，读来发人深省。它也可以看作是诸葛亮对其一生的总结，后来更成为修身立志的名篇。\n《诫子书》的主旨是劝勉儿子勤学立志，修身养性要从淡泊宁静中下功夫，最忌怠惰险躁。文章概括了做人治学的经验，着重围绕一个“静”字加以论述，同时把失败归结为一个“躁”字，对比鲜明。\n在《诫子书》中，诸葛亮教育儿子，要“澹泊”自守，“宁静”自处，鼓励儿子勤学励志，从澹泊和宁静的自身修养上狠下功夫。他说，“夫学须静也，才须学也，非学无以广才，非志无以成学”。意思是说，不安定清静就不能为实现远大理想而长期刻苦学习，要学得真知必须使身心在宁静中研究探讨，人们的才能是从不断的学习中积累起来的；不下苦功学习就不能增长与发扬自己的才干；没有坚定不移的意志就不能使学业成功。《诸葛亮教育儿子切忌心浮气躁，举止荒唐。在书信的后半部分，他则以慈父的口吻谆谆教导儿子：少壮不努力，老大徒伤悲。这话看起来不过是老生常谈罢了，但它是慈父教诲儿子的，字字句句是心中真话，是他人生的总结，因而格外令人珍惜。\n这篇《诫子书》，不但讲明修身养性的途径和方法，也指明了立志与学习的关系；不但讲明了宁静淡泊的重要，也指明了放纵怠慢、偏激急躁的危害。诸葛亮不但在大的原则方面对其子严格要求，循循善诱，甚至在一些具体事情上也体现出对子女的细微关怀。在这篇《诫子书》中，有宁静的力量：“静以修身”，“非宁静无以致远”；有节俭的力量：“俭以养德”；有超脱的力量：“非澹泊无以明志”；有好学的力量：“夫学须静也，才须学也”；有励志的力量：“非学无以广才，非志无以成学”；有速度的力量：“淫慢则不能励精”；有性格的力量：“险躁则不能治性”；有惜时的力量：“年与时驰，意与岁去”；有想象的力量：“遂成枯落，多不接世，悲守穷庐，将复何及”；有简约的力量。这篇文章短短几十字，传递出的讯息，比起长篇大论，诫子效果好得多。\n文章短小精悍，言简意赅，文字清新雅致，不事雕琢，说理平易近人，这些都是这篇文章的特出之处。\n","categories":["哲学思考"],"tags":["诫子书"]},{"title":"誓刷红楼，品味经典","url":"/2017_05_11_dream__of_red/","content":"最近刷了一遍红楼，开始的目的是想借此了解一下清朝人们的生活状态，感受一下大观园富丽堂皇的生活，当然，也借此去找寻一下生活的意义；然而，迷上了红楼的文字艺术，辞藻的华丽，让人惊叹。即使是每一个丫头，佣人的名字艺术感也是非常强烈的，因是，在想，以后给某某取名，应多借鉴红楼。另外，关于清代人们的价值观，思想状态，也是有很多感受的，在这儿，就不细说，先列出优美的句子。\n\n\n品读佳句\n你证我证，心证意证。是无有证，斯可云证。无可云证，是立足境。无立足境，是方干净。\n\n彼此都想从对方得到感情的印证而频添烦恼；看来只有到了灭绝情谊，无需再验证时，方谈得上感情上的彻悟；到了万境归空，什么都无可验证之时，才是真正的立足之境。后一句是黛玉加的。证，在佛教用语中是领受、领悟道法之意，这里第一句中的证可以解释为印证。主要讲的是他们之间的感情纠葛。意谓彼此都想从对方心灵和表情达意中印证相互之间的感情；当然我们如果纯以禅理的角度讲可以理解为参禅的第一步。第二句“无有证”即无证，意谓无求于身外，不要证验，才谈得上参悟禅机，证得上层。第三句意谓到万境归空无证验可言时，才算找到了禅宗的境界。黛玉所续之句的意思是连禅境都放弃了才算是最彻底的。简单地说宝玉最终追求的是精神境界，而黛玉却连精神境界也一并不要了，从而达到空无纯明之境，“心体亦空，万缘俱寂”。这正好与禅宗三境界相对应。   \n\n\n菩提本无树，明镜亦非台。本来无一物，何处若尘埃。  \n\n假作真时真亦假，无为有处有还无。\n\n《太虚幻境》   \n\n\n世事洞明皆学问，人情练达即文章。\n\n处事哲学乎？  \n\n\n莫失莫忘，仙寿恒昌。不离不弃，芳龄永继。\n\n“莫失莫忘,仙寿恒昌”是_贾宝玉佩带的通灵宝玉上的字,“不离不弃,芳龄永继“是薛宝钗佩带的金锁;简言“莫失莫忘，不离不弃”。  一块玉一块金，此之谓“金玉良缘”。\n\n\n满纸荒唐言，一把辛酸泪。都云作者痴，谁解其中味？\n\n如花美眷，怎敌似水流年。\n\n花谢花飞花满天，红消香断有谁怜？游丝软系飘春榭，落絮轻沾扑绣帘。闺中女儿惜春暮，愁绪满怀无释处。手把花锄出绣帘，忍踏落花来复去？柳丝榆荚自芳菲，不管桃飘与李飞。桃李明年能再发，明年闺中知有谁？三月香巢已垒成，梁间燕子太无情！明年花发虽可啄，却不道人去梁空巢也倾。一年三百六十日，风刀霜剑严相逼。明媚鲜妍能几时？一朝飘泊难寻觅。花开易见落难寻，阶前闷杀葬花人。独倚花锄泪暗洒，洒上空枝见血痕。杜鹃无语正黄昏，荷锄归去掩重门。青灯照壁人初睡，冷雨敲窗被未温。怪奴底事倍伤神？半为怜春半恼春。怜春忽至恼忽去，至又无言去不闻。昨宵庭外悲歌发，知是花魂与鸟魂。花魂鸟魂总难留，鸟自无言花自羞。愿依胁下生双翼，随花飞到天尽头。天尽头,何处有香丘?未若锦囊收艳骨，一杯净土掩风流。 质本洁来还洁去，强于污淖陷渠沟。尔今死去依收葬，未卜依身何日丧? 依今葬花人笑痴，他年葬依知是谁?试看春残花渐落，便是红颜老死时。 一朝春尽红颜老，花落人亡两不知!  \n\n这是黛玉的《葬花吟》。最有名的我想是开头的“花谢花飞飞满天，红消香断有谁怜”跟结尾处“一朝春尽红颜老，花落人亡两不知”两句；翻译几句：花开易见落难寻，阶前闷杀葬花人。花开时容易被人发现，花落时却难寻觅，这真让我这个葬花人发愁啊!侬今葬花人笑痴，他年葬侬知是谁? 我今天葬花别人笑我傻，等我死时却又不知谁来埋葬我呢?试看春残花渐落，便是红颜老死时。看那春天将尽花也渐渐飘落，就是如花红颜衰老将死之时。一朝春尽红颜老，花落人亡两不知！等到哪一天春天彻底逝去，美人迟暮之后，花也落尽，人也去世，两边再无相知。  \n\n\n寒塘渡鹤影，冷月葬花魂。\n\n对仗炒鸡工整。  \n\n\n春恨秋悲皆自惹，花容月貌为谁妍。  \n\n滴不尽相思血泪抛红豆 ，开不完春柳春花满画楼，睡不稳纱窗风雨黄昏后 ，忘不了新愁与旧愁。\n\n厚地高天，堪叹古今情不尽；痴男怨女，可怜风月债难偿。\n\n太高人愈妒，过洁世同嫌。\n\n世人都晓神仙好，只有功名忘不了！古今将相在何方，荒冢一堆草没了！世人都晓神仙好，只有金银忘不了！终朝只恨聚无多，及到多时眼闭了！世人都晓神仙好，只有娇妻忘不了！君生日日说恩情，君死又随人去了！世人都晓神仙好，只有儿孙忘不了！痴心父母古来多，孝顺子孙谁见了！\n\n 《好了歌》诗歌内容隐射小说情节，表达了作者对现实的愤懑和失望。  \n\n\n茜纱窗下，公子无缘。黄土垅中，卿何薄命。\n\n意淫二字，惟心会而不可口传，可神通而不可语达。\n\n任凭弱水三千，我只取一瓢饮。\n\n弱水三千只取一瓢饮。\n\n\n纵然生得好皮囊，腹内原来草莽。\n\n这原始初中时候最喜欢的的一句，嘲讽下某某人\n\n\n半卷湘帘半掩门，碾冰为土玉为盆。偷来梨蕊三分白，借得梅花一缕魂。月窟仙人缝缟袂，秋闺怨女拭啼痕。娇羞默默同谁诉，倦倚西风夜已昏。\n\n女儿悲，青春已大守空闺。女儿愁，悔教夫婿觅封侯。女儿喜，对镜晨妆颜色美。女儿乐，秋千架上春衫薄。\n\n茶靡花开，末路之美，开到荼蘼花事了，尘烟过，知多少? \n\n悲伤的茶靡花–开到荼蘼花事了。  \n\n\n偶因一回顾，便为心上人。  \n\n瘦影自临春水照，卿须怜我我怜卿。\n\n孤芳自赏，憔悴的黛玉…\n\n\n\n人物别号\n林黛玉——潇湘妃子\n\n薛宝钗——蘅芜君\n\n李 纨——稻香老农\n\n史湘云——枕霞旧友\n\n贾宝玉——怡红公子\n\n贾探春——蕉下客\n\n贾迎春——菱洲\n\n贾惜春——藕榭\n\n\n人物名称\n十二金钗：林黛玉、薛宝钗、贾元春、贾迎春、贾探春、贾惜春、李纨、妙玉、史湘云、王熙凤、贾巧姐、秦可卿。 　　\n\n十二丫环：晴雯、麝月、袭人、鸳鸯、雪雁、紫鹃、碧痕、平儿、香菱、金钏、司棋、抱琴。  \n\n十二家人：赖大、焦大、王善保、周瑞、林之孝、乌进孝、包勇、吴贵、吴新登、邓好时、王柱儿、余信。   \n\n十二儿：庆儿、昭儿、兴儿、隆儿、坠儿、喜儿、寿儿、丰儿、住儿、小舍儿、李十儿、玉柱儿。  \n\n十二贾氏：贾敬、贾赦、贾政、贾宝玉、贾琏、贾珍、贾环、贾蓉、贾兰、贾芸、贾蔷、贾芹。   \n\n十二官：琪官、芳官、藕官、蕊官、药官、玉官、宝官、龄官、茄官、艾官、豆官、葵官。   \n\n七尼：妙玉、智能、智通、智善、圆信、大色空、净虚。  \n\n七彩：彩屏、彩儿、彩凤、彩霞、彩鸾、彩明、彩云。  \n\n四春：贾元春、贾迎春、贾探春、贾惜春。  \n\n四宝：贾宝玉、甄宝玉、薛宝钗、薛宝琴。  \n\n四薛：薛蟠、薛蝌、薛宝钗、薛宝琴。 　 \n\n四王：王夫人、王熙凤、王子腾、王仁。 　\n\n四尤：尤老娘、尤氏、尤二姐、尤三姐。   \n\n四草辈：贾蓉、贾兰、贾芸、贾芹。  \n\n四玉辈：贾珍、贾琏、贾环、贾瑞。 　\n\n四文辈：贾敬、贾赦、贾政、贾敏 。　\n\n四代辈：贾代儒、贾代化、贾代修、贾代善。 　\n\n四烈婢：晴雯、金钏、鸳鸯、司棋。 　\n\n四清客：詹光、单聘仁、程日兴、王作梅。 　\n\n四无辜：石呆子、张华、冯渊、张金哥。 　\n\n四小厮：茗烟、扫红、锄药、伴鹤。 　 \n\n四小：小鹊、小红、小蝉、小舍儿。 　　\n\n四婆子：刘姥姥、马道婆、宋嬷嬷、张妈妈。 　 \n\n四情友：秦锺、蒋玉菡、柳湘莲、东平王。 \n\n四壮客：乌进孝、冷子兴、山子野、方椿。  \n\n四宦官：载权、夏秉忠、周太监、裘世安。  \n\n文房四宝：抱琴、司棋、侍画、入画。  \n\n四珍宝：珍珠、琥珀、玻璃、翡翠。  \n\n一主三仆：史湘云–翠缕、笑儿、篆儿。贾探春–侍画、翠墨、小蝉。贾宝玉–茗烟、袭人、晴雯。林黛玉–紫鹃、雪雁、春纤。贾惜春–入画、彩屏、彩儿。贾迎春–彩凤、彩云、彩霞。\n\n\n","categories":["读书笔记"],"tags":["辞藻","佳句","红楼梦","红楼"]},{"title":"遥远的救世主","url":"/2017_05_12_distant_savior/","content":"不知道是谁推荐过《遥远的救世主》，也不知怎么就把它和《天道》相连，以为是两本书，总之就是记住了。后来知道《天道》是电视剧，众人捧的热烈，改编自这本书。很偶然的机会，图书馆里看到了它，就借来一观。五十万字，不是随意打发下午时光就可看完的。小说里佛学的光辉、哲学的深奥与“禅”的玄机不谈，“文化属性”也不说，这不是我如今的知识层面所能评判的，仅能在思想上被“灌输”而已，然后再顺便感慨几句晦涩难懂，大呼看不明白，作者有才。废话不多说，列些句子，慢慢品味。\n\n品读佳句\n一颗阴暗的心，永远托不起一张灿烂的脸。  \n\n人从根本上是面对两个问题，一，生存，得活下来；二，是要回答生命价值的问题，让心有个安处。\n\n有招有术的感情，招术里是什么不去论它了，没招没术的感情，剩下的就该是造物主给的那颗心了。  \n\n命题错误，答既有错；只要是需要证明的感情就有错误。\n\n\n当人一旦从危险里跳出来，他就不再去关注这个事物的危险了，他的目光就会全部落在这个事物的利益上。  \n\n神即道，道法自然，如来。  \n\n神就是道，道就是规律，规律如来，容不得你思议，按规律办事的人就是神。\n\n\n女人是形式逻辑的典范，是辩证逻辑的障碍，我无意摧残女人，也不想被女人摧残。  \n\n女人和男人的对话方式只有两个，要么躺着，要么站着。\n\n进了窄门，神立刻就会告诉你：我是不存在的，神就是你自己。但是，证到如此也并不究竟，神是什么?神即道，道法自然，如来。  \n\n文明对于不能以人字来界定的人无能为力。  \n\n所谓的神话竟是这么简单。原来能做到实事求是就是神话！原来能说老实话，能办老实事的人就是神！  \n\n衡量一种文化属性不是看它积淀的时间长短，而是看它与客观规律的距离远近。  \n\n一、天上掉馅饼的神话，实惠、破格，是为市井文化。二、最不道德的道德，明辨是非，是为哲人文化。三、不打碎点东西，不足以缘起主题，大智大爱，是为英雄文化。  \n\n无论做什么，市场都不是一块无限大的蛋糕。神话的实质就是强力作用的杀富济贫，这就可能产生两个问题，一是杀富是不是破坏性开采市场资源?二是让井底的人扒着井沿看了一眼再掉下去是不是让他患上精神绝症?  \n\n这就是圆融世故，不显山不露水，各得其所。可品性这东西，今天缺个角、明天裂道缝，也就离塌陷不远了。  \n\n生存法则很简单，就是忍人所不忍，能人所不能。忍是一条线，能是一条线，两者的间距就是生存机会。  \n\n这东西有点像禅，知之为不知，不知更非知。  \n\n强势文化就是遵循事物规律的文化，弱势文化就是依赖强者的道德期望破格获取的文化，也是期望救主的文化。强势文化在武学上被称为“秘笈”，而弱势文化由于易学、易懂、易用，成了流行品种。  \n\n比如说文化产业，文学、影视是扒拉灵魂的艺术，如果文学、影视的创作能破解更高思维空间的文化密码，那么它的功效就是启迪人的觉悟、震撼人的灵魂，这就是众生所需，就是功德、市场、名利，精神拯救的暴利与毒品麻醉的暴利完全等值，而且不必像贩毒那样耍花招，没有心理成本和法律风险。  \n\n股票的暴利并不产生于生产经营，而是产生于股票市场本身的投机性。它的运作动力是：把你口袋里的钱装到我口袋里去。它的规则是：把大多数羊的肉填到极少数狼的嘴里。私募基金是从狼嘴里夹肉，这就要求你得比狼更黑更狠，但是心理成本也更高，而且又多了一重股市之外的风险。所以，得适可而止。  \n\n《圣经》的教义如果不能经受逻辑学的检验，可能在实践上就会存在障碍。如果经受了逻辑学的检验，那表明神的思维即是人的思维，就会否定神性。换一种说法，神性如果附加上人性的期望值，神性就打了折扣。然而神性如果失去了人性的期望值，那么人还需要神吗?  \n\n基督教相信，太高的道德平台需要太高的教育、太深的觉悟和太复杂的炼造过程，是一道靠人性本能很难迈进的窄门。于是，基督教便有了神与人的约，有了神的关于天国与火湖、永生与死亡的应许，让凡夫俗子因为恐惧死亡和向往天堂而守约。这是智与善的魔术，非读懂的人不能理解。但《圣经》告诉世人了，要进窄门。  \n\n说魔说鬼都是个表述，本质是思维逻辑和价值观与普通人不同，所谓的地域之门也无非是价值观冲突所带来的精神痛苦。如果你是觉者，我尊敬你，向你学习，如果你是魔鬼，我鉴别你，弃你而去。  \n\n即便是呼之欲出，你也讲不出，因为一说就错，这就像法律不能单纯以推理定罪，得允许在可能与事实之间存续一个演化的过程。  \n\n红颜知己自古有之，这还得看男人是不是一杯好酒，自古又有几个男人能把自己酿到淡而又淡的名贵?这不适为之而可为的事情。  \n\n我把一个女人所能及的事都做了，包括我的廉耻和可能被你认为的淫荡，以后我就不遗憾了。  \n\n你是一块玉，但我不是匠人，你要求的，是一种雄性文化的魂，我不能因为你没说出来而装不知道。接受你，就接受了一种高度，我没有这个自信。  \n\n你让我用灵魂而不是文字去理解一个女人的圣洁。你这样做，是基于一种对应的人格，谢谢你能这样评价我。  \n\n你是那么的执著于孤独吗?我就眼看着让你走了，可心在问我，那我又该怎么去疼你?  \n\n所有的幸福、快乐、委屈，在这一刻都找到了接纳的地方。  \n\n顿悟天堂地狱的分别无二，证到极乐了。  \n\n视社会依次有三个层面：技术、制度和文化。小到一个人，大到一个国家一个民族，任何一种命运归根到底都是那种文化属性的产物。强势文化造就强者，弱势文化造就弱者，这是规律，也可以理解为天道，不以人的意志为转移。  \n\n俄罗斯是一个伟大的名族，历史上没有什么人能够战胜他们，但是再世界两大阵营五十多年意识形态的对抗里，他们却输在了他们还没有完全读懂的文化里，而美国，尊重客观规律的文化，赢得了靠飞机大炮赢得不了的胜利，以至于连联合国都成了一个失宠的王妃；在中国，有人动不动就拿民主指责共产党，但是他们根本就不知道，中国的政治文化也是传统文化的牺牲品，把沉积了几千年文化属性问题都记在一个只有几十年的政党的账上，这不公平，也不是真是的国情。\n\n丁对小丹说：不管是文化艺术还是生存艺术，有道无术，术尚可求也，有术无道，止于术；你的前途在于众生，众生没有真理真相，只有好恶，所以你就有了价值。觉悟天道，是名开天眼，你缺的就是这双眼睛，你需要的也是这双天眼，是一双剥离了政治，文化，传统，道德，宗教之分别的眼睛。然后再如实关照政治，文化，传统把文化道德颠倒了的真理真相再颠倒回来，不管随便你怎么写怎么拍，都是新意，深度，这就是钱，就是名利，成就，价值。\n\n丁为晓丹创造了一个神话，揭示了文化属性决定命运，使晓丹觉悟。\n\n\n\n资源共享小说下载链接： http://pan.baidu.com/s/1cmyvU2 密码：9620  \n电视剧《天道》： http://pan.baidu.com/s/1sloBCXf 密码：s0az\n","categories":["读书笔记"],"tags":["豆豆","遥远的救世主"]},{"title":"教育知识与能力知识总结","url":"/2018_07_01_educational_knowledge_and_ability/","content":"大纲-思维导图\n第一章 教育基础知识和基本原理1.生产力与教育的关系。⁕2.20世纪以后教育的特点。⁕3.个体身心发展的一般规律。⁕4.影响人身心发展的因素。⁕5.教育制度确立的依据。⁕6.确立我国教育目的的依据。⁕7.全面发展教育的构成及作用。⁕8.政治经济制度与教育的关系。⁕9.学校教育在人的身心发展中起主导作用的原因。10.现代教育制度的发展趋势。第二章 中学课程1.课程内容的文本表现形式。⁕2.课程改革的结构。⁕3.新课程改革背景下的评价观。⁕4.活动中心课程理论的观点&#x2F;简述活动课程的特点。5.学科中心课程论的观点。6.我国新一轮基础教育课程改革的具体目标有哪些？7.教材（教科书）编写的基本要求&#x2F;原则。8.综合时间活动课程的主要内容。第三章 中学教学1.我国现阶段的教学任务。⁕2.教学过程的结构&#x2F;基本阶段。⁕3.直观性教学原则的含义及贯彻要求。⁕4.循序渐进教学原则的含义及贯彻要求。⁕5.讲授法的概念和要求。⁕6.理论联系实际教学原则的含义及贯彻要求。⁕7.教学方法选用的依据。⁕8.教师备课的基本要求。9.教学过程的基本规律。10.班级授课制的优缺点。11.教学过程是一种特殊的认识过程。12.贯彻科学性和思想性相统一教学原则的基本要求。第四章 中学生学习心理1.如何培养中学生的注意力。⁕2.影响问题解决的主要因素。⁕3.影响遗忘进程的因素。⁕4.学生学习的特点。⁕5.有意义学习的实质及条件。⁕6.学习动机与学习效率的关系。⁕7.如何激发学生的学习动机。⁕8.如何培养学生的学习动机。⁕9.建构主义学习理论&#x2F;建构主义的知识观、学生观、学习观。10.有效促进学习迁移的教学。11.如何在教学中应用注意的规律。12.培养学生想象力的方法。13.提高问题解决能力的教学&#x2F;学生问题解决能力的培养。14.影响迁移的主要因素。15.操作（动作）技能的培养要素。16.心智技能的培养要求。17.学习策略的分类。18.中学生记忆发展的特点。19.马斯洛需求层理理论。20.加涅的学习结果分类。21.创造性思维&#x2F;发散性思维的特征。22.知觉的基本特征。23.短时记忆的特点。24.自我效能感理论及其功能。25.学习动机的定义和功能。第五章 中学生发展心理1.最近发展区及启示。⁕2.维果斯基的心理发展理论。⁕3.不通气质类型的教育措施。⁕4.影响人格形成的影响因素。⁕5.中学生情绪的特点和指导学生有效调节方法。⁕6.如何培养学生的能力。7.影响学生能力形成的因素。第六章 中学生心里辅导1.学校开展心理健康教育的途径。⁕2.简述学校心理辅导的原则。⁕第七章 中学德育1.促进中学生形成良好平的的方法。⁕2.德语过程的基本规律。⁕3.贯彻疏导原则的要求。⁕4.尊重与严格要求原则的贯彻要求。⁕5.知行统一原则的贯彻要求。⁕6.中学德育的途径。⁕7.皮亚杰道德发展理论阶段。⁕8.科尔伯格的道德发展理论。⁕9.榜样示范法的贯彻要求。⁕10.依靠积极与克服消极因素相结合原则的贯彻要求&#x2F;长善救失原则。11.说服教育法的要求。12.影响品德发展的因素。第八章 中学班级管理与教师心理1.班集体的发展阶段。⁕2.个别教育工作。⁕3.教师成长与发展的基本途径。⁕4.班主任工作的基本内容。5.班主任应具备的基本条件。6.建立教师的威信&#x2F;建立教师威信的途径。","categories":["读书笔记"],"tags":["教师资格","教育基础知识","教育原理"]},{"title":"兰亭集序","url":"/2018_08_11_lanting/","content":"原文【作者】王羲之 【朝代】魏晋\n永和九年，岁在癸丑，暮春之初，会于会稽山阴之兰亭，修禊事也。群贤毕至，少长咸集。此地有崇山峻岭，茂林修竹，又有清流激湍，映带左右，引以为流觞曲水，列坐其次。虽无丝竹管弦之盛，一觞一咏，亦足以畅叙幽情。\n是日也，天朗气清，惠风和畅。仰观宇宙之大，俯察品类之盛，所以游目骋怀，足以极视听之娱，信可乐也。\n夫人之相与，俯仰一世。或取诸怀抱，悟言一室之内；或因寄所托，放浪形骸之外。虽趣舍万殊，静躁不同，当其欣于所遇，暂得于己，快然自足，不知老之将至；及其所之既倦，情随事迁，感慨系之矣。向之所欣，俯仰之间，已为陈迹，犹不能不以之兴怀，况修短随化，终期于尽！古人云：“死生亦大矣。”岂不痛哉！\n每览昔人兴感之由，若合一契，未尝不临文嗟悼，不能喻之于怀。固知一死生为虚诞，齐彭殇为妄作。后之视今，亦犹今之视昔，悲夫！故列叙时人，录其所述，虽世殊事异，所以兴怀，其致一也。后之览者，亦将有感于斯文。\n\n在讲一个什么事情3月河边聚会，边聊边吃饭喝酒，边做活动，快乐的很，然后乐极生悲啦！\n人与人相互交往，很快便度过一生。\n有的人从自己的情趣思想中体悟出一些东西，在室内跟朋友面对面地交谈快乐。\n有的人通过寄情于自己所爱的形体之外的事物,在外面放浪快乐。\n自己体悟也快乐，醉心于外部事物，一内一外的快乐，有万种不同，心中暂时有快乐，就会觉得满足，不知道已经年近将老。（一内一外的快乐）\n等到你所追求的疲倦了，你的感情也随着这些事情改变了，你就会产生某种感慨。\n之前感到欣喜的事，很短时间内，就变成了痕迹。 看到这些痕迹不由自主的感慨着，心绪波动着。\n何况人的生命长短随着造化不同，最终都要走向死亡。\n古人说死亡生存都是大事，不让人哀痛么！\n每次看从前人兴发感想的原因，好像跟我一样，总难免要在读前人文章时叹息哀伤，不能明白于心。（人会有情感波动，原因都是一样）\n庄子把死亡生存看作一样，把长寿和短寿看作一样，我王羲之认为这是非常疯狂荒诞狂妄的想法，人是做不到的。（因为人是情感的动物，时间和情感，死亡活着和情感）\n后人看我就和我看古人一样，难过呀！\n所以我要列出和我一起的人，记录他们叙述的事。虽然事情不一样，但是高兴和难过的情感是一样的。\n后边人读到这儿，也会有感受吧！\n想强调什么人是感情动物，事情时代时空不一样，感情却是一样的。 高兴，悲伤，亲情，友情，爱情…\n","categories":["哲学思考"],"tags":["兰亭集序","感情"]},{"title":"陶渊明汇总","url":"/2018_09_01_taoyuanm/","content":"陶渊明（约365年—427年），字元亮，（又一说名潜，字渊明）号五柳先生，私谥“靖节”，东晋末期南朝宋初期诗人、文学家、辞赋家、散文家。汉族，东晋浔阳柴桑人（今江西九江）。曾做过几年小官，后因厌烦官场辞官回家，从此隐居，田园生活是陶渊明诗的主要题材。\n归去来兮辞·并序原文余家贫，耕植不足以自给。幼稚盈室，瓶无储粟，生生所资，未见其术。亲故多劝余为长吏，脱然有怀，求之靡途。会有四方之事，诸侯以惠爱为德，家叔以余贫苦，遂见用于小邑。于时风波未静，心惮远役，彭泽去家百里，公田之利，足以为酒。故便求之。及少日，眷然有归欤之情。何则？质性自然，非矫厉所得。饥冻虽切，违己交病。尝从人事，皆口腹自役。于是怅然慷慨，深愧平生之志。犹望一稔，当敛裳宵逝。寻程氏妹丧于武昌，情在骏奔，自免去职。仲秋至冬，在官八十余日。因事顺心，命篇曰《归去来兮》。乙巳岁十一月也。\n归去来兮，田园将芜胡不归？既自以心为形役，奚惆怅而独悲？悟已往之不谏，知来者之可追。实迷途其未远，觉今是而昨非。舟遥遥以轻飏，风飘飘而吹衣。问征夫以前路，恨晨光之熹微。\n乃瞻衡宇，载欣载奔。僮仆欢迎，稚子候门。三径就荒，松菊犹存。携幼入室，有酒盈樽。引壶觞以自酌，眄庭柯以怡颜。倚南窗以寄傲，审容膝之易安。园日涉以成趣，门虽设而常关。策扶老以流憩，时矫首而遐观。云无心以出岫，鸟倦飞而知还。景翳翳以将入，抚孤松而盘桓。\n归去来兮，请息交以绝游。世与我而相违，复驾言兮焉求？悦亲戚之情话，乐琴书以消忧。农人告余以春及，将有事于西畴。或命巾车，或棹孤舟。既窈窕以寻壑，亦崎岖而经丘。木欣欣以向荣，泉涓涓而始流。善万物之得时，感吾生之行休。\n已矣乎！寓形宇内复几时？曷不委心任去留？胡为乎遑遑欲何之？富贵非吾愿，帝乡不可期。怀良辰以孤往，或植杖而耘耔。登东皋以舒啸，临清流而赋诗。聊乘化以归尽，乐夫天命复奚疑！\n讲的什么事情不想当官的陶渊明辞官回家，以及回家后的所思所想O(∩_∩)O陶渊明的内耗，做自己想做的事，还是内耗，可见做自己想做的事不能避免内耗(●ˇ∀ˇ●)。\n家里穷的揭不开锅，亲戚劝我当官（当官还要劝，有点小背景），我不情愿的当了官，但是我喜欢田园， 刚好嫁到程家的妹妹在武昌去世了，一方面确实很思念这个妹妹，另一方面乘着去妹妹追悼会这个由头，在做了80多天官的时候，我辞官回家了，写了这个小日记，名字就叫回去吧！《归去来兮辞》\n田地荒芜了为啥不回去？内心被形体裹挟役使，还要内耗思绪焦灼？过去的就算了，未来还能补救，还好错的不是很远，现在知道现在是对的，之前是错的…\n终于回来了，心中开心故奔跑过去。家人来迎接太开心了。回来后每天到院子里走走，开心啊！拄着拐出去走走也开心，抬头看天，看云，看鸟，看落日， 不知不觉由开心转为彷徨。\n终于回来了，我要和世俗绝交，出去有啥好的，在家和亲戚胡侃聊天开心，弹弹琴看看书就不觉忧愁，村里老农说春天来了，我就去西边种地。种完地，我去划船，坐车，蜿蜒曲折，高高低低，青草多好看，水流多好看，一片生机，而我老了，快要结束一生了。\n算了吧，活在世上还能有多久，为啥不能放心下来任其自然生死。为啥心神不定，想要到哪去？我不求荣华富贵，修仙也是没啥希望的，乘着大好春光，顺其自然走完一生，还有啥犹豫疑惑的呢！\n五柳先生传原文先生不知何许人也，亦不详其姓字，宅边有五柳树，因以为号焉。闲静少言，不慕荣利。好读书，不求甚解；每有会意，便欣然忘食。性嗜酒，家贫不能常得。亲旧知其如此，或置酒而招之；造饮辄尽，期在必醉。既醉而退，曾不吝情去留。环堵萧然，不蔽风日；短褐穿结，箪瓢屡空，晏如也。常著文章自娱，颇示己志。忘怀得失，以此自终。\n赞曰：黔娄之妻有言：“不戚戚于贫贱，不汲汲于富贵。”其言兹若人之俦乎？衔觞赋诗，以乐其志，无怀氏之民欤？葛天氏之民欤？\n讲的什么事情据说这是陶渊明的自传，存在争议。看起来就是一个流浪汉，邋邋遢遢，混吃混喝，活那在哪。\n不知道五柳先生是什么地方的人，也不清楚他的姓字。因为住宅旁边有五棵柳树，就把这个作为号了。他安安静静，很少说话，也不羡慕荣华利禄。他喜欢读书，不在一字一句的解释上过分深究；每当对书中的内容有所领会的时候，就会高兴得连饭也忘了吃。他生性喜爱喝酒，家里穷经常没有酒喝。亲戚朋友知道他这种境况，有时摆了酒席叫他去喝。他去喝酒就喝个尽兴，希望一定喝醉；喝醉了就回家，竟然说走就走。简陋的居室里空空荡荡，遮挡不住严寒和烈日，粗布短衣上打满了补丁，盛饭的篮子和饮水的水瓢里经常是空的，可是他还是安然自得。常常写文章来自娱自乐，也稍微透露出他的志趣。他从不把得失放在心上，从此过完自己的一生。赞语说：黔娄的妻子曾经说过：“不为贫贱而忧愁，不热衷于发财做官。这话大概说的是五柳先生这一类的人吧？一边喝酒一边作诗，因为自己抱定的志向而感到无比的快乐。不知道他是无怀氏时代的人呢？还是葛天氏时代的人呢？\n桃花源记原文晋太元中，武陵人捕鱼为业。缘溪行，忘路之远近。忽逢桃花林，夹岸数百步，中无杂树，芳草鲜美，落英缤纷。渔人甚异之，复前行，欲穷其林。\n林尽水源，便得一山，山有小口，仿佛若有光。便舍船，从口入。初极狭，才通人。复行数十步，豁然开朗。土地平旷，屋舍俨然，有良田、美池、桑竹之属。阡陌交通，鸡犬相闻。其中往来种作，男女衣着，悉如外人。黄发垂髫，并怡然自乐。\n见渔人，乃大惊，问所从来。具答之。便要还家，设酒杀鸡作食。村中闻有此人，咸来问讯。自云先世避秦时乱，率妻子邑人来此绝境，不复出焉，遂与外人间隔。问今是何世，乃不知有汉，无论魏晋。此人一一为具言所闻，皆叹惋。余人各复延至其家，皆出酒食。停数日，辞去。此中人语云：“不足为外人道也。”\n既出，得其船，便扶向路，处处志之。及郡下，诣太守，说如此。太守即遣人随其往，寻向所志，遂迷，不复得路。\n南阳刘子骥，高尚士也，闻之，欣然规往。未果，寻病终，后遂无问津者。\n讲的什么事情东晋太元年间，武陵郡有个人以打渔为生。他顺着溪水行船，忘记了路程的远近。忽然遇到一片桃花林，生长在溪水的两岸，长达几百步，中间没有别的树，花草鲜嫩美丽，落花纷纷的散在地上。渔人对此（眼前的景色）感到十分诧异，继续往前行船，想走到林子的尽头。桃林的尽头就是溪水的发源地，于是便出现一座山，山上有个小洞口，洞里仿佛有点光亮。于是他下了船，从洞口进去了。\n起初洞口很狭窄，仅容一人通过。又走了几十步，突然变得开阔明亮了。（呈现在他眼前的是）一片平坦宽广的土地，一排排整齐的房舍。还有肥沃的田地、美丽的池沼，桑树竹林之类的。田间小路交错相通，鸡鸣狗叫到处可以听到。人们在田野里来来往往耕种劳作，男女的穿戴，跟桃花源以外的世人完全一样。老人和小孩们个个都安适愉快，自得其乐。村里的人看到渔人，感到非常惊讶，问他是从哪儿来的。渔人详细地做了回答。村里有人就邀请他到自己家里去（做客），设酒杀鸡做饭来款待他。村里的人听说来了这么一个人，就都来打听消息。他们自己说他们的祖先为了躲避秦时的战乱，领着妻子儿女和乡邻来到这个与人世隔绝的地方，不再出去，因而跟外面的人断绝了来往。他们问渔人现在是什么朝代，他们竟然不知道有过汉朝，更不必说魏晋两朝了。渔人把自己知道的事一一详尽地告诉了他们，听完以后，他们都感叹惋惜。其余的人各自又把渔人请到自己家中，都拿出酒饭来款待他。\n渔人停留了几天，向村里人告辞离开。村里的人对他说：“我们这个地方不值得对外面的人说啊。”\n渔人出来以后，找到了他的船，就顺着旧路回去，处处都做了标记。到了郡城，到太守那里去说，报告了这番经历。太守立即派人跟着他去，寻找以前所做的标记，结果迷失了方向，再也找不到通往桃花源的路了。\n南阳人刘子骥，是个志向高洁的隐士，听到这件事后，高兴地计划前往。但没有实现，不久因病去世了。此后就再也没有问桃花源路的人了。\n","categories":["哲学思考"],"tags":["感情","田园","颓废","内耗"]},{"title":"禅宗历史和经典偈语","url":"/2018_07_10_buddhism/","content":"禅宗的起源禅宗是佛教的一个重要宗派，起源于中国。禅宗的核心思想是通过禅修实现觉醒，这种禅修通常包括坐禅、行禅、打坐等方式。禅宗强调直接体验，而不是通过文字或逻辑推理来理解佛法。\n禅宗的历史禅宗的历史可以追溯到公元前6世纪的印度。当时，佛陀创立了佛教，其中包括了禅修的方法。禅修是指通过冥想和内省来实现觉醒和解脱的修行方法。佛陀的禅修方法在中国得到了广泛传播，形成了禅宗。\n禅宗最初在中国南北朝时期（420-581年）得到了发展。在这个时期，禅宗的代表人物是南宗祖师慧思和北宗祖师神秀。他们都致力于将禅宗的思想和修行方法传播到更广泛的人群中。\n在唐朝（618-907年）时期，禅宗得到了更广泛的发展。禅宗的代表人物有慧能、法眼、道信、神秀等。他们的教诲和著作对禅宗的发展产生了深远的影响。慧能是禅宗中最为著名的人物之一，他的《坛经》和《入门四论》等著作被誉为禅宗经典之一。\n在五代十国时期（907-979年），禅宗进一步得到了发展。五代时期的禅宗代表人物有临济宗祖六祖惠能、曹洞宗祖道元等。临济宗和曹洞宗是禅宗的两个主要流派，它们都对后来的禅宗发展产生了深远的影响。\n在宋朝（960-1279年）时期，禅宗得到了更广泛的发展。在这个时期，禅宗的代表人物如智顗、大愚、道原等都取得了很大的成就。智顗是禅宗中最为杰出的人物之一，他的《华严经》和《法华经》等著作被誉为佛教经典之一。\n禅宗在中国的发展经历了多个阶段。每个阶段都有不同的代表人物和特点。这些人物和特点对禅宗的发展产生了深远的影响，成为禅宗文化的重要组成部分。\n禅宗的经典禅宗的经典文献禅宗的经典文献主要包括以下几部分：\n\n《楞严经》《楞严经》是禅宗最重要的经典之一，它强调了空性和缘起的理论，提出了“一切法无我”的观念，是禅宗中重要的参禅经典。\n《心经》《心经》是禅宗中最短、最精要的经典之一，它强调了空性和缘起的理论，提出了“般若波罗蜜多心经”的观念，是禅宗中重要的参禅经典。\n《华严经》《华严经》是禅宗中最为广泛流传的经典之一，它强调了诸法的互相依存和缘起的理论，提出了“一切法皆如梦幻泡影”的观念，是禅宗中重要的参禅经典。\n《法华经》《法华经》是禅宗中最为广泛流传的经典之一，它强调了佛性和菩萨道的理论，提出了“一切众生皆有佛性”的观念，是禅宗中重要的参禅经典。\n《坛经》《坛经》是禅宗中的经典之一，它强调了禅宗的实践方法和境界，提出了“见性成佛”的观念，是禅宗中重要的参禅经典。\n《金刚经》全称《金刚般若波罗蜜经》，一卷，印度大乘佛教般若系经典，后秦鸠摩罗什译。\n\n禅宗的经典文献涵盖了空性、缘起、佛性、菩萨道、禅修方法和境界等方面的内容，是禅宗行者进行参禅修行和领悟佛法的重要依据。\n禅宗顿悟，不立文字，教外别传，直指人心，见性成佛，禅宗有三部必看经文，第一部《金刚经》，第二部《坛经》，第三部《心经》。看了这三部经文之后，就会产生个人的观点与理解。这些都只是个人的主观看法，不是悟。\n禅宗的经典偈语禅宗的经典偈语是禅修者在修行中常用的语句，它们简短而富有哲理和启示性，可以帮助行者深入领悟佛法的精髓。\n下面是一些常见的禅宗经典偈语：\n\n身心是道场，念念不二。——出自《坛经》，强调禅修的重点在于身心的净化，要把身心当作道场，不断净化自己的念头。\n不立文字，教外别传。——出自《南宗顿教正脉纲要》，意味着禅宗强调的是直接体验，而非依靠文字传授。\n不思议境界，无所得而成佛。——出自《华严经》，表明了禅修的目的在于超越思维，放下执着，才能成佛。\n一花一世界，一叶一菩提。——出自《金刚经》，表明了万物皆有佛性，只要发掘自己内在的潜力，就能成佛。\n直指人心，见性成佛。——出自《法华经》，强调了禅修的核心在于直接指向人心，通过觉悟而成佛。\n不立文字，教外别传，直指人心，见性成佛。——出自《南宗顿教正脉纲要》，是禅宗的三句箴言，强调了禅修的重点和目的。\n万法归一，一念清净。——出自《楞严经》，表明了禅修的目的在于归一万法，通过一念清净而达到解脱。\n身心清净，自然成佛。——出自《法华经》，意味着禅修的目的在于净化身心，达到自然成佛的境界。\n三世诸佛，皆在此中。——出自《华严经》，表明了禅修的重点在于当下，只有当下的觉悟才能成就佛道。\n一念不生，万法无生。——出自《华严经》，表明了禅修的目的在于超越生死轮回，达到无生的境界。\n大道无门，千般万般皆是道。——出自《信心骨髓》，意味着禅修的道路是没有门槛的，只要心存正念，万事万物都是道。\n佛法本无文字，因心而立言语。——出自《华严经》，表明了禅宗强调的是直接体验，禅修的经验需要通过语言表达出来。\n禅宗不立文字，直指人心。——出自《南宗顿教正脉纲要》，表明了禅宗强调的是直接体验，禅修的经验需要通过直接指向人心来实现。\n无心即是道，无物即是禅。——出自《法华经》，表明了禅修的目的在于超越心物二元对立，达到无心无物的境界。\n一念贪嗔痴，万劫不复生。——出自《华严经》，表明了禅修的目的在于放下执着，达到无念无执的境界。\n一切法门，皆由心起。——出自《法华经》，强调了心的作用，禅修的关键在于觉察自己的心念。\n一念之差，天堂地狱。——出自《楞严经》，表明了禅修的重要性，一个念头的转变可以影响一个人的命运。\n禅宗无门，法外传灯。——出自《南宗顿教正脉纲要》，强调了禅修的无门无派，只要有心，就能得到法眼传承。\n心外无法，法外无心。——出自《坛经》，意味着禅修的目的在于超越心法二元对立，达到心法合一的境界。\n有法即失，无法可持。——出自《法华经》，表明了禅修的目的在于超越对法的执着，达到无法可持的境界。\n一切法皆空，无自性可得。——出自《般若波罗蜜多心经》，表明了禅修的目的在于超越对法的执着，达到法空自性的境界。\n一念清净，万法清净。——出自《华严经》，表明了禅修的目的在于通过清净自己的心念，达到清净万法的境界。\n心如止水，万象皆明。——出自《华严经》，表明了禅修的目的在于平静自己的心念，达到洞悉万象的境界。\n禅宗无上法门，直指人心。——出自《南宗顿教正脉纲要》，强调了禅修的重点在于直接指向人心，达到无上法门的境界。\n一念善恶，天人两界。——出自《华严经》，表明了禅修的重要性，一个念头的转变可以影响到自己的生死轮回。\n一念不生，万法无边。——出自《华严经》，表明了禅修的目的在于超越生死轮回，达到无边无界的境界。\n\n禅宗的流派禅宗是中国佛教的一个流派，发展出了五个主要的派别。以下是每个派别的简要介绍：\n\n潮州宗：又称南宗，起源于唐代。该派别注重禅修的实践，强调“顿悟”（即一瞬间的证悟），并提倡“无相禅”（即不依赖任何具体的对象进行禅修）。代表人物有南泉普贤、临济義玄等。\n唐宗：又称北宗，起源于唐代。该派别注重禅修的实践，强调“渐悟”（即逐步的证悟），并提倡“有相禅”（即通过禅修对象来证悟真理）。代表人物有神秀、华严智海等。\n法眼宗：起源于宋代。该派别注重禅修的实践，强调“顿悟”，并提倡“无门禅”（即不依赖任何门派或传承进行禅修）。代表人物有法眼、道信等。\n洛阳宗：起源于唐代。该派别注重禅修的实践，强调“渐悟”，并提倡“律严禅”（即通过对具体律法的遵守来进行禅修）。代表人物有珂罗版行者、道宣等。\n临济宗：起源于宋代。该派别注重禅修的实践，强调“顿悟”，并提倡“公案禅”（即通过对禅宗公案的研究来进行禅修）。代表人物有临济義玄、黄龙师隐等。\n\n《金刚经》的偈语\n诸法无我，如梦幻泡影。这句话体现了金刚经中的空性思想，即所有事物都是虚幻的，不存在固定的实体。\n一切有为法，如梦幻泡影，如露亦如电，应作如是观。这句话也是在强调一切法皆无常、无我、无相。\n色不异空，空不异色。色即是空，空即是色。这句话表明了色与空是相互依存的，没有色就没有空，没有空也就没有色。\n无我法界，生死相续。这句话意味着，只有放下自我，才能摆脱生死轮回的束缚。\n一切众生，皆有如来智慧。这句话表明了佛性存在于所有众生之中，只要发掘自己内在的潜力，就能成佛。\n一切法门，悉皆不二。这句话意味着，所有的修行方法都是相通的，只要找到适合自己的方法，就能达到成佛的目的。\n菩提本无树，明镜亦非台，本来无一物，何处惹尘埃。这句话表明了菩提本无所在，只有放下执念，才能觉悟。\n舍利子，色不异空，空不异色，色即是空，空即是色。这句话重复了第三条中的观点，强调了色与空的相互依存。\n舍利子，一切法无我，我亦无所得，得法者多劫修。这句话表明了修行的过程中，要放下执念，不执着于任何事物，才能获得真正的解脱。\n舍利子，若以色见我，以我见色，不见如来。这句话意味着，只有超越了对物质的执着，才能真正看到佛性的存在。\n\n","categories":["哲学思考"],"tags":["禅宗","偈语","金刚经","佛教"]},{"title":"儒释道思想和分与合","url":"/2021_06_20_3religion/","content":"人心无限，事物有限，以有限求无限不可得，矛盾出现了，怎么解决？\n儒、道、佛都给了方法。\n儒家：无所为而为何谓无所为？\n我们先看什么是有所为\n有所为而为：抱着目的去做事，说的现代点就是功利主义\n无所为即：本该做的，因该做的，读书不是为了功名，而是增长知识与涵养，尽孝不是为了名声，而是报答养育之恩，等等诸如此类\n还有一种无所为，是明知不可为而为，本该做的，但是做了利益有损。\n有所为和无所为在有利于我们的方面可以统一，那么在明知不可为的情况下就对立了，功利主义就妥协退缩了。做了我们本该做的事，却有损了我们的利益，错了吗？没有错。儒家讲的是仁者无敌。\n道家：无为而无不为无为：不做我们不该做的事，什么是我们不该做的事呢？这个不可言说，从自身实际出发，可小可大、可虚可实。\n无不为：去掉无为的就是无不为\n佛家：无心而为佛家讲众生平等，因果轮回。佛家是无神论，佛是觉醒的众生，众生是未觉醒的佛\n心，因无所住而生其心，人人皆有佛性，见性成佛 ，即心即佛。\n为：用为来消业，最高追求，摆脱轮回，是为涅槃\n无心而为，通俗来讲但行好事、莫问前程，这里的好事即心，即佛，\n三家汇合佛道儒三家，各自给了解决问题的方法，无所为而为、无为而无不为、无心而为，我们不难发现，三者都有为\n为便是做事的意思\n儒家让我们做该做的事，道家让我们除去不该做的事都要做，佛家让我们不抱有目的的做本该做的事。\n是不是有些惊愕，原本我以为儒家代表腐朽、道家代表消极、佛家就是迷信，原来小丑就是我自己。\n上面巴拉巴拉说了一大堆，如何应用自身呢？\n安心立命此心为何心？\n王阳明讲，心即理，自性具足，理，生命情感的真相，良知存于心，良知即天理，和孟子的人本性善、万物皆备于我一脉相承。\n那佛家的贪、痴、嗔是不是出于此心呢？\n王阳明讲的良知，佛家说的贪、痴、嗔皆来于心，\n如何安此心？儒家说是修心，佛家称为修行，现在我们讲：树立良好的道德观、价值观。\n焦虑、急躁，惶惶不可终日。此为心不安。\n心有所求而不得，心有所虑而不安，空空如也。\n此命为何命？佛家说因果轮回，此生是前世的果，要想来世有福报，今世就用无心而为来消前世的业，修来世的因。\n佛家讲无心而为，冥冥之中，自有天命。\n如果我们认同佛的因果轮回，那么嫉妒之心可消散全无，但是大家信命吗？\n你要说我信命，既然命运安排好了，该来的总会来，我坐吃等死就行了，此为大缪。\n佛家讲的命是和为是分不开的，为是因，命是果。因在前，果在后。\n你要说我不信命，人定胜天，想什么、干什么、就要得什么。这和佛家的因果关系有相似之处，不同的是佛家为是因，命是果，到了你这，想是因，为是果，随心所欲，但往往痴人说梦哉！\n信命也好，不信命也罢，通俗来讲大家都是想有个好的归宿，不同的是有人为己求归宿，有人为天下求归宿。\n如何达此命？\n孔子讲：仁，仁者无敌\n孟子讲：心，万物皆备于我，反身而诚，乐莫大焉\n朱熹讲：格物致知\n王阳明讲：知行合一\n教员说：从实践中来到实践中去\n安心立命:养成正确的道德观、价值观，在此基础上树立自己的理想抱负，运用适合自己的方法，去完成自己的抱负。\n与君共勉之。\n","categories":["哲学思考"],"tags":["佛教","道家","儒家"]},{"title":"读《深入理解Java虚拟机3》","url":"/2021_06_21_read_jvm/","content":"必须拜读的java圣书。\n\n\n\n第一部分　走近Java第1章　走近Java 21.1　概述 21.2　Java技术体系 31.3　Java发展史 41.4　Java虚拟机家族 121.4.1　虚拟机始祖：Sun Classic&#x2F;Exact VM 121.4.2　武林盟主：HotSpot VM 131.4.3　小家碧玉：Mobile&#x2F;Embedded VM 141.4.4　天下第二：BEA JRockit&#x2F;IBM J9 VM 151.4.5　软硬合璧：BEA Liquid VM&#x2F;Azul VM 161.4.6　挑战者：Apache Harmony&#x2F;Google Android Dalvik VM 171.4.7　没有成功，但并非失败：Microsoft JVM及其他 181.4.8　百家争鸣 191.5　展望Java技术的未来 211.5.1　无语言倾向 211.5.2　新一代即时编译器 231.5.3　向Native迈进 241.5.4　灵活的胖子 261.5.5　语言语法持续增强 271.6　实战：自己编译JDK 291.6.1　获取源码 291.6.2　系统需求 311.6.3　构建编译环境 331.6.4　进行编译 341.6.5　在IDE工具中进行源码调试 361.7　本章小结 39第二部分　自动内存管理第2章　Java内存区域与内存溢出异常 422.1　概述 422.2　运行时数据区域 422.2.1　程序计数器 432.2.2　Java虚拟机栈 432.2.3　本地方法栈 442.2.4　Java堆 442.2.5　方法区 462.2.6　运行时常量池 472.2.7　直接内存 472.3　HotSpot虚拟机对象探秘 482.3.1　对象的创建 482.3.2　对象的内存布局 512.3.3　对象的访问定位 522.4　实战：OutOfMemoryError异常 532.4.1　Java堆溢出 542.4.2　虚拟机栈和本地方法栈溢出 562.4.3　方法区和运行时常量池溢出 612.4.4　本机直接内存溢出 652.5　本章小结 66第3章　垃圾收集器与内存分配策略 673.1　概述 673.2　对象已死？ 683.2.1　引用计数算法 683.2.2　可达性分析算法 703.2.3　再谈引用 713.2.4　生存还是死亡？ 723.2.5　回收方法区 743.3　垃圾收集算法 753.3.1　分代收集理论 753.3.2　标记-清除算法 773.3.3　标记-复制算法 783.3.4　标记-整理算法 793.4　HotSpot的算法细节实现 813.4.1　根节点枚举 813.4.2　安全点 823.4.3　安全区域 833.4.4　记忆集与卡表 843.4.5　写屏障 853.4.6　并发的可达性分析 873.5　经典垃圾收集器 893.5.1　Serial收集器 903.5.2　ParNew收集器 923.5.3　Parallel Scavenge收集器 933.5.4　Serial Old收集器 943.5.5　Parallel Old收集器 953.5.6　CMS收集器 963.5.7　Garbage First收集器 983.6　低延迟垃圾收集器 1043.6.1　Shenandoah收集器 1053.6.2　ZGC收集器 1123.7　选择合适的垃圾收集器 1213.7.1　Epsilon收集器 1213.7.2　收集器的权衡 1213.7.3　虚拟机及垃圾收集器日志 1223.7.4　垃圾收集器参数总结 1273.8　实战：内存分配与回收策略 1293.8.1　对象优先在Eden分配 1303.8.2　大对象直接进入老年代 1313.8.3　长期存活的对象将进入老年代 1323.8.4　动态对象年龄判定 1343.8.5　空间分配担保 1353.9　本章小结 137第4章　虚拟机性能监控、故障处理工具 1384.1　概述 1384.2　基础故障处理工具 1384.2.1　jps：虚拟机进程状况工具 1414.2.2　jstat：虚拟机统计信息监视工具 1424.2.3　jinfo：Java配置信息工具 1434.2.4　jmap：Java内存映像工具 1444.2.5　jhat：虚拟机堆转储快照分析工具 1454.2.6　jstack：Java堆栈跟踪工具 1464.2.7　基础工具总结 1484.3　可视化故障处理工具 1514.3.1　JHSDB：基于服务性代理的调试工具 1524.3.2　JConsole：Java监视与管理控制台 1574.3.3　VisualVM：多合-故障处理工具 1644.3.4　Java Mission Control：可持续在线的监控工具 1714.4　HotSpot虚拟机插件及工具 1754.5　本章小结 180第5章　调优案例分析与实战 1815.1　概述 1815.2　案例分析 1815.2.1　大内存硬件上的程序部署策略 1825.2.2　集群间同步导致的内存溢出 1845.2.3　堆外内存导致的溢出错误 1855.2.4　外部命令导致系统缓慢 1875.2.5　服务器虚拟机进程崩溃 1875.2.6　不恰当数据结构导致内存占用过大 1885.2.7　由Windows虚拟内存导致的长时间停顿 1895.2.8　由安全点导致长时间停顿 1905.3　实战：Eclipse运行速度调优 1925.3.1　调优前的程序运行状态 1935.3.2　升级JDK版本的性能变化及兼容问题 1965.3.3　编译时间和类加载时间的优化 2005.3.4　调整内存设置控制垃圾收集频率 2035.3.5　选择收集器降低延迟 2065.4　本章小结 209第三部分　虚拟机执行子系统第6章　类文件结构 2126.1　概述 2126.2　无关性的基石 2126.3　Class类文件的结构 2146.3.1　魔数与Class文件的版本 2156.3.2　常量池 2186.3.3　访问标志 2246.3.4　类索引、父类索引与接口索引集合 2256.3.5　字段表集合 2266.3.6　方法表集合 2296.3.7　属性表集合 2306.4　字节码指令简介 2516.4.1　字节码与数据类型 2516.4.2　加载和存储指令 2536.4.3　运算指令 2546.4.4　类型转换指令 2556.4.5　对象创建与访问指令 2566.4.6　操作数栈管理指令 2566.4.7　控制转移指令 2576.4.8　方法调用和返回指令 2576.4.9　异常处理指令 2586.4.10　同步指令 2586.5　公有设计，私有实现 2596.6　Class文件结构的发展 2606.7　本章小结 261第7章　虚拟机类加载机制 2627.1　概述 2627.2　类加载的时机 2637.3　类加载的过程 2677.3.1　加载 2677.3.2　验证 2687.3.3　准备 2717.3.4　解析 2727.3.5　初始化 2777.4　类加载器 2797.4.1　类与类加载器 2807.4.2　双亲委派模型 2817.4.3　破坏双亲委派模型 2857.5　Java模块化系统 2877.5.1　模块的兼容性 2887.5.2　模块化下的类加载器 2907.6　本章小结 292第8章　虚拟机字节码执行引擎 2938.1　概述 2938.2　运行时栈帧结构 2948.2.1　局部变量表 2948.2.2　操作数栈 2998.2.3　动态连接 3008.2.4　方法返回地址 3008.2.5　附加信息 3018.3　方法调用 3018.3.1　解析 3018.3.2　分派 3038.4　动态类型语言支持 3158.4.1　动态类型语言 3168.4.2　Java与动态类型 3178.4.3　java.lang.invoke包 3188.4.4　invokedynamic指令 3218.4.5　实战：掌控方法分派规则 3248.5　基于栈的字节码解释执行引擎 3268.5.1　解释执行 3278.5.2　基于栈的指令集与基于寄存器的指令集 3288.5.3　基于栈的解释器执行过程 3298.6　本章小结 334第9章　类加载及执行子系统的案例与实战 3359.1　概述 3359.2　案例分析 3359.2.1　Tomcat：正统的类加载器架构 3359.2.2　OSGi：灵活的类加载器架构 3389.2.3　字节码生成技术与动态代理的实现 3419.2.4　Backport工具：Java的时光机器 3459.3　实战：自己动手实现远程执行功能 3489.3.1　目标 3489.3.2　思路 3499.3.3　实现 3509.3.4　验证 3559.4　本章小结 356第四部分　程序编译与代码优化第10章　前端编译与优化 35810.1　概述 35810.2　Javac编译器 35910.2.1　Javac的源码与调试 35910.2.2　解析与填充符号表 36210.2.3　注解处理器 36310.2.4　语义分析与字节码生成 36410.3　Java语法糖的味道 36710.3.1　泛型 36710.3.2　自动装箱、拆箱与遍历循环 37510.3.3　条件编译 37710.4　实战：插入式注解处理器 37810.4.1　实战目标 37910.4.2　代码实现 37910.4.3　运行与测试 38510.4.4　其他应用案例 38610.5　本章小结 386第11章　后端编译与优化 38811.1　概述 38811.2　即时编译器 38911.2.1　解释器与编译器 38911.2.2　编译对象与触发条件 39211.2.3　编译过程 39711.2.4　实战：查看及分析即时编译结果 39811.3　提前编译器 40411.3.1　提前编译的优劣得失 40511.3.2　实战：Jaotc的提前编译 40811.4　编译器优化技术 41111.4.1　优化技术概览 41111.4.2　方法内联 41511.4.3　逃逸分析 41711.4.4　公共子表达式消除 42011.4.5　数组边界检查消除 42111.5　实战：深入理解Graal编译器 42311.5.1　历史背景 42311.5.2　构建编译调试环境 42411.5.3　JVMCI编译器接口 42611.5.4　代码中间表示 42911.5.5　代码优化与生成 43211.6　本章小结 436第五部分　高效并发第12章　Java内存模型与线程 43812.1　概述 43812.2　硬件的效率与一致性 43912.3　Java内存模型 44012.3.1　主内存与工作内存 44112.3.2　内存间交互操作 44212.3.3　对于volatile型变量的特殊规则 44412.3.4　针对long和double型变量的特殊规则 45012.3.5　原子性、可见性与有序性 45012.3.6　先行发生原则 45212.4　Java与线程 45512.4.1　线程的实现 45512.4.2　Java线程调度 45812.4.3　状态转换 46012.5　Java与协程 46112.5.1　内核线程的局限 46112.5.2　协程的复苏 46212.5.3　Java的解决方案 46412.6　本章小结 465第13章　线程安全与锁优化 46613.1　概述 46613.2　线程安全 46613.2.1　Java语言中的线程安全 46713.2.2　线程安全的实现方法 47113.3　锁优化 47913.3.1　自旋锁与自适应自旋 47913.3.2　锁消除 48013.3.3　锁粗化 48113.3.4　轻量级锁 48113.3.5　偏向锁 48313.4　本章小结 485\n","categories":["读书笔记"],"tags":["Java","JVM"]},{"title":"读《Go语言实战》","url":"/2021_05_23_read_goinaction/","content":"Go语言是谷歌2007年开发的语言，开源社区活跃，比较流行的Docker等项目都是使用go语言开发的。Go语言凭借出色的多核多线程高性能模型大大收到后端开发者的喜爱，goroutines和channel的go语言的出色特性之一，除此之外Go语言还包含丰富的标准库、丰富的组件。基于对Go编程语言的好奇和喜爱，笔者开始了阅读学习这方面书籍，这本书推荐给大家。\n\n全书分为9个章节，讲了go要解决的问题、语法糖、几个标准库的介绍、单元测试几方面问题，行文思路比较简单，适合初学者阅读。\n\n目录\n\n","categories":["读书笔记"],"tags":["Go"]},{"title":"mybatis-sql拦截器打印SQL执行时间","url":"/2021_08_06_mybatis-sql%E6%8B%A6%E6%88%AA%E5%99%A8%E6%89%93%E5%8D%B0sql%E6%89%A7%E8%A1%8C%E6%97%B6%E9%97%B4/","content":"集成mybatis，打印sql以及执行时间~\n\nmybatis拦截器import lombok.extern.slf4j.Slf4j;import org.apache.ibatis.cache.CacheKey;import org.apache.ibatis.executor.Executor;import org.apache.ibatis.mapping.BoundSql;import org.apache.ibatis.mapping.MappedStatement;import org.apache.ibatis.mapping.ParameterMapping;import org.apache.ibatis.plugin.*;import org.apache.ibatis.reflection.MetaObject;import org.apache.ibatis.session.Configuration;import org.apache.ibatis.session.ResultHandler;import org.apache.ibatis.session.RowBounds;import org.apache.ibatis.type.TypeHandlerRegistry;import org.springframework.util.CollectionUtils;import java.text.DateFormat;import java.util.Date;import java.util.List;import java.util.Locale;import java.util.Properties;import java.util.regex.Matcher;/** * @Author * @Date 2020/7/29 14:19 * @Version 版本号 * @Description mybatis执行sql耗时 */@Slf4j@Intercepts(&#123;@Signature(        type = Executor.class,        method = &quot;update&quot;,        args = &#123;MappedStatement.class, Object.class&#125;), @Signature(        type = Executor.class,        method = &quot;query&quot;,        args = &#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class&#125;), @Signature(        type = Executor.class,        method = &quot;query&quot;,        args = &#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class, CacheKey.class, BoundSql.class&#125;)&#125;)public class SqlStatementInterceptor implements Interceptor &#123;    @Override    public Object intercept(Invocation invocation) throws Throwable &#123;        long startTime = System.currentTimeMillis();        try &#123;            return invocation.proceed();        &#125; finally &#123;            long timeConsuming = System.currentTimeMillis() - startTime;            int level;            if (timeConsuming &lt; 100) &#123;                level = 0;            &#125; else if (timeConsuming &lt; 200) &#123;                level = 1;            &#125; else if (timeConsuming &lt; 300) &#123;                level = 2;            &#125; else if (timeConsuming &lt; 400) &#123;                level = 3;            &#125; else if (timeConsuming &lt; 500) &#123;                level = 4;            &#125; else &#123;                level = 5;            &#125;            Object[] args = invocation.getArgs();            MappedStatement ms = (MappedStatement) args[0];            Object parameter = null;            //获取参数，if语句成立，表示sql语句有参数，参数格式是map形式            if (invocation.getArgs().length &gt; 1) &#123;                parameter = invocation.getArgs()[1];            &#125;            String sqlId = ms.getId();// 获取到节点的id,即sql语句的id            BoundSql boundSql = ms.getBoundSql(parameter);  // BoundSql就是封装myBatis最终产生的sql类            Configuration configuration = ms.getConfiguration();  // 获取节点的配置            String sql = showSql(configuration, boundSql); // 获取到最终的sql语句            log.info(&quot;【执行SQL】: &#123;&#125;level &#123;&#125;ms &#123;&#125;&quot;, level, timeConsuming, sql);        &#125;    &#125;    @Override    public Object plugin(Object target) &#123;        return Plugin.wrap(target, this);    &#125;    @Override    public void setProperties(Properties properties) &#123;    &#125;    private String showSql(Configuration configuration, BoundSql boundSql) &#123;        // 获取参数        Object parameterObject = boundSql.getParameterObject();        List&lt;ParameterMapping&gt; parameterMappings = boundSql                .getParameterMappings();        // sql语句中多个空格都用一个空格代替        String sql = boundSql.getSql().replaceAll(&quot;[\\\\s]+&quot;, &quot; &quot;);        if (!CollectionUtils.isEmpty(parameterMappings) &amp;&amp; parameterObject != null) &#123;            // 获取类型处理器注册器，类型处理器的功能是进行java类型和数据库类型的转换　　　　　// 如果根据parameterObject.getClass(）可以找到对应的类型，则替换            TypeHandlerRegistry typeHandlerRegistry = configuration.getTypeHandlerRegistry();            if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123;                sql = sql.replaceFirst(&quot;\\\\?&quot;, Matcher.quoteReplacement(getParameterValue(parameterObject)));            &#125; else &#123;                MetaObject metaObject = configuration.newMetaObject(parameterObject);                // MetaObject主要是封装了originalObject对象，提供了get和set的方法用于获取和设置originalObject的属性值,                // 主要支持对JavaBean、Collection、Map三种类型对象的操作                for (ParameterMapping parameterMapping : parameterMappings) &#123;                    String propertyName = parameterMapping.getProperty();                    if (metaObject.hasGetter(propertyName)) &#123;                        Object obj = metaObject.getValue(propertyName);                        sql = sql.replaceFirst(&quot;\\\\?&quot;, Matcher.quoteReplacement(getParameterValue(obj)));                    &#125; else if (boundSql.hasAdditionalParameter(propertyName)) &#123;                        Object obj = boundSql.getAdditionalParameter(propertyName);  // 该分支是动态sql                        sql = sql.replaceFirst(&quot;\\\\?&quot;, Matcher.quoteReplacement(getParameterValue(obj)));                    &#125; else &#123;                        sql = sql.replaceFirst(&quot;\\\\?&quot;, &quot;缺失&quot;);                    &#125;//打印出缺失，提醒该参数缺失并防止错位                &#125;            &#125;        &#125;        return sql;    &#125;    /**     * 如果参数是String，则添加单引号， 如果是日期，则转换为时间格式器并加单引号；     * 对参数是null和不是null的情况作了处理     */    private static String getParameterValue(Object obj) &#123;        String value = null;        if (obj instanceof String) &#123;            value = &quot;&#x27;&quot; + obj.toString() + &quot;&#x27;&quot;;        &#125; else if (obj instanceof Date) &#123;            Date date = (Date) obj;            DateFormat formatter = DateFormat.getDateTimeInstance(DateFormat.DEFAULT, DateFormat.DEFAULT, Locale.CHINA);            value = &quot;&#x27;&quot; + formatter.format(date) + &quot;&#x27;&quot;;        &#125; else &#123;            if (obj != null) &#123;                value = obj.toString();            &#125; else &#123;                value = &quot;&quot;;            &#125;        &#125;        return value;    &#125;&#125;\n配置文件import com.alibaba.druid.spring.boot.autoconfigure.DruidDataSourceBuilder;import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor;import com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean;import org.apache.ibatis.plugin.Interceptor;import org.apache.ibatis.session.SqlSessionFactory;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.io.support.PathMatchingResourcePatternResolver;import javax.sql.DataSource;@Configuration@MapperScan(basePackages = &quot;com.xx.staytime.mapper&quot;,sqlSessionFactoryRef = &quot;xxDatasourceSessionFactory&quot;)public class SxFactoryDatasourceConfig &#123;    @Bean(name = &quot;xxDataSource&quot;)    @ConfigurationProperties(prefix = &quot;xx.datasource&quot;)    public DataSource dataSource()&#123;        return DruidDataSourceBuilder.create().build();    &#125;    @Bean(name = &quot;xxDatasourceSessionFactory&quot;)    public SqlSessionFactory sqlSessionFactory(MybatisPlusInterceptor mybatisPlusInterceptor,SqlStatementInterceptor sqlStatementInterceptor) throws Exception &#123;        MybatisSqlSessionFactoryBean sessionFactoryBean = new MybatisSqlSessionFactoryBean();        sessionFactoryBean.setDataSource(dataSource());        sessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(&quot;classpath:mapper/*.xml&quot;));        Interceptor[] plugins = &#123;mybatisPlusInterceptor,sqlStatementInterceptor&#125;;        sessionFactoryBean.setPlugins(plugins);        return sessionFactoryBean.getObject();    &#125;&#125;\n\neg.16:40:00.119 app [scheduling-1] INFO  com.x.conf.SqlStatementInterceptor - 【执行SQL】: 0level 2ms SELECT id,cross_record_syscode,entrance_name,vehicle_out,release_mode,cross_time,plate_no,responsible_user_name,responsible_user_tel,order_type,scr_id,wv_id,delete_status,updater FROM trucks_cross_records WHERE (cross_record_syscode = &#x27;5879c4b1746343daa49bceeaec583de2_5c8df9aeea91c_17d&#x27;) 16:40:00.121 app [scheduling-1] INFO  com.x.conf.SqlStatementInterceptor - 【执行SQL】: 0level 2ms SELECT id,cross_record_syscode,entrance_name,vehicle_out,release_mode,cross_time,plate_no,responsible_user_name,responsible_user_tel,order_type,scr_id,wv_id,delete_status,updater FROM trucks_cross_records WHERE (cross_record_syscode = &#x27;5879c4b1746343daa49bceeaec583de2_5c8df9aeea91c_17d&#x27;) 16:40:00.124 app [scheduling-1] INFO  com.x.conf.SqlStatementInterceptor - 【执行SQL】: 0level 1ms SELECT id,cross_record_syscode,entrance_name,vehicle_out,release_mode,cross_time,plate_no,responsible_user_name,responsible_user_tel,order_type,scr_id,wv_id,delete_status,updater FROM trucks_cross_records WHERE (cross_record_syscode = &#x27;5879c4b1746343daa49bceeaec583de2_5c8df9aeea91c_17d&#x27;) 16:40:00.126 app [scheduling-1] INFO  com.x.conf.SqlStatementInterceptor - 【执行SQL】: 0level 2ms SELECT id,cross_record_syscode,entrance_name,vehicle_out,release_mode,cross_time,plate_no,responsible_user_name,responsible_user_tel,order_type,scr_id,wv_id,delete_status,updater FROM trucks_cross_records WHERE (cross_record_syscode = &#x27;5879c4b1746343daa49bceeaec583de2_5c8df9aeea91c_17d&#x27;) 16:40:00.128 app [scheduling-1] INFO  com.x.conf.SqlStatementInterceptor - 【执行SQL】: 0level 2ms SELECT id,cross_record_syscode,entrance_name,vehicle_out,release_mode,cross_time,plate_no,responsible_user_name,responsible_user_tel,order_type,scr_id,wv_id,delete_status,updater FROM trucks_cross_records WHERE (cross_record_syscode = &#x27;5879c4b1746343daa49bceeaec583de2_5c8df9aeea91c_17d&#x27;)","categories":["应用笔记"],"tags":["Java"]},{"title":"操作系统与计算机网络总结","url":"/2021_10_16_os_net/","content":"操作系统知识点\n\n进程与线程上图进程与线程部分是一个非常重要的考察点。\n\n首先需要掌握进程与线程的区别和联系：\n\n进程是系统资源分配的最小单位，线程是程序执行的最小单位；\n进程使用独立的数据空间，而线程共享进程的数据空间。\n\n\n线程调度，简单了解线程的几种调度算法就可以了。比如时间片轮转调度、先来先服务调度、优先级调度、多级反馈队列调度以及高响应比优先调度。\n\n线程切换的步骤，主要是了解线程的上下文切换，明白线程切换的代价。关于线程的知识在后面的多线程课程中还会有详细讲解，这里先略过。\n\n在进程与线程部分还有一个比较常见的考察点，就是进程间通信，也就是IPC。这部分在面试中间件研发的相关职位时经常会考察。如上面知识点汇总图中所示，需要了解这6种进程通信方式的原理与适用场景。例如，进程间数据共享的场景可以使用共享内存；进程间数据交换的场景可以使用UnixSocket或者消息队列。\n\n最后协程部分，简单了解协程更轻量化，是在用户态进行调度，切换的代价比线程上下文切换要低很多就可以了，也可以了解Java的第三方协程框架，例如Kilim、Quasar等。\n\n\nLinux 常用命令大部分互联网公司的服务都是在Linux系统上运行的，因此Linux命令也是面试时的常考点，这部分其实主要考察的是候选人是否有线上问题的排查经验，重点学习AWK、top、netstat、grep等高频使用的工具\n还有一些知识点不常考，做适当了解，例如内存分页管理与Swap机制、任务队列与CPULoad等，这些知识在分析线上问题中十分有用。\n扩展知识最后是扩展知识点，例如内存屏障、指令乱序、分支预测、NUMA与CPU亲和性等，如果在面试时有机会谈到的话，会在知识深度上给面试官留下比较好的印象\n计算机网络知识点计算机网络也是非常重要的基础知识，服务之间通过不同的网络协议进行交互，例如HTTP协议、RPC协议等，在Java面试中网络知识被考到的几率非常大。网络知识点汇总如下图。\n\n\n首先你应该深刻理解网络的4&#x2F;7层模型，这是网络知识的基础。\n另外两个非常重要的网络协议就是HTTP和TCP了，这两个协议也是服务交互中使用最多的协议。先来看TCP协议，TCP协议中的三次握手建连与四次挥手断连是一个高频考点，后面会详细介绍。\nTCP的报文状态标志与链接状态，在排查网络问题时非常重要，必须要明白协议状态，才方便抓包分析。\n另一个知识点是Nagel算法和ACK延迟，需要了解产生的背景，是要解决小包问题，提高数据载荷比。知道对于延迟比较敏感且发送数据频率较低的场景可以关闭Nagel算法\n关于TCP的Keepalive，是一种长时间没有数据发送的场景下，TCP保持链接可用的机制，需要知道TCPKeepalive的开启和设置方式。\n最后一点，需要明白TCP是如何通过滑动窗口机制来实现流量控制的。\nHTTP协议部分\n需要掌握HTTP协议的规范，知道协议中的Method、Header、Cookies，需要了解常见状态码的含义，例如404、503、302等。\n另外还有HTTPS的交互流程。\n协议的了解可以在一定程度上体现对新技术的关注程度。可以关注：HTTP2多路复用、Stream流式交互、流量控制、服务端推送、头部压缩等新特性。\n\n除了HTTP和TCP外，UDP也是一个比较常见的传输层协议，UDP的特点是非链接、非可靠传输，但是效率非常高。\n最后可以对QUIC协议进行一些了解，QUIC已经被标准化为HTTP3协议。QUIC是基于UDP协议，但QUIC提供了类似TCP的可靠性保证和流量控制。QUIC可以有效避免HTTP2协议的前序包阻塞问题，能实现零RTT建连，提供FEC前向纠错能力。\n详解 TCP 协议特点TCP是传输层协议，对应OSI网络模型的第四层传输层，特点如下。\n\nTCP协议是基于链接的，也就是传输数据前需要先建立好链接，然后再进行传输。\nTCP链接一旦建立，就可以在链接上进行双向的通信\nTCP的传输是基于字节流而不是报文，将数据按字节大小进行编号，接收端通过ACK来确认收到的数据编号，通过这种机制，TCP协议能够保证接收数据的有序性和完整性，因此TCP能够提供可靠性传输。\nTCP还能提供流量控制能力，通过滑动窗口来控制数据的发送速率。滑动窗口的本质是动态缓冲区，接收端根据自己的处理能力，在TCP的Header中动态调整窗口大小，通过ACK应答包通知给发送端，发送端根据窗口大小调整发送的的速度。\n仅仅有了流量控制能力还不够，TCP协议还考虑到了网络问题可能会导致大量重传，进而导致网络情况进一步恶化，因此TCP协议还提供拥塞控制。TCP处理拥塞控制主要用到了慢启动、拥塞避免、拥塞发生、快速恢复四个算法，感兴趣的同学可以进一步了解。\n\n除了TCP协议的特点，还可以进一步了解TCP协议的报文状态、滑动窗口的工作流程、Keepalive的参数设置和Nagel算法的规则等一些细节。\n另外还有典型的TCP协议问题，例如特定场景下Nagel和ACK延迟机制配合使用可能会出现delay40ms超时后才回复ACK包的问题\n详解三次握手建连接下来看TCP建连的三次握手。TCP是基于链接的，所以在传输数据前需要先建立链接，TCP在传输上是双工传输，不区分Client端与Server端，为了便于理解，我们把主动发起建连请求的一端称作Client端，把被动建立链接的一端称作Server端。\n如下图，建连的时序是从上到下，左右两边的绿色字分别代表Client端与Server端当时的链接状态。\n\n\n首先建立链接前需要Server端先监听端口，因此Server端建立链接前的初始状态就是LISTEN状态，这时Client端准备建立链接，先发送一个SYN同步包，发送完同步包后，Client端的链接状态变成了SYN_SENT状态。Server端收到SYN后，同意建立链接，会向Client端回复一个ACK。\n由于TCP是双工传输，Server端也会同时向Client端发送一个SYN，申请Server向Client方向建立链接。发送完ACK和SYN后，Server端的链接状态就变成了SYN_RCVD。\nClient收到Server的ACK后，Client端的链接状态就变成了ESTABLISHED状态，同时，Client向Server端发送ACK，回复Server端的SYN请求\nServer端收到Client端的ACK后，Server端的链接状态也就变成了的ESTABLISHED状态，此时建连完成，双方随时可以进行数据传输。\n需要明白三次握手是为了建立双向的链接，需要记住Client端和Server端的链接状态变化。另外回答建连的问题时，可以提到SYN洪水攻击发生的原因，就是Server端收到Client端的SYN请求后，发送了ACK和SYN，但是Client端不进行回复，导致Server端大量的链接处在SYN_RCVD状态，进而影响其他正常请求的建连。可以设置tcp_synack_retries &#x3D; 0加快半链接的回收速度，或者调大tcp_max_syn_backlog来应对少量的SYN洪水攻击\n详解四次挥手断连再来看看TCP的断连，如下图所示。\n\n\n\nTCP链接的关闭，通信双方都可以先发起，我们暂且把先发起的一方看作Client，从图中看出，通信中Client和Server两端的链接都是ESTABLISHED状态，然后Client先主动发起了关闭链接请求，Client向Server发送了一个FIN包，表示Client端已经没有数据要发送了，然后Client进入了FIN_WAIT_1状态。\nServer端收到FIN后，返回ACK，然后进入CLOSE_WAIT状态。此时Server属于半关闭状态，因为此时Client向Server方向已经不会发送数据了，可是Server向Client端可能还有数据要发送。\n当Server端数据发送完毕后，Server端会向Client端发送FIN，表示Server端也没有数据要发送了，此时Server进入LAST_ACK状态，就等待Client的应答就可以关闭链接了。\nClient端收到Server端的FIN后，回复ACK，然后进入TIME_WAIT状态。TIME_WAIT状态下需要等待2倍的最大报文段生存时间，来保证链接的可靠关闭，之后才会进入CLOSED关闭状态。而Server端收到ACK后直接就进入CLOSED状态。\n这里可能会问为什么需要等待2倍最大报文段生存时间之后再关闭链接，原因有两个：\n\n保证TCP协议的全双工连接能够可靠关闭；\n保证这次连接的重复数据段从网络中消失，防止端口被重用时可能产生数据混淆。\n\n从这个交互流程可以看出，无论是建连还是断链，都是需要在两个方向上进行，只不过建连时，Server端的SYN和ACK合并为一次发送，而断链时，两个方向上数据发送停止的时间可能不同，所以不能合并发送FIN和ACK。这就是建连三次握手而断链需要四次的原因。\n另外回答断链的问题时，可以提到实际应用中有可能遇到大量Socket处在TIME_WAIT或者CLOSE_WAIT状态的问题。一般开启tcp_tw_reuse和tcp_tw_recycle能够加快TIME-WAIT的Sockets回收；而大量CLOSE_WAIT可能是被动关闭的一方存在代码bug，没有正确关闭链接导致的。\n","categories":["总结笔记"],"tags":["操作系统","计算机网络"]},{"title":"Java语言特性与设计模式总结","url":"/2021_10_17_java_feature/","content":"设计模式知识点设计模式的考察点，一般有两个：\n\n常用设计模式的实现；\n设计模式的使用场景。\n\n设计模式分为3大类型共23种：\n\n创建型：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。\n结构型：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。\n行为型：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。\n\n最常见的设计模式有：单例模式、工厂模式、代理模式、构造者模式、责任链模式、适配器模式、观察者模式等，如下图所示。\n\n\n对于设计模式，你应该明白不同的设计用来解决什么场景问题，对于常用的设计模式能够灵活运用。下面重点介绍几种常用的设计模式。\n单例模式首先是单例模式，这个模式在实际业务中会经常用到，也是设计模式中的主要考察点。这里介绍线程安全的单例模式实现方式。\n单例模式常见的实现方式有三种。\n\n第一种是静态初始化方式，也叫作饿汉方式。实现的思路就是在类初始化时完成单例实例的创建，因此不会产生并发问题，在这种方式下不管是否会使用到这个单例，都会创建这个单例。\n第二种实现方式是双重检查，也叫作懒汉方式，只有在真正用到这个单例实例的时候才会去创建，如果没有使用就不会创建。这个方式必然会面对多个线程同时使用实例时的并发问题。为了解决并发访问问题，通过synchronized或者lock进行双重检查，保证只有一个线程能够创建实例。这里要注意内存可见性引起的并发问题，必须使用volatile关键字修饰单例变量。\n第三种是单例注册表方式，Spring中Bean的单例模式就是通过单例注册表方式实现的。\n\n下面结合设计模式的实际应用，来介绍常用的设计模式，如下图所示。在面试时遇到类似问题，记得要将设计模式与实际业务场景进行结合，来体现对设计模式的理解和应用能力。\n\n\n工厂模式工厂模式是创建不同类型实例时常用的方式，例如Spring中的各种Bean是有不同Bean工厂类进行创建的。\n代理模式代理模式，主要用在不适合或者不能直接引用另一个对象的场景，可以通过代理模式对被代理对象的访问行为进行控制。Java的代理模式分为静态代理和动态代理。静态代理指在编译时就已经创建好了代理类，例如在源代码中编写的类；动态代理指在JVM运行过程中动态创建的代理类，使用动态代理的方法有JDK动态代理、CGLIB、Javassist等。面试时遇到这个问题可以举个动态代理的例子，比如在Motan RPC中，是使用JDK的动态代理，通过反射把远程请求进行封装，使服务看上去就像在使用本地的方法。\n\n责任链模式责任链模式有点像工厂的流水线，链上每一个节点完成对对象的某一种处理，例如Netty框架在处理消息时使用的Pipeline就是一种责任链模式。\n\n模式演进案例\n\n适配器模式适配器模式，类似于我们常见的转接头，把两种不匹配的对象来进行适配，也可以起到对两个不同的对象进行解藕的作用。例如我们常用的日志处理框架SLF4J，如果我们使用了SLF4J就可以跟Log4j或者Logback等具体的日志实现框架进行解藕。通过不同适配器将SLF4J与Log4j等实现框架进行适配，完成日志功能的使用\n\n适配器模式和代理模式的一个显著差别：代理模式是方法名相同，一般实现同接口，适配器模式是方法名不同，一般用组合方式嵌入适配对象。\n\n观察者模式观察者模式也被称作发布订阅模式，适用于一个对象的某个行为需要触发一系列事件的场景，例如gRPC中的Stream流式请求的处理就是通过观察者模式实现的。\n构造者模式构造者模式，适用于一个对象有很多复杂的属性，需要根据不同情况创建不同的具体对象，例如创建一个PB对象时使用的builder方式。\nJava语言特性知识点Java语言特性的知识点汇总如下图所示。\n\n\n常用集合类实现与Java并发工具包JUC是常见考点，JUC会在后面的多线程总结中进行详细讲解。\nJava的集合类中部分需要重点了解类的实现。例如，HashMap、TreeMap是如何实现的等。\n动态代理与反射是Java语言的特色，需要掌握动态代理与反射的使用场景，例如在ORM框架中会大量使用代理类。而RPC调用时会使用到反射机制调用实现类方法\nJava基础数据类型也常常会在面试中被问到，例如各种数据类型占用多大的内存空间、数据类型的自动转型与强制转型、基础数据类型与wrapper数据类型的自动装箱与拆箱等。\nJava对对象的引用分为强引用、软引用、弱引用、虚引用四种，这些引用在GC时的处理策略不同，强引用不会被GC回收；软引用内存空间不足时会被GC回收；弱引用则在每次GC时被回收；虚引用必须和引用队列联合使用，主要用于跟踪一个对象被垃圾回收的过程。\nJava的异常处理机制就是try-catch-finally机制，需要知道异常时在try catch中的处理流程；需要了解Error和Exception的区别。\n\nError和Exception同实现自Throwable异常分类区别\n\n最后Java的注解机制和SPI扩展机制可以作为扩展点适当了解。\n详解Map关于Java的基础知识重点讲解最常考察点HashMap和ConcurrentHashMap，以及Java的不同版本新技术特性，如下图所示。\n\n\n面试中，Map的实现这个题目能够考察到数据结构、Java基础实现以及对并发问题处理思路的掌握程度。\n\nHashMap\n\n先来看HashMap的实现，简单来说，Java的HashMap就是数组加链表实现的，数组中的每一项是一个链表。通过计算存入对象的HashCode，来计算对象在数组中要存入的位置，用链表来解决散列冲突，链表中的节点存储的是键值对。\n除了实现的方式，我们还需要知道填充因子的作用与Map扩容时的rehash机制，需要知道HashMap的容量都是2的幂次方，是因为可以通过按位与操作来计算余数，比求模要快。另外需要知道HashMap是非线程安全的，在多线程put的情况下，有可能在容量超过填充因子时进行rehash，因为HashMap为了避免尾部遍历，在链表插入元素时使用头插法，多线程的场景下有可能会产生死循环\n\n\nConcurrentHashMap\n\n从HashMap的非线程安全，面试官很自然地就会问到线程安全的ConcurrentHashMap。ConcurrentHashMap采用分段锁的思想来降低并发场景下的锁定发生频率，在JDK1.7与1.8中的实现差异非常大，1.7中使用Segment进行分段加锁，降低并发锁定；1.8中使用CAS自旋锁的乐观锁来提高性能，但是在并发度较高时性能会比较一般。另外1.8中的ConcurrentHashMap引入了红黑树来解决Hash冲突时链表顺序查找的问题。红黑树的启用条件与链表的长度和Map的总容量有关，默认是链表大于8且容量大于64时转为红黑树。这部分内容建议详细阅读源码进行学习。\n\n\n\n详解 Java 版本特性\n\nJava近些年一改以往的版本发布风格，发布频率提高了很多。目前大部分公司的生产环境使用的还是1.8版本，一少部分升级到1.9或1.10 版本，Java的1.8版本是一个长期支持的版本，最新发布的1.11版本也是一个长期支持的版本，1.11版本中已经包含了1.9、1.10 版本的功能，所以1.8和1.11版本是我们要重点关注的版本\n在1.8版本中Java增加了对lambda表达式的支持，使Java代码的编写可以更简洁，也更方便支持并行计算。并且提供了很多Stream流式处理的API。1.8版本还支持了方法引用的能力，可以进一步简化lambda表达式的写法。\n在1.8版本中，接口可以提供默认方法了，这样可以简化一些简单的抽象类。最后在1.8版本中对方法区进行调整，使用Metaspace替换掉了PermGen的永久代。Metaspace与PermGen之间最大的区别在于：Metaspace并不在虚拟机中，而是使用本地内存。替换的目的一方面是可以提升对元数据的管理同时提升GC效率，另一方面是方便后续HotSpot与JRockit合并。\n在1.9、1.10版本中的主要特性是增加了模块系统，将G1设为默认垃圾回收器、支持局部变量推断等功能。这些功能都已经包含在1.11版本中。\n1.11版本是Java最新的长期支持版本，也将会是未来一段时间的主要版本，1.11版本中提供的最激动人心的功能是ZGC这个新的垃圾回收器，ZGC为大内存堆设计，有着非常强悍的性能，能够实现10ms以下的GC暂停时间。关于ZGC会在下一课中进一步介绍。除此之外，1.11版本对字符串处理API进行了增强，提供了字符复制等功能。1.11版本还内置了HttpClient\n考察点从面试官角度出发，总结本课时对于计算机基础和Java语言特性的考察点如下：\n\n第一考察点就是对基本概念和基本原理的考察。要求对这两项的理解必须是正确的，清晰的。例如网络协议的4&#x2F;7层模型的概念，TCP协议流量控制的实现原理等。\n第二个考察点是常用工具、模型的实现方式和使用姿势，例如HashMap在JDK 1.8中的实现方式是怎样的？单例模式有几种实现方式？什么场景下该使用懒汉式单例实现，什么场景下该使用饿汉式单例实现等。\n第三个考察点是经常使用到的一些知识点，例如你常用的Linux命令有哪些，都用来解决什么问题？\n第四个考察点是实际应用中容易犯错的点，例如&#x3D;&#x3D;与equals的区别，例如对象的强引用使用不当可能导致内存泄露，主要考察候选人对于不同对象引用方式的作用和理解。\n第五个考察点是与面试方向相关的知识点。例如面试的岗位是中间件研发，面试时可能会涉及更多的存储、网络相关的知识的考察。\n\n加分项前面提到的考察点是面试通过的必要条件，回答出问题并不一定能保证通过面试，所以如何做到比其他竞争者更优秀，给面试官留下更好的印象，是成功的关键。你需要一些buff。这些加分能力不仅仅针对这一课的内容，后续课程也有一定的通用性。能将面试考察点与实际业务场景结合，或者与实际使用经验结合。\n这样能够更好的体现对知识点的理解，突出实践能力。例如，在回答 “你知道哪几种设计模式” 这个问题时，不但能说出几种设计模式，以及适合哪类场景，而且还能指出哪些著名的框架在处理什么问题时使用了哪种设计模式，或者自己在处理某个项目的什么场景时，使用了哪种设计模式，取得了什么效果，这样肯定会给面试官留下非常好的印象。\n\n用反例来描述在实际场景中，误用某些功能会带来的问题。\n\n例如，介绍反射机制时，除了介绍反射机制的实现方式、应用场景外，还可以提到大量使用反射会对性能产生影响，应避免滥用。\n\n\n知道与考察知识点相关的优化点。\n\n例如在介绍TCP建连与断连时，最好能够指出线上如果出现大量time_wait时，可以通过调整系统参数加快连接的回收与复用\n\n\n了解与知识点相关的最新技术趋势\n\n例如介绍ConcurrentHashMap的实现时，能够知道1.8版本的改进细节。或者在介绍HTTP时能够说出HTTP2和QUIC的特点与实现等\n回答面试问题时，在比较了解的前提下，尽量增加回答内容的深度。例如在介绍TCP的滑动窗口时，能讲到流量和拥塞控制，近一步能指出不同的解决拥塞的算法等\n这里要注意，面试官一般会沿着候选人的回答继续追问，如果对细节不太了解可能会适得其反。\n\n\n\n真题汇总\n\n解题思路如下。\n\n第一题：线程、进程的区别和联系，主要从资源占用、切换效率、通信方式等方面进行解答；\n第二题：线程的切换过程主要考察上下文切换，需要保存寄存器、栈等现场，需要由用户态切换到内核态。最后通过vmstat命令查看上下文切换的情况；\n第三题：常用的Linux命令可以参考前面操作系统汇总提到的命令；\n第四题、第五题，知识点详解中已经介绍过了，务必要掌握；\n第六题：大致包括DNS解析、TCP建连、HTTP请求、HTTP响应等，实际回答时，可以画个简单的交互图来说明。\n\n再汇总一些真题，包括基础概念，以及前面介绍过的知识点，如下图所示。\n","categories":["总结笔记"],"tags":["Java","设计模式"]},{"title":"Java-SPI机制","url":"/2022_02_03_java_spi/","content":"随着应用程序越来越复杂，对于我们开发人员来说，如何实现高效的组件化和模块化已经成为了一个重要的问题。而 Java SPI（Service Provider Interface）机制，作为一种基于接口的服务发现机制，可以帮助我们更好地解决这个问题。这样会程序具有高度的灵活性、解耦、可扩展性！\nSPI概念与原理概念Java SPI（Service Provider Interface）是Java官方提供的一种服务发现机制，它允许在运行时动态地加载实现特定接口的类，而不需要在代码中显式地指定该类，从而实现解耦和灵活性。\n具体机制如下图：\n实现原理Java SPI 的实现原理基于 Java 类加载机制和反射机制。\n当使用 ServiceLoader.load(Class service) 方法加载服务时，会检查 META-INF&#x2F;services 目录下是否存在以接口全限定名命名的文件。如果存在，则读取文件内容，获取实现该接口的类的全限定名，并通过 Class.forName() 方法加载对应的类。\n在加载类之后，ServiceLoader 会通过反射机制创建对应类的实例，并将其缓存起来。\n这里涉及到一个懒加载迭代器的思想：\n当我们调用 ServiceLoader.load(Class service) 方法时，并不会立即将所有实现了该接口的类都加载进来，而是返回一个懒加载迭代器。\n只有在使用迭代器遍历时，才会按需加载对应的类并创建其实例。\n这种懒加载思想有以下两个好处：\n\n节省内存如果一次性将所有实现类全部加载进来，可能会导致内存占用过大，影响程序的性能。\n\n增强灵活性由于 ServiceLoader 是动态加载的，因此可以在程序运行时添加或删除实现类，而无需修改代码或重新编译。\n\n\n总的来说，Java SPI 的实现原理比较简单，利用了 Java 类加载和反射机制，提供了一种轻量级的插件化机制，可以很方便地扩展功能。\n优缺点\n优点\n\n\n松耦合性：SPI具有很好的松耦合性，应用程序可以在运行时动态加载实现类，而无需在编译时将实现类硬编码到代码中。\n扩展性：通过SPI，应用程序可以为同一个接口定义多个实现类。这使得应用程序更容易扩展和适应变化。\n易于使用：使用SPI，应用程序只需要定义接口并指定实现类的类名，即可轻松地使用新的服务提供者。\n\n\n缺点\n\n\n配置较麻烦：SPI需要在META-INF&#x2F;services目录下创建配置文件，并将实现类的类名写入其中。这使得配置相对较为繁琐。\n安全性不足：SPI提供者必须将其实现类名称写入到配置文件中，因此如果未正确配置，则可能存在安全风险。\n性能损失：每次查找服务提供者都需要重新读取配置文件，这可能会增加启动时间和内存开销。\n\n应用场景Java SPI机制是一种服务提供者发现的机制，适用于需要在多个实现中选择一个进行使用的场景。\n常见的应用场景包括：\n我们上面对Java SPI的缺点说了一下，我们来说一下：Spring的SPI机制相对于Java原生的SPI机制进行了改造和扩展，主要体现在以下几个方面：\n\n支持多个实现类：Spring的SPI机制允许为同一个接口定义多个实现类，而Java原生的SPI机制只支持单个实现类。这使得在应用程序中使用Spring的SPI机制更加灵活和可扩展。\n\n支持自动装配：Spring的SPI机制支持自动装配，可以通过将实现类标记为Spring组件（例如@Component），从而实现自动装配和依赖注入。这在一定程度上简化了应用程序中服务提供者的配置和管理。\n\n支持动态替换：Spring的SPI机制支持动态替换服务提供者，可以通过修改配置文件或者其他方式来切换服务提供者。而Java原生的SPI机制只能在启动时加载一次服务提供者，并且无法在运行时动态替换。\n\n提供了更多扩展点：Spring的SPI机制提供了很多扩展点，例如BeanPostProcessor、BeanFactoryPostProcessor等，可以在服务提供者初始化和创建过程中进行自定义操作。\n\n\n其他框架也是对Java SPI进行改造和扩展增强，从而更好的提供服务！\n使用步骤\n定义接口：首先需要定义一个接口，所有实现该接口的类都将被注册为服务提供者。\n\n创建实现类：创建一个或多个实现接口的类，这些类将作为服务提供者。\n\n配置文件：在 META-INF&#x2F;services 目录下创建一个以接口全限定名命名的文件，文件内容为实现该接口的类的全限定名，每个类名占一行。\n\n加载使用服务：使用 java.util.ServiceLoader 类的静态方法 load(Class service) 加载服务，默认情况下会加载 classpath 中所有符合条件的提供者。调用 ServiceLoader 实例的 iterator() 方法获取迭代器，遍历迭代器即可获取所有实现了该接口的类的实例。\n\n\n使用 Java SPI 时，需要注意以下几点：\n\n接口必须是公共的，且只能包含抽象方法。\n\n实现类必须有一个无参构造函数。\n\n配置文件中指定的类必须是实现了相应接口的非抽象类。\n\n配置文件必须放在 META-INF&#x2F;services 目录下。\n\n配置文件的文件名必须为接口的全限定名。\n\n\n实践案例组织模块\n接口层//MLogger.javapackage h.xd.spi;public interface MLogger &#123;    void info(String msg);    void debug(String msg);&#125;\nspi实现层//MLogback.javapackage h.xd.spi.impl;import h.xd.spi.MLogger;public class MLogback implements MLogger &#123;    @Override    public void info(String msg) &#123;        System.err.println(&quot;MLogback info &quot; + msg);    &#125;    @Override    public void debug(String msg) &#123;        System.err.println(&quot;MLogback debug &quot; + msg);    &#125;&#125;\n//h.xd.spi.MLoggerh.xd.spi.impl.MLogback\n客户端层\n\n// SpiLogger.javapackage com.h.xd.spi;import h.xd.spi.MLogger;import java.util.ArrayList;import java.util.List;import java.util.ServiceLoader;public class SpiLogger implements MLogger &#123;    private final MLogger logger;    public SpiLogger() &#123;        ServiceLoader&lt;MLogger&gt; load = ServiceLoader.load(MLogger.class);        List&lt;MLogger&gt; mLoggerList = new ArrayList&lt;&gt;();        for(MLogger mLogger: load)&#123;            mLoggerList.add(mLogger);        &#125;        if(!mLoggerList.isEmpty())&#123;            this.logger = mLoggerList.get(0);        &#125;else&#123;            this.logger = null;        &#125;    &#125;    @Override    public void info(String msg) &#123;        if(logger != null)&#123;            logger.info(msg);        &#125;else &#123;            System.out.println(&quot;info无SPI&quot;);        &#125;    &#125;    @Override    public void debug(String msg) &#123;        if(logger != null)&#123;            logger.debug(msg);        &#125;else &#123;            System.out.println(&quot;info无SPI&quot;);        &#125;    &#125;&#125;\n\n//Main.javapackage com.h.xd;public class Main &#123;        public static void main(String[] args) &#123;        SpiLogger spiLogger = new SpiLogger();        spiLogger.debug(&quot;hello&quot;);    &#125;&#125;","categories":["应用笔记"],"tags":["Java","Java SPI"]},{"title":"Springboot自定义指标并使用Prometheus监控预警","url":"/2022_06_18_springboot_actuator/","content":"spring套件为我们提供了很多starter，其中spring-boot-starter-actuator支持指标采集，本文介绍使用Prometheus监控Spring Boot提供的默认指标，以及自定义业务指标，并使用Prometheus进行监控并报警，同时在 Grafana 进行展现\n","categories":["应用笔记"],"tags":["Springboot","Prometheus"]},{"title":"Go channel和select","url":"/2022_06_02_go_channel/","content":"channel是指定类型的值的线程安全队列, channel的最大用途是goroutines之间进行通信。\ngoroutines通信时使用ch&lt;-value将值写入channel,使用value&lt;-ch从channel中接收值。\nchannel基本使用方法package mainimport (\t&quot;fmt&quot;\t&quot;math/rand&quot;\t&quot;time&quot;)func genInts(chInts chan int) &#123;\tchInts &lt;- rand.Intn(1000)&#125;func main() &#123;\trand.Seed(time.Now().UnixNano())\tchInts := make(chan int)\tfor i := 0; i &lt; 2; i++ &#123;\t\tgo genInts(chInts)\t&#125;\tfmt.Printf(&quot;n: %d\\n&quot;, &lt;-chInts)\tfmt.Printf(&quot;n: %d\\n&quot;, &lt;-chInts)&#125;// n: 578// n: 424\n\n启动两个协程，相chInts 通道放随机数\n然后获取打印该随机数两次\n使用range从channel中读取数据当从channel中读取多个值时,通常会使用range:\npackage mainimport (\t&quot;fmt&quot;)func foo(ch chan int) &#123;\tch &lt;- 1\tch &lt;- 2\tclose(ch)&#125;func main() &#123;\tch := make(chan int)\tgo foo(ch)\tfor n := range ch &#123;\t\tfmt.Println(n)\t&#125;\tfmt.Println(&quot;channel is now closed&quot;)&#125;// 1// 2// channel is now closed\n\nchannel关闭,循环就会结束\n使用工作池时，这是常见的模式:\n\n为所有工作创建一个channel\n启动工作\n工作使用v:&#x3D;range chan来提取要处理的任务\n在对所有作业进行排队之后，关闭channel，以便goroutine处理channel中的所有作业\n\n使用select从channel中超时读取从channel中读取数据时,有时候希望限制等待的时间\n使用select可以达到目的:\npackage mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)func main() &#123;\ttimeStart := time.Now()\tchResult := make(chan int, 1)\tgo func() &#123;\t\ttime.Sleep(10 * time.Second)\t\tchResult &lt;- 5\t\tfmt.Printf(&quot;Worker finished&quot;)\t&#125;()\tselect &#123;\tcase res := &lt;-chResult:\t\tfmt.Printf(&quot;Got %d from worker\\n&quot;, res)\tcase &lt;-time.After(100 * time.Millisecond):\t\tfmt.Printf(&quot;Timed out before worker finished\\n&quot;)\t&#125;\tfmt.Printf(&quot;cost %f s&quot;, time.Since(timeStart).Seconds())&#125;// Timed out before worker finished// cost 0.115807 s\n\n向chResult 放入值需要等1秒，  select的时候， 先等到 100毫秒的信号，故输出结果。\n关闭channel使用close(chan)关闭channel关闭channel的主要目的是通知worker goroutine他们的工作已经完成并且可以结束。保证了goroutines不会泄露\npackage mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)func main() &#123;\tch := make(chan string)\tgo func() &#123;\t\tfor s := range ch &#123;\t\t\tfmt.Printf(&quot;received from channel: %s\\n&quot;, s)\t\t&#125;\t\tfmt.Print(&quot;range loop finished because ch was closed\\n&quot;)\t&#125;()\tch &lt;- &quot;foo&quot;\ttime.Sleep(1 * time.Second)\tclose(ch)\ttime.Sleep(1 * time.Second)&#125;// received from channel: foo// range loop finished because ch was closed\n\n从已关闭的channel中读取数据会立即返回零值package mainimport (\t&quot;fmt&quot;)func main() &#123;\tch := make(chan string)\tclose(ch)\tv := &lt;-ch\tfmt.Printf(&quot;Receive from closed channel immediately returns zero value of the type: %#v\\n&quot;, v)&#125;// Receive from closed channel immediately returns zero value of the type: &quot;&quot;\n\n\n判断channel是否关闭package mainimport (\t&quot;fmt&quot;)func main() &#123;\tch := make(chan int)\tgo func() &#123;\t\tch &lt;- 1\t\tclose(ch)\t&#125;()\tv, isOpen := &lt;-ch\tfmt.Printf(&quot;received %d, is channel open: %v\\n&quot;, v, isOpen)\tv, isClosed := &lt;-ch\tfmt.Printf(&quot;received %d, is channel open: %v\\n&quot;, v, isClosed)&#125;// received 1, is channel open: true// received 0, is channel open: false\n\n重复关闭channel会引发panicpackage mainfunc main() &#123;\tch := make(chan string)\tclose(ch)\tclose(ch)&#125;// panic: close of closed channel\n\n发送数据到关闭的channel引发panicpackage mainfunc main() &#123;\tch := make(chan int)\tclose(ch)\tch &lt;- 5 // panics&#125;// panic: send on closed channel\n\n\n是否缓冲发送和接收goroutines块，除非发送goroutine具有要发送的值，并且接收goroutine已准备好接收。\n对每个接收&#x2F;发送操作坚持同步可能会导致不必要的速度降低。\n想象一个场景，一个工人生产，而另一个工人消费。\n如果产生一个值要花一秒钟，消耗也要花一秒钟，则要花2秒的时间来产生和消耗一个值。\n如果生产者可以在channel中排队，则不必等待消费者为每个值做好准备。\n这是缓冲channel的好处。\n通过允许生产者独立于消费者进行生产，我们可以加快某些场景:\npackage mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)func producer(ch chan int) &#123;\tfor i := 0; i &lt; 5; i++ &#123;\t\tif i%2 == 0 &#123;\t\t\ttime.Sleep(10 * time.Millisecond)\t\t&#125; else &#123;\t\t\ttime.Sleep(1 * time.Millisecond)\t\t&#125;\t\tch &lt;- i\t&#125;&#125;func consumer(ch chan int) &#123;\ttotal := 0\tfor i := 0; i &lt; 5; i++ &#123;\t\tif i%2 == 1 &#123;\t\t\ttime.Sleep(10 * time.Millisecond)\t\t&#125; else &#123;\t\t\ttime.Sleep(1 * time.Millisecond)\t\t&#125;\t\ttotal += &lt;-ch\t&#125;&#125;func unbuffered() &#123;\ttimeStart := time.Now()\tch := make(chan int)\tgo producer(ch)\tconsumer(ch)\tfmt.Printf(&quot;Unbuffered version took %s\\n&quot;, time.Since(timeStart))&#125;func buffered() &#123;\ttimeStart := time.Now()\tch := make(chan int, 5)\tgo producer(ch)\tconsumer(ch)\tfmt.Printf(&quot;Buffered version took %s\\n&quot;, time.Since(timeStart))&#125;func main() &#123;\tunbuffered()\tbuffered()&#125;// Unbuffered version took 96.2924ms// Buffered version took 78.0755ms\n\n使用select非阻塞接收可以使用select语句的默认部分进行非阻塞等待。\npackage mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)func main() &#123;\tch := make(chan int, 1)end:\tfor &#123;\t\tselect &#123;\t\tcase n := &lt;-ch:\t\t\tfmt.Printf(&quot;Received %d from a channel\\n&quot;, n)\t\t\tbreak end\t\tdefault:\t\t\tfmt.Print(&quot;Channel is empty\\n&quot;)\t\t\tch &lt;- 8\t\t&#125;\t\t// wait for channel to be filled with values\t\t// don&#x27;t use time.Sleep() like that in production code\t\ttime.Sleep(20 * time.Millisecond)\t&#125;&#125;// Channel is empty// Received 8 from a channel\n\n在for循环的第一次迭代中，由于channel为空，因此select立即以default子句结束。\n我们将值发送到该通道，以便下一个选择将从通道中获取该值。\nchan struct{}信号事件有时不想通过channel发送值，而仅将其用作信号事件的一种方式。\n信令通道通常用来通知goroutine结束:\nstruct{} 不占用内存空间，作为信号节省内存\npackage mainimport (\t&quot;fmt&quot;)func worker(ch chan int, chQuit chan struct&#123;&#125;) &#123;\tfor &#123;\t\tselect &#123;\t\tcase v := &lt;-ch:\t\t\tfmt.Printf(&quot;Got value %d\\n&quot;, v)\t\tcase &lt;-chQuit:\t\t\tfmt.Printf(&quot;Signalled on quit channel. Finishing\\n&quot;)\t\t\tchQuit &lt;- struct&#123;&#125;&#123;&#125;\t\t\treturn\t\t&#125;\t&#125;&#125;func main() &#123;\tch, chQuit := make(chan int), make(chan struct&#123;&#125;)\tgo worker(ch, chQuit)\tch &lt;- 3\tchQuit &lt;- struct&#123;&#125;&#123;&#125;\t// wait to be signalled back by the worker\t&lt;-chQuit&#125;// Got value 3// Signalled on quit channel. Finishing\n\n检查通道是否有可用数据如果通道中没有数据，则在通道上接收会阻塞。\n如果您不想阻止怎么办？\n您可能很想在接收之前检查通道是否有数据。\n您无法在Go中执行此操作，因为它可能无法正常运行。 在您检查可用性的时间和您收到数据的时间之间，其他一些goroutine可能会获取该值。\n如果要避免无限等待，可以使用select添加超时或进行非阻塞等待。\n发送数据到nil channel将永久阻塞package mainfunc main() &#123;\tvar ch chan bool\tch &lt;- true // deadlocks because ch is nil&#125;// fatal error: all goroutines are asleep - deadlock!\n\n通道的未初始化值是nil，因此上述程序会永远阻塞。\n从nil channel接收数据将永久阻塞package mainimport &quot;fmt&quot;func main() &#123;\tvar ch chan bool\tfmt.Printf(&quot;Value received from ch is: %v\\n&quot;, &lt;-ch) // deadlock because c is nil&#125;// fatal error: all goroutines are asleep - deadlock!\n\n发送数据到关闭的channel引发panicpackage mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)func main() &#123;\tvar ch = make(chan int, 100)\tgo func() &#123;\t\tch &lt;- 1\t\ttime.Sleep(time.Second)\t\tclose(ch)\t\tch &lt;- 1\t&#125;()\tfor i := range ch &#123;\t\tfmt.Printf(&quot;i: %d\\n&quot;, i)\t&#125;&#125;// i: 1// panic: send on closed channel\n\n您应该对程序进行架构设计，以使一个发送方控制频道的生存期。\n该规则强调:如果只有一个频道发送者，那么确保您永远不会写入封闭的频道没有问题。\n如果您有多个发件人，这将变得很困难:如果一个发件人关闭了一个频道，那么其他发件人应该不会崩溃吗？\n无需尝试解决上述问题的方法，而是重新设计代码，以使只有一个发送方可以控制通道的生存期。\n从已关闭的channel接收数据会立即返回零值package mainimport &quot;fmt&quot;func main() &#123;    // show    ch := make(chan int, 2)    ch &lt;- 1    ch &lt;- 2    close(ch)    for i := 0; i &lt; 3; i++ &#123;        fmt.Printf(&quot;%d &quot;, &lt;-ch) // -&gt; 1 2 0    &#125;    // show end&#125;// 1 2 0\n\n很容易补救:\npackage mainimport &quot;fmt&quot;func main() &#123;    ch := make(chan int, 2)    ch &lt;- 1    ch &lt;- 2    close(ch)    // show    for &#123;        v, ok := &lt;-ch        if !ok &#123;            break        &#125;        fmt.Printf(&quot;%d &quot;, v) // -&gt; 1 2    &#125;    // show end&#125;\n\n更好更惯用的方法:\npackage mainimport &quot;fmt&quot;func main() &#123;    ch := make(chan int, 2)    ch &lt;- 1    ch &lt;- 2    close(ch)    // show    for v := range ch &#123;        fmt.Printf(&quot;%d &quot;, v) // -&gt; 1 2    &#125;    // show end&#125;\n\n关闭channel以表明Goroutine已结束有时我们需要等到goroutine完成。\n来自已关闭channel的接收会立即返回，可以通过共享done channel来在goroutine之间进行协调。\npackage mainimport &quot;fmt&quot;// showfunc checkState(ch chan struct&#123;&#125;) &#123;\tselect &#123;\tcase &lt;-ch:\t\tfmt.Printf(&quot;channel is closed\\n&quot;)\tdefault:\t\tfmt.Printf(&quot;channel is not closed\\n&quot;)\t&#125;&#125;// show endfunc main() &#123;\t// show\tch := make(chan struct&#123;&#125;)\tcheckState(ch)\tclose(ch)\tcheckState(ch)\t// show end&#125;// channel is not closed// channel is closed","categories":["应用笔记"],"tags":["Go","Go Channel","Go Select"]},{"title":"再次通过结构型模式视角回顾Go","url":"/2022_07_02_go_design_pattern/","content":"结构型模式主要关注如何将类或者对象组合成更大的结构，以便在不改变原有类或者对象的情况下，实现新的功能或者优化结构。\n结构型模式核心思想是通过组合(Composition)而不是继承(Inheritance)来实现代码的复用和扩展\n代理，桥接，组合，装饰器，适配器，外观，享元，七种模式。\n结构型模式-代理模式代理模式：通过代理对象来控制另一个对象，核心是不改变原对象的情况下，通过代理对象来增强或者限制对原对象的访问。\n常见场景：\n\n延迟初始化\n访问控制\n日志记录\n缓存\n\npackage structural_patternimport &quot;fmt&quot;type Log struct &#123;&#125;func (Log) Info(content string) &#123;\tfmt.Println(content)&#125;type ProxyLog struct &#123;\tlog *Log&#125;func (p *ProxyLog) Info(content string) &#123;\t//延迟初始化\tif p.log == nil &#123;\t\tp.log = &amp;Log&#123;&#125;\t&#125;\t//访问前\tp.log.Info(content)\t//访问后&#125;\n\npackage structural_patternimport &quot;testing&quot;func TestProxyLog_Info(t *testing.T) &#123;\tpl := ProxyLog&#123;&#125;\tpl.Info(&quot;hello world&quot;)&#125;\n结构型模式-桥接模式核心思想是将抽象部分和实现部分分离，是他们可以独立变化。避免类的数量爆炸，提高可扩展可维护性。\npackage bridgeimport &quot;fmt&quot;// 电脑type Computer interface &#123;\tPrint(file string)  //打印文件\tSetPrinter(Printer) //设置打印机&#125;// 打印机type Printer interface &#123;\tPrintFile(file string) // 打印文件&#125;type Epson struct&#123;&#125;func (Epson) PrintFile(file string) &#123;\tfmt.Println(&quot;使用爱普生打印机打印文件&quot;, file)&#125;type Hp struct&#123;&#125;func (hp Hp) PrintFile(file string) &#123;\tfmt.Println(&quot;使用惠普打印机打印文件&quot;, file)&#125;type Mac struct &#123;\tprinter Printer&#125;func (m *Mac) Print(file string) &#123;\t//桥接到打印机的打印方法上\tm.printer.PrintFile(&quot;mac:&quot; + file)&#125;func (m *Mac) SetPrinter(p Printer) &#123;\tm.printer = p&#125;type Windows struct &#123;\tprinter Printer&#125;func (ws *Windows) Print(file string) &#123;\tws.printer.PrintFile(&quot;windows:&quot; + file)&#125;func (ws *Windows) SetPrinter(p Printer) &#123;\tws.printer = p&#125;\n\npackage bridgeimport &quot;testing&quot;func TestBridge(t *testing.T) &#123;\tw := Windows&#123;&#125;\thp := Hp&#123;&#125;\tw.SetPrinter(hp)\tw.Print(&quot;xxx&quot;)&#125;\n\n结构型模式-组合模式将对象组合成树形层次关系，  “部分-整体”，  组合模式让客户端可以统一的处理单个对象和对象的组合。\n应用场景：\n\n文件系统：文件，文件夹，文档树\n组织结构：部门员工关系\n\n为什么使用组合模式：\n\n简化客户端代码\n增强灵活性\n提高可扩展性\n\npackage compositeimport &quot;fmt&quot;type Node interface &#123;\tDisplay(ident string)&#125;type File struct &#123;\tName string&#125;type Dir struct &#123;\tName     string\tChildren []Node&#125;func (f File) Display(ident string) &#123;\tfmt.Println(ident + f.Name)&#125;func (d Dir) Display(ident string) &#123;\tfmt.Println(ident + d.Name)\tfor _, child := range d.Children &#123;\t\tchild.Display(ident + &quot;  &quot;)\t&#125;&#125;\n\npackage compositeimport &quot;testing&quot;func TestComposite(t *testing.T) &#123;\troot := Dir&#123;\t\tName: &quot;CreateProjects&quot;,\t\tChildren: []Node&#123;\t\t\tDir&#123;\t\t\t\tName: &quot;cmd&quot;,\t\t\t\tChildren: []Node&#123;\t\t\t\t\tFile&#123;\t\t\t\t\t\tName: &quot;main.go&quot;,\t\t\t\t\t&#125;,\t\t\t\t&#125;,\t\t\t&#125;,\t\t\tFile&#123;\t\t\t\tName: &quot;go.mod&quot;,\t\t\t&#125;,\t\t&#125;,\t&#125;\troot.Display(&quot;&quot;)&#125;\n\n结构型模式-装饰器模式动态的为对象添加行为和职责，不需要修改原始类。或者引入装饰者类， 运行时灵活的组合不通功能，而不需要创建大量子类。\n装饰者的核心是为对象包装在一个或多个装饰者中，每个装饰者可以在调用被装饰方法前后添加额为的行为。\n例如：\n\nweb服务添加，日志记录\nweb服务添加性能监控\n\n很像代理模式，代理模式除了增强还可以限制，  装饰器模式一般增强\npackage decoratorimport (\t&quot;fmt&quot;\t&quot;time&quot;)type ReqI interface &#123;\tHandler(url string) string&#125;type Req struct &#123;&#125;func (r Req) Handler(url string) string &#123;\tfmt.Println(&quot;请求&quot; + url)\treturn &quot;&quot;&#125;// LogDecorator 日志装饰器type LogDecorator struct &#123;\treq ReqI&#125;func (l LogDecorator) Handler(url string) string &#123;\tfmt.Println(&quot;日志记录前&quot;)\tres := l.req.Handler(url)\tfmt.Println(&quot;日志记录后&quot;)\treturn res&#125;type MonitorDecorator struct &#123;\treq ReqI&#125;func (m MonitorDecorator) Handler(url string) string &#123;\tt1 := time.Now()\tres := m.req.Handler(url)\tsub := time.Since(t1)\tfmt.Println(&quot;耗时：&quot;, sub)\treturn res&#125;\npackage decoratorimport (\t&quot;testing&quot;)func TestReq_Handler(t *testing.T) &#123;\treq := Req&#123;&#125;\tlogReq := LogDecorator&#123;\t\treq: req,\t&#125;\tmReq := MonitorDecorator&#123;\t\treq: logReq,\t&#125;\tmReq.Handler(&quot;baidu.com&quot;)&#125;\n\n结构型模式-适配器模式结构型模式最简单的一种\n将一个类的接口转换成客户端期望的另一个接口，从而使不兼容的类能够一起工作\n假如你的系统需要继承一个第三方的支付功能，它的功能与你的接口不兼容，转换接口\npackage adaptertype AliPay struct &#123;&#125;func (a AliPay) GetPayPage(price int64) string &#123;\treturn &quot;支付宝连接&quot;&#125;type WeixinPay struct &#123;&#125;func (w WeixinPay) PayPage(price int64) string &#123;\treturn &quot;微信支付连接&quot;&#125;type PayI interface &#123;\tPayPage(price int64) string&#125;func PayPage(pi PayI, price int64) string &#123;\treturn pi.PayPage(price)&#125;type AliPayAdapter struct &#123;\taliPay *AliPay&#125;func (a AliPayAdapter) PayPage(price int64) string &#123;\treturn a.aliPay.GetPayPage(price)&#125;\n\npackage adapterimport (\t&quot;fmt&quot;\t&quot;testing&quot;)func TestPayPage(t *testing.T) &#123;\tfmt.Println(PayPage(WeixinPay&#123;&#125;, 1))\tfmt.Println(PayPage(AliPayAdapter&#123;aliPay: &amp;AliPay&#123;&#125;&#125;, 1))&#125;\n\n结构型模式-外观模式提供了一个统一的接口，用于访问子系统中的一组接口\n外观模式的核心思想是简化复杂系统的使用，通过提供一个高层接口，隐藏系统的复杂性，使客户端更容易使用\n比如：前后端解构\npackage facadeimport &quot;fmt&quot;type Inventory struct &#123;&#125;func (k Inventory) Deduction() &#123;\tfmt.Println(&quot;扣库存&quot;)&#125;type Pay struct &#123;&#125;func (p Pay) Pay() &#123;\tfmt.Println(&quot;下单&quot;)&#125;type Logistics struct&#123;&#125;func (l Logistics) SendOutGoods() &#123;\tfmt.Println(&quot;发货&quot;)&#125;type Order struct &#123;\ti *Inventory\tp *Pay\tl *Logistics&#125;func NewOrder() *Order &#123;\treturn &amp;Order&#123;\t\ti: &amp;Inventory&#123;&#125;,\t\tp: &amp;Pay&#123;&#125;,\t\tl: &amp;Logistics&#123;&#125;,\t&#125;&#125;func (o Order) place() &#123;\to.i.Deduction()\to.p.Pay()\to.l.SendOutGoods()&#125;\n\npackage facadeimport &quot;testing&quot;func TestLogistics_SendOutGoods(t *testing.T) &#123;\to := NewOrder()\to.place()&#125;\n\n结构型模式-享元模式通过共享对象来减少内存使用和提高性能\n核心思想是将对象共享部分（内部状态）与不可共享部分（外部状态）分离，从而减少重复对象的创建\n举个例子：共享单车和百度网盘中的文件\n核心思想：\n\n共享对象\n分离状态\n工厂管理\n\n各种池技术，连接池，对象池等\npackage flyweightimport (\t&quot;fmt&quot;)type DB struct &#123;\tid int&#125;func NewDB(id int) *DB &#123;\treturn &amp;DB&#123;id&#125;&#125;func (db DB) Query(str string) &#123;\tfmt.Printf(&quot;使用 %d 连接对象 进行查询操作\\n&quot;, db.id)&#125;type DBPool struct &#123;\tpool   map[int]*DB\tnextId int&#125;func NewDBPool(num int) *DBPool &#123;\tvar pool = map[int]*DB&#123;&#125; //sync.Map&#123;&#125; 这里线程不安全\tfor i := 0; i &lt; num; i++ &#123;\t\tpool[i] = NewDB(i)\t&#125;\treturn &amp;DBPool&#123;\t\tpool:   pool,\t\tnextId: num - 1,\t&#125;&#125;func (p *DBPool) GetDB() *DB &#123;\tif len(p.pool) &gt; 0 &#123;\t\tfor id, db := range p.pool &#123;\t\t\tdelete(p.pool, id)\t\t\treturn db\t\t&#125;\t&#125;\tdb := NewDB(p.nextId)\treturn db&#125;func (p *DBPool) ReleaseDB(db *DB) &#123;\tp.pool[db.id] = db&#125;\n\npackage flyweightimport &quot;testing&quot;func TestNewDBPool(t *testing.T) &#123;\tpool := NewDBPool(10)\tdb1 := pool.GetDB()\tdb1.Query(&quot;select * from xxx&quot;)\tdb2 := pool.GetDB()\tdb2.Query(&quot;select * from xxx&quot;)\tpool.ReleaseDB(db2)\tdb3 := pool.GetDB()\tdb3.Query(&quot;select * from xxx&quot;)\tpool.ReleaseDB(db3)&#125;\n\n","categories":["总结笔记"],"tags":["Go","Proxy","Bridge","Composite","Decorator","Adapter","Facade","Flyweight"]},{"title":"再次通过创建型模式视角回顾Go","url":"/2022_07_01_go_design_pattern/","content":"创建型模式主要目标是提供一种灵活方式创建对象，同事隐藏创建的具体细节，降低代码耦合度，提高复用性和可维护性。\n创建型模式-单例单例模式，Singleton， 确保只有一实例，并提供全局访问点。\n使用场景：配置管理，日志记录， 数据库连接池等。\nglobal.DB,  global.Config 并不是单例模式，而是直接使用全局变量。\npackage databaseimport &quot;sync&quot;type DB struct &#123;&#125;var db *DBvar once sync.Oncefunc initDB(dsn string) *DB &#123;\treturn &amp;DB&#123;&#125;&#125;func GetDB() *DB &#123;\tonce.Do(func() &#123;\t\tdb = initDB(&quot;xxx&quot;)\t&#125;)\treturn db&#125;\n单测：\npackage databaseimport (\t&quot;fmt&quot;\t&quot;testing&quot;)func TestGetDB(t *testing.T) &#123;\tdb1 := GetDB()\tdb2 := GetDB()\tdb3 := GetDB()\tfmt.Printf(&quot;%p\\n&quot;, db1)\tfmt.Printf(&quot;%p\\n&quot;, db2)\tfmt.Printf(&quot;%p\\n&quot;, db3)&#125;\n\n创建型模式-简单工厂模式目标是将对象的创建和使用分离，解耦合\n简单工厂模式：一个工厂类负责创建所有产品，通过条件判断来决定创建哪种产品。\n简单工厂并不是正式的设计模式，而是一种编程习惯。（所以有23种设计模式，和24种设计模式两种说法）\npackage factory_paytype Pay interface &#123;\tPayPage(price int64) (string, error)&#125;type AliPay struct&#123;&#125;func (p *AliPay) PayPage(price int64) (string, error) &#123;\treturn &quot;aliPay&quot;, nil&#125;type WexinPay struct&#123;&#125;func (p *WexinPay) PayPage(price int64) (string, error) &#123;\treturn &quot;wexinPay&quot;, nil&#125;type PayType int8const (\tAliPayType   = 1\tWexinPayType = 2)func NewPayPage(payType PayType) Pay &#123;\tswitch payType &#123;\tcase AliPayType:\t\treturn &amp;AliPay&#123;&#125;\tcase WexinPayType:\t\treturn &amp;WexinPay&#123;&#125;\t&#125;\treturn nil&#125;\n\n单测：\npackage factory_payimport (\t&quot;fmt&quot;\t&quot;testing&quot;)func TestNewPayPage(t *testing.T) &#123;\tpage, _ := NewPayPage(WexinPayType).PayPage(1)\tpayPage, _ := NewPayPage(AliPayType).PayPage(1)\tfmt.Println(page)\tfmt.Println(payPage)&#125;\n\n创建型模式-工厂方法模式工厂方法模式定义了一个创建对象接口，单具体的创建逻辑延迟到了子类种，每一个子类负责创建一种具体的产品\n特点：每个产品对应一个工厂类，符合开闭原则，新增产品只需要增加新的工厂类，无需修改现有代码。\n使用场景：产品种类较多，且创建逻辑复杂的场景。\npackage factory_methodtype Pay interface &#123;\tPayPage(price int64) (string, error)&#125;type AliPay struct&#123;&#125;func (p *AliPay) PayPage(price int64) (string, error) &#123;\treturn &quot;aliPay&quot;, nil&#125;type WexinPay struct&#123;&#125;func (p *WexinPay) PayPage(price int64) (string, error) &#123;\treturn &quot;wexinPay&quot;, nil&#125;type PayType int8const (\tAliPayType   = 1\tWexinPayType = 2)type PayFactory interface &#123;\tCreatePay() Pay&#125;type AliPayFactory struct&#123;&#125;func (p *AliPayFactory) CreatePay() Pay &#123;\t//xxxx\treturn &amp;AliPay&#123;&#125;&#125;type WexinPayFactory struct&#123;&#125;func (p *WexinPayFactory) CreatePay() Pay &#123;\t//xxx\treturn &amp;WexinPay&#123;&#125;&#125;\n\n\npackage factory_methodimport (\t&quot;fmt&quot;\t&quot;testing&quot;)func TestPayPage(t *testing.T) &#123;\taliPayFactory := AliPayFactory&#123;&#125;\taliPay := aliPayFactory.CreatePay()\tfmt.Println(aliPay.PayPage(1))\twexinPayFactory := WexinPayFactory&#123;&#125;\twexinPay := wexinPayFactory.CreatePay()\tfmt.Println(wexinPay.PayPage(1))&#125;\n使用确实麻烦了，但是修改微信支付，不会影响到其他支付。扩展新的支付方式更容易。\n创建型模式-抽象工厂模式每个工厂类可以创建一组相关产品，强调产品族的概念。\n使用场景：需要创建一组相关对象的场景。\npackage abstract_methodimport &quot;fmt&quot;type Pay interface &#123;\tPayPage(price int64) (string, error)&#125;type AliPay struct&#123;&#125;func (p *AliPay) PayPage(price int64) (string, error) &#123;\treturn &quot;aliPay&quot;, nil&#125;type WexinPay struct&#123;&#125;func (p *WexinPay) PayPage(price int64) (string, error) &#123;\treturn &quot;wexinPay&quot;, nil&#125;type PayType int8const (\tAliPayType   = 1\tWexinPayType = 2)type PayFactory interface &#123;\tCreatePay() Pay\tCreateRefund() Refund&#125;type AliPayFactory struct&#123;&#125;func (p *AliPayFactory) CreatePay() Pay &#123;\t//xxxx\treturn &amp;AliPay&#123;&#125;&#125;type WexinPayFactory struct&#123;&#125;func (p *WexinPayFactory) CreatePay() Pay &#123;\t//xxx\treturn &amp;WexinPay&#123;&#125;&#125;// 退款产品type Refund interface &#123;\tRefund(orderNo string) error&#125;type AliRefund struct&#123;&#125;func (p *AliRefund) Refund(orderNo string) error &#123;\tfmt.Println(&quot;ali 退款&quot;)\treturn nil&#125;type WexinRefund struct&#123;&#125;func (p *WexinRefund) Refund(orderNo string) error &#123;\tfmt.Println(&quot;wx 退款&quot;)\treturn nil&#125;func (p *AliPayFactory) CreateRefund() Refund &#123;\treturn &amp;AliRefund&#123;&#125;&#125;func (p *WexinPayFactory) CreateRefund() Refund &#123;\treturn &amp;WexinRefund&#123;&#125;&#125;\n\npackage abstract_methodimport (\t&quot;fmt&quot;\t&quot;testing&quot;)func TestPayPage(t *testing.T) &#123;\taliPayFactory := AliPayFactory&#123;&#125;\taliPay := aliPayFactory.CreatePay()\tfmt.Println(aliPay.PayPage(1))\taliPayFactory.CreateRefund().Refund(&quot;&quot;)\twexinPayFactory := WexinPayFactory&#123;&#125;\twexinPay := wexinPayFactory.CreatePay()\tfmt.Println(wexinPay.PayPage(1))\twexinPayFactory.CreateRefund().Refund(&quot;&quot;)&#125;\n\n创建型模式-建造者模式核心思想： 分步构建复杂对象。 将复杂对象的构建过程分离，分步。 体现单一职责\n适用场景：\n\n对象的构建过程复杂，包含多个步骤\n对象构建过程需要支持不通的配置\n\n比如要建立房子, 需要以下几个元素房子：最终制品建造规范：制定包工头需要符合的规范包工头：按照建造规范建，交付房子老板：告诉包工头建什么样的房子，获取房子\npackage builderimport &quot;fmt&quot;type House struct &#123;\tDoor   string\tWindow string&#125;// 建造规范，制定包工头需要符合的规范type HouseBuilder interface &#123;\tbuildDoor(val string)\tbuildWindow(val string)\tgetHouse() *House&#125;// 包工头负责，按照老板的要求建造房子，交付房子type Bao struct &#123;\thouse *House&#125;func (b *Bao) getHouse() *House &#123;\treturn b.house&#125;func (b *Bao) buildDoor(val string) &#123;\tb.house.Door = val\tfmt.Println(&quot;门建造成功&quot;)&#125;func (b *Bao) buildWindow(val string) &#123;\tb.house.Window = val\tfmt.Println(&quot;窗户建造成功&quot;)&#125;func NewBao() *Bao &#123;\treturn &amp;Bao&#123;\t\thouse: &amp;House&#123;&#125;,\t&#125;&#125;// 老板负责管理包工头，负责告诉包工头建造怎么样的房子type Boss struct &#123;\tbuilder HouseBuilder&#125;func NewBoss(bao *Bao) *Boss &#123;\treturn &amp;Boss&#123;\t\tbuilder: bao,\t&#125;&#125;func (b *Boss) GetHouse() *House &#123;\tb.builder.buildDoor(&quot;dor&quot;)\tb.builder.buildWindow(&quot;win&quot;)\treturn b.builder.getHouse()&#125;\n\npackage builderimport (\t&quot;fmt&quot;\t&quot;testing&quot;)func TestNewBao(t *testing.T) &#123;\tb := NewBao()\tboss := NewBoss(b)\tfmt.Println(boss.GetHouse())&#125;\n\n创建型模式-原型模式通过复制现有对象来创建新对象，而不是通过新建类的方式。\n避免重复初始化，特别适用于创建成本较高的对象。\n局限：如果遇到应用类型，需要考虑深拷贝浅拷贝\npackage prototypetype Prototype interface &#123;\tClone() Prototype&#125;type Student struct &#123;\tName string\tAge  int&#125;func (s *Student) Clone() Prototype &#123;\treturn &amp;Student&#123;\t\tName: s.Name,\t\tAge:  s.Age,\t&#125;&#125;\n\npackage prototypeimport (\t&quot;fmt&quot;\t&quot;testing&quot;)func TestStudent_Clone(t *testing.T) &#123;\ts1 := Student&#123;\t\tName: &quot;xxx&quot;,\t\tAge:  18,\t&#125;\ts2 := s1.Clone().(*Student)\ts2.Name = &quot;yyyy&quot;\ts2.Age = 111\tfmt.Println(s1)\tfmt.Println(s2)&#125;\n","categories":["总结笔记"],"tags":["Go","Singleton","Simple Factory","Factory Method","Abstract Factory","Builder","Prototype"]},{"title":"Go实现端口扫描","url":"/2023_12_27_go_scan_port/","content":"端口扫描基本原理\n向目标主机的某个端口，发送建立链接的请求，如果对方开放了这个端口，就会响应；如果没有没开放，则不会响应。\n\n根据这个原理，向一些常用的端口逐个建立链接，就能知道对方开放了哪些端口。\n\n\n端口扫描方法TelnetWindows系统自带的 Telnet 命令，可以用来探测目标主机的端口是否开放。\n格式：\ntelnet IP 端口\nNmapnmap -sV -p 1-65535 206.119.105.9\n\nMasscanmasscan -p 0-65535 206.119.105.9\n几种扫描工具的原理和区别\nTelnet 使用完整的三次握手建立链接，常用于单个端口的测试。\nMasscan 只发送SYN包，如果对方返回 ACK+SYN 就说明端口开放。\nNmap 默认使用SYN扫描，可以通过修改参数来修改扫描的方式。\n\n端口扫描分类完全链接扫描使用TCP三次握手建立一次完整的链接，从系统调用 connect()开始，端口开放则建立链接，端口不开放则返回-1。\n\n半链接扫描就是我们常说的SYN扫描，只建立TCP的前两次链接，发送一个SYN后，就停止建立链接，等待对方的响应。如果返回一个ACK，就说明端口开放；如果返回一个RESET，就说明端口没开放。\n\ngo实现端口扫描在Go中,我们通常使用net.Dial进行TCP连接。它就两种情况成功:返回conn，失败:err !&#x3D; nil。\n单线程版本// 扫描440到450的端口打开情况package mainimport (\t&quot;fmt&quot;\t&quot;net&quot;)func main() &#123;\tvar ip = &quot;127.0.0.1&quot;\tfor i := 440; i &lt;= 450; i++ &#123;\t\tvar address = fmt.Sprintf(&quot;%s:%d&quot;, ip, i)\t\tconn, err := net.Dial(&quot;tcp&quot;, address)\t\tif err != nil &#123;\t\t\tfmt.Println(address, &quot;是关闭的&quot;)\t\t\tcontinue\t\t&#125;\t\tconn.Close()\t\tfmt.Println(address, &quot;打开&quot;)\t&#125;&#125;\n\n多线程版本package mainimport (\t&quot;fmt&quot;\t&quot;net&quot;\t&quot;sync&quot;\t&quot;time&quot;)func main() &#123;\tvar begin = time.Now()\t//wg\tvar wg sync.WaitGroup\t//ip\tvar ip = &quot;127.0.0.1&quot;\t//var ip = &quot;192.168.43.34&quot;\t//循环\tfor j := 21; j &lt;= 1000; j++ &#123;\t\t//添加wg\t\twg.Add(1)\t\tgo func(i int) &#123;\t\t\t//释放wg\t\t\tdefer wg.Done()\t\t\tvar address = fmt.Sprintf(&quot;%s:%d&quot;, ip, i)\t\t\t//conn, err := net.DialTimeout(&quot;tcp&quot;, address, time.Second*10)\t\t\tconn, err := net.Dial(&quot;tcp&quot;, address)\t\t\tif err != nil &#123;\t\t\t\t//fmt.Println(address, &quot;是关闭的&quot;, err)\t\t\t\treturn\t\t\t&#125;\t\t\tconn.Close()\t\t\tfmt.Println(address, &quot;打开&quot;)\t\t&#125;(j)\t&#125;\t//等待wg\twg.Wait()\tvar elapseTime = time.Now().Sub(begin)\tfmt.Println(&quot;耗时:&quot;, elapseTime)&#125;\n\n线程池版本package main//线程池方式import (\t&quot;fmt&quot;\t&quot;net&quot;\t&quot;sync&quot;\t&quot;time&quot;\t&quot;github.com/loveleshsharma/gohive&quot;)//wgvar wg sync.WaitGroup//地址管道,100容量var addressChan = make(chan string, 100)type Worker struct &#123;&#125;func (s Worker) Run() &#123;\tworker()&#125;//工人func worker() &#123;\t//函数结束释放连接\tdefer wg.Done()\tfor &#123;\t\taddress, ok := &lt;-addressChan\t\tif !ok &#123;\t\t\tbreak\t\t&#125;\t\t//fmt.Println(&quot;address:&quot;, address)\t\tconn, err := net.Dial(&quot;tcp&quot;, address)\t\t//conn, err := net.DialTimeout(&quot;tcp&quot;, address, 10)\t\tif err != nil &#123;\t\t\t//fmt.Println(&quot;close:&quot;, address, err)\t\t\tcontinue\t\t&#125;\t\tconn.Close()\t\tfmt.Println(&quot;open:&quot;, address)\t&#125;&#125;func main() &#123;\tvar begin = time.Now()\t//ip\tvar ip = &quot;127.0.0.1&quot;\t//线程池大小\tvar pool_size = 10000\tvar pool = gohive.NewFixedPool(pool_size)\t//拼接ip:端口\t//启动一个线程,用于生成ip:port,并且存放到地址管道种\tgo func() &#123;\t\tfor port := 1; port &lt;= 60000; port++ &#123;\t\t\tvar address = fmt.Sprintf(&quot;%s:%d&quot;, ip, port)\t\t\t//将address添加到地址管道\t\t\t//fmt.Println(&quot;&lt;-:&quot;,address)\t\t\taddressChan &lt;- address\t\t&#125;\t\t//发送完关闭 addressChan 管道\t\tclose(addressChan)\t&#125;()\t//启动pool_size工人,处理addressChan种的每个地址\tfor work := 0; work &lt; pool_size; work++ &#123;\t\twg.Add(1)\t\tpool.Submit(Worker&#123;&#125;)\t&#125;\t//等待结束\twg.Wait()\t//计算时间\tvar elapseTime = time.Now().Sub(begin)\tfmt.Println(&quot;耗时:&quot;, elapseTime)&#125;\n\n","categories":["应用笔记"],"tags":["Go","端口扫描"]},{"title":"Docker安装Hexo编译环境","url":"/2023_12_26_docker_hexo/","content":"hexo编译打包静态页面需要依赖node，npm等环境，为了不污染本地环境，考虑用docker拉取ubuntu来搭建hexo编译环境，用来编译博客，以下记录详细过程。\n// 拉取镜像，运行镜像，并进入docker pull ubuntu:22.04docker run -it -p 4000:4000 -v $PWD/data:/home -p 22:22 --name ubuntu -d ubuntu:22.04docker exec -it ubuntu bash\n\n//更新包，安装nodejs, 安装 npm  安装vimapt-get updateapt-get install nodejsroot@5890065e0c87:/home/hexo-blog# node -vv12.22.9apt-get install npmroot@5890065e0c87:/home/hexo-blog# npm -v8.5.1root@5890065e0c87:/home/hexo-blog# npm installapt install vim\n\n// hexo 找不到命令，写一下环境变量vim ~/.bashrc# 在最后一行加上export PATH=$PATH:/home/hexo-blog/node_modules/hexo/bin#重新加载当前用户的 bashrc 文件source ~/.bashrc\n\n// 启动博客服务root@5890065e0c87:/home/hexo-blog# hexo sINFO  Validating configINFO  Start processingINFO  Hexo is running at http://localhost:4000 . Press Ctrl+C to stop.","categories":["应用笔记"],"tags":["Docker","Hexo"]},{"title":"Java 9 ~ Java 21 的新特性","url":"/2023_12_30_java/","content":"学习必须往深处挖，挖的越深，基础越扎实！\nJava 现在发布的版本很快，每年两个，但是真正会被大规模使用的是 3 年一个的 LTS 版本。\n每 3 年发布一个 LTS（Long-Term Support），长期维护版本。意味着只有Java 8 ，Java 11， Java 17，Java 21 才可能被大规模使用。\n每年发布两个正式版本，分别是 3 月份和 9 月份。\n在 Java 版本中，一个特性的发布都会经历孵化阶段、预览阶段和正式版本。其中孵化和预览可能会跨越多个 Java 版本。所以在介绍 Java 新特性时采用如下这种策略：\n\n每个版本的新特性，都会做一个简单的概述。\n单独出文介绍跟编码相关的新特性，一些如 JVM、性能优化的新特性不单独出文介绍。\n孵化阶段的新特性不出文介绍。\n首次引入为预览特性、新特性增强、首次引入的正式特性，单独出文做详细介绍。\n影响比较大的新特性如果在现阶段没有转正的新特性不单独出文介绍，单独出文的重大特性一般都在 Java 21 版本之前已转为正式特性，例如：\n虚拟线程，Java 19 引入的，在 Java 21 转正，所以在 Java 19 单独出文做详细介绍\n作用域值，Java 20 引入的，但是在 Java 21 还处于预览阶段，所以不做介绍，等将来转正后会详细介绍\n\n\n\nJava 9 新特性JEP 261: 模块系统JEP 269: 集合工厂方法：新增只读集合和工厂方法JEP 222：REPL 工具：JSheel 命令JEP 213：接口支持私有方法Stream API 增强Optional 的增强改进 try-with-resourcesJEP 102：Process APIJEP 264：平台日志 API 和 服务JEP 266: 反应式流（Reactive Streams）JEP 224: HTML5 JavadocJEP 238: 多版本兼容 JAR 文件JEP 277：改进的弃用注解 @DeprecatedJEP 213：改进钻石操作符(Diamond Operator)增强 CompletableFutureJava 10 新特性JEP 286：局部变量类型推断JEP 304：统一的垃圾回收接口JEP 307：并行全垃圾回收器 G1JEP 310：应用程序类数据共享JEP 312：线程-局部变量管控JEP 313：移除 Native-Header 自动生成工具JEP 314：额外的 Unicode 语言标签扩展JEP 316：备用存储装置上的堆分配JEP 317：基于 Java 的 实验性 JIT 编译器JEP 319：根证书认证JEP 322：基于时间的版本发布模式新增 APIJava 11 新特性JEP 181: 基于嵌套的访问控制新增 String APIJEP 321：全新的 HTTP 客户端 APIJEP 323：局部变量类型推断的增强JEP 318：Epsilon—低开销垃圾回收器ZGC：可伸缩低延迟垃圾收集器JEP 335：废弃 Nashorn JavaScript 引擎增加 Files APIOptional API 增强JEP 328：飞行记录器（Flight Recorder）JEP 330：运行单文件源码程序JEP 320：删除 Java EE 和 corba 模块Java 12 新特性JEP 189：Shenandoah 垃圾收集器（预览特性）JEP 325：Switch 表达式（预览特性）JEP 334：JVM 常量 APIJEP 230：微基准测试套件（JMH）的支持新增 String API新增 Files API新增 NumberFormat API新增 Collectors APIJEP 340：移除多余ARM64实现JEP 341：默认CDS归档JEP 344：G1的可中断 mixed GCJava 13 新特性JEP 354：增强 Switch 表达式（第二次预览）JEP 355：文本块（预览特性）JEP 353：重构 Socket APIJEP 350：动态 CDSJEP 351：增强 ZGC 释放未使用内存Java 14 新特性JEP 361：表达式（正式特性）JEP 368：增强文本块（第二次预览）JEP 359：Records (预览)JEP 305：模式匹配的 instanceof（预览）JEP 358：改进 NullPointerExceptions 提示信息JEP 343：打包工具（孵化）JEP 345：NUMA-Aware 内存分配JEP 349：JFR Event StreamingJEP 364：macOS 上的 ZGC（实验性）JEP 365：Windows 上的 ZGC（实验性）JEP 366：弃用 ParallelScavenge + SerialOld GC 组合JEP 367：删除 Pack200 工具和 APIJEP 363：删除 CMS 垃圾收集器JEP 370：外部存储器访问 API（孵化器版）Java 15 新特性JEP 339：Edwards-Curve 数字签名算法 (EdDSA)JEP 360：密封的类和接口（预览）：Java 15 新特性—密封的类与接口JEP 371：隐藏类 Hidden Classes：Java 15 新特性—隐藏类JEP 372：移除 Nashorn JavaScript 引擎JEP 373：重新实现 DatagramSocket APIJEP 374：禁用偏向锁定JEP 375：模式匹配的 instanceof（第二次预览）JEP 377：ZGC—可伸缩低延迟垃圾收集器（正式特性）JEP 378：文本块（正式特性）JEP 379：Shenandoah—低暂停时间垃圾收集器（正式特性）JEP 381：移除 Solaris 和 SPARC 支持JEP 383：外部存储器访问 API （二次孵化器版）JEP 384：Record (第二次预览)JEP 385：废除 RMI 激活Java 16 新特性JEP 338：向量 API（孵化器）JEP 347：启用 C++14 语言特性JEP 357：将JDK的源代码库从Mercurial迁移到GitJEP 369：将JDK的源代码库托管到GitHubJEP 376：ZGC 并发线程处理JEP 380：Unix-Domain 套接字通道JEP 386：AlpineLinux 移植JEP 387：弹性元空间JEP 388：Windows&#x2F;AArch64 移植JEP 389：外部函数与内存 API（孵化器）JEP 390：对基于值的类发出警告JEP 392：打包工具（正式版）JEP 393：外部存储器访问 API（第三次孵化）JEP 394：instanceof 模式匹配（正式特性）JEP 395：Records (正式特性)JEP 396：默认强封装 JDK 内部元素JEP 397：密封类（第二预览）\nJava 17 新特性JEP 356：增强型伪随机数生成器：Java 17 新特性—增强型伪随机数生成器JEP 382：新的 macOS 渲染管线JEP 391：macOS&#x2F;AArch64 端口JEP 398：移除 Applet APIJEP 406：模式匹配的 Swith 表达式（预览）：Java 17 新特性—模式匹配的 Swith 表达式JEP 407：删除 RMI 激活JEP 409：密封类（正式特性）JEP 410：移除实验性的 AOT 和 JIT 编译JEP 411：废弃安全管理器JEP 412：外部函数与内存 API（第二次孵化）JEP 414：向量 API（第二次孵化）\nJava 18 新特性JEP 400：默认UTF-8编码JEP 408：简易Web服务器JEP 413：支持在 Java API 文档中加入代码片段JEP 416：用方法句柄重新实现核心反射JEP 417：向量 API（第三孵化器）JEP 418：互联网地址解析 SPIJEP 419：外部函数和内存 API（第三孵化器）JEP 420：模式匹配 Switch 表达式（预览）JEP 421：弃用 Finalization 功能\nJava 19 新特性JEP 405：Record模式（预览）：Java 19 新特性—Record模式JEP 422：JDK移植到Linux&#x2F;RISC-VJEP 424：外部函数和内存API（预览）JEP 425：虚拟线程（预览）：Java 19 新特性—虚拟线程JEP 426：向量API（第四次孵化）JEP 427：模式匹配的 Switch（第三次预览）JEP 428：结构化并发（孵化功能）\nJava 20 新特性JEP 429：作用域值（第一次孵化）JEP 432：Record 模式（第二次预览）JEP 433：模式匹配的 Switch 表达式（第四次预览）JEP 434：外部函数与内存 API（第二次预览）JEP 436：虚拟线程（第二次预览）JEP 437：结构化并发（第二次孵化）JEP 438：向量 API（第五次孵化）\nJava 21 新特性JEP 430：字符串模板 （预览）：Java 21 新特性—字符串模板JEP 431：有序集合：Java 21 新特性—有序集合JEP 439：分代 ZGCJEP 440：Record 模式JEP 441：switch 模式匹配JEP 442：外部函数和内存 API （第三次预览）JEP 443：未命名模式和变量 （预览）：Java 21 新特性—未命名模式和变量JEP 444：虚拟线程（正式特性）JEP 445：未命名类和 main 方法 （预览）：Java 21 新特性—未命名类和 main 方法JEP 446：作用域值 （预览）JEP 448：向量 API（第六次孵化）JEP 449：弃用 Windows 32 位 x86 端口JEP 451：准备禁止动态加载代理JEP 452：密钥封装机制 API  安全库JEP 453：结构化并发（预览）\n","categories":["总结笔记"],"tags":["Java","Java9","Java10"]},{"title":"go-swagger-api应用","url":"/2024_05_17_go_swagger/","content":"该项目包含Swagger 2.0的golang实现 (又名OpenAPI 2.0)。 它提供了与swagger规范一起工作的工具。\nswagger 是RESTful API的简单而强大的实现。\ngithub：https://github.com/go-swagger/go-swagger\n文档：https://goswagger.io/go-swagger/\n聊聊Swagger拥有全球最大的API工具生态系统，几乎所有现代编程语言和部署环境中都支持Swagger。\n使用支持Swagger的API，您可以获得交互式文档、生成客户端SDK和发现服务。\nSwagger帮助Apigee，Getty Images，Intuit，LivingSocial，McKesson，Microsoft，Morningstar和PayPal等公司使用RESTful api构建最佳服务。现在在2.0版本中，Swagger比以往任何时候都更加易用。它是完全开源的软件。\n特点go-swagger为go社区带来了一整套功能齐全、高性能的API组件，可与Swagger API配合使用: 开发服务端、客户端和数据模型。\n\n按照swagger规范生成服务端代码\n按照swagger规范生成客户端代码\n按照swagger规范 (alpha阶段) 生成CLI (命令行工具)\n支持jsonschema和swagger提供的大多数功能，包括多态\n从带注释的go代码生成swagger规范\n使用swagger规范的其他工具\n出色的自定义功能，具有自带的扩展和可自定义的模板\n\n我们对代码生成的理念是：生成惯用的，快速的go代码，它与golint，go vet等兼容得很好。\n安装从源安装按章支持命令，docker，源安装，这里只记录下我用源码安装的操作。\n&gt; go versiongo version go1.23.1 windows/amd64&gt; go install github.com/go-swagger/go-swagger/cmd/swagger@latest...&gt; swagger.exe versionversion: v0.31.0# 查看环境变量&gt; go env# 找到 GOPATHGOPATH=C:\\Users\\hxd\\go# 进入目录，可以看到 swagger.exe 可执行文件，已经安装到gopath了# 后续这个二进制可执行文件可以拷贝到项目中使用，统一版本避免版本问题\nswagger工具说明：\nUsage:  swagger [OPTIONS] &lt;command&gt;Swagger tries to support you as best as possible when building APIs.It aims to represent the contract of your API with a language agnostic description of your application in json or yaml.Application Options:  -q, --quiet                  silence logs      --log-output=LOG-FILE    redirect logs to fileHelp Options:  -h, --help                   Show this help messageAvailable commands:  diff      diff swagger documents  expand    expand $ref fields in a swagger spec  flatten   flattens a swagger document  generate  generate go code  init      initialize a spec document  mixin     merge swagger documents  serve     serve spec and docs  validate  validate the swagger document  version   print the version\n具体怎么用可以参考官网。\n生成服务端参考：https://goswagger.io/go-swagger/generate/server/\n# 生成描述文件swagger.exe init spec# 初始化go modgo mod init mlss-cc-service# git初始化git init\n如图，我新建了一个项目，按照这个目录来构建应用\n把swagger.exe放到项目里，编写好swagger.yaml  执行swagger生成代码\n.\\pkg\\restapi\\swagger\\swagger.exe generate server -m ../models -f .\\pkg\\restapi\\swagger\\swagger.yaml -t .\\pkg\\restapi\n\n新建启动文件，启动：\nD:\\goworkspace\\mlss-cc-service&gt; cd .\\cmd\\mlss-cc-go\\     PS D:\\goworkspace\\mlss-cc-service\\cmd\\mlss-cc-go&gt; ls    目录: D:\\goworkspace\\mlss-cc-service\\cmd\\mlss-cc-goMode                 LastWriteTime         Length Name----                 -------------         ------ -----a----         2024/3/26     16:34           1356 main.goPS D:\\goworkspace\\mlss-cc-service\\cmd\\mlss-cc-go&gt; go run .\\main.goServing open API swagger at http://127.0.0.1:56434\n已经开源到仓库https://gitee.com/deepter/mlss-cc-service\nhttps://gitee.com/deepter/mlss-cc-a\n服务端中间件再生成的可修改文件中，例如中，最后一个一个方法添加全局中间件：\n// The middleware configuration happens before anything, this middleware also applies to serving the swagger.json document.// So this is a good place to plug in a panic handling middleware, logging and metrics.func setupGlobalMiddleware(handler http.Handler) http.Handler &#123;\tlocateHandler := mv.NewLocateMiddleWare(handler)\tloginHandler := mv.NewLoginMiddleWare(locateHandler)\treturn loginHandler&#125;\n\nfunc NewLocateMiddleWare(handler http.Handler) http.Handler &#123;\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123;\t\tacceptLang := r.Header.Get(&quot;Accept-Language&quot;)\t\tlogger.Logger().Debugf(&quot;acceptLanguate: %v&quot;, acceptLang)\t\tctx := context.WithValue(r.Context(), &quot;lang&quot;, acceptLang)\t\t//继续下一个拦截器\t\thandler.ServeHTTP(w, r.WithContext(ctx))\t&#125;)&#125;func NewLoginMiddleWare(handler http.Handler) http.Handler &#123;\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123;\t\thandler.ServeHTTP(w, r.WithContext(context.Background()))\t&#125;)&#125;\n","categories":["应用笔记"],"tags":["Go","Swagger"]},{"title":"PostgreSQL数据库总结","url":"/2024_06_08_pg/","content":"PG简介posgreSQL 是一个免费的对象-关系数据库服务器（ORDBMS）。\nBSD许可证。（可以基于开源版本二次开发，可以不开源使用。 mysql的GPL是二开之后必须也开源）\npostgreSQL 的 Slogan 是： “世界上最先进的开源关系型数据库”。\n“开源界的Oracle”，  是去O（oracle）的首选.\nmysql 已经被oracle收购了。\n官网：https://www.postgresql.org/\n中文社区： http://www.postgres.cn/index.php/v2/home\n全球数据库排行： https://db-engines.com/en/\n中国数据库排行： https://www.modb.pro/dbRank部分是基于pg二开的。\n历史沿革最初设想于1986年， 当时被叫做Berkley Postgres Project。教学用。\nPostgre95在开源社区开放。\n1996年， postgresSQL6.0发布。\n2005年，发布8.0版本，开始支持windows系统环境。\npostgreSQL 9.0 发布， 支持64位windows系统，异步流数据复制， HostStandby;postgreSQL 9.1 发布， 支持数据同步复制，等特性\n目前笔者的生产环境版本是\nPostgreSQL 15.6 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44), 64-bit  \npg和mysql的比较pg相对于mysql优势\n在SQL的标准实现上要比MYSQL完善，而且功能实现比较严谨。\n\n对表连接支持较完整，优化器功能较完整，支持的索引类型多，复杂查询能力强。\n\npg主表采用堆表存放，mysql采用索引组织表，能够支持比mysql更大的数据量。\n\npg的主备复制属于物理复制，相对于mysql基于binlog的逻辑复制，数据的一致性更加可靠，复制性能更高，对主机性能影响更小。\n\npg支持json和其他noSQL功能，如本机xml支持和使用hstore的键值对，它还支持索引json数据加快访问速度，特别是10版本jsonb更是强大。\n\npg完全免费，bsd协议，如果你把pg拿去改一改，拿去卖钱也没人管你。 mysql虽然开源，但是bsd协议已经被oracle收购了，由oracle控制\n\n\nmysql相对于pg优势\ninnodb 是基于回滚段实现的mvcc机制，相对pg新老数据一起存放的基于xid的mvcc机制是占优势的，新老数据一起存放需要定时触发 vacuum， 会带来多余的io和数据库加锁开销，引起数据库整体并发能力下降。而且vacuum清理不及时，还可能英法数据膨胀。\n\nmysql采用索引组织表，这种存储方式非常适合基于主键匹配的查询，删改操作，但是对表结构设计存在约束。\n\nmysql的优化器比较简单，系统表，运算符，数据类型实现比较精简，非常适合简单的查询操作。\n\nmysql相对于pg在国内流行度更高。\n\nmysql的存储引擎插件化机制，是的它的应用更加广泛，比如除了innodb适合事务处理场景外，myisam适合静态数据查询场景。\n\n\n总结来说从应用场景上，pg更加适合严格的企业应用场景，比如金融，电信，ERP， CRM，但不仅限于此，pg的json， jsonb, hstore等数据格式，特别使用一些大数据格式的分析； 而mysql更加适合业务逻辑比较简单，数据可靠性要求较低的场景，比如google， facebook， alibaba等。当然现在mysql的innodb引擎大理发展，功能表现良好。\npg下载安装linux安装，参考官网，这里重点在于学习使用，所以这里不详细介绍。docker安装\ndocker pull postgres:14# 创建映射目录mkdir postgresql/data # 启动容器docker run -d -p 5432:5432 -e POSTGRES_PASSWORD=123456 --name postgres postgres:14docker run -d -p 5432:5432 -v $(pwd)/postgresql/data:/var/lib/postgresql/data -e POSTGRES_PASSWORD=123456 --name postgres postgres:14 # 修改配置文件/data/postgresql/data/postgresql.conf# 设置时区timezone = &#x27;Asia/Shanghai&#x27;# 连接数max_connections = 1000\n\n使用dbeaver可以连接：\n进去docker连接：\npsql -U postgres -d postgres -h 127.0.0.1 -p 5432##退出postgres=# \\q## 创建库postgres=# create database mydb;CREATE DATABASE## 切换数据库postgres=# \\c mydbYou are now connected to database &quot;mydb&quot; as user &quot;postgres&quot;.## 删除drop\n\npg数据类型三类常见的：\n\n数值类型smallint 2字节 -32768 到 32767integer 4字节 -2147483648 到 2147483647bigint 8字节 -9223372036854775808 到 9223372036854775807decimal 可变长 精确的十进制数值numeric 可变长 精确的十进制数值real 4字节 单精度浮点数double 8字节 双精度浮点数\n\n字符串类型char(n) 固定长度字符串，n为字符串长度varchar(n) 可变长度字符串，n为字符串长度text 变长字符串\n\n日期&#x2F;时间类型timestamp  日期和时间date 日期time 时间\n\n\n除此之外还有boolean，  money 和几何数据\ncreate table test(    id serial primary key,    name varchar(100),    age int,    created_at timestamp);insert into test(name, age, created_at) values(&#x27;jack&#x27;, 18, now()), (&#x27;marry&#x27;, 19, now()), (&#x27;tom&#x27;, 20, now());-- 创建schemacreate schema myschema;-- 备份pg_dump mydb &gt; mydb.bak","categories":["总结笔记"],"tags":["Postgresql","数据库","PG"]},{"title":"DeepSeek+Dify 工作流","url":"/2025_02_10_deepseek_dify/","content":"Deepseek是杭州深度求索公司开发的大语言模型，包含基础模型和代码模型。基础模型有7B和67B参数版本，7B版本在主流英文和中文基准测试中表现出色；67B版本则在多个基准测试中优于GPT-3.5 Turbo。代码模型有1.3B、7B和67B三种参数规模，在多个代码评测基准上有卓越表现，如7B代码模型在HumanEval基准测试中以65%的通过率超越GPT-3.5 Turbo，67B代码模型以82.7%的通过率超越GPT-4。\nDify 是一款开源的大语言模型(LLM) 应用开发平台。它融合了后端即服务（Backend as Service）和 LLMOps 的理念，使开发者可以快速搭建生产级的生成式 AI 应用。即使你是非技术人员，也能参与到 AI 应用的定义和数据运营过程中。\nDify最牛的地方就是像搭积木一样简单——不用懂代码，普通人稍微学学就能用它的「智能机器人」和「流程图」功能，自己拼出一套自动化工具。比如自动回复客户、处理文件这些事，你拖拖拽拽就能搭出想要的功能，特别适合折腾些好玩的小发明。我们可以通过智能体或工作流，自定义工具完成很多我们好玩的功能。报文篇幅较长，简单说下内容：从0开始创建一个票务识别智能体；介绍搭建过程中的各个细节；教会你每一步为什么，而不是只是完成；通过实践这个流程，我相信你可以学会自己搭建自己需要的智能体。\ndeepseek私有化部署\n首先下载并安装Ollama参考官网即可https://ollama.com/\n\n安装deepseek打开Ollama官网首页，在搜索框里输入deepseek-r1，你会发现这个模型排在第一个位置，热度相当高。模型有多个版本，比如1.5b、7b、8b等，数字越大，模型越强大，但对硬件要求也越高。\n\n\n根据你的电脑配置选择合适的模型版本。一般来说，8b是一个比较平衡的选择，既能保证性能，又不会对硬件要求太高。如果你有高性能显卡，当然可以选择更大的模型。笔者显卡是4070super。由于硬盘容量不足，部署的7B版本。\nollama run deepseek-r1:7b\n这个过程类似于Docker拉取镜像，耐心等待即可。安装完成就自动启动了。\ndify安装部署笔者是windows系统，已经安装了docker desktop。\n然后直接访问它的GitHub仓库（https://github.com/langgenius/dify），获取最新版本。解压缩后，进入项目根目录，找到docker文件夹。\n拉取镜像并启动\ndocker compose up -d\n安装完之后，查看：\n初始化：在浏览器地址栏输入以下地址：\nhttp://127.0.0.1/install\n按照提示完成安装并登录账号，进入Dify的主页。\n\n关联本地大模型与Dify\n\n界面界面如下：\n\n新建智能体（工作流）\n\n智能体配置\n\n开始,可以配置入参，文件，图片等 \n节点类型  \n比如python代码节点\n配置python代码\n\n\n提供对外接口\n\napi调用\n\n\n可以实现什么功能\n自定义工作流，解决重复流程问题\n二次开发更复杂能力的节点，实现个性化方案\n对外提供服务，监控服务\n创建智能体应用\n\n最重要的点\n要会用提示词\n\n附录：根据提供的智能体学习智能体首页提供了很多智能体，可以添加到工作空间，学习每个节点组件怎么使用\n附录：dify结构梳理\napi服务\n\nworker服务\n\nweb服务\n\ndb-postgresql服务\n\nredis服务\n\nsandbox服务\n\nplugin_daemon服务\n\nssrf_proxy服务\n\ncertbot服务\n\n网络\n\n\n","categories":["应用笔记"],"tags":["Deepseek","AI","Dify"]},{"title":"一条长江，半部华夏文明史","url":"/2025_03_01_the_long_river/","content":"一、长江概况\n长江是世界第三大长河，且是中国独有的河流\n尼罗河跨越9个国家\n亚马逊河跨越8个国家\n长江仅流经中国\n\n\n\n\n二、长江源头与上游\n长江源头：青海唐古拉山沱沱河\n\n沱沱河冰川水是长江的源头\n下一站是通天河，即《西游记》八十一难最后一难”通天河遇鼋湿经书”的发生地\n\n\n三江源地区\n\n长江、黄河、澜沧江的源头交汇处\n澜沧江即湄公河，在云南形成”三江并流”奇观\n\n\n\n\n\n\n\n金沙江段\n长江在云南段称为金沙江\n著名景点：云南迪庆雨崩村、玉龙雪山、虎跳峡（长江第一大峡谷）\n\n\n\n三、长江中游与支流\n主要支流交汇城市\n\n攀枝花：长江与雅砻江交汇\n宜宾：长江与岷江交汇，被称为”万里长江第一城”\n重庆：长江与嘉陵江交汇，朝天门为古城门\n涪陵：长江与乌江交汇\n\n\n三峡地区\n\n白帝城：李白”朝辞白帝彩云间”的出处\n三峡大坝：瞿塘峡、巫峡、西陵峡\n屈原故里：秭归\n武汉：黄鹤楼所在地，和汉江的交汇处\n\n\n\n\n\n鄂州：长江中游\n\n\n四、长江下游与文明\n重要城市与湖泊\n\n荆州：楚国故都，屈原《离骚》创作地， 曾经沧海难为水，除却巫山不是云，写的荆州巫山\n洞庭湖：中国第二大淡水湖，岳阳楼所在地\n鄱阳湖：朱元璋与陈友谅决战之地\n\n\n江南三大名楼\n\n岳阳楼：范仲淹”先天下之忧而忧，后天下之乐而乐”\n黄鹤楼：李白”故人西辞黄鹤楼，烟花三月下扬州”\n滕王阁：王勃”落霞与孤鹜齐飞，秋水共长天一色”\n\n\n文化名人\n\n陶渊明：九江人，”采菊东篱下，悠然见南山” “山气日夕佳，飞鸟相与还” 南山就是庐山\n白居易：被贬江州，写下《琵琶行》\n苏轼：题西林壁”不识庐山真面目，只缘身在此山中”\n诸葛亮：古隆中再汉江边上\n\n\n\n五、长江三角洲\n南京：六朝古都，金陵文化中心\n长三角城市群：扬州、镇江、无锡、苏州、南通\n上海：长江入海口，现代化大都市\n\n","categories":["人文地理"],"tags":["长江"]},{"title":"Java线程总结","url":"/2017_07_03_java_thread/","content":"什么是线程？线程是进程的一个实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器，一组寄存器和栈)，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。\n有时候我们说线程是轻量级进程。就象进程一样，线程在程序中是独立的、并发的执行路径，每个线程有它自己的堆栈、自己的程序计数器和自己的局部变量。但是，与分隔的进程相比，进程中的线程之间的隔离程度要小。它们共享内存、文件句柄和其它每个进程应有的状态。\nJava语言是第一个在语言本身中显式地包含线程的主流编程语言，它没有把线程化看作是底层操作系统的工具。\n为什么要用线程？\n响应更快的 UI（如GUI中事件线程）\n利用多处理器系统（单处理器多线程本质是处理器的短时间间隔复用，多处理器多线程就可以高效使用多处理器系统）\n简化建模（比如五大常用算法中的分治法，求多维数组的排序问题，多线程可以简化建模）\n异步或后台处理（这个很常见，比如轮询套接字，异步响应请求，servlet请求等等）\n\n一个简单线程：一个计时线程案例\n/*** 一个线程案例： （计时功能）* 主线程开启一个打印素数的线程之后，主线程自己休息10秒，* 10秒之后通过改变finished状态值，break新线程。*/public class CalculatePrimes extends Thread&#123;    public static final int MAX_PRIMES = 1000000;    public static final int TEN_SECONDS = 10000;    public volatile boolean finished = false;    public void run()&#123;        int[] primes = new int[MAX_PRIMES];        int count = 0;        for (int i=2; count&lt;MAX_PRIMES; i++)&#123;            // Check to see if the timer has expired            if (finished) &#123;            break;            &#125;            boolean prime = true;            for (int j=0; j&lt;count; j++)&#123;                if (i % primes[j] == 0)&#123;                    prime = false;                    break;                &#125;            &#125;            if (prime)&#123;                primes[count++] = i;                System.out.println(&quot;Found prime: &quot; + i);            &#125;        &#125;    &#125;    public static void main(String[] args)&#123;        CalculatePrimes calculator = new CalculatePrimes();        calculator.start();        try &#123;            Thread.sleep(TEN_SECONDS);        &#125;        catch (InterruptedException e)&#123;            // fall through        &#125;        calculator.finished = true;    &#125;&#125;\n\n线程的使用方法生命周期5状态说起\n新建（new Thread）当创建Thread类的一个实例（对象）时，此线程进入新建状态（未被启动）。例如：Thread  t1&#x3D;new Thread();\n就绪（runnable）线程已经被启动，正在等待被分配给CPU时间片，也就是说此时线程正在就绪队列中排队等候得到CPU资源。例如：t1.start();\n运行（running）线程获得CPU资源正在执行任务（run()方法），此时除非此线程自动放弃CPU资源或者有优先级更高的线程进入，线程将一直运行到结束。\n死亡（dead）当线程执行完毕或被其它线程杀死，线程就进入死亡状态，这时线程不可能再进入就绪状态等待执行。自然终止：正常运行run()方法后终止异常终止：调用stop()方法让一个线程终止运行\n堵塞（blocked）由于某种原因导致正在运行的线程让出CPU并暂停自己的执行，即进入堵塞状态。正在睡眠：用sleep(longt)方法可使线程进入睡眠方式。一个睡眠着的线程在指定的时间过去可进入就绪状态。正在等待：调用wait()方法。（调用motify()方法回到就绪状态）被另一个线程所阻塞：调用suspend()方法。（调用resume()方法恢复）\n\n三种创建线程的方法1.继承Thread类创建线程类（1）定义Thread类的子类，并重写该类的run方法，该run方法的方法体就代表了线程要完成的任务。因此把run()方法称为执行体。（2）创建Thread子类的实例，即创建了线程对象。（3）调用线程对象的start()方法来启动该线程。\npublic class FirstThreadTest extends Thread&#123;    int i = 0;    //重写run方法，run方法的方法体就是现场执行体    public void run()&#123;        for(;i&lt;100;i++)&#123;        System.out.println(getName()+&quot;  &quot;+i);        &#125;    &#125;    public static void main(String[] args)&#123;        for(int i = 0;i&lt; 100;i++)&#123;            System.out.println(Thread.currentThread().getName()+&quot;  : &quot;+i);            if(i==20)&#123;                new FirstThreadTest().start();                new FirstThreadTest().start();            &#125;        &#125;    &#125;&#125;\n2.通过Runnable接口创建线程类（1）定义runnable接口的实现类，并重写该接口的run()方法，该run()方法的方法体同样是该线程的线程执行体。（2）创建 Runnable实现类的实例，并依此实例作为Thread的target来创建Thread，该Thread对象才是真正的线程对象。（3）调用线程对象的start()方法来启动该线程。\npublic class RunnableThreadTest implements Runnable&#123;    private int i;    public void run()&#123;        for(i = 0;i &lt;100;i++)&#123;            System.out.println(Thread.currentThread().getName()+&quot; &quot;+i);        &#125;    &#125;    public static void main(String[] args)&#123;        for(int i = 0;i &lt; 100;i++)&#123;            System.out.println(Thread.currentThread().getName()+&quot; &quot;+i);            if(i==20)&#123;                RunnableThreadTest rtt = new RunnableThreadTest();                new Thread(rtt,&quot;新线程1&quot;).start();                new Thread(rtt,&quot;新线程2&quot;).start();            &#125;        &#125;    &#125;&#125;\n3.通过Callable和Future创建线程（1）创建Callable接口的实现类，并实现call()方法，该call()方法将作为线程执行体，并且有返回值。（2）创建Callable实现类的实例，使用FutureTask类来包装Callable对象，该FutureTask对象封装了该Callable对象的call()方法的返回值。（3）使用FutureTask对象作为Thread对象的target创建并启动新线程。（4）调用FutureTask对象的get()方法来获得子线程执行结束后的返回值。\nimport java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask;public class CallableThreadTest implements Callable&lt;Integer&gt;&#123;    @Override    public Integer call() throws Exception&#123;        int i = 0;        for(;i&lt;100;i++)&#123;            System.out.println(Thread.currentThread().getName()+&quot; &quot;+i);        &#125;        return i;    &#125;    public static void main(String[] args)&#123;        CallableThreadTest ctt = new CallableThreadTest();        FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(ctt);        for(int i = 0;i &lt; 100;i++)&#123;            System.out.println(Thread.currentThread().getName()+&quot; 的循环变量i的值&quot;+i);            if(i==20)&#123;                new Thread(ft,&quot;有返回值的线程&quot;).start();            &#125;        &#125;        try&#123;            System.out.println(&quot;子线程的返回值：&quot;+ft.get());        &#125; catch (InterruptedException e)&#123;            e.printStackTrace();        &#125; catch (ExecutionException e)&#123;            e.printStackTrace();        &#125;    &#125;&#125;\n采用实现Runnable、Callable接口的方式创见多线程时，优势是：线程类只是实现了Runnable接口或Callable接口，还可以继承其他类。在这种方式下，多个线程可以共享同一个target对象，所以非常适合多个相同线程来处理同一份资源的情况，从而可以将CPU、代码和数据分开，形成清晰的模型，较好地体现了面向对象的思想。劣势是：编程稍微复杂，如果要访问当前线程，则必须使用Thread.currentThread()方法。\n使用继承Thread类的方式创建多线程时优势是：编写简单，如果需要访问当前线程，则无需使用Thread.currentThread()方法，直接使用this即可获得当前线程。劣势是：线程类已经继承了Thread类，所以不能再继承其他父类。\n一些常见API在介绍生命周期的时候，我们已经接触了一些常见API,建议直接看API文档JDK7-API-java.lang.Thread\n/**常用API**///几毫秒加几纳秒之后调用线程将阻塞，直到目标线程完成为止.调用线程继续。void join();void join(long millis);void join(long millis,int nanos);//继承Object.导致线程进入等待状态，直到它被其他线程通过notify()或者notifyAll唤醒。该方法只能在同步方法中调用。如果当前线程不是锁的持有者，该方法抛出一个IllegalMonitorStateException异常。void wait();void wait(long millis);void wait(long millis,int nanos);//随机选择一个在该对象上调用wait方法的线程，解除其阻塞状态。该方法只能在同步方法或同步块内部调用。如果当前线程不是锁的持有者，该方法抛出一个IllegalMonitorStateException异常。void notify();//解除所有那些在该对象上调用wait方法的线程的阻塞状态。该方法只能在同步方法或同步块内部调用。如果当前线程不是锁的持有者，该方法抛出一个IllegalMonitorStateException异常。void notifyAll();/**wait、notify和notifyAll方法是Object类的final native方法。所以这些方法不能被子类重写，Object类是所有类的超类，因此在程序中有以下三种形式调用wait等方法。wait();//方式1：this.wait();//方式2：super.wait();//方式3**///将使当前线程进入等待状态，直到过了一段指定时间，或者直到另一个线程对当前线程的Thread对象调用了Thread.interrupt()，从而中断了线程。//当过了指定时间后，线程又将变成可运行的，并且回到调度程序的可运行线程队列中。//如果线程是由对 Thread.interrupt() 的调用而中断的，那么休眠的线程会抛出InterruptedException，这样线程就知道它是由中断唤醒的，就不必查看计时器是否过期。static void sleep(long millis);static void sleep(long millis, int nanos);//中断发起调用的线程。void interrupt();//就像sleep() 一样，但它并不引起休眠，而只是暂停当前线程片刻，这样其它线程就可以运行了。//在大多数实现中，当较高优先级的线程调用Thread.yield() 时，较低优先级的线程就不会运行。static void yield();//指明某个线程是守护程序线程。void setDaemon (boolean on)//启动线程void start();//结束线程void stop();\n\n关于守护线程大概是受到操作系统中守护进程的设计思路，在设计java线程的时候也同样的也有守护线程机制。\njava的线程分为两类：User Thread(用户线程)、Daemon Thread(守护线程)，其实User Thread线程和Daemon Thread守护线程本质上来说去没啥区别的，唯一的区别之处就在虚拟机的离开：如果User Thread全部撤离，那么Daemon Thread也就没啥线程好服务的了，所以虚拟机也就退出了。\nJava语言机制是构建在JVM的基础之上的，java内部的守护线程也存在与JVM中，比如GC线程。\n守护线程并非虚拟机内部可以提供，用户也可以自行的设定守护线程，方法：public final void setDaemon(boolean on) ；但是有几点需要注意：\n\nthread.setDaemon(true)必须在thread.start()之前设置，否则会跑出一个IllegalThreadStateException异常。你不能把正在运行的常规线程设置为守护线程。  （备注：这点与守护进程有着明显的区别，守护进程是创建后，让进程摆脱原会话的控制+让进程摆脱原进程组的控制+让进程摆脱原控制终端的控制；所以说寄托于虚拟机的语言机制跟系统级语言有着本质上面的区别）\n\n在Daemon线程中产生的新线程也是Daemon的。   （这一点又是有着本质的区别了：守护进程fork()出来的子进程不再是守护进程，尽管它把父进程的进程相关信息复制过去了，但是子进程的进程的父进程不是init进程，所谓的守护进程本质上说就是“父进程挂掉，init收养，然后文件0,1,2都是&#x2F;dev&#x2F;null，当前目录到&#x2F;”）\n\n不是所有的应用都可以分配给Daemon线程来进行服务，比如读写操作或者计算逻辑。因为在Daemon Thread还没来的及进行操作时，虚拟机可能已经退出了。\n\n\n例子：\nimport java.io.*;class TestRunnable implements Runnable&#123;    public void run()&#123;        try&#123;            Thread.sleep(1000);//守护线程阻塞1秒后运行            File f=new File(&quot;daemon.txt&quot;);            FileOutputStream os=new FileOutputStream(f,true);            os.write(&quot;daemon&quot;.getBytes());        &#125;catch(IOException e1)&#123;            e1.printStackTrace();        &#125;catch(InterruptedException e2)&#123;            e2.printStackTrace();        &#125;    &#125;&#125;public class TestDemo2&#123;    public static void main(String[] args) throws InterruptedException&#123;        Runnable tr=new TestRunnable();        Thread thread=new Thread(tr);        //thread.setDaemon(true);        thread.setDaemon(true); //设置守护线程        thread.start(); //开始执行分进程    &#125;&#125;\n运行结果：文件daemon.txt中没有”daemon”字符串。\n但是如果把thread.setDaemon(true); 注释掉，文件daemon.txt是可以被写入daemon字符串的。\nJVM判断程序是否执行结束的标准是所有的前台执线程行完毕了，而不管后台线程（守护线程）的状态，因此，在使用守护线程的时候一定要注意这个问题。\n举个例子，web服务器中的Servlet容器启动时后台初始化一个服务线程，即调度线程，负责处理http请求，然后每个请求过来调度线程从线程池中取出一个工作者线程来处理该请求，从而实现并发控制的目的。\n同步的问题为了确保可以在线程之间以受控方式共享数据，Java语言提供了两个关键字：synchronized 和 volatile。\nVolatile 只适合于控制对基本变量（整数、布尔变量等）的单个实例的访问。当一个变量被声明成volatile，任何对该变量的写操作都会绕过高速缓存，直接写入主内存，而任何对该变量的读取也都绕过高速缓存，直接取自主内存。这表示所有线程在任何时候看到的 volatile 变量值都相同，这保证了变量的一致性，但是如果要保护比较大的代码段还需要用Synchronized。\nSynchronized 同步：\n同步使用监控器（monitor）或锁的概念，以协调对特定代码块的访问。\n每个 Java 对象都有一个相关的锁。同一时间只能有一个线程持有 Java 锁。当线程进入synchronized代码块时，线程会阻塞并等待，直到锁可用，当它可用时，就会获得这个锁，然后执行代码块。当控制退出受保护的代码块时，即到达了代码块末尾或者抛出了没有在 synchronized 块中捕获的异常时，它就会释放该锁。\n这样，每次只有一个线程可以执行受给定监控器保护的代码块。从其它线程的角度看，该代码块可以看作是原子的，它要么全部执行，要么根本不执行。\n例子：\npublic class SyncExample &#123;    private static lockObject = new Object();    private static class Thread1 extends Thread &#123;        public void run() &#123;            synchronized (lockObject) &#123;                x = 0;                y = 0;                System.out.println(x);            &#125;        &#125;    &#125;    private static class Thread2 extends Thread &#123;        public void run() &#123;            synchronized (lockObject) &#123;                x = 1;                y = 1;                System.out.println(y);            &#125;        &#125;    &#125;    public static void main(String[] args) &#123;        new Thread1().run();        new Thread2().run();    &#125;&#125;\n使用 synchronized 块可以让您将一组相关更新作为一个集合来执行，而不必担心其它线程中断或看到计算的中间结果。以下示例代码将打印“10”或“01”。如果没有同步，它还会打印“1 1” 或“0 0”。\n以上是synchronized 块的原理，除此之外还可以同步一个方法：\npublic class Point &#123;    private x;private y;    public synchronized void setXY(int x, int y) &#123;    this.x = x;    this.y = y;    &#125;&#125;\n对于普通的 synchronized 方法，这个锁是一个对象，将针对它调用方法。对于静态 synchronized方法，这个锁是本对象，在该对象中声明了方法。仅仅因为 setXY() 被声明成 synchronized 并不表示两个不同的线程不能同时执行 setXY()，只要它们调用不同的 Point 实例的 setXY() 就可同时执行。对于一个 Point 实例，一次只能有一个线程执行 setXY()。\n示例：简单的线程安全的高速缓存：\npublic class SimpleCache&#123;    private final Map cache = new HashMap();    public Object load(String objectName)&#123;    // load the object somehow    &#125;    public void clearCache()&#123;        synchronized (cache)&#123;        cache.clear();        &#125;    &#125;    public Object getObject(String objectName) &#123;        synchronized (cache)&#123;            Object o = cache.get(objectName);            if (o == null)&#123;                o = load(objectName);                cache.put(objectName, o);            &#125;        &#125;    return o;    &#125;&#125;\n以上代码，使用 HashMap 为对象装入器提供了一个简单的高速缓存。load()方法知道怎样按对象的键装入对象。在一次装入对象之后，该对象就被存储到高速缓存中，这样以后的访问就会从高速缓存中检索它，而不是每次都全部地装入它。对共享高速缓存的每个访问都受到synchronized 块保护。由于它被正确同步，所以多个线程可以同时调用 getObject 和clearCache 方法，而没有数据损坏的风险。\n同步？不同步？什么时候必须同步？\n\n需要保证在多线程中，一部分数据是一致的即用于一致性的同步\n递增共享计数器（多线程共用一个计数器类或方法），本质还是一致性\nfinal字段是线程友好的，不必担心同步问题\n\n什么时候不需要同步？\n\n由静态初始化器（在静态字段上或 static{} 块中的初始化器）初始化数据时，JVM隐性的帮我们同步了\n访问final变量时\n死锁\n性能考虑\n\n同步准则？\n\n使代码块保持简短。Synchronized块应该简短,在保证相关数据操作的完整性的同时，尽量简短。把不随线程变化的预处理和后处理移出 synchronized 块\n不要阻塞。不要在 synchronized块或方法中调用可能引起阻塞的方法，如InputStream.read()\n在持有锁的时候，不要对其它对象调用方法。这听起来可能有些极端，但它消除了最常见的死锁源头。\n\n其他一些案例使用java.util.TimerTask解决计数器的问题这是上文的案例，我们可以不让主线程休眠，方法如下：\n/*** 一个线程案例： （计时功能）* 主线程开启一个打印素数的线程之后，主线程自己休息10秒，* 10秒之后通过改变finished状态值，break新线程。*/public class CalculatePrimes extends Thread&#123;    public static final int MAX_PRIMES = 1000000;    public static final int TEN_SECONDS = 10000;    public volatile boolean finished = false;    public void run()&#123;        int[] primes = new int[MAX_PRIMES];        int count = 0;        for (int i=2; count&lt;MAX_PRIMES; i++)&#123;            // Check to see if the timer has expired            if (finished) &#123;            break;            &#125;            boolean prime = true;            for (int j=0; j&lt;count; j++)&#123;                if (i % primes[j] == 0)&#123;                    prime = false;                    break;                &#125;            &#125;            if (prime)&#123;                primes[count++] = i;                System.out.println(&quot;Found prime: &quot; + i);            &#125;        &#125;    &#125;    public static void main(String[] args)&#123;        Timer timer = new Timer();        final CalculatePrimes calculator = new CalculatePrimes();        calculator.start();        timer.schedule(            new TimerTask() &#123;                public void run()&#123;                    calculator.finished = true;                &#125;            &#125;, TEN_SECONDS);    &#125;&#125;\nservlet 和 JavaServer Pages 技术实现 RMI 对象","categories":["总结笔记"],"tags":["Java","多线程"]},{"title":"Letcode刷题记录","url":"/2019_01_01_letcode/","content":"88. 合并两个有序数组给你两个按 非递减顺序 排列的整数数组 nums1 和 nums2，另有两个整数 m 和 n ，分别表示 nums1 和 nums2 中的元素数目。\n请你 合并 nums2 到 nums1 中，使合并后的数组同样按 非递减顺序 排列。\n注意：最终，合并后数组不应由函数返回，而是存储在数组 nums1 中。为了应对这种情况，nums1 的初始长度为 m + n，其中前 m 个元素表示应合并的元素，后 n 个元素为 0 ，应忽略。nums2 的长度为 n 。\n示例 1：\n输入：nums1 &#x3D; [1,2,3,0,0,0], m &#x3D; 3, nums2 &#x3D; [2,5,6], n &#x3D; 3输出：[1,2,2,3,5,6]解释：需要合并 [1,2,3] 和 [2,5,6] 。合并结果是 [1,2,2,3,5,6] ，其中斜体加粗标注的为 nums1 中的元素。示例 2：\n输入：nums1 &#x3D; [1], m &#x3D; 1, nums2 &#x3D; [], n &#x3D; 0输出：[1]解释：需要合并 [1] 和 [] 。合并结果是 [1] 。示例 3：\n输入：nums1 &#x3D; [0], m &#x3D; 0, nums2 &#x3D; [1], n &#x3D; 1输出：[1]解释：需要合并的数组是 [] 和 [1] 。合并结果是 [1] 。注意，因为 m &#x3D; 0 ，所以 nums1 中没有元素。nums1 中仅存的 0 仅仅是为了确保合并结果可以顺利存放到 nums1 中。\npackage h.xd.algo;public class Main39 &#123;    public static void main(String[] args) &#123;        new Solution39().merge(new int[]&#123;1,2,3,0,0,0&#125;,3, new int[]&#123;2,5,6&#125;,3);    &#125;&#125;class Solution39 &#123;    public void merge(int[] nums1, int m, int[] nums2, int n) &#123;        int last = m+n-1;        for(;;)&#123;            if(m-1 &lt; 0)&#123;                while(n-1 &gt;=0)&#123;                    nums1[last] = nums2[n-1];                    n--;                    last--;                &#125;                return;            &#125;            if(n-1 &lt;0) &#123;                while(m-1 &gt;=0)&#123;                    nums1[last] = nums1[m-1];                    m--;                    last--;                &#125;                return;            &#125;            if(nums1[m-1] &gt; nums2[n-1])&#123;                nums1[last] = nums1[m-1];                m--;                last--;                continue;            &#125;else&#123;                nums1[last] = nums2[n-1];                n--;                last--;                continue;            &#125;        &#125;    &#125;&#125;\n\npackage algoimport &quot;testing&quot;func TestAlgo1(t *testing.T) &#123;\tmerge([]int&#123;1, 2, 3, 0, 0, 0&#125;, 3, []int&#123;2, 5, 6&#125;, 3)&#125;func merge(nums1 []int, m int, nums2 []int, n int) &#123;\tlast := m + n - 1\tfor &#123;\t\tif m-1 &lt; 0 &#123;\t\t\tfor n-1 &gt;= 0 &#123;\t\t\t\tnums1[last] = nums2[n-1]\t\t\t\tn--\t\t\t\tlast--\t\t\t&#125;\t\t\treturn\t\t&#125;\t\tif n-1 &lt; 0 &#123;\t\t\tfor m-1 &gt;= 0 &#123;\t\t\t\tnums1[last] = nums1[m-1]\t\t\t\tm--\t\t\t\tlast--\t\t\t&#125;\t\t\treturn\t\t&#125;\t\tif nums1[m-1] &gt; nums2[n-1] &#123;\t\t\tnums1[last] = nums1[m-1]\t\t\tm--\t\t\tlast--\t\t&#125; else &#123;\t\t\tnums1[last] = nums2[n-1]\t\t\tn--\t\t\tlast--\t\t&#125;\t&#125;&#125;\n\n注意点：\n\n一个数组为空的判断是m-1 &lt; 0 和 n-1&lt;0 而不是  &lt;&#x3D;\n一个驻足为空也要last–\n\n27. 移除元素给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素。元素的顺序可能发生改变。然后返回 nums 中与 val 不同的元素的数量。\n假设 nums 中不等于 val 的元素数量为 k，要通过此题，您需要执行以下操作：\n更改 nums 数组，使 nums 的前 k 个元素包含不等于 val 的元素。nums 的其余元素和 nums 的大小并不重要。返回 k。用户评测：\n评测机将使用以下代码测试您的解决方案：\nint[] nums = [...]; // 输入数组int val = ...; // 要移除的值int[] expectedNums = [...]; // 长度正确的预期答案。                            // 它以不等于 val 的值排序。int k = removeElement(nums, val); // 调用你的实现assert k == expectedNums.length;sort(nums, 0, k); // 排序 nums 的前 k 个元素for (int i = 0; i &lt; actualLength; i++) &#123;    assert nums[i] == expectedNums[i];&#125;\n如果所有的断言都通过，你的解决方案将会 通过。\n示例 1：\n输入：nums &#x3D; [3,2,2,3], val &#x3D; 3输出：2, nums &#x3D; [2,2,,]解释：你的函数函数应该返回 k &#x3D; 2, 并且 nums 中的前两个元素均为 2。你在返回的 k 个元素之外留下了什么并不重要（因此它们并不计入评测）。示例 2：\n输入：nums &#x3D; [0,1,2,2,3,0,4,2], val &#x3D; 2输出：5, nums &#x3D; [0,1,4,0,3,,,_]解释：你的函数应该返回 k &#x3D; 5，并且 nums 中的前五个元素为 0,0,1,3,4。注意这五个元素可以任意顺序返回。你在返回的 k 个元素之外留下了什么并不重要（因此它们并不计入评测）。\nclass Solution &#123;    public int removeElement(int[] nums, int val) &#123;        int last = nums.length-1;        int start = 0;        for(int i=0;i&lt;nums.length-1;i++)&#123;            if(i &gt; last) break;            if(nums[i] == val)&#123;                int tmp = nums[i];                nums[i] = nums[last];                nums[last] = tmp;                last--;                i--;            &#125;        &#125;        return last +1;    &#125;&#125;\n\nfunc removeElement(nums []int, val int) int &#123;    start := 0    last := len(nums)-1    for &#123;        if start &gt; last &#123;            break        &#125;        if nums[start] == val &#123;            nums[start],nums[last] = nums[last],nums[start]            last--        &#125;else&#123;            start++        &#125;    &#125;    return last+1&#125;\n\n注意点：\n\n不要忘了两指针交会  if(i &gt; last) break\n\n134. 加油站在一条环路上有 n 个加油站，其中第 i 个加油站有汽油 gas[i] 升。\n你有一辆油箱容量无限的的汽车，从第 i 个加油站开往第 i+1 个加油站需要消耗汽油 cost[i] 升。你从其中的一个加油站出发，开始时油箱为空。\n给定两个整数数组 gas 和 cost ，如果你可以按顺序绕环路行驶一周，则返回出发时加油站的编号，否则返回 -1 。如果存在解，则 保证 它是 唯一 的。\n示例 1:\n输入: gas &#x3D; [1,2,3,4,5], cost &#x3D; [3,4,5,1,2]输出: 3解释:从 3 号加油站(索引为 3 处)出发，可获得 4 升汽油。此时油箱有 &#x3D; 0 + 4 &#x3D; 4 升汽油开往 4 号加油站，此时油箱有 4 - 1 + 5 &#x3D; 8 升汽油开往 0 号加油站，此时油箱有 8 - 2 + 1 &#x3D; 7 升汽油开往 1 号加油站，此时油箱有 7 - 3 + 2 &#x3D; 6 升汽油开往 2 号加油站，此时油箱有 6 - 4 + 3 &#x3D; 5 升汽油开往 3 号加油站，你需要消耗 5 升汽油，正好足够你返回到 3 号加油站。因此，3 可为起始索引。示例 2:\n输入: gas &#x3D; [2,3,4], cost &#x3D; [3,4,3]输出: -1解释:你不能从 0 号或 1 号加油站出发，因为没有足够的汽油可以让你行驶到下一个加油站。我们从 2 号加油站出发，可以获得 4 升汽油。 此时油箱有 &#x3D; 0 + 4 &#x3D; 4 升汽油开往 0 号加油站，此时油箱有 4 - 3 + 2 &#x3D; 3 升汽油开往 1 号加油站，此时油箱有 3 - 3 + 3 &#x3D; 3 升汽油你无法返回 2 号加油站，因为返程需要消耗 4 升汽油，但是你的油箱只有 3 升汽油。因此，无论怎样，你都不可能绕环路行驶一周。\n以下解题暴力解法，一个一个看能不能走一圈，不能走一圈就break掉，下一个继续走，以此类推。 双轮循环， 时间复杂度超了，为n^2难点：\n\n怎么判断走一圈，用计数法，计数等于长度则为走了一圈class Solution &#123;    public int canCompleteCircuit(int[] gas, int[] cost) &#123;        for(int i=0;i&lt;gas.length;i++)&#123;            int current = 0;            current += gas[i];            if(current &lt; cost[i])&#123;                continue;            &#125;            current -= cost[i];            int start = i;            int next = start+1;            for (int j=0;j&lt;gas.length;j++)&#123;                if(next &gt; gas.length-1)                    next=0;                current += gas[next];                if(current &lt; cost[next])&#123;                    break;                &#125;                if(next == start)&#123;                    return start;                &#125;                current-=cost[next];                next++;            &#125;        &#125;        return -1;    &#125;&#125;\n以下为时间复杂度N的解法，遍历一次，用多个存储变量记录状态并判断。需要记录总油，总花费，用来判断总油不够总花费，直接-1需要记录  result 为暂时起点，默认无暂时起点，为-1需要记录  curLast 为有暂时起点情况下， 暂时起点至目前总剩余油量\n\n难点：\n\n逻辑复杂class Solution &#123;    public int canCompleteCircuit(int[] gas, int[] cost) &#123;        int allGas = 0;        int allCost = 0;        int result = -1;        int curLast = 0;        for(int i=0;i&lt;gas.length;i++)&#123;            allGas = allGas + gas[i];            allCost = allCost +cost[i];           if(gas[i] &gt;= cost[i])&#123;                if(result == -1)&#123;                    result = i;                    curLast = gas[i] - cost[i];                &#125;else&#123;                    curLast = curLast + gas[i] - cost[i];                &#125;           &#125;else&#123;                if(result != -1)&#123;                     if(curLast + gas[i] - cost[i] &lt; 0)&#123;                        result = -1;                        curLast = 0;                         &#125;else&#123;                        curLast = curLast + gas[i] - cost[i];                     &#125;                &#125;else&#123;                    continue;                &#125;           &#125;        &#125;        if(allGas - allCost &gt;= 0)&#123;            return result;        &#125;else&#123;            return -1;        &#125;    &#125;&#125;\nfunc canCompleteCircuit(gas []int, cost []int) int &#123;    allGas :=0    allCost :=0    result := -1    curLast := 0    for i,_ := range gas&#123;        allGas = allGas + gas[i]        allCost = allCost + cost[i]        if gas[i] &gt;= cost[i] &#123;            //当前为起点的话，油够跑到下一个点            if result == -1 &#123;                //当前没有暂存点，开始记录暂存点                result = i                curLast = gas[i] - cost[i]            &#125;else &#123;                //当前有暂存点，一定能过去，暂存点一定需要改变，记录花费                curLast = curLast + gas[i] - cost[i]            &#125;        &#125;else&#123;            //当前为起点的话，油不够跑到下一个点            if result == -1 &#123;                //没有起点，当前也不能是起点 应跳过                continue            &#125;else&#123;                //有起点了，需要看下是否需要重置起点                if curLast + gas[i] - cost[i]  &lt; 0 &#123;                    //走不到下个点，重置                    result = -1                    curLast = 0                &#125;else&#123;                    //走到下个点了，记录汇总油耗                    curLast = curLast + gas[i] - cost[i];                &#125;            &#125;        &#125;    &#125;    if allGas - allCost &gt;= 0 &#123;        return result    &#125;else&#123;        return -1    &#125;&#125;\n\n135. 分发糖果n 个孩子站成一排。给你一个整数数组 ratings 表示每个孩子的评分。\n你需要按照以下要求，给这些孩子分发糖果：\n每个孩子至少分配到 1 个糖果。相邻两个孩子评分更高的孩子会获得更多的糖果。请你给每个孩子分发糖果，计算并返回需要准备的 最少糖果数目 。\n示例 1：\n输入：ratings &#x3D; [1,0,2]输出：5解释：你可以分别给第一个、第二个、第三个孩子分发 2、1、2 颗糖果。示例 2：\n输入：ratings &#x3D; [1,2,2]输出：4解释：你可以分别给第一个、第二个、第三个孩子分发 1、2、1 颗糖果。     第三个孩子只得到 1 颗糖果，这满足题面中的两个条件。\n解题思路：例子比较少，不好看出规律，注意左右相等， 右侧可以为1糖果自己再举几个特殊的例子：1，2，3，4，5  的话， 糖果为  1,2,3,4,5 需要15个1，1，1，1，1 的话，需要   1,1,1,1,1 需要5个5，4，3，2，1的话， 需要   5,4,3,2,1 需要15个， 和第一个对称。对称很重要，距离几个对称的例子。1，2，2，3，3的话，需要    1，2，1，2，1 需要  7个3，3，2，2，1的话，需要    1，2，1，1，0，需要  5个，但是不满足条件，而是   1，2，1，2，1  需要7个是最优解\n这里有个规律，    正反求一次，  max  上下 ，时间复杂度2N, , 还可以\n class Solution &#123;    public int candy(int[] ratings) &#123;        int[] left = new int[ratings.length];        int[] right = new int[ratings.length];        for(int i=0;i&lt;ratings.length;i++)&#123;            if(i&gt;0 &amp;&amp; ratings[i] &gt; ratings[i-1])&#123;                left[i] = left[i-1] + 1;            &#125;else&#123;                left[i] = 1;            &#125;        &#125;        for(int i=ratings.length-1;i&gt;=0;i--)&#123;            if(i &lt; ratings.length-1 &amp;&amp; ratings[i]&gt;ratings[i+1])&#123;                right[i] = right[i+1] + 1;            &#125;else&#123;                right[i] = 1;            &#125;        &#125;                int rst = 0;        for(int i=0;i&lt;ratings.length;i++)&#123;            rst += (left[i] &gt; right[i]? left[i]:right[i]);        &#125;        return rst;    &#125;&#125;\n\n42. 接雨水给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。\n示例 1：输入：height &#x3D; [0,1,0,2,1,0,1,3,2,1,2,1]输出：6解释：上面是由数组 [0,1,0,2,1,0,1,3,2,1,2,1] 表示的高度图，在这种情况下，可以接 6 个单位的雨水（蓝色部分表示雨水）。示例 2：\n输入：height &#x3D; [4,2,0,3,2,5]输出：9\n思路：    两个单调递增栈，找规律比较大小\nclass Solution &#123;    //3,3,3,3,3,3,3,3,2,2,2,1    //0,1,1,2,2,2,2,3,3,3,3,3    //0,1,0,2,1,0,1,3,2,1,2,1    //0,0,1,0,1,2,1,0,0,1,0,0    public int trap(int[] height) &#123;        int[] left = new int[height.length];        int[] right = new int[height.length];        left[0] = height[0];        for(int i=1;i&lt;height.length;i++)&#123;            left[i] = height[i] &gt; left[i-1] ? height[i]:left[i-1];        &#125;        right[height.length-1] = height[height.length-1];        for(int i=height.length-1-1;i&gt;=0;i--)&#123;            right[i] = height[i] &gt; right[i+1] ? height[i]:right[i+1];        &#125;        int cost = 0;        for(int i=0;i&lt;height.length;i++)&#123;            int min = left[i] &lt; right[i] ? left[i]:right[i];            if (height[i] &lt; min) &#123;                cost = cost + min - height[i];            &#125;        &#125;        return cost;    &#125;&#125;\n\n13. 罗马数字转整数罗马数字包含以下七种字符: I， V， X， L，C，D 和 M。\n字符          数值I             1V             5X             10L             50C             100D             500M             1000例如， 罗马数字 2 写做 II ，即为两个并列的 1 。12 写做 XII ，即为 X + II 。 27 写做  XXVII, 即为 XX + V + II 。\n通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况：\nI 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。给定一个罗马数字，将其转换成整数。\nclass Solution &#123;    //穷举 1到10 I II III VI V VI VII VIII IX X    //重点需要关注4 9 40 90 400 900，其他相加即可    public int romanToInt(String s) &#123;        String str = s.replace(&quot;CM&quot;,&quot;900,&quot;).replace(&quot;CD&quot;,&quot;400,&quot;).replace(&quot;XC&quot;,&quot;90,&quot;)        .replace(&quot;XL&quot;,&quot;40,&quot;).replace(&quot;IX&quot;,&quot;9,&quot;).replace(&quot;IV&quot;,&quot;4,&quot;)        .replace(&quot;M&quot;,&quot;1000,&quot;).replace(&quot;D&quot;,&quot;500,&quot;).replace(&quot;C&quot;,&quot;100,&quot;)        .replace(&quot;L&quot;,&quot;50,&quot;).replace(&quot;X&quot;,&quot;10,&quot;).replace(&quot;V&quot;,&quot;5,&quot;).replace(&quot;I&quot;,&quot;1,&quot;);        String[] strArray = str.split(&quot;,&quot;);        int rst = 0;        for(int i=0;i&lt;strArray.length;i++)&#123;            rst+=Integer.parseInt(strArray[i]);        &#125;        return rst;    &#125;&#125;\n\n12. 整数转罗马数字七个不同的符号代表罗马数字，其值如下：\n符号\t值I\t1V\t5X\t10L\t50C\t100D\t500M\t1000罗马数字是通过添加从最高到最低的小数位值的转换而形成的。将小数位值转换为罗马数字有以下规则：\n如果该值不是以 4 或 9 开头，请选择可以从输入中减去的最大值的符号，将该符号附加到结果，减去其值，然后将其余部分转换为罗马数字。如果该值以 4 或 9 开头，使用 减法形式，表示从以下符号中减去一个符号，例如 4 是 5 (V) 减 1 (I): IV ，9 是 10 (X) 减 1 (I)：IX。仅使用以下减法形式：4 (IV)，9 (IX)，40 (XL)，90 (XC)，400 (CD) 和 900 (CM)。只有 10 的次方（I, X, C, M）最多可以连续附加 3 次以代表 10 的倍数。你不能多次附加 5 (V)，50 (L) 或 500 (D)。如果需要将符号附加4次，请使用 减法形式。给定一个整数，将其转换为罗马数字。\n示例 1：\n输入：num &#x3D; 3749\n输出： “MMMDCCXLIX”\n解释：\n3000 &#x3D; MMM 由于 1000 (M) + 1000 (M) + 1000 (M) 700 &#x3D; DCC 由于 500 (D) + 100 (C) + 100 (C)  40 &#x3D; XL 由于 50 (L) 减 10 (X)   9 &#x3D; IX 由于 10 (X) 减 1 (I)注意：49 不是 50 (L) 减 1 (I) 因为转换是基于小数位示例 2：\n输入：num &#x3D; 58\n输出：”LVIII”\n解释：\n50 &#x3D; L 8 &#x3D; VIII示例 3：\n输入：num &#x3D; 1994\n输出：”MCMXCIV”\n解释：\n1000 &#x3D; M 900 &#x3D; CM  90 &#x3D; XC   4 &#x3D; IV\nclass Solution &#123;    public String intToRoman(int num) &#123;        int t = num / 1000;        int to = num % 1000;        int h = to / 100;        int ho = to % 100;        int ten = ho / 10;        int teno = ho % 10;        String rst = &quot;&quot;;        for (int i=0;i&lt;t;i++)&#123;            rst += &quot;M&quot;;        &#125;        if(h == 9)&#123;            rst+=&quot;CM&quot;;            h-=9;        &#125;        if (h &gt;= 5) &#123;            rst += &quot;D&quot;;            h-=5;        &#125;        if(h == 4)&#123;            rst+=&quot;CD&quot;;            h-=4;        &#125;        for(int i=0;i&lt;h;i++)&#123;            rst+=&quot;C&quot;;        &#125;        if(ten == 9)&#123;            rst+=&quot;XC&quot;;            ten-=9;        &#125;        if(ten &gt;=5)&#123;            rst+=&quot;L&quot;;            ten-=5;        &#125;        if(ten == 4)&#123;            rst+=&quot;XL&quot;;            ten-=4;        &#125;        for(int i=0;i&lt;ten;i++)&#123;            rst+=&quot;X&quot;;        &#125;        if(teno ==9)&#123;            rst+=&quot;IX&quot;;            teno-=9;        &#125;        if(teno &gt;=5) &#123;            rst+=&quot;V&quot;;            teno-=5;        &#125;        if(teno == 4)&#123;            rst+=&quot;IV&quot;;            teno-=4;        &#125;        for(int i=0;i&lt; teno;i++)&#123;            rst+=&quot;I&quot;;        &#125;        return rst;    &#125;&#125;\n\n151. 反转字符串中的单词给你一个字符串 s ，请你反转字符串中 单词 的顺序。\n单词 是由非空格字符组成的字符串。s 中使用至少一个空格将字符串中的 单词 分隔开。\n返回 单词 顺序颠倒且 单词 之间用单个空格连接的结果字符串。\n注意：输入字符串 s中可能会存在前导空格、尾随空格或者单词间的多个空格。返回的结果字符串中，单词间应当仅用单个空格分隔，且不包含任何额外的空格。\n示例 1：\n输入：s &#x3D; “the sky is blue”输出：”blue is sky the”示例 2：\n输入：s &#x3D; “  hello world  “输出：”world hello”解释：反转后的字符串中不能存在前导空格和尾随空格。示例 3：\n输入：s &#x3D; “a good   example”输出：”example good a”解释：如果两个单词间有多余的空格，反转后的字符串需要将单词间的空格减少到仅有一个。\n解题思路：\n\n双指针法\n\nclass Solution &#123;    public String reverseWords(String s) &#123;        int all = s.length();        int last = all;        int start = all;        String str = &quot;&quot;;        for(int i=all-1;i&gt;=0;i--)&#123;            if(s.charAt(i) == &#x27; &#x27; &amp;&amp; start==last)&#123;                last--;                start--;            &#125;            if(s.charAt(i) == &#x27; &#x27; &amp;&amp; start!=last)&#123;                str+=(&quot; &quot; +s.substring(start,last));                start =i;                last=i;            &#125;            if(s.charAt(i) != &#x27; &#x27;)&#123;                start--;            &#125;        &#125;        if(start !=last)            str+=(&quot; &quot; +s.substring(start,last));        return str.substring(1);    &#125;&#125;\n\n6. Z 字形变换将一个给定字符串 s 根据给定的行数 numRows ，以从上往下、从左到右进行 Z 字形排列。\n比如输入字符串为 “PAYPALISHIRING” 行数为 3 时，排列如下：\nP   A   H   NA P L S I I GY   I   R\n之后，你的输出需要从左往右逐行读取，产生出一个新的字符串，比如：”PAHNAPLSIIGYIR”。\n请你实现这个将字符串进行指定行数变换的函数：\nstring convert(string s, int numRows);\n示例 1：\n输入：s &#x3D; “PAYPALISHIRING”, numRows &#x3D; 3输出：”PAHNAPLSIIGYIR”示例 2：输入：s &#x3D; “PAYPALISHIRING”, numRows &#x3D; 4输出：”PINALSIGYAHRPI”解释：\nP     I    NA   L S  I GY A   H RP     I\n示例 3：\n输入：s &#x3D; “A”, numRows &#x3D; 1输出：”A”\n思路：根据路径， 向下走，或者向上走，两个方向，判断边界即可\nclass Solution &#123;    //00   02    //10 11    //20    //俩方向，向下，斜向上！ 到边界就切换，  到数组结尾就结束，边界为行数3，列数小于等于   总数/行数    public String convert(String s, int numRows) &#123;        if(numRows == 1) return s;        char[][] rst = new char[numRows][10000];        int a = 0;int b=0;        boolean isBottom = true;        for(int i = 0;i&lt; s.length();i++)&#123;            if (isBottom) &#123;                if(a&lt;numRows)&#123;                    rst[a][b] = s.charAt(i);                    a++;                    continue;                &#125;else&#123;                    isBottom = false;                    i--;                    a--;                    continue;                &#125;            &#125;            if(!isBottom)&#123;                if(a&gt;0)&#123;                    rst[a-1][b+1] = s.charAt(i);                    a--;                    b++;                    continue;                &#125;else&#123;                    isBottom = true;                    i--;                    a++;                    continue;                &#125;            &#125;        &#125;        String result = &quot;&quot;;        for(int i=0; i&lt; rst.length;i++)&#123;            for(int j=0;j&lt;rst[0].length;j++)&#123;                if(rst[i][j] != &#x27;\\0&#x27;)&#123;                    result+=rst[i][j];                &#125;            &#125;        &#125;        return result;    &#125;&#125;\n\n28. 找出字符串中第一个匹配项的下标给你两个字符串 haystack 和 needle ，请你在 haystack 字符串中找出 needle 字符串的第一个匹配项的下标（下标从 0 开始）。如果 needle 不是 haystack 的一部分，则返回  -1 。\n示例 1：\n输入：haystack &#x3D; “sadbutsad”, needle &#x3D; “sad”输出：0解释：”sad” 在下标 0 和 6 处匹配。第一个匹配项的下标是 0 ，所以返回 0 。示例 2：\n输入：haystack &#x3D; “leetcode”, needle &#x3D; “leeto”输出：-1解释：”leeto” 没有在 “leetcode” 中出现，所以返回 -1 。\n提示：\n1 &lt;&#x3D; haystack.length, needle.length &lt;&#x3D; 104haystack 和 needle 仅由小写英文字符组成\nclass Solution &#123;    public int strStr(String haystack, String needle) &#123;        for(int i=0;i&lt;haystack.length();i++)&#123;            if(haystack.charAt(i) != needle.charAt(0))&#123;                continue;            &#125;            int start = i;            int j;            for(j=0;j&lt;needle.length();j++)&#123;                if(start &gt;= haystack.length()) break;                if(needle.charAt(j) != haystack.charAt(start))&#123;                    break;                &#125;                start++;            &#125;            if(j==needle.length())            return i;        &#125;        return -1;    &#125;&#125;\n\n68. 文本左右对齐给定一个单词数组 words 和一个长度 maxWidth ，重新排版单词，使其成为每行恰好有 maxWidth 个字符，且左右两端对齐的文本。\n你应该使用 “贪心算法” 来放置给定的单词；也就是说，尽可能多地往每行中放置单词。必要时可用空格 ‘ ‘ 填充，使得每行恰好有 maxWidth 个字符。\n要求尽可能均匀分配单词间的空格数量。如果某一行单词间的空格不能均匀分配，则左侧放置的空格数要多于右侧的空格数。\n文本的最后一行应为左对齐，且单词之间不插入额外的空格。\n注意:\n单词是指由非空格字符组成的字符序列。每个单词的长度大于 0，小于等于 maxWidth。输入单词数组 words 至少包含一个单词。\n示例 1:\n输入: words &#x3D; [“This”, “is”, “an”, “example”, “of”, “text”, “justification.”], maxWidth &#x3D; 16输出:[   “This    is    an”,   “example  of text”,   “justification.  “]示例 2:\n输入:words &#x3D; [“What”,”must”,”be”,”acknowledgment”,”shall”,”be”], maxWidth &#x3D; 16输出:[  “What   must   be”,  “acknowledgment  “,  “shall be        “]解释: 注意最后一行的格式应为 “shall be    “ 而不是 “shall     be”,     因为最后一行应为左对齐，而不是左右两端对齐。     第二行同样为左对齐，这是因为这行只包含一个单词。示例 3:\n输入:words &#x3D; [“Science”,”is”,”what”,”we”,”understand”,”well”,”enough”,”to”,”explain”,”to”,”a”,”computer.”,”Art”,”is”,”everything”,”else”,”we”,”do”]，maxWidth &#x3D; 20输出:[  “Science  is  what we”,  “understand      well”,  “enough to explain to”,  “a  computer.  Art is”,  “everything  else  we”,  “do                  “]\n解题思路：\n\n比较无聊，边间很麻烦\n\nclass Solution &#123;    // this   is   an    // example of text    // justification.    public List&lt;String&gt; fullJustify(String[] words, int maxWidth) &#123;        List&lt;Line&gt; ll = new ArrayList();        int count = 0;        List&lt;String&gt; tmp = new ArrayList();        for(int i=0;i&lt;words.length;i++)&#123;            if(count == 0)&#123;                tmp = new ArrayList();                count+=words[i].length();                tmp.add(words[i]);            &#125;else&#123;                if(count + 1 + words[i].length() &gt; maxWidth)&#123;                    i--;                    Line l = new Line();                    l.w = tmp;                    ll.add(l);                    count=0;                &#125;else if(count + 1 + words[i].length() == maxWidth)&#123;                    tmp.add(words[i]);                    Line l = new Line();                    l.w = tmp;                    ll.add(l);                    count=0;                &#125;else&#123;                    tmp.add(words[i]);                    count = count + 1 + words[i].length();                &#125;            &#125;        &#125;        if(count !=0)&#123;            Line l = new Line();            l.w = tmp;            ll.add(l);        &#125;        List&lt;String&gt; rst = new ArrayList();        for(int i=0;i&lt;ll.size()-1;i++)&#123;            Line l = ll.get(i);            int[] blk = getBlk(l,maxWidth);            List&lt;String&gt; s = l.w;            String ln = &quot;&quot;;            for(int j=0;j&lt;s.size();j++)&#123;                ln += s.get(j);                if(j &lt; s.size()-1)&#123;                    for(int k=0;k&lt;blk[j];k++)&#123;                        ln += &quot; &quot;;                    &#125;                &#125;                if(blk.length == s.size())&#123;                     for(int k=0;k&lt;blk[s.size()-1];k++)&#123;                        ln += &quot; &quot;;                    &#125;                &#125;            &#125;            rst.add(ln);        &#125;        Line lastLine = ll.get(ll.size()-1);        List&lt;String&gt; lastLineStr = lastLine.w;        String ln = &quot;&quot;;        for(int i=0;i&lt;lastLineStr.size();i++)&#123;            ln = ln + lastLineStr.get(i) + &quot; &quot;;        &#125;        ln = ln.substring(0,ln.length()-1);        int blank = maxWidth - ln.length();        for(int i=0;i&lt;blank;i++)&#123;             ln = ln + &quot; &quot;;        &#125;        rst.add(ln);        return rst;    &#125;    int[] getBlk(Line l, int maxWidth)&#123;        int se = l.w.size();        if(se == 1) return new int[]&#123;maxWidth - l.w.get(0).length()&#125;;        int count = 0;        for(int i=0;i&lt;se;i++)&#123;            count+=l.w.get(i).length();        &#125;        int blk = maxWidth - count;        int f = blk / (se-1);        int e = blk % (se-1);        int[]rst= new int[se-1];        for(int i=0;i&lt;rst.length;i++)&#123;            if(i&lt; e)&#123;                rst[i] = f+1;                continue;            &#125;            rst[i] = f;        &#125;        return rst;    &#125;&#125;class Line&#123;    List&lt;String&gt; w;    int[] blk;&#125;","categories":["其他笔记"],"tags":["Java","Go","Letcode","Algothm"]},{"title":"读《爱有8种习惯》","url":"/2021_05_01_read_8habitsoflove/","content":"我发现爱而不会的现象在身边发生的太多，究其本质，是主动爱的人总是站在自己的立场去爱（关心），其结果往往是自我感觉良好，亦或者是连自我感觉都不良好，轻者单身孤苦伶仃，重者众叛亲离（言过其实O(∩_∩)O）。\n\n\n爱的8种习惯分别是慷慨、静默、求真、坦诚、游戏、宽恕、慈悲，和社群。\n慷慨的习惯人类的精神就像大海，既需要河水流入，也需要河水流出，这样才能孕育生命，产生能量。\n当爱从我们心中流出时，更多的爱会流入我们的心中。\n当我恩向爱敞开心扉时，我们不仅将这种传递给了他人，也能接受到其他人给予的爱。\n流出决定了流入。我们给予得越多，我们的人生就越有活力，精神就越强大，生命就越深刻。\n每个慷慨的举动都是在给予祝福。\n在祝福他人时，某种力量就被释放出来了这种力量能够穿透并挫败源于恐惧的抗拒。\n从外表看，它或许没有立竿见影的效果，\n但是，被祝福着的内心却被触动，变化已然发生。\n如何践行慷慨\n\n每日制作感恩清单，列出今天需要感恩的五件事，与他人分享。\n列出让你感到害怕的人际关系。贬低或不赞同或失望。以祝福之心尝试着拜访他们。\n每一个会面结束之时，让每个人都表达自己的感激和遗憾。\n尽可能地捐赠行善。如果你将收入的10%捐赠，剩余的90%就将派上更大的用场。\n不要将自己的善意只限定在每年的特殊时刻，随时向周围的人表达你的爱。\n\n心怀感恩之情。多想一想过去或现在让你心怀感恩的人们。引导自己多做善举。\n静默的习惯恐惧常常以忙乱和疲劳为食\n生活的压力，紧要的事情，基本上都是以自我为中心的，\n因为涉及许多我们必须承担和履行的责任。\n而当我们进入静默中，我们就能找到自我，超越自我，更轻松承受这些日常生活的压力。\n取而代之的，是无言的信心。\n由于现在我们和心灵深处的爱之源泉联系起来了，我们会有足够的本领来解决出现的问题。\n静默既是身体的体验，也是心灵和灵性的状态。\n当我们的肌肉在静默中放松下来时，我们身体内在状态也会发生变化，从紧张，激动变得清醒，清凉。\n我们的呼吸节奏也会变得平静而从容。\n我们的心灵，也初见下沉，到充满动荡，混乱的人生睡眠的下方，所有的自我特征在深处汇聚，与我们的灵魂融合，我们的灵魂是爱的居所，是我们内心中的至爱者。\n如何修习静默\n\n反复尝试，找到属于自己体验静默的方式。凝望大海，或静坐，或绘画创作。\n安静舒适地让思绪尽情徜徉。回想人生中不同的时光和往事。\n每天至少给自己十分钟时间来修习静默，到真正变成安全根基的习惯。\n尝试在每天不同时刻练习，以确定最佳练习时间。\n\n求真的习惯生活不是戏剧，我们不会收到能够帮助我们做出抉择和摆脱困境的剧本和文件，\n然而求真的习惯能够帮我们认识到，哪些言语，举止，行为涉及到我们的名字。\n真理不会追随我们，而我们必须追随真理，真理并不听从给我们的计划，相反它有时给到我们冲击和阻力，但是如果我们真诚地相信自己在追随真理，那么我们就能相信，我们也能驾驭随后可能出现的任何问题，这恰恰是信仰的本质。\n求真过程中，最棘手的问题就在于，真理是个观点问题，它不是一个事实问题。\n在聆听真理对我们的呼唤时，我们首先必须履行自身责任，而不是坚持让其他人用完全相同的方式来回答这个问题。有时我们需要接受分歧，知道怎样最好接纳分歧。这可能意味着离弃我们所珍爱的人，也可能意味着接纳真理观念不同于自己的人。\n真理不是成套的想法，不能被完全包含在一个人的头脑，言语，概念或想法当中，它过于活泼广阔，不受人类控制。真理是不断发展的，是我们对自身和世界运转方式的一系列洞见，理解，启示和顿悟。真理总是让我们能够更好地理解自己和他人。\n如何实践真理\n\n每日修习静默\n以简短开放的句子表述思考的内容。\n记住实践爱的习惯的最终目标是意识到至爱者多么深切地真爱着你和所有其他人。\n识别思考中的冲突是来自于内在的，家人的，朋友的，或是爱人的，外在的。\n思考比起背叛真实的自我，他人的谴责和阻力是否更强大更可怕\n思考信心，平安，喜乐，忍耐，恩慈，自律，宽容，大度在其中的位置和影响力\n结交有类似经验的友人聆听他们的故事。\n意识到没有真理能够让你完全脱离恐惧。\n了解到践行真理有时似乎是危险的，令人敬而远之的，然而当它引导我们觉悟上升到新的层次时，最终构建的会是平安，坚不可摧的堡垒。接纳那个爱的自我。\n\n坦诚的习惯坦诚的做法实际上是关爱之举，关心自己和他人，以及彼此的交情。坦诚也是充满爱与信念的举动，使人际关系拥有更坚实的基础，与此同时，勇敢而坦诚的对话能够让彼此关系更丰富，更深刻，更持久，经受各种挑战。有些时候，你可能觉得坦诚是徒然的，事与愿违的，但是必须记住，坦诚的习惯，是一个过程，是一种生活方式，不是终点。\n在坦诚时如何表达可能会让对方失控，愤怒或产生戒备心理的看法，是一种挑战，也是技巧。当我们与他人意见分歧时，坦诚会让我们接纳并珍惜这段宝贵而持久的人际关系，如果我们能够分享不同的看法并尊重彼此，这是我们能够给予他人的最大赞美。\n通常情况下，在坦诚的交流中，互动的成功与否可能会取决于很多外在因素，例如时间和地点，在不带偏见的场所，双方都冷静的时候，这种勇敢的谈话能够更有成效。但是即使我们采取了所有能够想到的预防措施，心态开明并有宽宏大量的精神，交流仍然可能导致感情受到伤害。我们没有办法来决定或引导别人如何回应我们的行为。这时候怀着爱的态度来真诚践行坦诚的习惯，本身就已经足够。\n如何实践坦诚\n\n在准备实践坦诚时，先自问一些先觉性问题以确定事实是需要我们去践行爱而非恐惧。\n在坦诚对待他人之前，要先修习静默。\n清醒地意识到自己的动机。是存在的建设性的，积极的或者是报复性的，消极的。\n坦诚过程中需要在存在的层面上高度尊重他人，批评就事论事不针对人。\n坦诚之前找出对方存在和行为中的可取之处。列出清单。\n无法坦诚时，不强迫。只有不执着于结果时，坦诚才充满了爱意。\n坦诚前谨慎奠定沟通基础。询问对方是否有足够的时间，心情，以及明确温和表示重要性。\n坦诚前表明彼此配合的重要性。\n沟通时，以自身，对方，彼此之间的关系三个角度来时刻梳理和自省。\n需要给对方留出时间，来对你的话作出回应。11.充满自信并保持静默。消除戒备心理。你已深思熟虑，你的意图是好的。要忠诚于那个渴望爱和被爱的自我。竭尽全力，就可以无怨无悔。\n\n游戏的习惯焦虑会让我们无法跟随生活的节奏，让我们无法接触充满爱的自我。每一种爱的习惯都需要我们认真参与，但游戏要求我们区分这种认真和致命的严肃。严肃会让我们以为自己所担忧的某个问题是整个宇宙唯一迫切的问题。把自己太当回事，就会无法从创造性的角度看待问题和寻求解决问题的办法。除了让我们害怕的利害关系之外，我们会丧失对其他所有事物的兴趣。这是胆怯。而当我们出于爱而行动，就更容易让游戏进入生活，并将受益于随之而来的无忧无虑和灵活变通。\n游戏的习惯能真正改变我们大脑的化学物质，让我们得到释放，发挥我们的想象力，变得更有创造性，有建设性，快乐。游戏使我们可以给予自己以及他人最有爱心的礼物之一。通过它，我们变得更有创意，神清气爽，不沉闷呆板。其他人可以更轻松接近我们，也使我们的观点也变得更深刻。\n如何实践游戏\n\n以学习者的心态来面对生活就可以更自然地实践游戏的精神。\n留意并尊重身体所传达的讯息。了解身上恐惧与爱的力量对比。\n紧张陌生的场合，可以考虑融入游戏元素放松心情。但是要专注于自己。\n练习游戏的精神。学习一两个笑话，学习幽默的心态。\n花时间与孩子相处，观察他们并向他们学习。\n犯下错误的时候，幽默承认。没有人可以完美到任何时候都不犯错。\n想想可以通过哪些方法把游戏融入到工作之中。你的日常就会有更多的喜悦和创造力。\n有意识地多花时间和幽默诙谐的朋友相处。\n\n宽恕的习惯宽恕的习惯更多设计受难者，而不是引起痛苦的人，事和情况。我们常常很难接受宽恕的概念，因为我们相信冒犯我们的人才是问题的根源。我们怎么能原谅肇事逃逸的司机，虐待我们的配偶，或是疏忽的外科医生呢？宽恕的习惯给予我们的礼物就是，它避免让施害者的罪遮盖了受害者的自由和权利。最终，宽恕更多涉及受害者的痊愈和自由。而不是施害者。\n当我们经历宽恕时，有爱的强大能量被释放出来，穿透全身。在我们实现宽恕之前，那些现实和想象中的伤害无比痛苦悲伤混乱地纠缠我们的身心。但当我们最终原谅的时候，淤塞物边会融化，生命之河又可以重新流淌。这种能量变成了爱，光明和清醒，我们的灵魂就好像从囚禁中解脱。\n通过宽恕的习惯，我们会面对人生旅程中及其艰巨的事情，在经历重大伤痛以后，回归自由，完整，心灵开放的自我。我们关注那些让我们遭受蔑视，羞辱，不公，暴力或威胁的时刻。这些伤害让我们内心恐惧，害怕不公得不到纠正。这种伤害根于我们的内心，成为痛苦，愤怒和怨恨的根源，让我们陷入充满恐惧的自我之中。这种生活会让我们心力交瘁，让我们遭受的痛苦在心中持续下去。我们需要思考，我们是继续停留在过去，还是利用宽恕的力量来继续生活，走向自由和爱。我们陷越深，就越可能诱使他人也陷入留存在我们心里的伤害之中。至爱者希望我们是条河，而不是个死谭。\n宽恕真的仅仅是某种自我治愈和自强自立的行为。\n而当实在无法彻底原谅那些伤害我们的人时，只要做出宽恕时可取的决定便可以。尽管我们无法宽恕，但是我们可以选择宽恕。至爱者的强大力量将满足你宽恕别人的愿望，帮助你踏上治疗之旅。\n如何实践宽恕\n\n修习静默是宽恕的前提条件。这个过程可能会很困难，你需要持之以恒地坚持。\n列一个宽恕清单。把清单像杂志一样保存在安全的地方。最终目标是不再需要这张清单。\n从名单中挑选一个人，用自己的心灵之眼观察TA。想想自己沐浴在治疗之光中。\n制定一份宽恕声明，再三念给自己听。关键是要放下自己的怨恨。不诅咒他人。\n记住你们可以不必再是朋友，也不必再以任何形式进行交往。放下蚕食心灵的旧关系。\n寻找能够帮助你保护自己的合适人选。这个过程关乎自我治愈和解脱，你必须有安全感。\n让爱的力量战胜恐惧的力量。\n\n慈悲的习惯当我们实践慈悲的习惯，就选择了为他人映照出他们自身再也无法看到的东西。所有人心中都有神圣的至爱者之光，每个人，无论我们看起来多么平凡，出色或古怪，都远远不是我们在生活中所做事情的总和。如果相信所有人本质上都是善良的我们必然会做出这样的推论，我们是为毫不人道或伤天害理的行为，体现了作恶者的痛苦和疾病。\n虽然慈悲并非最难理解的爱的习惯，但是却可能是最难以接受并付诸实践的习惯。它要求我们处于这样的信念而行动，即每个人本质上都是善良的。对于许多人来说，这似乎是不可能完成的。\n宽恕将人引向慈悲。在宽恕中我们重点关注别人对我们做过的事情。而在慈悲中，我们专注于别人可能对我们和其他人所做的事情。当我们能超越他人的伤害性行为，洞察到潜藏在阴影深处的善良时，这将有助于我们揭示那种善良，激发那个人重新觉悟到充满爱的自我。在实践慈悲的习惯时，我们是在馈赠他人。这并不意味着我们要纵容令人发指的行为或淡化这些罪行的严重性。在公正的社会必须有法治问责。这表明，我们知道肇事者也在承受痛苦，而且相信他们内心最深处仍然有善良和光明。他们并没有丧失全部的良知。在非常复杂的情况下，我们通过扩展慈悲心，帮助那个人再次扎到那个爱与被爱的自我。当我们这么做时，是在正式痊愈的可能性。\n虽然我们有时候可能很难产生慈悲心，当我们受到伤害或感到恐惧时尤其如此，但我们可以学会将其纳入我们的日常活动之中。不需要立刻就做到慈悲，重要的是，我们要逐渐前进。只要我们希望将慈悲的能量给予别人，克服那个充满恐惧的自我阻力和狡辩，我们就已经踏上了慈悲的征程。\n如何实践慈悲\n\n花时间静默，回忆你接受他人慈悲的时刻。\n如果无法做到，就向至爱者或宇宙的精神或更高的力量敞开自己的心灵。请求感受到从出生之处就具有的美善。\n参加能够导致自我祝福的活动。寻求承受者从我的祝福的礼物中再次绽放的状态。\n参加静修。由静修老师指导。\n当逐渐相信的时候，就可以将他给予别人了，从最亲近的人开始。慢慢扩大范围。\n第一阶段慈悲后，可以逐渐挑战那些我们认为不配，残忍，很坏的人。达到真正慈悲。\n始终相信每个人都对自己人生家庭充满希望和梦想。\n\n社群的习惯当与他人隔绝时，我们只不过是一粒微笑的沙子。轻易就能被吹走。在我们选择的社区中，我们成了岩石。能够勇敢面对大海的怒涛。直接影响一个人的事物，会间接影响到所有人。人不能离群索居，群体能够克服其他习惯无法克服的恐惧—最核心的恐惧，即：我们本质上都孤独地活在这个世界上。\n我们需要社群给我们勇气，激励我们去改变，要求我们承担责任，不管这种社群是我们采用什么形式找到或创建的，我们不能独自渡过难关。也不想独自度过美好时光。与他人分享我们的痛苦和喜悦有助于让我们远离恐惧本性中的黑暗，接纳我们心中始终存在的爱与被爱的自我。社交有助于我们敞开心灵。\n然而团队并不意味着盲从，真正的团队能够包容意见，甚至鼓励不同意见和个性存在。当拥有独立思考的人组成齐心协力的团体，欣赏和肯定相互之间的分歧并且不会因此相互排斥时，就形成了健康的社群。\n我们终生都需要远离与世隔绝和从众思维。走向温暖和力量的群社。\n如何实践社群\n\n自觉选择与那些充满爱和正面能量的人共处，而不是那些排斥不同意见或喜好说教的人共处。\n留意家庭，生意场，社交网络中那些喜欢将人分为三六九等并且加以褒贬的人。\n真诚寻找社群成员，并了解社群在他们的生活中所扮演的角色。\n以梦想或兴趣爱好的方式寻找社群。\n练习静默。\n在社区活动中慷慨地对待别人。\n尊重每个人的差异性，让每个人都可以分享至爱者的光明。\n当我们向丰盈之爱敞开心扉之时，我们的生命就会变得更加美好，世界也将变得更为公平公正。让我们放下积怨，放下对自己或他人的责备，通过赞美并分享已然安住在我们心中的爱，让自己摆脱深受其苦的恐惧，愤怒和悲伤。在内心找到勇敢而充满创造力的声音，告别索然无味的沉闷生活，开始充满活力的欢快生活。\n\n","categories":["读书笔记"],"tags":["沟通","爱"]},{"title":"JVM知识点汇总","url":"/2021_10_15_jvm/","content":"JVM 知识点汇总\n\n\n内存模型：程序计数器、方法区、堆、栈、本地方法栈的作用，保存哪些数据。\n类加载：双亲委派的加载机制，以及常用类加载器分别加载哪种类型的类。\nGC：分代回收的思想和依据，以及不同垃圾回收算法实现的思路、适合的场景。 \n性能调优：常用的 JVM 优化参数的作用，参数调优的依据，常用的 JVM 分析工具能分析哪类问题，以及使用方法。\n执行模式：解释、编译、混合模式的优缺点，Java7 提供的分层编译技术。需要知道 JIT 即时编译技术和 OSR（栈上替换），知道C1、C2编译器针对的场景，其中 C2针对 Server模式，优化更激进。在新技术方面可以了解Java10 提供的由 Java 实现的 Graal 编译器。\n编译优化：前端编译器javac 的编译过程、AST 抽象语法树、编译期优化和运行期优化。编译优化的常用技术包括公共子表达式的消除、方法内联、逃逸分析、栈上分配、同步消除等。明白了这些才能写出对编译器友好的代码。\n\nJVM 内存模型JVM 内存模型主要指运行时的数据区，包括 5 个部分，如下图所示。\n   \n\n\n\n栈也叫方法栈，是线程私有的，线程在执行每个方法时都会同时创建一个栈帧，用来存储局部变量表、操作栈、动态链接、方法出口等信息。调用方法时执行入栈，方法返回时执行出栈。\n本地方法栈与栈类似，也是用来保存线程执行方法时的信息，不同的是，执行 Java 方法使用栈，而执行 native 方法使用本地方法栈。\n程序计数器保存着当前线程所执行的字节码位置，每个线程工作时都有一个独立的计数器。程序计数器为执行Java方法服务，执行 native 方法时，程序计数器为空。\n栈、本地方法栈、程序计数器这三个部分都是线程独占的。\n堆是 JVM 管理的内存中最大的一块，堆被所有线程共享，目的是为了存放对象实例，几乎所有的对象实例都在这里分配。当堆内存没有可用的空间时，会抛出 OOM 异常。\n根据对象存活的周期不同，JVM 把堆内存进行分代管理，由垃圾回收器来进行对象的回收管理。\n方法区也是各个线程共享的内存区域，又叫非堆区。用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据，JDK 1.7 中的永久代和JDK 1.8 中的 Metaspace 都是方法区的一种实现。\n试回答这个问题时，要答出两个要点：一个是各部分的功能，另一个是哪些线程共享，哪些独占。\n\nJMM 内存可见性JMM 是 Java 内存模型，与 JVM 内存模型是两回事，JMM 的主要目标是定义程序中变量的访问规则，如下图所示，所有的共享变量都存储在主内存中共享。每个线程有自己的工作内存，工作内存中保存的是主内存中变量的副本，线程对变量的读写等操作必须在自己的工作内存中进行，而不能直接读写主内存中的变量。\n\n\n\n在多线程进行数据交互时，例如线程 A 给一个共享变量赋值后，由线程 B 来读取这个值，A 修改完变量是修改在自己的工作区内存中，B 是不可见的，只有从 A 的工作区写回主内存，B 再从主内存读取自己的工作区才能进行进一步的操作。由于指令重排序的存在，这个写—读的顺序有可能被打乱。因此 JMM 需要提供原子性、可见性、有序性的保证。\n\n详解JMM保证如下图所示，来看JMM如何保证原子性、可见性，有序性。\n \n\n原子性JMM 保证对除 long 和 double 外的基础数据类型的读写操作是原子性的。另外关键字 synchronized 也可以提供原子性保证。synchronized 的原子性是通过 Java 的两个高级的字节码指令 monitorenter 和 monitorexit 来保证的。\n可见性JMM可见性的保证，一个是通过 synchronized，另外一个就是 volatile。volatile 强制变量的赋值会同步刷新回主内存，强制变量的读取会从主内存重新加载，保证不同的线程总是能够看到该变量的最新值。\n有序性对有序性的保证，主要通过 volatile 和一系列 happens-before 原则。volatile 的另一个作用就是阻止指令重排序，这样就可以保证变量读写的有序性。\nhappens-before原则包括一系列规则，如：\n程序顺序原则，即一个线程内必须保证语义串行性；\n锁规则，即对同一个锁的解锁一定发生在再次加锁之前；\nhappens-before原则的传递性、线程启动、中断、终止规则等。\n\n类加载机制类的加载指将编译好的 Class 类文件中的字节码读入内存中，将其放在方法区内并创建对应的 Class 对象。类的加载分为加载、链接、初始化，其中链接又包括验证、准备、解析三步。如下图所示。\n  \n\n\n加载是文件到内存的过程。通过类的完全限定名查找此类字节码文件，并利用字节码文件创建一个 Class 对象。\n验证是对类文件内容验证。目的在于确保 Class 文件符合当前虚拟机要求，不会危害虚拟机自身安全。主要包括四种：文件格式验证，元数据验证，字节码验证，符号引用验证。\n准备阶段是进行内存分配。为类变量也就是类中由 static 修饰的变量分配内存，并且设置初始值。这里要注意，初始值是 0 或者null，而不是代码中设置的具体值，代码中设置的值是在初始化阶段完成的。另外这里也不包含用 final 修饰的静态变量，因为 final 在编译的时候就会分配。\n解析主要是解析字段、接口、方法。主要是将常量池中的符号引用替换为直接引用的过程。直接引用就是直接指向目标的指针、相对偏移量等。\n初始化，主要完成静态块执行与静态变量的赋值。这是类加载最后阶段，若被加载类的父类没有初始化，则先对父类进行初始化。\n只有对类主动使用时，才会进行初始化，初始化的触发条件包括在创建类的实例时、访问类的静态方法或者静态变量时、Class.forName() 反射类时、或者某个子类被初始化时。\n如上图所示，浅绿的两个部分表示类的生命周期，就是从类的加载到类实例的创建与使用，再到类对象不再被使用时可以被 GC 卸载回收。这里要注意一点，由 Java 虚拟机自带的三种类加载器加载的类在虚拟机的整个生命周期中是不会被卸载的，只有用户自定义的类加载器所加载的类才可以被卸载。\n\n详解类加载器\n\n\n如上图所示，Java 自带的三种类加载器分别是：BootStrap 启动类加载器、扩展类加载器和应用加载器（也叫系统加载器）。图右边的桔黄色文字表示各类加载器对应的加载目录。启动类加载器加载 java home 中 lib 目录下的类，扩展加载器负责加载 ext 目录下的类，应用加载器加载 classpath 指定目录下的类。除此之外，可以自定义类加载器。\n\n的类加载使用双亲委派模式，即一个类加载器在加载类时，先把这个请求委托给自己的父类加载器去执行，如果父类加载器还存在父类加载器，就继续向上委托，直到顶层的启动类加载器，如上图中蓝色向上的箭头。如果父类加载器能够完成类加载，就成功返回，如果父类加载器无法完成加载，那么子加载器才会尝试自己去加载。如图中的桔黄色向下的箭头。\n\n这种双亲委派模式的好处，可以避免类的重复加载，另外也避免了 Java 的核心 API 被篡改。\n\n\n详解分代回收Java 的堆内存被分代管理，为什么要分代管理呢？分代管理主要是为了方便垃圾回收，这样做基于2个事实，第一，大部分对象很快就不再使用；第二，还有一部分不会立即无用，但也不会持续很长时间。\n虚拟机划分为年轻代、老年代、和永久代，如下图所示。\n  \n\n\n年轻代主要用来存放新创建的对象，年轻代分为 Eden 区和两个 Survivor 区。大部分对象在 Eden 区中生成。当 Eden 区满时，还存活的对象会在两个 Survivor 区交替保存，达到一定次数的对象会晋升到老年代。\n老年代用来存放从年轻代晋升而来的，存活时间较长的对象。\n永久代，主要保存类信息等内容，这里的永久代是指对象划分方式，不是专指 1.7 的 PermGen，或者 1.8 之后的 Metaspace。\n\n根据年轻代与老年代的特点，JVM 提供了不同的垃圾回收算法。垃圾回收算法按类型可以分为引用计数法、复制法和标记清除法。\n\n引用计数法是通过对象被引用的次数来确定对象是否被使用，缺点是无法解决循环引用的问题。\n复制算法需要 from 和 to 两块相同大小的内存空间，对象分配时只在 from 块中进行，回收时把存活对象复制到 to 块中，并清空 from 块，然后交换两块的分工，即把 from 块作为 to 块，把 to 块作为 from 块。缺点是内存使用率较低。\n标记清除算法分为标记对象和清除不在使用的对象两个阶段，标记清除算法的缺点是会产生内存碎片。\n\nJVM 中提供的年轻代回收算法 Serial、ParNew、Parallel Scavenge 都是复制算法，而 CMS、G1、ZGC 都属于标记清除算法。\n详解 CMS 算法基于分代回收理论，详细介绍几个典型的垃圾回收算法，先来看 CMS 回收算法。CMS 在 JDK1.7 之前可以说是最主流的垃圾回收算法。CMS 使用标记清除算法，优点是并发收集，停顿小。\nCMS 算法如下图所示。\n  \n\n\n第一个阶段是初始标记，这个阶段会 stop the world，标记的对象只是从 root 集最直接可达的对象；\n第二个阶段是并发标记，这时 GC \n第三个阶段是重新标记阶段，这个阶段是第二个 stop the world 的阶段，停顿时间比并发标记要小很多，但比初始标记稍长，主要对对象进行重新扫描并标记；\n第四个阶段是并发清理阶段，进行并发的垃圾清理\n最后一个阶段是并发重置阶段，为下一次 GC 重置相关数据结构。\n\n详解 G1 算法G1 在 1.9 版本后成为 JVM 的默认垃圾回收算法，G1 的特点是保持高回收率的同时，减少停顿。\nG1 算法取消了堆中年轻代与老年代的物理划分，但它仍然属于分代收集器。G1 算法将堆划分为若干个区域，称作 Region，如下图中的小方格所示。一部分区域用作年轻代，一部分用作老年代，另外还有一种专门用来存储巨型对象的分区。\n\n\nG1 也和 CMS 一样会遍历全部的对象，然后标记对象引用情况，在清除对象后会对区域进行复制移动整合碎片空间。\nG1 回收过程如下。\n\nG1 的年轻代回收，采用复制算法，并行进行收集，收集过程会 STW。\nG1 的老年代回收时也同时会对年轻代进行回收。主要分为四个阶段：\n依然是初始标记阶段完成对根对象的标记，这个过程是STW的\n并发标记阶段，这个阶段是和用户线程并行执行的；\n最终标记阶段，完成三色标记周期;\n复制&#x2F;清除阶段，这个阶段会优先对可回收空间较大的 Region 进行回收，即 garbage first，这也是 G1 名称的由来。\n\n\n\nG1 采用每次只清理一部分而不是全部的 Region 的增量式清理，由此来保证每次 GC 停顿时间不会过长。\n总结如下，G1 是逻辑分代不是物理划分，需要知道回收的过程和停顿的阶段。此外还需要知道，G1 算法允许通过 JVM 参数设置 Region 的大小，范围是 1～32MB，可以设置期望的最大 GC 停顿时间等。有兴趣读者也可以对 CMS 和 G1 使用的三色标记算法做简单了解。\n详解 ZGC算法ZGC特点ZGC 是最新的 JDK1.11 版本中提供的高效垃圾回收算法，ZGC 针对大堆内存设计可以支持 TB 级别的堆，ZGC 非常高效，能够做到 10ms 以下的回收停顿时间。\n这么快的响应，ZGC 是如何做到的呢？这是由于 ZGC 具有以下特点。\n\nZGC 使用了着色指针技术，我们知道 64 位平台上，一个指针的可用位是 64 位，ZGC 限制最大支持 4TB 的堆，这样寻址只需要使用 42 位，那么剩下 22 位就可以用来保存额外的信息，着色指针技术就是利用指针的额外信息位，在指针上对对象做着色标记\n第二个特点是使用读屏障，ZGC 使用读屏障来解决 GC 线程和应用线程可能并发修改对象状态的问题，而不是简单粗暴的通过 STW 来进行全局的锁定。使用读屏障只会在单个对象的处理上有概率被减速。\n由于读屏障的作用，进行垃圾回收的大部分时候都是不需要 STW 的，因此 ZGC 的大部分时间都是并发处理，也就是 ZGC 的第三个特点。\n第四个特点是基于 Region，这与 G1 算法一样，不过虽然也分了 Region，但是并没有进行分代。ZGC 的 Region 不像 G1 那样是固定大小，而是动态地决定 Region 的大小，Region 可以动态创建和销毁。这样可以更好的对大对象进行分配管理。\n第五个特点是压缩整理。CMS 算法清理对象时原地回收，会存在内存碎片问题。ZGC 和 G1 一样，也会在回收后对 Region 中的对象进行移动合并，解决了碎片问题。\n\n虽然 ZGC 的大部分时间是并发进行的，但是还会有短暂的停顿。来看一下 ZGC 的回收过程。\nZGC 回收过程如下图所示，使用 ZGC 算法进行回收，从上往下看。初始状态时，整个堆空间被划分为大小不等的许多 Region，即图中绿色的方块。\n\n\n开始进行回收时，ZGC 首先会进行一个短暂的 STW，来进行 roots 标记。这个步骤非常短，因为 roots 的总数通常比较小。\n然后就开始进行并发标记，如上图所示，通过对对象指针进行着色来进行标记，结合读屏障解决单个对象的并发问题。其实，这个阶段在最后还是会有一个非常短的 STW 停顿，用来处理一些边缘情况，这个阶段绝大部分时间是并发进行的，所以没有明显标出这个停顿。\n下一个是清理阶段，这个阶段会把标记为不在使用的对象进行回收，如上图所示，把橘色的不在使用的对象进行了回收。\n最后一个阶段是重定位，重定位就是对 GC 后存活的对象进行移动，来释放大块的内存空间，解决碎片问题。\n重定位最开始会有一个短暂的 STW，用来重定位集合中的 root 对象。暂停时间取决于 root 的数量、重定位集与对象的总活动集的比率。\n最后是并发重定位，这个过程也是通过读屏障，与应用线程并发进行的。\n面试考察点\n深入了解 JVM 的内存模型和 Java 的内存模型；\n要了解类的加载过程，了解双亲委派机制；\n要了解常用的 GC 算法的特点、执行过程，和适用场景，例如 G1 适合对最大延迟有要求的场合，ZGC 适用于 64 位系统的大内存服务中\n要了解常用的 JVM 参数，明白对不同参数的调整会有怎样的影响，适用什么样的场景，例如垃圾回收的并发数、偏向锁设置等。\n\n加分项如果想要给面试官留下更好的印象，注意这些加分项。\n\n如果在编译器优化方面有深入的了解的话，会让面试官觉得你对技术的深度比较有追求。例如知道在编程时如何合理利用栈上分配降低 GC 压力、如何编写适合内联优化等代码等。\n如果你能有线上实际问题的排查经验或思路那就更好了，面试官都喜欢动手能力强的同学。例如解决过线上经常 FullGC 问题，排查过内存泄露问题等。\n如果能有针对特定场景的 JVM 优化实践或者优化思路，也会有意想不到的效果。例如针对高并发低延迟的场景，如何调整 GC 参数尽量降低 GC 停顿时间，针对队列处理机如何尽可能提高吞吐率等；\n如果对最新的 JVM 技术趋势有所了解，也会给面试官留下比较深刻的印象。例如了解 ZGC 高效的实现原理，了解 Graalvm 的特点等。\n\n真题汇总总结 JVM 相关的面试真题，第一部分真题如下，课后可以重点练习。\n\n解题思路如下所示。\n\n\n第 1 题 Java 内存模型前面讲过，面试时回答这个问题时记得和面试官确认是希望回答 JVM 的内存模型，还是 Java 对内存访问的模型，不要答跑偏。\n第 2 题要复习一下什么场景下会触发 FullGC，例如年轻代晋升时老年代空间不足，例如永久代空间不足等。\n第 3～6 题前面已经有过讲解，因此不再重复。\n\n第二部分真题如下所示。\n\n\n解题思路如下所示。\n\n第 7 题 volatile 要重点回答强制主内存读写同步以及防止指令重排序两点。\n第 8、9 题前面已经讲过\n第 10 题重点介绍出强、弱、软、虚四种引用，以及在 GC 中的处理方式。\n第 11 题可以了解一下 Java 自带的几种工具的功能，例如 JMC 中的飞行记录器，堆分析工具 MAT，线程分析工具 jstack 和获取堆信息的 jmap 等。\n\n","categories":["总结笔记"],"tags":["Java","JVM","JMM"]},{"title":"Java并发与多线程总结","url":"/2021_10_18_multity_thread/","content":"本文的主要内容是 Java 的多线程和并发。重点知识有线程的状态转换、线程的同步与互斥、线程池的运作机制详解，以及JUC 中常用的工具类。\n多线程知识点\n\n多线程协作时，因为对资源的锁定与等待会产生死锁，这里需要了解产生死锁的四个基本条件，要明白竞争条件与临界区的概念，知道可以通过破坏造成死锁的 4 个条件来防止死锁。\n前面讲过进程间的通信方式，这里还要知道线程间的通信方式，通信主要指线程之间的协作机制，例如 wait、notify 等。\n还需要知道 Java 为多线程提供的一些机制，例如 ThreadLocal 用来保存线程独享的数据， Fork&#x2F;Join 机制用于大任务的分割与汇总，Volatile 对多线程数据可见性的保证，以及线程的中断机制\n其他还有：ThreadLocal 的实现机制。Fork&#x2F;Join 的工作窃取算法等内容\n详解线程状态转换线程是 JVM 执行任务的最小单元，理解线程的状态转换是理解后续多线程问题的基础。在 JVM 运行中，线程一共有 NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED 六种状态，这些状态对应 Thread.State 枚举类中的状态\n如下图所示，当创建一个线程时，线程处在 NEW 状态，运行 Thread 的 start 方法后，线程进入 RUNNABLE 可运行状态。\n\n\n这时，所有可运行状态的线程并不能马上运行，而是需要先进入就绪状态等待线程调度，如图中间所示的 READY 状态。在获取 CPU 后才能进入运行状态，如图中所示的 RUNNING。运行状态可以随着不同条件转换成除 NEW 以外的其他状态。\n如图左侧所示，在运行态中的线程进入 synchronized 同步块或者同步方法时，如果获取锁失败，则会进入到 BLOCKED 状态。当获取到锁后，会从 BLOCKED 状态恢复到就绪状态\n如图右侧所示，运行中的线程还会进入等待状态，这两个等待一个是有超时时间的等待，例如调用 Object.wait、Thread.join 等；另外一个是无超时的等待，例如调用 Thread.join 或者 Locksupport.park 等。这两种等待都可以通过 notify 或 unpark 结束等待状态并恢复到就绪状态。\n最后是线程运行完成结束时，如图下侧所示，线程状态变成 TERMINATED。\n详解 CAS 与 ABA 问题这部分内容详解线程的同步与互斥，解决线程同步与互斥的主要方式是 CAS、synchronized 和 lock。\nCASCAS 是乐观锁的一种实现方式，是一种轻量级锁，JUC 中很多工具类的实现就是基于 CAS 的。CAS 操作的流程如下图所示，线程在读取数据时不进行加锁，在准备写回数据时，比较原值是否修改，若未被其他线程修改则写回，若已被修改，则重新执行读取流程。这是一种乐观策略，认为并发操作并不总会发生。\n\n\n比较并写回的操作是通过操作系统原语实现的，保证执行过程中不会被中断。\nABACAS 容易出现 ABA 问题，就是如下面时序图所示，如果线程 T1 读取值 A 之后，发生两次写入，先由线程 T2 写回了 B，又由 T3 写回了 A，此时 T1 在写回比较时，值还是 A，就无法判断是否发生过修改。\n\n\nABA 问题不一定会影响结果，但还是需要防范，解决的办法可以增加额外的标志位或者时间戳。JUC 工具包中提供了这样的类。\n详解 synchronizedsynchronized 是最常用的线程同步手段之一，它是如何保证同一时刻只有一个线程可以进入临界区呢\nsynchronized 对对象进行加锁，在 JVM 中，对象在内存中分为三块区域：对象头、实例数据和对齐填充。在对象头中保存了锁标志位和指向 monitor 对象的起始地址，如下图所示，右侧就是对象对应的 Monitor 对象。当 Monitor 被某个线程持有后，就会处于锁定状态，如图中的 Owner 部分，会指向持有 Monitor 对象的线程。另外 Monitor 中还有两个队列，用来存放进入及等待获取锁的线程。\n\n\nsynchronized 应用在方法上时，在字节码中是通过方法的 ACC_SYNCHRONIZED 标志来实现的，synchronized 应用在同步块上时，在字节码中是通过 monitorenter 和 monitorexit 实现的\n针对 synchronized 获取锁的方式，JVM 使用了锁升级的优化方式，就是先使用偏向锁优先同一线程然后再次获取锁，如果失败，就升级为 CAS 轻量级锁，如果失败就会短暂自旋，防止线程被系统挂起。最后如果以上都失败就升级为重量级锁。\n详解 AQS 与 Lock在介绍 Lock 前，先介绍 AQS，也就是队列同步器，这是实现 Lock 的基础。下图就是 AQS 的结构图，从图中可以看出，AQS 有一个 state 标记位，值为1 时表示有线程占用，其他线程需要进入到同步队列等待。同步队列是一个双向链表。\n\n\n当获得锁的线程需要等待某个条件时，会进入 condition 的等待队列，等待队列可以有多个。当 condition 条件满足时，线程会从等待队列重新进入同步队列进行获取锁的竞争。ReentrantLock 就是基于 AQS 实现的，如下图所示，ReentrantLock 内部有公平锁和非公平锁两种实现，差别就在于新来的线程是否比已经在同步队列中的等待线程更早获得锁。\n和 ReentrantLock 实现方式类似，Semaphore 也是基于 AQS 的，差别在于 ReentrantLock 是独占锁，Semaphore 是共享锁。\n\n\n详解线程池线程池通过复用线程，避免线程频繁地创建和销毁。Java 的 Executors 工具类中提供了 5 种类型的线程池创建方法，如下图所示，来看它们的特点和适用场景。\n\n\n\n固定大小线程池，特点是线程数固定，使用无界队列，适用于任务数量不均匀的场景、对内存压力不敏感但系统负载比较敏感的场景\nCached 线程池，特点是不限制线程数，适用于要求低延迟的短期任务场景；\n单线程线程池，就是一个线程的固定线程池，适用于需要异步执行但需要保证任务顺序的场景；\nScheduled 线程池，适用于定期执行任务场景，支持按固定频率定期执行和按固定延时定期执行两种方式\n工作窃取线程池，使用的是 ForkJoinPool，是固定并行度的多任务队列，适合任务执行时长不均匀的场景。\n\n详解线程池参数线程池除了工作窃取线程池外，都是通过 ThreadPoolExecutor 的不同初始化参数来创建的。\n创建参数列表如下图所示。\n\n\n\n第一个参数设置核心线程数。默认情况下核心线程会一直存活。\n第二个参数设置最大线程数。决定线程池最多可以创建的多少线程。\n第三个参数和第四个参数用来设置线程空闲时间，和空闲时间的单位，当线程闲置超过空闲时间就会被销毁。可以通过 allowCoreThreadTimeOut 方法来允许核心线程被回收。\n第五个参数设置缓冲队列，上图中左下方的三个队列是设置线程池时常使用的缓冲队列。其中 ArrayBlockingQueue 是一个有界队列，就是指队列有最大容量限制。LinkedBlockingQueue 是无界队列，就是队列不限制容量。最后一个是 SynchronousQueue，是一个同步队列，内部没有缓冲区。\n第六个参数设置线程池工厂方法，线程工厂用来创建新线程，可以用来对线程的一些属性进行定制，例如线程的 group、线程名、优先级等。一般使用默认工厂类即可。\n第七个参数设置线程池满时的拒绝策略。如上图右下方所示有四种策略，Abort 策略在线程池满后，提交新任务时会抛出 RejectedExecutionException，这个也是默认的拒绝策略。Discard 策略会在提交失败时对任务直接进行丢弃。CallerRuns 策略会在提交失败时，由提交任务的线程直接执行提交的任务。DiscardOldest 策略会丢弃最早提交的任务。\n\n再来看前面的几种线程池都是使用怎样的参数来创建的。\n\n固定大小线程池创建时核心和最大线程数都设置成指定的线程数，这样线程池中就只会使用固定大小的线程数。\n队列使用无界队列 LinkedBlockingQueue\nSingle 线程池就是线程数设置为 1 的固定线程池\nCached 线程池的核心线程数设置为 0，最大线程数是 Integer.MAX_VALUE，主要是通过把缓冲队列设置成 SynchronousQueue，这样只要没有空闲线程就会新建。\nScheduled 线程池与前几种不同的是使用了 DelayedWorkQueue，这是一种按延迟时间获取任务的优先级队列。\n\n详解线程池执行流程向线程提交任务时可以使用 execute 和 submit，区别就是 submit 可以返回一个 future 对象，通过 future 对象可以了解任务执行情况，可以取消任务的执行，还可获取执行结果或执行异常。submit 最终也是通过 execute 执行的。\n\n向线程池提交任务时的执行顺序如下图所示。\n\n\n\n向线程池提交任务时，会首先判断线程池中的线程数是否大于设置的核心线程数，如果不大于，就创建一个核心线程来执行任务\n如果大于核心线程数，就会判断缓冲队列是否满了，如果没有满，则放入队列，等待线程空闲时执行任务。\n如果队列已经满了，则判断是否达到了线程池设置的最大线程数，如果没有达到，就创建新线程来执行任务。\n如果已经达到了最大线程数，则执行指定的拒绝策略。\n\n这里需要注意队列的判断与最大线程数判断的顺序，不要搞反\n详解 JUC 工具类JUC 是 Java 提供的用于多线程处理的工具类库，来看其中的常用工具类的作用，如下图所示。\n\n\n如上图所示，第一行的类都是基本数据类型的原子类，包括 AtomicBoolean、AtomicLong、AtomicInteger 类。\n\nAtomicLong 通过 unsafe 类实现，基于CAS。unsafe 类是底层工具类，JUC 中很多类的底层都使用到了 unsafe 包中的功能。unsafe 类提供了类似 C 的指针操作，提供 CAS 等功能。unsafe 类中的所有方法都是 native 修饰的\nLongAdder等 4 个类是 JDK1.8 中提供的更高效的操作类。LongAdder 基于 Cell 实现，使用分段锁思想，是一种空间换时间的策略，更适合高并发场景；LongAccumulator 提供了比 LongAdder 更强大的功能，能够指定对数据的操作规则，例如可以把对数据的相加操作改成相乘操作。\n\n第二行中的类提供了对对象的原子读写功能，后两个类 AtomicStampedReference 和 AtomicMarkableReference 用于解决前面提到的 ABA 问题，分别基于时间戳和标记位来解决问题。\n再看下图。\n\n\n第一行的类主要是锁相关的类，例如前面介绍过的 Reentrant 重入锁。\n\n与 ReentrantLock 的独占锁不同，Semaphore 是共享锁，允许多个线程共享资源，适用于限制使用共享资源线程数量的场景，例如 100 个车辆要使用 20 个停车位，那么最多允许 20 个车占用停车位\nStampedLock 是JDK 1.8 改进的读写锁，是使用一种 CLH 的乐观锁，能够有效防止写饥饿。所谓写饥饿就是在多线程读写时，读线程访问非常频繁，导致总是有读线程占用资源，写线程很难加上写锁。\n\n第二行中主要是异步执行相关的类\n\n重点了解 JDK 1.8 中提供的 CompletableFuture，可以支持流式调用，可以方便的进行多 future 的组合使用，例如可以同时执行两个异步任务，然后对执行结果进行合并处理。还可以很方便地设置完成时间\n另外一个是 JDK 1.7 中提供的 ForkJoinPool，采用分治思想，将大任务分解成多个小任务处理，然后在合并处理结果。ForkJoinPool 的特点是使用工作窃取算法，可以有效平衡多任务时间长短不一的场景。\n\n其他 JUC 常用工具如下图所示。\n\n\n第一行是常用的阻塞队列，讲解线程池时已经简单介绍过了，这里再补充一些。\n\nLinkedBlockingDeque 是双端队列，也就是可以分别从队头和队尾操作入队、出队。\nArrayBlockingQueue 单端队列，只能从队尾入队，队头出队。\n\n第二行是控制多线程协作时使用的类。\n\nCountDownLatch 实现计数器功能，可以用来控制等待多个线程执行任务后进行汇总\nCyclicBarrier 可以让一组线程等待至某个状态之后，再全部同时执行，一般在测试时使用，可以让多线程更好的并发执行。\nSemaphore 用来控制对共享资源的访问并发度。\n\n最后一行是比较常用的两个集合类，ConcurrentHashMap 我们前面的课程已经详细介绍过了，这里可以了解 CopyOnWriteArrayList，COW 通过写入数据时进行 copy 修改，然后更新引用的方式，来消除并行读写中的锁使用，比较适合读多写少，数据量比较小，但是并发非常高的场景。\n考察点讲解完本课时的知识点，总结下面试考察点。\n\n要理解线程同步与互斥的原理，包括临界资源、临界区的概念，知道重量级锁、轻量级锁、自旋锁、偏向锁、重入锁、读写锁的概念。\n要掌握线程安全相关机制，例如 CAS、synchronized、Lock 三种同步方式的实现原理、要明白 ThreadLocal 是每个线程独享的局部变量，了解 ThreadLocal 使用弱引用的 ThreadLocalMap 保存不同的 ThreadLocal 变量。\n要了解 JUC 中的工具类的使用场景与主要的几种工具类的实现原理，例如 Reentrantlock，ConcurrentHashMap、LongAdder 等实现方式。\n要熟悉线程池的原理、使用场景、常用配置，例如大量短期任务的场景适合使用 Cached 线程池；系统资源比较紧张时，可以选择固定线程池。另外注意慎用无界队列，可能会有 OOM 的风险。\n要深刻理解线程的同步与异步、阻塞与非阻塞，同步和异步的区别在于任务是否是同一个线程执行，阻塞与非阻塞的区别在于异步执行任务时，线程是会阻塞等待结果，还是会继续执行后续逻辑。\n\n加分项掌握了上面这些内容，如果能做到这几点加分项，一定会给面试官留下更好的印象。\n\n可以结合实际项目经验或者实际案例介绍原理，例如介绍线程池设置时，可以提到自己的项目中有一个需要高吞吐量的场景，使用了 Cached 的线程池。\n如果有过解决多线程问题的经验或者排查思路的话会获得面试加分。\n能够熟悉常用的线程分析工具与方法，例如会用 jstack 分析线程的运行状态，查找锁对象持有状况等。\n了解 Java 8 对 JUC 工具类做了哪些增强，例如提供了 LongAdder 来替换 AtomicLong，更适合并发度比较高的场景。\n了解 Reactive 异步编程思想，了解 back pressure 背压的概念与应用场景。\n\n真题汇总总结相关的面试真题，如下图所示，对重点题目提供一些思路。\n\n\n\n第 1 题如何实现一个生产者与消费者模型？可以尝试通过锁、信号量、线程通信、阻塞队列等不同方式实现。\n\n第 4 题 wait 与 sleep 的有什么不同？回答的要点四个：\n\nwait 属于 Object 类，sleep 属于 Thread 类；\nwai\n使用的位置不同，wait 需要在同步块中使用，sleep 可以在任意地方\nleep 需要捕获异常，而 wait 不需要。\n\n\n第 6 题，读写锁适用于什么场景？可以回答读写锁适合读并发多，写并发少的场景，另外一个解决这种场景的方法是 copyonwrite。\n\n\n\n\n\n第 7 题，线程之间如何通信？主要可以介绍一下 wait&#x2F;notify 机制，共享变量的 synchronized 或者 Lock 同步机制等。\n第 8 题，保证线程安全的方法有哪些？可以提 CAS、synchronized、Lock，以及 ThreadLocal 等机制。\n第 9 题，如何尽可能提高多线程并发性能？可以从尽量减少临界区范围，使用 ThreadLocal，减少线程切换、使用读写锁或 copyonwrite 等机制这些方面来回答\n第 10 题，ThreadLocal 用来解决什么问题？ThreadLocal 是如何实现的？可以重点回答 ThreadLocal 不是用来解决多线程共享变量的问题，而是用来解决线程数据隔离的问题。\n\n","categories":["总结笔记"],"tags":["Java","多线程","并发"]},{"title":"数据结构与算法总结","url":"/2021_10_19_algo/","content":"本文的主题为数据结构与算法。行业里流行一种说法：程序 &#x3D; 数据结构 + 算法。虽然有些夸张，但足以说明数据结构与算法的重要性。本文重点讲解四个知识点：\n\n从搜索树到 B+ 树，讲解与树有关的数据结构；\n字符串匹配相关的题目；\n算法面试经常考察的 TopK 问题\n算法题的几种常用解题方法。\n\n数据结构知识点首先看数据结构的知识点都有哪些，如下图所示。\n\n\n\n队列和栈是经常使用的数据结构，需要了解它们的特点。队列是先进先出，栈是后进先出。\n表，包括很多种，有占用连续空间的数组、用指针链接的单向和双向链表，首尾相接的循环链表、以及散列表，也叫哈希表\n图，在特定领域使用的比较多，例如路由算法中会经常使用到，图分为有向图、无向图及带权图，这部分需要掌握图的深度遍历和广度遍历算法，了解最短路径算法\n树的内容，树一般用作查找与排序的辅助结构，剩下两个部分都和树有关，一个是二叉树，一个是多叉树。\n多叉树包括 B 树族，有 B 树、B+ 树、B* 树，比较适合用来做文件检索；另外一个是字典树，适合进行字符串的多模匹配。\n二叉树包括平衡二叉树、红黑树、哈夫曼树，以及堆，适合用于进行数据查找和排序。这部分需要了解二叉树的构建、插入、删除操作的实现，需要掌握二叉树的前序、中序、后序遍历。\n\n算法知识点来看算法部分的知识点汇总，如下图所示。\n\n\n\n算法题的常用解题方法。\n复杂度是衡量算法好坏的标准之一，我们需要掌握计算算法时间复杂度和空间复杂度的方法。计算时间复杂度的方法一般是找到执行次数最多的语句，然后计算语句执行次数的数量级，最后用大写 O 来表示结果。\n常用的字符串匹配算法，了解不同算法的匹配思路\n排序也是经常考察的知识点，排序算法分为插入、交换、选择、归并、基数五类，其中快速排序和堆排序考察的频率最高，要重点掌握，需要能够手写算法实现\n常用的查找算法，包括二分查找、二叉排序树、B 树、Hash、BloomFilter 等，需要了解它们的适用场景，例如二分查找适合小数量集内存查找，B 树适合文件索引，Hash 常数级的时间复杂度更适合对查找效率要求较高的场合，BloomFilter 适合对大数据集进行数据存在性过滤。\n\n详解二叉搜索树二叉搜索树如下图所示，二叉搜索树满足这样的条件，每个节点包含一个值，每个节点至多有两个子树。每个节点左子树节点的值都小于自身的值，每个节点右子树节点的值都大于自身的值。\n\n\n二叉树的查询时间复杂度是 log(N)，但是随着不断的插入、删除节点，二叉树的树高可能会不断变大，当一个二叉搜索树所有节点都只有左子树或者都只有右子树时，其查找性能就退化成线性的了。\n平衡二叉树平衡二叉树可以解决上面这个问题，平衡二叉树保证每个节点左右子树的高度差的绝对值不超过 1，例如 AVL 树。AVL 树是严格的平衡二叉树，插入或删除数据时可能经常需要旋转来保持平衡，比较适合插入、删除比较少的场景\n红黑树红黑树是一种更加实用的非严格的平衡二叉树。红黑树更关注局部平衡而非整体平衡，确保没有一条路径会比其他路径长出 2 倍，所以是接近平衡的，但减少了许多不必要的旋转操作，更加实用。前面提到过，Java 8 的 HashMap 中就应用了红黑树来解决散列冲突时的查找问题。TreeMap 也是通过红黑树来保证有序性的。\n红黑树除了拥有二叉搜索树的特点外，还有以下规则，如下图所示。\n\n\n\n每个节点不是红色就是黑色。\n根节点是黑色。\n每个叶子节点都是黑色的空节点，如图中的黑色三角。\n红色节点的两个子节点都是黑色的。\n任意节点到其叶节点的每条路径上，包含相同数量的黑色节点。\n\n详解B 树B树B 树是一种多叉树，也叫多路搜索树。B 树中每个节点可以存储多个元素，非常适合用在文件索引上，可以有效减少磁盘 IO 次数。B 树中所有结点的最大子节点数称为 B 树的阶，如下图所示是一棵 3 阶 B 树，也叫 2-3 树。\n\n\n一个 m 阶 B 树有如下特点：\n\n非叶节点最多有 m 棵子树\n根节点最少有两个子树，非根、非叶节点最少有 m&#x2F;2 棵子树；\n非叶子结点中保存的关键字个数，等于该节点子树个数−1，就是说一个节点如果有 3棵子树，那么其中必定包含 2 个关键字；\n非叶子节点中的关键字大小有序，如上图中左边的节点中 37、51 两个元素就是有序的；\n节点中每个关键字的左子树中的关键字都小于该关键字，右子树中的关键字都大于该关键字。如上图中关键字 51 的左子树有 42、49，都小于 51，右子树的节点有 59，大于51；\n所有叶节点都在同一层。\n\nB 树在查找时，从根结点开始，对结点内的有序的关键字序列进行二分查找，如果找到就结束，没有找到就进入查询关键字所属范围的子树进行查找，直到叶节点。\n总结一下：\n\nB 树的关键字分布在整颗树中，一个关键字只出现在一个节点中；\n搜索可能在非叶节点停止；\nB 树一般应用在文件系统。\n\nB+树下图是 B 树的一个变种，叫作 B+ 树。\n\n\nB+ 树的定义与 B 树基本相同，除了下面这几个特点。\n\n节点中的关键字与子树数目相同，比如节点中有 3 个关键字，那么就有 3 棵子树；\n关键字对应的子树中的节点都大于或等于关键字，子树中包括关键字自身\n所有关键字都出现在叶子节点中；\n所有叶子节点都有指向下一个叶子节点的指针。\n\n与 B 树不同，B+ 树在搜索时不会在非叶子节点命中，一定会查询到叶子节点；另外一个，叶子节点相当于数据存储层，保存关键字对应的数据，而非叶子节点只保存关键字和指向叶节点的指针，不保存关键字对应的数据，所以同样数量关键字的非叶节点，B+ 树比 B 树要小很多。\nB+ 树更适合索引系统，MySQL 数据库的索引就提供了 B+ 树实现。原因有三个：\n\n由于叶节点之间有指针相连，B+ 树更适合范围检索\n由于非页节点只保存关键字和指针，同样大小非叶节点，B+ 树可以容纳更多的关键字，可以降低树高，查询时磁盘读写代价更低；\nB+ 树的查询效率比较稳定。任何关键字的查找必须走一条从根结点到叶子结点的路，所有关键字查询的路径长度相同，效率相当。\n\n最后可以简单了解，还有一种 B* 树的变种，在 B+ 树的非叶节点上，也增加了指向同一层下一个非叶节点的指针。\n详解字符串匹配字符串匹配问题在面试时，字符串相关的问题经常作为算法考察题，下面来看字符串匹配的问题。先来了解一道常考的面试题：“判断给定字符串中的括号是否匹配”。\n一般面试题目的描述都比较简单，在解答前，可以跟面试官进一步沟通一下题目要求和细节。以这道题为例，可以跟面试官确认括号的范围，是不是只考虑大中小括号就可以，包不包括尖括号；对函数的入参和返回值有没有什么样的要求；需不需要考虑针对大文件的操作等。\n我们假定细化后本题的要求为：只考虑大中小括号；不考虑针对大文件的操作，以字符串作为入参，返回值为布尔类型；未出现括号也算作匹配的情况。那么，解题思路如下。\n\n字符匹配问题可以考虑使用栈的特性来处理。\n遇到左括号时入栈，遇到右括号时出栈对比，看是不是成对的括号。\n当匹配完成时，如果栈内为空说明匹配，否则说明左括号多于右括号。\n\n字符串代码来看实际的实现代码，如下图所示。\n\n\n按照上面的思路，需要对字符串进行遍历，所以首先要能确定栈操作的触发条件，就是定义好括号对，方便入栈和出栈匹配。这里要注意，编码实现时一定要注意编码风格与规范，例如变量命名必须要有明确意义，不要简单使用 a、b 这种没有明确意义的变量名。\n我们首先定义了 brackets 的 map，key 是所有右括号，value 是对应的左括号，这样定义方便出栈时对比括号是否是成对\n再看一下匹配函数的逻辑。这里也要注意，作为工具类函数，要做好健壮性防御，首先要对输入参数进行验空。\n然后我们定义一个保存字符类型的栈，开始对输入的字符串进行遍历。\n如果当前字符是 brackets 中的值，也就是左括号，则入栈。这里要注意，map 的值查询方法是 O(N) 的，因为本题中括号种类很少，才使用这种方式让代码更简洁一些。如果当前字符不是左括号，在使用 containskey 来判断是不是右括号。如果是右括号，需要检验是否匹配，如果栈为空表示右括号多于左括号，如果栈不空，但出栈的左括号不匹配，这两种情况都说明字符串中的括号是不匹配的。\n当遍历完成时，如果栈中没有多余的左括号，则匹配。\n最后强调一下：编码题除了编程思路，一定要注意编程风格和细节点的处理。\n字符串解题思路接下来，总结一下字符串匹配类问题的解题技巧。\n\n首先要认真审题，避免答偏。可以先确定是单模式匹配问题还是多模式匹配问题，命中条件是否有多个。\n然后确定对算法时间复杂度或者内存占用是否有额外要求。\n最后要明确期望的返回值是什么，比如存在有多个命中结果时，是返回第一个命中的，还是全部返回。\n\n关于解题思路。\n\n如果是单模式匹配问题，可以考虑使用 BM 或者 KMP 算法。\n如果是多模匹配，可以考虑使用 Tire 树来解决。\n在实现匹配算法时，可以考虑用前缀或者后缀匹配的方式来进行。\n最后可以考虑是否能够通过栈、二叉树或者多叉树等数据结构来辅助解决。\n\n建议了解一下常见的字符串单模、多模匹配算法的处理思路。\n详解TopKTopK 问题是在实际业务中经常出现的典型问题，例如微博的热门排行就属于 TopK 问题。\nTopK 一般是要求在 N 个数的集合中找到最小或者最大的 K 个值，通常 N 都非常得大。TopK 可以通过排序的方式解决，但是时间复杂度较高，一般是 O(nk)，这里我们来看看更加高效的方法。\n如下图所示，首先取前 K 个元素建立一个大根堆，然后对剩下的 N-K 个元素进行遍历，如果小于堆顶的元素，则替换掉堆顶元素，然后调整堆。当全部遍历完成时，堆中的 K 个元素就是最小的 K 个值。\n\n\n这个算法的时间复杂度是 N*logK。算法的优点是不用在内存中读入全部的元素，能够适用于非常大的数据集。\nTopK 变种问题TopK 变种的问题，就是从 N 个有序队列中，找到最小或者最大的 K 个值。这个问题的不同点在于，是对多个数据集进行排序。由于初始的数据集是有序的，因此不需要遍历完 N 个队列中所有的元素。因此，解题思路是如何减少要遍历的元素。\n解题思路如下图所示。\n\n\n\n第一步先用 N 个队列的队头元素，也就是每个队列的最小元素，组成一个有 K 个元素的小根堆。方式同 TopK 中的方法\n第二步获取堆顶值，也就是所有队列中最小的一个元素\n第三步用这个堆顶元素所在队列的下一个值放入堆顶，然后调整堆。\n最后重复这个步骤直到获取够 K 个数。\n\n这里还可以有个小优化就是第三步往堆顶放入新值时，跟堆的最大值进行一下比较，如果已经大于堆中最大值，就可以提前终止循环了。这个算法的时间复杂度是 (N+K-1)*logK，注意这里与队列的长度无关。\n详解常用算法算法的知识点比较多，提高算法解题能力需要适当刷题，但不能单纯依靠刷题来解决问题。需要掌握几种常用解题思路与方法，才能以不变应万变。这里讲一下：分治、动态规划、贪心、回溯和分支界定这五种常用的算法题解题方法，来看看它们分别适用于什么场景，如何应用。\n分治法分治法的思想是将一个难以直接解决的复杂问题或者大问题，分割成一些规模较小的相同问题，分而治之。比如快速排序、归并排序等都是应用了分治法\n适合使用分治法的场景需要满足三点要求：\n\n可以分解为子问题；\n子问题的解可以合并为原问题的解；\n子问题之间没有关联。\n\n使用分治法解决问题的一般步骤如下图表格所示\n\n\n\n第一步，要找到最小子问题的求解方法；\n第二步，要找到合并子问题解的方法；\n第三步，要找到递归终止条件。\n\n动态规划法动态规划法，与分治法类似，也是将问题分解为多个子问题。与分治法不同的是，子问题的解之间是有关联的。前一子问题的解，为后一子问题的求解提供了有用的信息。动态规划法依次解决各子问题，在求解每一个子问题时，列出所有局部解，通过决策保留那些有可能达到全局最优的局部解。最后一个子问题的解就是初始问题的解。\n使用动态规划的场景需要也满足三点条件\n\n子问题的求解必须是按顺序进行的；\n相邻的子问题之间有关联关系\n最后一个子问题的解就是初始问题的解。\n\n使用动态规划解决问题时，如上图表格第二行。\n\n第一步，先要分析最优解的性质；\n第二步，递归的定义最优解\n第三步，记录不同阶段的最优值；\n第四步，根据阶段最优解选择全局最优解\n\n贪心算法第三个贪心算法，因为它考虑的是局部的最优解，所以贪心算法不是对所有问题都能得到整体最优解。贪心算法的关键是贪心策略的选择。贪心策略必须具备无后效性，就是说某个状态以后的过程不会影响以前的状态，只与当前状态有关。\n贪心算法使用的场景必须满足两点：\n\n局部最优解能产生全局最优解；\n就是刚才说的必须具备无后效性。\n\n如下图所示，使用贪心算法解题的一般步骤为：\n\n第一步，先分解为子问题；\n第二步、按贪心策略计算每个子问题的局部最优解\n第三步，合并局部最优解。\n\n\n\n回溯算法回溯算法实际上是一种深度优先的搜索算法，按选优的条件向前搜索，当探索到某一步时，发现原先选择并不优或达不到目标，就退回上一步重新选择，这种走不通就退回再走的方法就是回溯法。\n回溯法适用于能够深度优先搜索，并且需要获取解空间的所有解的场合，例如迷宫问题等。\n如上图所示，回溯法一般的解题步骤为：\n\n第一步先针对所给问题，确定问题的解空间；\n第二步、确定结点的扩展搜索规则；\n第三步，以深度优先方式搜索解空间，并在搜索过程中用剪枝函数避免无效搜索。\n\n分支界定法最后是分支界定法，与回溯法的求解目标不同。回溯法的求解目标是找出满足约束条件的所有解，而分支界定法的求解目标则是找出满足约束条件的一个解。\n分支界定法适用于广度优先搜索，并且获取解空间的任意解就可以的场合，例如求解整数规划问题\n如上图所示，分支界定法一般的解题步骤：\n\n第一步先确定解的特征\n第二步在确定子节点搜索策略，例如是先入先出，还是先入后出；\n第三步通过广度优先遍历寻找解。\n\n考察点以上是针对数据结构与算法内容划的重点。接下来，从面试官角度出发，总结相关的面试考察点：\n\n了解基本数据结构及特点，例如数据结构中有哪些二叉树，这些树有哪些特点；\n要熟练掌握表、栈、队列、树，深刻理解不同类型实现的使用场景，例如红黑树适合用来做搜索，B+ 树适合用来做索引；\n要了解常用的搜索、排序算法，及复杂度和稳定性。特别是快速排序和堆排序的实现，要熟练掌握；\n要了解常用的字符串处理算法，和处理的思路，例如BM算法使用后缀匹配进行字符串匹配；\n要能够分析算法实现的复杂度，特别是时间复杂度，例如TopK问题的时间复杂度计算；\n要了解五种常用的解题方法，解决问题的思路和解决哪类问题，以及解题的步骤。\n\n加分项要想在算法面试的相关题目获得面试官的加分，牢记下面几点：\n\n能够将数据结构与实际使用场景结合，例如介绍红黑树时结合 TreeMap 的实现；介绍 B+ 树时结合 MySQL 中的索引实现等等；\n能知道不同算法在业务场景中有哪些应用，例如 TopK 算法在热门排序中的应用；\n面对模糊的题目能主动沟通确认条件和边界，例如前面介绍的括号匹配问题时列举的那些细节点，都可以跟面试官再次确认；\n在书写算法代码前，先讲一下解题思路，不要一上来埋头就写。一般解题思路存在问题时，面试官都会适当进行引导\n能够发现解答中的一些问题，给出改进的思路。比如面试时由于时间关系，大家可能都会选择比较保守的解题思路，不一定就是最优解，这时可以在解答后，指出当前算法存在的一些问题，以及改进的思路。比如可以考虑使用多线程的方式来提高求解性能\n\n真题汇总\n\n\n第 1、2 题都是基础算法，必须要牢牢掌握，一些题目要记住递归与非递归的实现，例如树的遍历、快速排序等；\n类似第 5 题这样的对使用内存进行限制的题目，要考虑使用分治思想进行分解处理\n第 6 题数组去重，可以有排序和 Hash 两种思路。\n\n\n\n\n第 9 题成语接龙，可以考虑使用深度优先搜索解决\n第 10 题寻找两节点公共祖先，可以考虑通过递归与非递归两种方式实现。\n\n","categories":["总结笔记"],"tags":["Java","多线程","并发"]},{"title":"缓存中间件总结","url":"/2021_10_22_cache/","content":"本文介绍缓存相关的知识点以及Memcache和Redis这两个最常使用的缓存。重点学习以下三个方面的内容：\n\n使用缓存时常遇到的典型问题；\nMemcache的内存结构；\nRedis相关的知识点以及Redis常用结构的实现。\n\n缓存知识点\n\n类型缓存是高并发场景下提高热点数据访问性能的一个有效手段，在开发项目时会经常使用到。缓存的类型分为：本地缓存、分布式缓存和多级缓存。\n本地缓存就是在进程的内存中进行缓存，比如我们的JVM堆中，可以用LRUMap来实现，也可以使用Ehcache这样的工具来实现。本地缓存是内存访问，没有远程交互开销，性能最好，但是受限于单机容量，一般缓存较小且无法扩展。\n分布式缓存可以很好得解决这个问题。分布式缓存一般都具有良好的水平扩展能力，对较大数据量的场景也能应付自如。缺点就是需要进行远程请求，性能不如本地缓存。\n为了平衡这种情况，实际业务中一般采用多级缓存，本地缓存只保存访问频率最高的部分热点数据，其他的热点数据放在分布式缓存中。\n淘汰策略不管是本地缓存还是分布式缓存，为了保证较高性能，都是使用内存来保存数据，由于成本和内存限制，当存储的数据超过缓存容量时，需要对缓存的数据进行剔除。一般的剔除策略有FIFO淘汰最早数据、LRU 剔除最近最少使用、和LFU剔除最近使用频率最低的数据几种策略。\nMemcache注意后面会把Memcache简称为MC。\n先来看看MC 的特点：\n\nMC处理请求时使用多线程异步IO的方式，可以合理利用CPU多核的优势，性能非常优秀；\nMC功能简单，使用内存存储数据，只支持K-V结构，不提供持久化和主从同步功能；\nMC的内存结构以及钙化问题后面会详细介绍;\nMC对缓存的数据可以设置失效期，过期后的数据会被清除；\n失效的策略采用延迟失效，就是当再次使用数据时检查是否失效；\n当容量存满时，会对缓存中的数据进行剔除，剔除时除了会对过期key进行清理，还会按LRU策略对数据进行剔除。\n\n另外，使用MC 有一些限制：\n\nkey不能超过250个字节\nvalue不能超过1M字节；\nkey的最大失效时间是30天。\n\nRedis先简单说一下Redis 的特点，方便和MC比较。\n与MC不同的是，Redis采用单线程模式处理请求。这样做的原因有2个：一个是因为采用了非阻塞的异步事件处理机制；另一个是缓存数据都是内存操作IO时间不会太长，单线程可以避免线程上下文切换产生的代价。\nRedis支持持久化，所以Redis不仅仅可以用作缓存，也可以用作NoSQL数据库。\n相比MC，Redis还有一个非常大的优势，就是除了K-V之外，还支持多种数据格式，例如list、set、sorted set、hash等。\nRedis提供主从同步机制，以及Cluster集群部署能力，能够提供高可用服务\n详解 Memcache（MC）内存结构首先来看MC的内存结构。MC默认是通过 SlabAllocator来管理内存，如下图所示。Slab机制主要是用来解决频繁malloc&#x2F;free会产生内存碎片的问题。\n\n\n如图左侧，MC会把内存分为许多不同类型的Slab，每种类型Slab用来保存不同大小的对象。每个Slab由若干的Page组成，如图中浅绿色的模块。不同Slab的Page，默认大小是一样的，都是1M，这也是默认MC存储对象不能超过1M的原因。每个Page内又划分为许多的Chunk，Chunk就是实际用来保存对象的空间，就是图中橘色的。不同类型的Slab中Chunk的大小是不同的，当保存一个对象时，MC会根据对象的大小来选择最合适的Chunk来存储，减少空间浪费。\nSlab Allocator创建Slab时的参数有三个，分别是Chunk大小的增长因子，Chunk大小的初始值以及Page的大小。在运行时会根据要保存的对象大小来逐渐创建Slab\n钙化问题来考虑这样一个场景，使用MC来保存用户信息，假设单个对象大约300字节。这时会产生大量的384字节大小的Slab。运行一段时间后，用户信息增加了一个属性，单个对象的大小变成了500字节，这时再保存对象需要使用768字节的Slab，而MC 中的容量大部分创建了384字节的Slab，所以768的Slab非常少。这时虽然384Slab的内存大量空闲，但768Slab还是会根据LRU算法频繁剔除缓存，导致MC的剔除率升高，命中率降低。这就是所谓的MC钙化问题。\n解决钙化问题可以开启MC的Automove机制，每10s调整Slab。也可以分批重启MC缓存，不过要注意重启时要进行一定时间的预热，防止雪崩问题。另外，在使用Memcached时，最好计算一下数据的预期平均长度，调整growth factor， 以获得最恰当的设置，避免内存的大量浪费。\n详解 RedisRedis的知识点结构如下图所示。\n\n\n功能来看Redis提供的功能。\nBitmap位图是支持按bit位来存储信息，可以用来实现BloomFilter；HyperLogLog提供不精确的去重计数功能，比较适合用来做大规模数据的去重统计，例如统计UV；Geospatial可以用来保存地理位置，并作位置距离计算或者根据半径计算位置等。这三个其实也可以算作一种数据结构。\npub&#x2F;sub功能是订阅发布功能，可以用作简单的消息队列。\nPipeline可以批量执行一组指令，一次性返回全部结果，可以减少频繁的请求应答。\nRedis支持提交Lua脚本来执行一系列的功能。\n最后一个功能是事务，但Redis提供的不是严格的事务，Redis只保证串行执行命令，并且能保证全部执行，但是执行命令失败时并不会回滚，而是会继续执行下去。\n持久化Redis提供了RDB和AOF两种持久化方式，RDB是把内存中的数据集以快照形式写入磁盘，实际操作是通过fork子进程执行，采用二进制压缩存储；AOF是以文本日志的形式记录Redis处理的每一个写入或删除操作。\nRDB把整个Redis的数据保存在单一文件中，比较适合用来做灾备，但缺点是快照保存完成之前如果宕机，这段时间的数据将会丢失，另外保存快照时可能导致服务短时间不可用。\nAOF对日志文件的写入操作使用的追加模式，有灵活的同步策略，支持每秒同步、每次修改同步和不同步，缺点就是相同规模的数据集，AOF要大于RDB，AOF在运行效率上往往会慢于RDB。\n高可用来看Redis的高可用。Redis支持主从同步，提供Cluster集群部署模式，通过Sentinel哨兵来监控Redis主服务器的状态。当主挂掉时，在从节点中根据一定策略选出新主，并调整其他从slaveof到新主。\n选主的策略简单来说有三个：\n\n slave的priority设置的越低，优先级越高；\n 同等情况下，slave复制的数据越多优先级越高；\n 相同的条件下runid越小越容易被选中。\n\n\n在Redis集群中，sentinel也会进行多实例部署，sentinel之间通过Raft协议来保证自身的高可用。\nRedisCluster使用分片机制，在内部分为16384个slot插槽，分布在所有master节点上，每个master节点负责一部分slot。数据操作时按key做CRC16来计算在哪个slot，由哪个master进行处理。数据的冗余是通过slave节点来保障。\nkey 失效机制Redis的key可以设置过期时间，过期后Redis采用主动和被动结合的失效机制，一个是和MC一样在访问时触发被动删除，另一种是定期的主动删除。\n淘汰策略Redis提供了6种淘汰策略，一类是只针对设置了失效期的key做LRU、最小生存时间和随机剔除；另一类是针对所有key做LRU、随机剔除。当然，也可以设置不剔除，容量满时再存储对象会返回异常，但是已存在的key还可以继续读取\n新特性可以了解一下Redis4.0和5.0的新特性，例如5.0的Stream，是一个可以支持多播，也就是一写多读的消息队列。还可以了解一下4.0的模块机制等。\n数据结构Redis内部使用字典来存储不同类型的数据，如下图中的dictht，字典由一组dictEntry组成，其中包括了指向key和value的指针以及指向下一个dictEntry的指针。\n\n\n在Redis中，所有的对象都被封装成了redisObject，如图中浅绿的模块。redisObject包括了对象的类型，就是Redis支持的string、hash、list、set和sortedset5种类型。另外redisObject还包括了具体对象的存储方式，如图最右边的虚线标出的模块内的几种类型。\n下面结合类型来介绍具体的数据存储方式。\n\nstring类型是Redis中最常使用的类型，内部的实现是通过SDS（Simple Dynamic String ）来存储的。SDS类似于Java中的ArrayList，可以通过预分配冗余空间的方式来减少内存的频繁分配。\nlist类型，有ziplist压缩列表和linkedlist双链表实现。ziplist是存储在一段连续的内存上，存储效率高，但是它不利于修改操作，适用于数据较少的情况；linkedlist在插入节点上复杂度很低，但它的内存开销很大，每个节点的地址不连续，容易产生内存碎片。此外在3.2版本后增加了quicklist，结合了两者的优点，quicklist本身是一个双向无环链表，它的每一个节点都是一个ziplist。\nhash类型在Redis中有ziplist和hashtable两种实现。当Hash表中所有的key和value字符串长度都小于64字节且键值对数量小于512个时，使用压缩表来节省空间；超过时，转为使用hashtable。\nset类型的内部实现可以是intset或者hashtable，当集合中元素小于512且所有的数据都是数值类型时，才会使用intset，否则会使用hashtable。\nsorted set是有序集合，有序集合的实现可以是ziplist或者是skiplist跳表。有序集合的编码转换条件与hash和list有些不同，当有序集合中元素数量小于128个并且所有元素长度都小于64字节时会使用ziplist，否则会转换成skiplist。\n\n提示：Redis的内存分配是使用jemalloc进行分配。jemalloc将内存空间划分为小、大、巨大三个范围，并在范围中划分了小的内存块，当存储数据时，选择大小最合适的内存块进行分配，有利于减小内存碎片。\n缓存常见问题对使用缓存时常遇到几个问题，整理出一个表格，如下图所示。\n\n\n缓存更新方式第一个问题是缓存更新方式，这是决定在使用缓存时就该考虑的问题。\n缓存的数据在数据源发生变更时需要对缓存进行更新，数据源可能是DB，也可能是远程服务。更新的方式可以是主动更新。数据源是DB时，可以在更新完DB后就直接更新缓存。\n当数据源不是DB而是其他远程服务，可能无法及时主动感知数据变更，这种情况下一般会选择对缓存数据设置失效期，也就是数据不一致的最大容忍时间\n这种场景下，可以选择失效更新，key不存在或失效时先请求数据源获取最新数据，然后再次缓存，并更新失效期。\n但这样做有个问题，如果依赖的远程服务在更新时出现异常，则会导致数据不可用。改进的办法是异步更新，就是当失效时先不清除数据，继续使用旧的数据，然后由异步线程去执行更新任务。这样就避免了失效瞬间的空窗期。另外还有一种纯异步更新方式，定时对数据进行分批更新。实际使用时可以根据业务场景选择更新方式。\n数据不一致第二个问题是数据不一致的问题，可以说只要使用缓存，就要考虑如何面对这个问题。缓存不一致产生的原因一般是主动更新失败，例如更新DB后，更新Redis因为网络原因请求超时；或者是异步更新失败导致。\n解决的办法是，如果服务对耗时不是特别敏感可以增加重试；如果服务对耗时敏感可以通过异步补偿任务来处理失败的更新，或者短期的数据不一致不会影响业务，那么只要下次更新时可以成功，能保证最终一致性就可以\n缓存穿透第三个问题是缓存穿透。产生这个问题的原因可能是外部的恶意攻击，例如，对用户信息进行了缓存，但恶意攻击者使用不存在的用户id频繁请求接口，导致查询缓存不命中，然后穿透DB查询依然不命中。这时会有大量请求穿透缓存访问到DB。\n解决的办法如下。\n\n对不存在的用户，在缓存中保存一个空对象进行标记，防止相同ID再次访问DB。不过有时这个方法并不能很好解决问题，可能导致缓存中存储大量无用数据。\n使用BloomFilter过滤器，BloomFilter的特点是存在性检测，如果BloomFilter中不存在，那么数据一定不存在；如果BloomFilter中存在，实际数据也有可能会不存在。非常适合解决这类的问题。\n\n缓存击穿第四个问题是缓存击穿，就是某个热点数据失效时，大量针对这个数据的请求会穿透到数据源\n解决这个问题有如下办法。\n\n可以使用互斥锁更新，保证同一个进程中针对同一个数据不会并发请求到DB，减小DB压力。\n使用随机退避方式，失效时随机sleep一个很短的时间，再次查询，如果失败再执行更新\n针对多个热点key同时失效的问题，可以在缓存时使用固定时间加上一个小的随机数，避免大量热点key同一时刻失效。\n\n缓存雪崩第五个问题是缓存雪崩。产生的原因是缓存挂掉，这时所有的请求都会穿透到DB。\n解决方法：\n\n使用快速失败的熔断策略，减少DB瞬间压力；\n使用主从模式和集群模式来尽量保证缓存服务的高可用。\n\n实际场景中，这两种方法会结合使用。\n考察点这一块内容的主要面试考察点是对缓存特性的理解，对MC、Redis的特点和使用方式的掌握。\n\n要知道缓存的使用场景，不同类型缓存的使用方式，例如：\n\n对DB热点数据进行缓存减少DB压力；对依赖的服务进行缓存，提高并发性能；\n单纯K-V缓存的场景可以使用MC，而需要缓存list、set等特殊数据格式，可以使用Redis；\n需要缓存一个用户最近播放视频的列表可以使用Redis的list来保存、需要计算排行榜数据时，可以使用Redis的zset结构来保存。\n\n\n要了解MC和Redis的常用命令，例如原子增减、对不同数据结构进行操作的命令等。\n\n了解MC 和Redis在内存中的存储结构，这对评估使用容量会很有帮助\n\n了解MC 和Redis的数据失效方式和剔除策略，比如主动触发的定期剔除和被动触发延期剔除\n\n要理解Redis的持久化、主从同步与Cluster部署的原理，比如RDB和AOF的实现方式与区别。\n\n\n加分项如果想要在面试中获得更好的表现，还应了解下面这些加分项。\n第一，是要结合实际应用场景来介绍缓存的使用。例如调用后端服务接口获取信息时，可以使用本地+远程的多级缓存；对于动态排行榜类的场景可以考虑通过Redis的sorted set来实现等等\n第二，最好你有过分布式缓存设计和使用经验，例如项目中在什么场景使用过Redis，使用了什么数据结构，解决哪类的问题；使用MC时根据预估值大小调整McSlab分配参数等等。\n第三，最好可以了解缓存使用中可能产生的问题。比如Redis是单线程处理请求，应尽量避免耗时较高的单个请求任务，防止相互影响；Redis服务应避免和其他CPU密集型的进程部署在同一机器；或者禁用Swap内存交换，防止Redis的缓存数据交换到硬盘上，影响性能。再比如前面提到的MC钙化问题等等。\n第四，要了解Redis的典型应用场景，例如，使用Redis来实现分布式锁；使用Bitmap来实现BloomFilter，使用HyperLogLog来进行UV统计等等。\n最后，知道Redis4.0、5.0中的新特性，例如支持多播的可持久化消息队列Stream；通过Module系统来进行定制功能扩展等等。\n真题汇总\n\n\n第1～4题前面都有提到，不再赘述\n第5题，可以从主从读写分离、多从库、多端口实例，以及Cluster集群部署来支持水平扩展等几方面回答，高可用可以回答用Sentinel来保证主挂掉时重新选主并完成从库变更。\n第6题，可以使用Redis的sorted set来实现延时队列，使用时间戳做Score，消费方使用zrangbyscore来获取指定延迟时间之前的数据。\n\n简单场景下分布式锁可以使用setnx实现，使用setnx设置key，如果返回1表示设置成功，即获取锁成功，如果返回0则获取锁失败。setnx需要同时使用px参数设置超时时间，防止获取锁的实例宕机后产生死锁。\n严格场景下，可以考虑使用RedLock方案。但是实现比较复杂。\n\n","categories":["总结笔记"],"tags":["Redis","Memcache","缓存击穿","缓存雪崩","缓存穿透"]},{"title":"研发排障常用工具总结","url":"/2021_10_20_tools/","content":"本文主要介绍常用的工具，将会讲解三个知识点：\n\nJVM 相关工具的作用和适用场景；\nGit 常用命令和工作流；\nLinux 系统中常用分析工具。\n\n常用工具汇总常用工具汇总如下图所示。\n\n\n\n说明：这里列出的都是一些相对独立的工具或者命令，不包括像 ZK、Redis 这样的服务，以及像 Spring 这类的框架。这些工具都是各自类型中最常用的，该图不是以全面为目的。\n团队协作工具如上图所示，先看左边的团队协作类工具。\n\nAnt+ivy、Maven、Gradle 都是用来构建项目、管理依赖的工具。其中 Ant 通过直接引用 jar 文件来进行依赖管理，通过脚本来描述，执行不同的构建目标。目前 Ant 使用得已经比较少，Maven 是比较主流的项目管理工具。\nMaven 通过 POM 文件对项目进行描述，通过约定提供可执行的目标，通过 GroupId、artifactId、version等坐标对依赖关系进行管理，Maven 可以从远程或本地仓库中自动下载依赖\nGradle 是结合了 Ant 与 Maven 优点的自动化构建工具，基于 Groovy 的 DSL 也就是领域专用语言。既有 Ant 的强大和灵活，又有 Maven 的生命周期管理，可以自动下载依赖。目前使用 Gradle 管理项目的团队也越来越多\nGit 和 SVN 都是版本管理工具，最主要区别是 SVN 是集中式的，Git 是分布式的，分支管理更灵活。目前 SVN 使用的已经相对较少了，Git 是大部分互联网公司使用的版本管理工具，后面的详解部分会专门针对 Git 的使用及 Git 工作流进行讲解。\n\n质量保证工具质量保证类工具有 CheckStyle、FindBugs、SonarQube 等等。\n\n其中 CheckStyle、FindBugs 是静态代码检测工具，可以通过 IDE 集成，对本地代码进行检测。\nSonarQube 是代码质量管理平台，默认集成了前面提到的两种工具，比较适合对项目质量进行整体保障。\n\n压测工具压测工具类有 LoadRunner、JMeter、AB、JMH。\n\nLoadRunner 和 JMeter 都是比较专业的测试工具，可以提供专业的报表和数据分析，比较适合 QA 人员使用\nAB 是 Apache 提供的一个简洁方便的压测工具，比较适合研发人员对 HTTP 接口进行简单并发压测\nJMH 主要是针对 JVM 进行基准测试，更关注方法层面的性能基准，如果想知道方法在两种不同实现下的吞吐量，就可以使用 JMH。对于应聘 Java 研发岗位的同学来说，测试工具部分可以重点了解一下 JMH。\n\n容器与代理工具容器与代理部分，目前主流的 Java Web 容器是 Tomcat，主流的代理是 Nginx。不过这里要多了解一些趋势，就是随着微服务的盛行，Envoy、OpenResty、Kong、Zuul 等的 API Gateway 网关的使用也越来越普遍。随着 DevOps 理念的普及，CI&#x2F;CD 也就是持续集成、持续部署，也越来越被大家所重视，这部分我们需要知道比较常用的 Jenkins 和 GitLab CI。\n\nJenkins，老牌的持续集成框架，可以支持不同类型的项目的构建、测试、部署，支持丰富的插件功能，和易用的管理界面。\nGitLab CI 作为 GitLab 提供的一个持续集成的套件，完美和 GitLab 进行集成，更加简单易用，比较适合 CI 流程比较简单的项目。\nTravis 和 CircleCI 都是开源项目中比较常用的持续集成框架，如果是研发开源项目可以进一步了解这两个框架的使用方式。\n\n文档管理工具如上图右边，JVM 工具和 Linux 系统分析工具，在后面会重点讲解，这里略过。来看文档管理工具。\n\nJavaDoc 通过注解方式，来对 Java 类和方法进行描述，并生成描述文档。\nSwagger 是一个规范、完整的框架，用于生成、描述 RESTfulAPI，Swagger 支持多种语言，提供了可视化的 Swagger UI，Java 中 Swagger 使用注解方式描述接口、参数、返回值等，非常适合用来对 RESTful 接口进行管理，特别是跨语言的 Web 服务。\n\n网络工具服务之间一般都要通过网络进行交互，所以工程师在调试、排查问题时需要掌握常用的网络工具。\n这里介绍几种常用网络工具。\n\nPostman 是调试网页的 Chrome 插件，相当于一个客户端，可以模拟用户发起的 HTTP 请求，是高效的接口测试工具，非常适合用来对 HTTP 接口进行联调与测试。\nWireshark 是个功能强大的网络包分析工具，支持各种协议的网络包分析，可以直接抓包，也可以配合 tcpdump 来使用，分析 tcpdump 抓包的结果。例如分析 HTTP 服务发、收包时间，链接的建立、关闭过程，请求包的分包大小与时序，TCP 窗口大小等等。\nFiddler 只针对 HTTP 请求进行抓包，可以修改请求或者模拟慢网速，是 Web 前端、移动端调试的利器，Charles 与 Fiddler 功能类似，支持 mac 系统，比较适合移动端抓包使用。\n\n详解 JVM 工具JMC首先是 JVM 的相关工具，第一个要介绍的是 JMC，就是 Java Mission Control。JMC 是 JDK1.7 中提供的图形化 JVM 监控与分析工具，如下图所示，JMC 包括 JVM 浏览器和 JMX 控制台，以及 JFR 也就是飞行记录器三部分。\n\n\n\nJVM 浏览器可以列出正在运行的 Java 程序的 JVM，每个 JVM 实例叫作一个 JVM 连接。JVM 浏览器使用 JDP 也就是 Java 发现协议，可以连接到本地和远程运行的 JVM。\nJMX 是 Java 管理扩展规范，能够管理并监控 JVM。JMX 通过对 Mbean 的管理，可以实时收集 JVM 信息，比如类实例信息、堆使用情况、CPU 负载、线程信息等，以及其他可以通过 MBeans 管理的一些运行时属性。\nJFR 提供了深入到 JVM 内部去看运行时状态的能力，是一个非常强大的性能 Profile 工具，适合对程序进行调优和问题排查。JFR对JVM运行时产生的事件进行采集，可以通过指定采集的事件类型和频率来收集非常全面的数据信息。这里我主要介绍一下使用JFR可以分析到哪些信息\n如下图所示，JFR 可以采集、分析五大类信息。\n\n\n\n内存信息，可以获取到 GC 的不同阶段及耗时情况、GC 的停顿时间、GC 的分代大小等配置信息，能够查看到对象分配，包括 TLAB 栈上分配情况，以及对象统计信息等等。\n代码信息，可以分析出热点的类、热点的方法、热点的调用树、运行时的异常信息、编译情况包括 OSR 栈上替换等信息，以及类的加载与卸载情况。\n线程信息部分，可以分析到：热点的线程、线程的争用情况、线程的等待时间、以及锁相关的信息。\nIO 信息部分，可以获得收集期间的磁盘 IO，也就是文件读写信息，以及网络 IO 等信息\n系统信息，可以获取到操作系统信息、进程相关信息以及环境变量等信息。\n\n总结一下：JMX 和 JFR 都可以获得 JVM 运行的信息。JMX 主要用来对 JVM 进行监控与管理，通过扩展 Mbean 支持自定义的管理能力。JFR 主要用来对 JVM 运行信息进行周期性采集，用来对运行状况进行分析。\nBTrace如果分析线上问题时，发现日志打的不全、无法定位怎么办？添加日志重新上线肯定不是个好主意，特别是调试时，可能需要反复添加日志来定位问题。或者，线上出现的问题很难复现，你根本没有机会添加日志再继续分析，这时就需要使用到 BTrace了。BTrace 是一个 JVM 实时监控工具，被 Java 工程师奉为性能调优和线上题诊断的神器。\nBTrace 基于动态字节码修改技术来实现对运行时的 Java 程序进行跟踪和替换。也就是说可以在不重启 JVM 的情况下监控系统运行情况，获取 JVM 运行时的数据信息，比如方法参数、返回值、全局变量、堆栈信息等。\nBTrace 可以做什么：\n\n可以对方法进行定位拦截，获取方法的入参、返回值、执行时间等信息\n可以查看某类对象的创建情况\n可以对内存使用情况进行统计，可以查看对象大小\n可以查看同步块执行情况\n可以查看异常抛出情况及导致异常的参数信息\n能够支持定时执行检测任务\n能够查看类加载的信息\n能够进行死锁检测\n可以打印线程栈信息\n可以监控文件或网络的读写情况。\n\n如上所述，BTrace 的功能非常强大，几乎无所不能。因为 Btrace 会把逻辑直接植入到运行的 JVM 中，为了保证安全，在使用上进行了一些限制。\n那么，BTrace 不能做什么：\n\nBTrace 不能创建新的对象\n不能抛出或捕获异常\n不能使用循环，例如 for、while\nBTrace 脚本的属性和方法必须使用 static 修饰\n不能使用 synchronized 的同步块或同步方法\n不能调用实例方法或静态方法，只能使用 BTraceUtils 类中提供的方法。\n\n可见，使用 BTrace 的条件还是非常严格的。需要注意三点：\n\n不恰当地使用 BTrace 可能导致 JVM 崩溃；\nBTrace 所做的修改是会一直生效的，直到重新启动 JVM 后才会消除；\n可以通过设置 JVM 参数取消 BTrace 的安全限制。\n\n其他 JVM 工具\n\n\njps 用来查看 Java 进程的信息，包括进程 id、主类名称、主类全路径等\njmap 可以查看JVM中对象的统计信息，包括内存占用、实例个数、对象类型等等，jmap 可以把堆 dump 下来配合内存分析工具 MAT 进行分析。\njstat 对 JVM 的资源和性能进行实时监控，统计项主要包括：类加载情况、内存容量及使用量、 GC 次数和时间等等。\njstack 可以查看 JVM 线程栈的信息，包括：线程名称、序号、优先级 prio、线程状态、锁状态等。\njinfo 可以查看运行中 JVM 的全部参数，还可以设置部分参数。\njcmd 是 JDK1.7 后提供的工具，可以向 JVM 发送诊断命令。它的功能非常强大，基本上包括了 jmap、jstack、jstat 的功能。可以重点了解这个工具。\n其他还有 jconsole、JProfiler、jvisualVM 等，功能跟 JMC 基本重合，建议直接使用 JMC 即可。\n\n列举几个实际应用场景。\n\n当你排查线上问题，需要查看 GC 日志，发现没有打印 GC 的详细信息，可以通过 jinfo 开启 JVM 参数 PrintGCDetails 来动态生效\n当你分析内存泄露风险时，可以通过 jmap 或 jcmd 定期获取堆对象的统计信息，来发现持续增长的可疑对象。\n当你遇到某一时刻所有服务都出现耗时较高的问题，可以通过 jstat 来观察 GC 回收状况，看看 GC 停顿耗时是否过高。\n当你遇到 JVM 中某一个服务卡死或者停止处理时，可以通过 jstack 查看线程栈，看是否有多个线程处于 BLOCKED 状态产生了死锁。\n当你的服务上线后发现性能达不到预期，可以使用 JMC 来分析 JVM 运行信息，看看有哪些热点方法可以优化，哪些线程争用可以避免。\n\n详解 GitGit 常用命令Git 与 SVN 的区别在前面知识点汇总时已经简单介绍过了。再看 Git 的常用命令及对应的使用场景。\nGit 对版本是分布式管理，因此有四个保存数据的区域，如下图中浅绿色的部分，分别是本地工作区 Workspace、本地暂存区 Stage、本地仓库和远程仓库。\n\n\n开发时先从远程拉取代码到工作区，可以有 clone、pull、fetch+checkout 几种方式，如图中向左的几个箭头所示。在提交代码时，先通过 add 命令添加到暂存区，然后 commit 提交到本地仓库，最后使用 push 推送到远程仓库。如图中向右的几个箭头所示。\n稍微注意一下 fetch 与 pull 的区别。\n\nfetch 是从远程仓库同步到本地仓库，但并不会合并到工作区\npull 相当于执行 fetch 命令+merge 命令，先同步到本地仓库，然后在 merge 到工作区。\n\nGit 的命令行提示非常友好，对常用 Git 操作的说明非常完善，其他的命令不展开介绍。\nGit 常用工作流使用 Git 进行团队协作开发时，多人协作、多分支开发是很常见的。为了更好得管理代码，需要制定一个工作流程，这就是我们说的工作流，也可以叫分支管理策略。常见的基于 Git 的工作流有 Git-flow工作流、GitHub 工作流和 GitLab 工作流，如下图所示。\n\n\n\nGit-Flow 工作流\n\n如上图左侧所示，Git-Flow 按功能来说，分为 5 条分支，在图中以不同颜色表示，其中 master 和 develop 是长期分支。master 分支上的代码都是版本发布状态；develop 分支则代表最新的开发进度\n当需要开发某些功能时，就从 develop 拉出 feature 分支进行开发，开发完成并验证后就可以合并回 develop 分支。当 develop 上的代码达到一个稳定的状态，可以发布版本的时候，会从 develop 合并到 release 分支进行发布，如果验证有问题就在 release 分支进行修复，修复验证通过后进行正式发布，然后合并到 master 分支和 develop 分支。还有一个 hotfix 分支用来做线上的紧急 bug 修复，hotfix 直接从 master 拉出分支修改，修改验证完成后直接合并回 master，并同步到 develop 分支。\nGit-Flow 流程非常完善，但对于很多开发人员和团队来说，会稍微有些复杂，而且没有图形页面。\n\n\nGitHub 工作流\n\n现在来看另一种更简单的工作流，如上图所示，中间的 GitHub 工作流\nGitHub 工作流只有一个长期分支 master，而且 master 分支的代码永远是可发布状态。如果有新功能开发，可以从 master 分支上检出新分支，开发完成需要合并时，创建一个合并到 master 到 PR，也就是 pull request。当 review 通过或者验证通过后，代码合并到 master 分支。GitHub 工作流中 hotfix 热修复的流程和 feature 分支完全一\n\n\nGitLab 工作流\n\n如上图所示，看右面的 GitLab 工作流。前两种工作流各有优缺点，Git-Flow 稍微复杂，GitHub 的单一主分支有时会略显不足。GitLab 结合了两者的优势，既支持 Git-Flow 的多分支策略，也有 GitHub Flow 的一些机制，比如 Merge Request和 issue 跟踪。GitLab工作流使用 pre-production 分支来进行预发管理，使用 prodution 分支来发布版本。我的团队目前使用的就是 GitLab 工作流。\n\n\n\nLinux 工具来看 Linux 系统下常用的分析工具。首先是如下图表格中列出的 stat 系列。\n\n\n\nvmstat 可以获得有关进程、内存页面交换、虚拟内存、线程上下文切换、等待队列等信息。能够反映系统的负载情况。一般用来查看进程等待数量、内存换页情况、系统上下文切换是否频繁等。\niostat 工具可以对系统的磁盘操作活动进行监视，同时也可以显示 CPU 使用情况，一般用来排查与文件读写有关的问题，例如排查文件写入耗时较高时，可以查看 await 和 util 是否过高。iotop 是查看磁盘 I&#x2F;O 使用状况的 top 类工具，想知道到底哪个进程产生了大量的 IO 时可以使用 iotop。\nifstat 是简洁的实时网络流量监控工具，可以查看系统的网络出口、入口使用情况。iftop 可以用来监控网卡的实时流量、反向解析 IP、显示端口信息等，通过iftop很容易找到哪个ip在霸占网络流量。\nnetstat 是一个监控系统网络状态的工具，它可以查看网络连接状态，监听了哪些接口、链接相关的进程等信息，能够显示与 IP、TCP、UDP 和 ICMP 协议相关的统计数据，是非常常用的网络工具。\ndstat 是一个全能实时系统信息统计工具，能够统计 CPU 占用，内存占用，网络状况，系统负载，进程信息，磁盘信息等等，可以用来替换 vmstat、iostat、netstat 和i fstat 这些工具。\n\n再来看如下图的几个工具。\n\n\n\nstrace 是一个用于诊断、调试程序运行时系统调用的工具，可以动态跟踪程序的运行，能够清楚地看到一个程序运行时产生的系统调用过程及其使用的参数、返回值和执行耗时。\nJVM 执行 native 方法时，可以很方便的通过 strace 来进行调试，例如在执行系统读写时，线程卡住很长时间，就可以用 strace 来查看系统调用的参数和耗时。\nGDB 是一个强大的命令行调试工具，可以让程序在受控的环境中运行，让被调试的程序在指定的断点处停住，也可以动态的改变程序的执行环境。当 JVM 因为未知原因 crash 时，可以通过 GDB 来分析 crash 时产生的 coredump 文件，来分析定位问题。\nlsof 是一个列出当前系统打开文件的工具。Linux 中一切皆文件，包括设备、链接等都是以文件形式管理的，因此通过 lsof 工具查看文件列表对系统监测以及排错都很有帮助。\ntcpdump 是一个强大的网络抓包工具，在分析服务之间调用时非常有用。可以将网络中传送的数据包抓取下来进行分析。tcpdump 提供灵活的抓取策略，支持针对网络层、协议、主机、网络或端口的过滤，并提供 and、or、not 等逻辑语句来去掉不想要的信息。\ntraceroute 是一个网络路由分析工具，利用 ICMP 协议定位本地计算机和目标计算机之间的所有路由。traceroute 对服务，特别是经过公网的服务之间的网络问题排查非常有帮助。\n\n考察点以上是常用工具的知识重点。接下来从面试官角度总结一下面试考察点：\n\n掌握常用的 JVM 分析工具主要用来分析哪类的问题，例如线程死锁可以用线程分析工具 jstack；内存溢出可以使用 jmap 查看堆中占用最大的对象类型；需要对程序性能进行分析时，可以使用 JMC 中的飞行记录器等等\n掌握常用的代码版本管理工具 Git，包括 Git 的常用命令与常见问题，以及理解 Git 工作流。例如知道 Git 的 merge 与 Git rebase 的区别，merge 是提交 commit 合并修改，rebase 是修改提交历史记录。知道自己团队在协作开发时，使用的哪种工作流，有什么样的优缺点。\n掌握 Linux 系统下的常用工具，也是突出实战能力。了解不同问题应该使用哪类工具来进行分析。例如，磁盘写入经常耗时较高可以通过 iostat 来分析磁盘 IO 情况，如果不能确定问题，可以通过 strace 对文件写入的系统调用进行分析；或者 CPU 负载较高，想要定位哪个线程导致，可以通过 top 结合 jstack 来进行分析等等。\n\n本课时的考察点以知识广度为主，对于不同类型的工具，需要知道适用场合，重点考察实际应用经验。面试时这部分内容可能会被问到一些原理，但一般不会深入询问工具的具体实现。\n加分项对于常用工具这部分，面试官可能不会直接问你“会用某某工具吗”，所以对于这一课的知识，你需要主动出击，才能获得加分。比如，在面试官询问项目经验时，带出你了解的工具，来体现你的知识广度与实战经验。\n举个例子，当面试官询问你遇到过哪些线上问题时，你可以说遇到过单机请求耗时高的问题，通过 JMC 的飞行记录器采样分析，发现写 log 日志时线程竞争非常激烈，很多线程在等待写锁时耗时非常大，进一步通过 iostat 排查发现 util 利用率百分比很高，最后定位是磁盘出现问题。解决方法，一方面更换磁盘解决了问题，另一方面对写竞争较激烈的日志文件使用了异步 log 机制。这样回答，既可以突出你对常用工具的掌握能力，也可以突出你的实战和解决问题能力\n另外再给提供两个思路：\n\n可以在介绍自己开发的某个项目时，提到在上线前使用 JMC 做了性能 Profile，发现并优化了某些问题。\n在介绍项目方案时，讲到自己对某两个不同方案进行了 JMH 测试，来验证方案实现的性能，等等。这两个 Case 都能够做到主动出击，体现自己的对常用工具的理解与掌握能力。\n\n真题汇总最后列出一些真题用于参考练习，如下。\n\n\n\n学习 JMC、BTrace、tcpdump、strace 等工具的使用。\n\n","categories":["总结笔记"],"tags":["Java","Jvm","Git","Linux"]},{"title":"分布式系统架构演进总结","url":"/2021_10_24_framework/","content":"本文会讲解分布式系统架构以及面试中做项目介绍的技巧，重点有如下三部分：\n\n介绍系统架构的演进：包括微服务架构、云原生以及业界最新趋势 ServiceMesh。\n讲解微服务的基础知识点：Docker 和 K8s。\n教你如何更有效地做项目介绍。\n\n系统架构演进首先以演进的方式来了解不同的系统架构。\n单体架构最简单的系统架构是单体服务，如下图所示。\n \n\n一个项目中的多个服务，混合部署在一个进程内，服务之间的交互都是通过进程内调用完成的，正如图中 Service 之间的红色箭头所示。这样做的好处是可以快速开发、部署服务，服务之间调用的性能也最好\n当然，这种架构缺点也非常多，比如：\n\n随着业务的增长，项目越来越臃肿；\n服务之间因为 JAR 包引用导致频繁的依赖冲突；\n服务资源变更困难，因为一个服务可能被多个不同的业务引用，升级资源需要多个业务方同时升级；\n因为不同业务方都可以直连服务的数据资源，这个架构也存在明显的数据安全风险；\n修改代码后回归困难、架构难以调整等等。\n\n以上所有问题都是因为服务耦合在一起导致的。在服务规模不大的情况下，比较适合采用单体架构，方便快速迭代。但是当服务规模变大时，单体架构就不是一个好的选择。\n微服务架构当服务的规模变大时，为了解决服务耦合的问题，出现了 SOA 就是面向服务架构，它的起源是为了解决企业应用问题，随着不断演进，发展到目前业界普遍采用的微服务架构，微服务架构如下所示。\n \n\n微服务架构的思想就是让服务尽可能做到高内聚、低耦合，不同的服务单独开发、单独测试、单独部署。服务之间通过 RPC 或者 HTTP 进行远程交互，如图中的蓝色加粗箭头所示\n微服务架构解决了单体架构的耦合问题，但同时也带来了新的问题。因为服务部署在不同的进程或服务器中，要使用服务前需要先找到服务，即所谓的服务发现\n一般微服务使用两种发现方式，一种是前面课程介绍过的 RPC 方式，通过注册中心进行服务的注册和订阅，来完成服务发现，比如图中间灰色的 Registry 模块。这种方式由服务的调用端获得到全部可用服务节点，由 Client 侧进行负载均衡，调用服务。另外一种是通过 HTTP 协议调用服务端提供的 RESTful 接口，这种方式不需要 Client 侧做服务发现，而是在 Server 端通过 Nignx 这样的反向代理来提供 Server 侧的负载均衡\n不论哪种方式，服务的交互都从进程内通信变成了远程通信，所以性能必然会受到一些影响。此外由于很多不确定性的因素，例如网络拥塞、Server 端服务器宕机、挖掘机铲断机房光纤等等，需要许多额外的功能和措施才能保证微服务流畅稳定的工作。前面在 Spring Cloud 内容中提到的 Hystrix 熔断器、Ribbon客户端负载均衡器、Eureka注册中心等等都是用来解决这些问题的微服务组件。\nCAP 原则与 BASE 理论在微服务架构中，有必要了解一下分布式系统中的 CAP 原则与 BASE 理论。如下图所示，CAP 原则指的是在一个分布式系统中，Consistency 一致性、 Availability 可用性、Partition tolerance 分区容错性，这三个特性最多只能同时满足两个，三者不可兼得。\n \n\n其中一致性指所有节点在同一时间的数据完全一致；可用性指任何时候对分布式系统总是可以成功读和写；分区容错性是指当某些节点或网络分区故障的时候，仍然能够提供满足一致性和可用性的服务\n既然无法同时满足三个特征，那就会有三种取舍。\n第一个选择是 CA，就是放弃分区容错，这也就等同于放弃了分布式系统，所以 CA 只存在于单机系统。\n第二个选择是 CP，也就是选择强一致和分区容错，允许极端情况下出现短时的服务不可用。采用 CP 原则实现的分布式系统比如 ZooKeeper。ZooKeeper是一个分布式协调系统，强一致性是 ZK 的主要目标，允许出现短时的系统不可用。也正是因为这个原因，ZK 其实并不适合用来做微服务的注册中心。其他选择 CP 实现的系统还有 Consul、etcd 等。\n第三个选择是 AP，也就是选择分区容错和高可用，允许数据出现短时间不一致。采用 AP 原则的分布式系统有 Eureka、Nacos。在服务注册的场景，短期的不一致一般不会对服务交互产生影响，因此采用 AP 原则的注册中心才是微服务比较适合的选择\n然后，介绍一下 BASE 理论，如上图底部的词汇所示，BASE 是指 Basically Available 基本可用，Soft-state 软状态，Eventual Consistency 最终一致性，它是对 CAP 中一致性和可用性权衡的结果。BASE 的核心思想是即使无法做到强一致性，也可以根据系统特点，采用适当的方式达到最终一致性。\n云原生服务继续讲解系统架构的演进。微服务架构的思路是服务解耦合，这会导致一个大的业务拆分成众多小的服务，每个服务的部署需要考虑单点问题，需要多机房多节点部署，会造成系统资源的浪费\n另外在服务扩容时需要重新整理服务运行依赖的环境，对微服务的普及有一定阻碍。容器化技术把服务的运行环境进行打包管理，解决了服务扩缩容时对运行环境的管理问题以及服务器的利用率问题。因此随着容器技术逐渐成熟，微服务架构也快速普及\n云原生架构由微服务组成，它不是一种业务系统架构，而是一种能够快速、持续、可靠、规模化地交付业务服务的模式。\n如下图所示，图上部列出了云原生的三个特征：\n\n容器化的微服务，这是云原生的主体；\nDevops，是对微服务的动态管理；\n持续交付能力，这是云原生的目的。\n\n \n\n\n云原生服务需要底层的云服务提供 IaaS 基础设施或者 PaaS 平台设施来运行，IaaS 可以理解为提供了服务器资源，PaaS 平台可以理解为提供了运行环境。\n常见的实现方式有两种：自建的私有云和云厂商提供的公有云。公有云比如阿里云、AWS、腾讯云等等，像新浪微博内部使用的是私有云与公有云结合的混合云模式。\n接下来看云原生应用开发的最佳实践原则：12 要素，如下图所示。\n \n\n12 要素定义了设计 SaaS 应用时需要遵循的一些基本原则，SaaS 是软件即服务的缩写，通过云原生应用来提供服务。 \n第 1 个要素是基准代码，是指代码由版本管理工具来管理，一个应用只有一份基准代码，运行时有多个的部署实例。\n第 2 个要素依赖，是指要在应用中显示的声明依赖，方便服务进行构建\n第 3 个要素配置，指要在环境中存储配置，而不是写在代码配置文件中。也就是说，配置与代码要分开管理，从代码外部进行加载，例如测试环境的配置、仿真环境的配置以及生产环境的配置都应该从对应的环境中进行加载。\n第 4 个要素后端服务，是指要把依赖的后端服务统一看作资源来对待。不论是 DB、缓存还是 HTTP 服务\n第 5 个要素是构建、发布、运行，是指要严格区分应用的构建、发布、运行这三个步骤，并且必须按顺序进行。\n第 6 个要素进程，是指应用以一个或多个进程运行，要保证应用的无状态性\n第 7 个要素端口绑定，是指不同的应用使用不同的端口提供服务。应用与端口是绑定的，不是指具体的某个端口号，而是指一旦服务启动确定了端口，那么这个端口就能够提供对应的服务，直到应用进程停止。\n第 8 个要素并发，是指应用进程之间可以并发处理，因此可以通过多进程方式进行水平扩展。\n第 9 个要素易处理，是指应用应该容易被管理，可以通过优雅停机和快速启动，构建最健壮的服务。\n第 10 个要素开发&#x2F;生产等价，是指要保证在开发、预览、生产等不同环境下的应用，尽可能一致。\n第 11 个要素日志，是指要合理记录应用的运行日志，并把日志当作一种事件流来对待，方便对日志的收集和处理。\n第 12 个要素管理进程，是指要把后台管理任务当作一次性进程来运行，而不是常驻后台进程的方式。\n以上 12 要素是对设计云原生服务的指导原则，在实际项目中可以结合实际业务场景进行架构设计，不一定完全照搬。\nService Mesh云原生应用是目前大部分互联网公司的服务架构推进方向，那么下一代的服务架构是什么样呢？这里介绍一个最新的服务化趋势，它离实际应用可能还有些遥远，我们可以静待它的发展\nService Mesh 是 2017 年逐渐在国内进入大家视野的一种架构方式，被誉为下一代的微服务。Service Mesh 在微服务的基础上引入了一个 Sidecar 边车的概念，如图中左下方的放大图所示，每个服务会伴生着部署一个 Sidecar，服务之间的交互不再由服务自身来完成，服务所有的出、入请求都交由这个 Sidecar 来进行处理，通过管理平面对所有的 Sidecar 进行统一管理，由 Sidecar 来实现服务发现、负载均衡、流量调度等能力。\n \n\n目前最有代表性的 Service Mesh 开源实现，是由 Google、IBM、Lyft 三家一起维护的 Istio，有兴趣的话可以持续关注，这里就不详细展开了。\n那么 Service Mesh 与微服务的区别是什么呢？Service Mesh 又可以解决哪些问题呢？如下图所示。\n \n\n微服务的出现是为了解决多个服务之间耦合的问题，如图中绿色的竖线，就是微服务架构做的事情，把 Service A、B、C 进行了解耦，服务单独部署、单独管理。这时每个服务都需要实现例如服务发现、服务的远程交互、交互过程中的负载均衡、高可用策略、服务熔断等等一系列的功能，这些功能与服务自身的业务逻辑没有任何关系\nService Mesh 的思路是把业务逻辑与业务无关的功能进行解耦，如图中红色的线，对服务进行横切，把与服务交互相关的功能从服务中剥离出来，统一交给 Sidecar 去实现，让服务更聚焦于业务逻辑，提高研发效率。同时由于功能相对独立，Sidecar 可以更专注于服务的交互与管理，更方便实现极致的功能与性能。\n所以，Service Mesh 不是一个全新的技术，它对业务与服务交互、管理进行了拆分，提供统一、强大的服务管理能力，是在微服务基础上的演进\n另外，Service Mesh 由于使用独立的 Sidecar 进程，天然适合为不同语言的服务提供统一的服务治理能力，因此跨语言服务治理也是 Service Mesh 的一个重要特点，像微博基于 Motan 研发的 Weibo Mesh，初衷就是为了解决内部不同语言之间服务化的问题。\n由于引入了额外的 Sidecar，Service Mesh 的架构复杂度更高，也会带来额外的可用性和性能问题，这也是 Service Mesh 架构需要努力解决的问题\n架构设计的意义通过了解系统架构的演进，我们发现，从单体架构到微服务架构，实现了服务之间解耦，但带来了额外的服务发现与交互问题；从微服务到 Service Mesh，实现了业务与服务治理功能的解耦，但是引入了额外的可用性和性能问题，架构复杂度也随之提高。那么这样做的意义在哪里？\n系统架构的设计从来就是一个权衡的艺术，很多情况下，我们只是让问题进行了转移，方便对问题进行集中整治和处理，让服务更聚焦业务研发，不同的功能就交给专门的组件来处理，正所谓术业有专攻。通过架构的演进，虽然当下没有消灭复杂度，但可以成功的让问题变的透明化，变的业务无感知，提升服务整体的开发效率与扩展能力，拓宽服务能力的上限。\n容器化基础微服务之所以能够快速发展，很重要的一个原因就是：容器化技术的发展和容器管理系统的成熟。所以接下来学习微服务架构的基础，容器化技术 Docker 和容器集群管理系统 Kubernetes。\nDocker 作用Docker 的作用主要是快速的构建、部署、运行服务，通过服务镜像能够为服务提供版本管理\n通过容器化技术可以屏蔽不同运行环境的差异，让服务在任何 Docker 环境中运行，就像 Java 的一次编译到处运行。\nDocker 是轻量虚拟化技术，可以在一台宿主机上运行多个服务，对运行的服务之间进行了有效的隔离，提高宿主机的资源利用率。\nDocker 特点\n开源，意味着可以免费使用 Docker 容器技术。\n基于 LXC 实现的轻量虚拟化，Docker 容器直接运行进程，不需要模拟，运行效率非常高。\n能够支持大规模构建。\nDocker 的架构十分灵活，可扩展不同的实现，例如支持不同存储驱动实现。\nDocker 提供可视化 UI，管理非常简单。\n\nDocker 主要概念\n镜像，就是服务代码和运行环境的封装，服务的版本管理就是通过镜像来实现的，镜像是部署的基础。\n容器，就是 Container，容器是基于镜像的服务运行状态，可以基于一个镜像运行多个容器。\n守护进程是运行在宿主机上的管理进程，用户通过 Client 与守护进程进行交互\n客户端是用来和守护进程交互的命令行工具，也可以通过 Socket 或者 RESTful API 访问远程的 Docker 守护进程。\n镜像仓库，类似我们的 Git 代码仓库，镜像仓库用来保存、管理不同服务不同版本的镜像。服务部署时会从镜像仓库拉取对应版本的镜像进行部署。\n\nDocker 实现原理Docker 是通过对不同运行进程进行隔离来实现虚拟化，主要利用三种方式来实现服务的隔离，如下图所示。\n \n\n首先是利用 Linux 的 Namespace 命名空间，来隔离进程之间的可见性，不同的服务进程彼此属于不同的 Namespace，互相无法感知对方的存在\nDocker 实现了 Host、Container、None 和 Bridge 四种网络模式，默认使用 Bridge 桥接模式。每一个容器在创建时都会创建一对虚拟网卡，两个虚拟网卡组成了数据的通道，其中一个会放在容器中，另一个会加入到 Docker0 的网桥中。Docker0 网桥通过 iptables 中的配置与宿主机上的网卡相连，所有符合条件的请求都会通过 iptables 转发到 Docker0 并由网桥分发给对应的容器网卡。为了防止容器进程修改宿主机的文件目录，Docker 通过改变进程访问文件目录的根节点，结合 Namespace 来隔离不同容器进程可以访问的文件目录。\n然后，通过 Namespace，Docker 隔离了进程、网络和文件目录，但是在进程运行中的 CPU 和内存等还是共享状态。Docker 通过 Control Groups 也就是 Cgroups 来对进程使用的资源进行限制，包括 CPU、内存和网络带宽等。\n那么，Docker 是如何把镜像运行起来的呢？Docker 的镜像是分层结构，例如一个服务镜像可以由操作系统层、基础环境层、Web 容器层、服务代码层，层层依赖构成。通过 UnionFS 就是联合文件系统把 Image 中的不同分层作为不同的只读目录，而 Container 是在只读的镜像目录上创建的可读可写的目录，通过这种方式来把镜像运行起来的。Docker 提供了 AUFS、Overlay、Devicemapper、ZFS 等多种不同存储驱动实现。\nKubernetes 作用Kubernetes 也叫 K8s，因为 K 与 s 之间一共有 8 个字母。K8s 是一个容器集群管理系统，不是一个 PaaS 平台，PaaS 平台是可以运行在 K8s 之上的。\nK8s 的作用是进行容器集群管理，它只针对容器管理，不部署源码不编译应用。它能够实现服务容器的自动部署与按指定条件进行自动扩缩容服务，来实现对应用的管理，支持应用的负载均衡、滚动更新、资源监控等等。\nKubernetes 特点\n可移植，支持在公有云，私有云，混合云中运行；\n可扩展，K8s 采用模块化实现方式，插件化的架构，可挂载，可组合\n自动化，支持服务的自动部署，自动重启，自动复制，自动伸缩。\n\nKubernetes 重要概念K8s 中的概念非常的多，这里列出了比较重要的几个。\nK8s 是容器集群管理系统，容器首先需要运行在宿主机上，因此，K8s 首先要管理宿主机集群，K8s 分为 Master 节点和 Node 节点，也叫 Worker Node\nMaster 负责管理节点，管理 K8s 集群。Master 协调集群中的所有行为&#x2F;活动，例如应用的运行、修改、更新等。\nNode 节点用来运行容器。Node 上可以运行多个 Pod，Pod 是 K8s 创建或部署的基本单位，Pod 中可以运行多个 Container，一个 Container 就是一个运行中的服务镜像。\nPod 中的 Container 共享网络与存储。 \nService 是 K8s 中的一个逻辑概念，通过对不同的 Pod 添加标签，来划分为不同的 Service。\nDeployment 表示用户对 K8s 集群的一次更新操作，可以是创建一个新的服务，更新一个新的服务，也可以是滚动升级一个服务。\nKubernetes 架构下图是 K8s 架构图，图左侧绿色的模块代表 Master 节点，右侧蓝色的模块代表运行容器的Worker Node 节点。\n \n\n先来看 Master 节点中的架构，灰色的部分是 Master 中的模块，其中 API Server 是用户对 K8s 中资源操作的唯一入口，创建应用部署、管理部署状态等都需要通过 api server 进行。API Server 提供了认证、授权、访问控制、API 注册和发现等机制\nController Manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等，Controller Manager 包含多个可以扩展 Controller，例如 Node Controller 负责初始化 Node 节点，获取运行中的 Node 信息、Route Controller 负责配置集群间通信的路由信息、Service Controller 负责监听服务创建、更新、删除等事件来调整负载均衡信息等等。\nScheduler 负责资源的调度，按照预定的调度策略选择哪个 Pod 运行在哪个节点上\n另外图下方的绿色模块是用来保存整个集群的状态的 etcd。\n图最左侧的 kubectl 是用于运行 K8s 命令的管理工具，kubectl 与 API Server 进行交互，通过 API Server 下发对 K8s 集群的指令。\n再来看图右侧的 Worker Node。刚才介绍概念时提过，Node 用来运行应用容器，所以 Node 中必须要有一个容器运行时，可以是 Docker，也可以是其他的容器技术，例如 Rkt。\nNode 中部署应用时，每个应用都由一个 Pod 组成，可以把 Pod 看作一个虚拟服务器，上面可以运行一个或多个 Container 容器。当应用服务需要多个进程共同协作时，可以把这些协作的镜像打包放在一个 Pod 中，共享 Pod 的存储和网络。比如 istio 中的 Sidecar 代理模式，就是通过在服务的 Pod 中注入一个 Sidecar 镜像来实现与服务 IP 绑定，进行流量控制的。\n看到右面图中灰色的两个 Node 模块，kubelet 负责与 Master 通信，它周期性地访问 APIcontroller 进行检查和报告、执行容器的操作，维护容器的生命周期，也负责 Volume（CVI）和网络（CNI）的管理。\nkube-proxy 处理网络代理和每个容器的负载均衡，它通过改变 iptables 规则来控制在容器上的 TCP 和 UDP 包。\nK8s 把所有被管理的资源看作对象，对资源的管理就变成了对对象属性的设置。K8s 对对象的配置采用 YAML 格式进行描述。K8s 中的对象概念非常多，大致可以分为四类：\n\n资源对象，例如 Pod、Job；\n配置对象，例如 Node、Namespace、Service；\n存储对象，例如 Volume、PresidentVolume；\n策略对象，例如 SecurityContext、ResourceQuota、LimitRange 等等。\n\n如果感兴趣，可以在课后练习。比如最简单的，可以在单机环境中，使用 Minikube 来部署 K8s 进行练习。\n考察点系统架构主要看一个人的综合能力和发展潜力怎么样，考察点有这几个方面：\n第一，要对分布式架构有自己的理解。比如系统可用性、扩展性，比如故障的应对方法，包括熔断、容灾、流量迁移、多机房多活；再比如架构设计中的解耦合等等。\n第二，要了解系统架构优化的常用方法。比如：并行、异步、水平扩展和垂直扩展、预处理、缓存、分区（Sharding）等等。\n第三，会考察对负责的工作了解程度、是否有责任⼼。如果连自己负责的服务的部署规模，调用量级都不清楚，怎么能有很强的责任心呢？\n加分项加分点主要在于表现出面试者的学习能力和思考能力。\n第一个，了解业界最新趋势，比如 Service Mesh 的思路和要解决的问题。\n第二个，在介绍项目时，如果有不同方案的选型或对比会更好。比如在介绍项目架构时，有两个方案，一个是同步方案，一个是异步方案，这两个方案各有什么优缺点，最后结合业务场景、实际需求、请求量级 选择了某一种。\n面试技巧介绍项目\n面试时，一定会遇到介绍项目这个问题。我见过的大多数人在里表现的并不好：要么讲不清楚项目的结构与交互流程；要么不能理解项目架构为什么要这样设计；要么没有思考过项目存在哪些问题，有哪些可以改进的地方。不仅是针对面试，在工作中我们更应该搞清楚这些问题，尤其是工作 1～3 年的工程师们。\n那么，在面试中如何更好地介绍自己负责的项目？如下所示，图中这些方法是根据面试考察点总结的，并且会提示每个方法要重点体现哪些能力。\n \n\n第一步，要简单交代项目背景，让面试官可以快速进入到项目上下文，更容易理解项目架构。一般采用 STAR 法则来进行介绍：\n\nSituation 介绍项目背景，比如这个项目是研发一个短视频 APP，配合公司主客户端来交叉提高用户量与活跃度\nTask 介绍自己的任务，比如我在这个项目中负责后端服务的架构设计与研发；\nAction 介绍自己做了哪些工作，比如当时用了 2 周时间做架构设计，4 周时间做研发，2 周时间测试上线；\nResult 介绍结果，这个也是大部分人容易忽视的部分，比如项目上线后 2 个月用户数 100w，后端服务接口总量峰值 50000qps，主要接口服务 SLA p99 小于 50ms。\n\n注意背景介绍是为后面详细介绍做铺垫，简洁明了即可。这一步主要体现你的表达能力。\n第二步，重点介绍项目的架构，这也是面试官最想了解的部分。\n务必要结合架构图、交互流程图来介绍，避免对一些关键问题理解歧义。架构图要注意边界清晰，就是你的服务与其他依赖的外部服务之间的边界，以及你服务内部模块之间的边界都要描述清晰。这有利于你下一步介绍自己做了哪些内容。这一步要体现出你对项目架构的理解\n第三步，介绍你在这个项目中具体做了哪些内容，例如我设计了整个架构，或者我实现了架构图中的某几个模块。注意这一步是你面试的绝对加分点，必须要把握住。\n这里要突出你在项目中做的最有挑战的点、优雅的架构设计、或者独特有效的解决方案。比如在数据量非常大的场景下，通过优化 Redis 存储结构，减少了 70% 的 Redis 使用容量；比如对查询接口应用双发功能使 p999 降低了 60%；再比如使用了 Trace 功能来快速定位问题，等等。这一步要体现出你的实现能力与亮点。\n第四步，要为第三步介绍的优秀架构或解决方案提供证明，比如前面介绍了系统架构中使用模块化来提高扩展性，那这里就可以说系统上线后，通过模块化方式支持了 7 个新业务的接入来体现你设计的架构的优点。\n这里要注意，所有的结果必须是可以量化的，不要用性能大幅提升，极大提高灵活性这类很虚的描述。好一点的表述可以是这样：通过增加二级缓存，对后端服务的调用请求从 7000qps 降低到 600qps。这一步要体现出你对项目的掌握能力和了解程度\n第五步，思考项目存在哪些问题，或者还有哪些可以进行优化的点。\n例如，现在项目 QPS 不高，某些任务是同步处理的，会有一定效率问题，这些处理步骤是可以异步执行的，如果请求量级增加，可以考虑使用 kafka 进行异步处理。处理时还应该考虑消息重复的问题，可以把处理逻辑设计成幂等性的。这一步要体现你对项目的思考以及总结反思能力。\n如果我作为面试官，遇到一位按照上面 5 个方向来交流的候选人，一定会非常看好他。\n面试技巧再来介绍几个备战面试的小技巧。\n第一点，肯定要提前思考、提前准备\n像项目架构图怎么画更容易理解，项目中到底哪个设计最有亮点，项目还存在哪些可以改进的地方等等问题，可能要花很多时间才能找到比较理想的答案，在面试现场临时回答难度非常大。一定要根据我前面的方法，提前准备。\n第二点，要记住项目在精不在多。\n有的人在介绍项目时，会抛出好几个项目，但每个项目介绍的都很潦草。在面试中，面试官是想通过项目介绍来考察你的各方面能力，一个重点的项目就足够了。一定要选你最了解、最能代表你能力的来介绍。\n第三点，我了解的，就是我的。\n有的同学可能因为机遇的原因，没有负责过重点的项目，不过项目介绍这么重要的考察点，也不能白白在这里丢分。你可以多了解一下其他同事或团队负责的项目，只要你能把细节搞明白，把架构理解透，那么知识就是你的，依然可以拿来进行介绍。\n第四点，要重点体现对架构的理解，对设计的思考\n这会让面试官觉得你会很有潜力。你可以在介绍项目设计思路时做适当的延伸。例如你可以说：在我的业务场景下，可以容忍低概率的消息丢失，所以基于性能优先考虑，去掉了 Kafka 的 ACK 应答。如果是严格要求不丢消息的场景，我会使用同步应答，并且使用最高消息可靠性等级。\n","categories":["总结笔记"],"tags":["架构设计"]},{"title":"缓存设计考量点总结","url":"/2021_11_05_cache_design/","content":"本文主要讲缓存的基本思想、缓存的优点、缓存的代价、然后介绍三种缓存读写模式、两种缓存分类方法、缓存设计架构考量点。\n缓存的定义\n缓存最初的含义，是指用于加速 CPU 数据交换的 RAM，即随机存取存储器，通常这种存储器使用更昂贵但快速的静态 RAM（SRAM）技术，用以对 DRAM进 行加速。这是一个狭义缓存的定义。\n而广义缓存的定义则更宽泛，任何可以用于数据高速交换的存储介质都是缓存，可以是硬件也可以是软件。\n\n\n\n缓存存在的意义就是通过开辟一个新的数据交换缓冲区，来解决原始数据获取代价太大的问题，让数据得到更快的访问。本课主要聚焦于广义缓存，特别是互联网产品大量使用的各种缓存组件和技术。\n缓存原理缓存的基本思想\n\n缓存构建的基本思想是利用时间局限性原理，通过空间换时间来达到加速数据获取的目的，同时由于缓存空间的成本较高，在实际设计架构中还要考虑访问延迟和成本的权衡问题。这里面有 3 个关键点。\n\n一是时间局限性原理，即被获取过一次的数据在未来会被多次引用，比如一条微博被一个人感兴趣并阅读后，它大概率还会被更多人阅读，当然如果变成热门微博后，会被数以百万&#x2F;千万计算的更多用户查看\n二是以空间换时间，因为原始数据获取太慢，所以我们开辟一块高速独立空间，提供高效访问，来达到数据获取加速的目的。\n三是性能成本 Tradeoff，构建系统时希望系统的访问性能越高越好，访问延迟越低小越好。但维持相同数据规模的存储及访问，性能越高延迟越小，成本也会越高，所以在系统架构设计时，你需要在系统性能和开发运行成本之间做取舍。比如左边这张图，相同成本的容量，SSD 硬盘容量会比内存大 10～30 倍以上，但读写延迟却高 50～100 倍。\n\n缓存的优势缓存的优势主要有以下几点：\n\n提升访问性能\n降低网络拥堵\n减轻服务负载\n增强可扩展性\n\n通过前面的介绍，我们已经知道缓存存储原始数据，可以大幅提升访问性能。不过在实际业务场景中，缓存中存储的往往是需要频繁访问的中间数据甚至最终结果，这些数据相比 DB 中的原始数据小很多，这样就可以减少网络流量，降低网络拥堵，同时由于减少了解析和计算，调用方和存储服务的负载也可以大幅降低。缓存的读写性能很高，预热快，在数据访问存在性能瓶颈或遇到突发流量，系统读写压力大增时，可以快速部署上线，同时在流量稳定后，也可以随时下线，从而使系统的可扩展性大大增强。\n缓存的代价然而不幸的是，任何事情都有两面性，缓存也不例外，我们在享受缓存带来一系列好处的同时，也注定需要付出一定的代价。\n\n首先，服务系统中引入缓存，会增加系统的复杂度。\n其次，由于缓存相比原始 DB 存储的成本更高，所以系统部署及运行的费用也会更高。\n最后，由于一份数据同时存在缓存和 DB 中，甚至缓存内部也会有多个数据副本，多份数据就会存在一致性问题，同时缓存体系本身也会存在可用性问题和分区的问题。这就需要我们加强对缓存原理、缓存组件以及优秀缓存体系实践的理解，从系统架构之初就对缓存进行良好设计，降低缓存引入的副作用，让缓存体系成为服务系统高效稳定运行的强力基石。\n\n一般来讲，服务系统的全量原始数据存储在 DB 中（如 MySQL、HBase 等），所有数据的读写都可以通过 DB 操作来获取。但 DB 读写性能低、延迟高，如 MySQL 单实例的读写 QPS 通常只有千级别（3000～6000），读写平均耗时 10～100ms 级别，如果一个用户请求需要查 20 个不同的数据来聚合，仅仅 DB 请求就需要数百毫秒甚至数秒。而 cache 的读写性能正好可以弥补 DB 的不足，比如 Memcached 的读写 QPS 可以达到 10～100万 级别，读写平均耗时在 1ms 以下，结合并发访问技术，单个请求即便查上百条数据，也可以轻松应对。\n但 cache 容量小，只能存储部分访问频繁的热数据，同时，同一份数据可能同时存在 cache 和 DB，如果处理不当，就会出现数据不一致的问题。所以服务系统在处理业务请求时，需要对 cache 的读写方式进行适当设计，既要保证数据高效返回，又要尽量避免数据不一致等各种问题。\n缓存读写模式如下图，业务系统读写缓存有 3 种模式：\n\nCache Aside（旁路缓存）\nRead&#x2F;Write Through（读写穿透）\nWrite Behind Caching（异步缓存写入）\n\n     \n\nCache Aside\n如上图所示，Cache Aside 模式中，业务应用方对于写，是更新 DB 后，直接将 key 从 cache 中删除，然后由 DB 驱动缓存数据的更新；而对于读，是先读 cache，如果 cache 没有，则读 DB，同时将从 DB 中读取的数据回写到 cache。\n这种模式的特点是，业务端处理所有数据访问细节，同时利用 Lazy 计算的思想，更新 DB 后，直接删除 cache 并通过 DB 更新，确保数据以 DB 结果为准，则可以大幅降低 cache 和 DB 中数据不一致的概率。\n如果没有专门的存储服务，同时是对数据一致性要求比较高的业务，或者是缓存数据更新比较复杂的业务，这些情况都比较适合使用 Cache Aside 模式。如微博发展初期，不少业务采用这种模式，这些缓存数据需要通过多个原始数据进行计算后设置。在部分数据变更后，直接删除缓存。同时，使用一个 Trigger 组件，实时读取 DB 的变更日志，然后重新计算并更新缓存。如果读缓存的时候，Trigger 还没写入 cache，则由调用方自行到 DB 加载计算并写入 cache。\nRead&#x2F;Write Through\n\n如上图，对于 Cache Aside 模式，业务应用需要同时维护 cache 和 DB 两个数据存储方，过于繁琐，于是就有了 Read&#x2F;Write Through 模式。在这种模式下，业务应用只关注一个存储服务即可，业务方的读写 cache 和 DB 的操作，都由存储服务代理。存储服务收到业务应用的写请求时，会首先查 cache，如果数据在 cache 中不存在，则只更新 DB，如果数据在 cache 中存在，则先更新 cache，然后更新 DB。而存储服务收到读请求时，如果命中 cache 直接返回，否则先从 DB 加载，回种到 cache 后返回响应。\n这种模式的特点是，存储服务封装了所有的数据处理细节，业务应用端代码只用关注业务逻辑本身，系统的隔离性更佳。另外，进行写操作时，如果 cache 中没有数据则不更新，有缓存数据才更新，内存效率更高。\n微博 Feed 的 Outbox Vector（即用户最新微博列表）就采用这种模式。一些粉丝较少且不活跃的用户发表微博后，Vector 服务会首先查询 Vector Cache，如果 cache 中没有该用户的 Outbox 记录，则不写该用户的 cache 数据，直接更新 DB 后就返回，只有 cache 中存在才会通过 CAS 指令进行更新。\nWrite Behind Caching   \nWrite Behind Caching 模式与 Read&#x2F;Write Through 模式类似，也由数据存储服务来管理 cache 和 DB 的读写。不同点是，数据更新时，Read&#x2F;write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB。该模式的特点是，数据存储的写性能最高，非常适合一些变更特别频繁的业务，特别是可以合并写请求的业务，比如对一些计数业务，一条 Feed 被点赞 1万 次，如果更新 1万 次 DB 代价很大，而合并成一次请求直接加 1万，则是一个非常轻量的操作。但这种模型有个显著的缺点，即数据的一致性变差，甚至在一些极端场景下可能会丢失数据。比如系统 Crash、机器宕机时，如果有数据还没保存到 DB，则会存在丢失的风险。所以这种读写模式适合变更频率特别高，但对一致性要求不太高的业务，这样写操作可以异步批量写入 DB，减小 DB 压力。\n讲到这里，缓存的三种读写模式讲完了，你可以看到三种模式各有优劣，不存在最佳模式。实际上，我们也不可能设计出一个最佳的完美模式出来，如同前面讲到的空间换时间、访问延迟换低成本一样，高性能和强一致性从来都是有冲突的，系统设计从来就是取舍，随处需要 trade-off。这个思想会贯穿整个 cache 设计。\n缓存分类及常用缓存介绍前面介绍了缓存的基本思想、优势、代价以及读写模式，接下来一起看下互联网企业常用的缓存有哪些分类。\n按宿主层次分类按宿主层次分类的话，缓存一般可以分为本地 Cache、进程间 Cache 和远程 Cache。\n\n本地 Cache 是指业务进程内的缓存，这类缓存由于在业务系统进程内，所以读写性能超高且无任何网络开销，但不足是会随着业务系统重启而丢失。\n进程间 Cache 是本机独立运行的缓存，这类缓存读写性能较高，不会随着业务系统重启丢数据，并且可以大幅减少网络开销，但不足是业务系统和缓存都在相同宿主机，运维复杂，且存在资源竞争。\n远程 Cache 是指跨机器部署的缓存，这类缓存因为独立设备部署，容量大且易扩展，在互联网企业使用最广泛。不过远程缓存需要跨机访问，在高读写压力下，带宽容易成为瓶颈。\n\n本地 Cache 的缓存组件有 Ehcache、Guava Cache 等，开发者自己也可以用 Map、Set 等轻松构建一个自己专用的本地 Cache。进程间 Cache 和远程 Cache 的缓存组件相同，只是部署位置的差异罢了，这类缓存组件有 Memcached、Redis、Pika 等。\n按存储介质分类还有一种常见的分类方式是按存储介质来分，这样可以分为内存型缓存和持久化型缓存。\n\n内存型缓存将数据存储在内存，读写性能很高，但缓存系统重启或 Crash 后，内存数据会丢失。\n持久化型缓存将数据存储到 SSD&#x2F;Fusion-IO 硬盘中，相同成本下，这种缓存的容量会比内存型缓存大 1 个数量级以上，而且数据会持久化落地，重启不丢失，但读写性能相对低 1～2 个数量级。Memcached 是典型的内存型缓存，而 Pika 以及其他基于 RocksDB 开发的缓存组件等则属于持久化型缓存。\n\n接下来会聊聊到如何引入缓存并进行设计架构，以及在缓存设计架构中的一些关键考量点。\n缓存的引入及架构设计缓存组件选择在设计架构缓存时，你首先要选定缓存组件，比如要用 Local-Cache，还是 Redis、Memcached、Pika 等开源缓存组件，如果业务缓存需求比较特殊，你还要考虑是直接定制开发一个新的缓存组件，还是对开源缓存进行二次开发，来满足业务需要\n缓存数据结构设计确定好缓存组件后，你还要根据业务访问的特点，进行缓存数据结构的设计。对于直接简单 KV 读写的业务，你可以将这些业务数据封装为 String、Json、Protocol Buffer 等格式，序列化成字节序列，然后直接写入缓存中。读取时，先从缓存组件获取到数据的字节序列，再进行反序列化操作即可。对于只需要存取部分字段或需要在缓存端进行计算的业务，你可以把数据设计为 Hash、Set、List、Geo 等结构，存储到支持复杂集合数据类型的缓存中，如 Redis、Pika 等。\n缓存分布设计确定了缓存组件，设计好了缓存数据结构，接下来就要设计缓存的分布。可以从 3 个维度来进行缓存分布设计。\n\n首先，要选择分布式算法，是采用取模还是一致性 Hash 进行分布。取模分布的方案简单，每个 key 只会存在确定的缓存节点，一致性 Hash 分布的方案相对复杂，一个 key 对应的缓存节点不确定。但一致性 Hash 分布，可以在部分缓存节点异常时，将失效节点的数据访问均衡分散到其他正常存活的节点，从而更好地保证了缓存系统的稳定性。\n其次，分布读写访问如何进行实施，是由缓存 Client 直接进行 Hash 分布定位读写，还是通过 Proxy 代理来进行读写路由？Client 直接读写，读写性能最佳，但需要 Client 感知分布策略。在缓存部署发生在线变化时，也需要及时通知所有缓存 Client，避免读写异常，另外，Client 实现也较复杂。而通过 Proxy 路由，Client 只需直接访问 Proxy，分布逻辑及部署变更都由 Proxy 来处理，对业务应用开发最友好，但业务访问多一跳，访问性能会有一定的损失。\n最后，缓存系统运行过程中，如果待缓存的数据量增长过快，会导致大量缓存数据被剔除，缓存命中率会下降，数据访问性能会随之降低，这样就需要将数据从缓存节点进行动态拆分，把部分数据水平迁移到其他缓存节点。这个迁移过程需要考虑，是由 Proxy 进行迁移还是缓存 Server 自身进行迁移，甚至根本就不支持迁移。对于 Memcached，一般不支持迁移，对 Redis，社区版本是依靠缓存 Server 进行迁移，而对 Codis 则是通过 Admin、Proxy 配合后端缓存组件进行迁移。\n\n存架构部署及运维管理设计完毕缓存的分布策略后，接下来就要考虑缓存的架构部署及运维管理了。架构部署主要考虑如何对缓存进行分池、分层、分 IDC，以及是否需要进行异构处理。\n\n核心的、高并发访问的不同数据，需要分别分拆到独立的缓存池中，进行分别访问，避免相互影响；访问量较小、非核心的业务数据，则可以混存。\n对海量数据、访问超过 10～100万 级的业务数据，要考虑分层访问，并且要分摊访问量，避免缓存过载。\n如果业务系统需要多 IDC 部署甚至异地多活，则需要对缓存体系也进行多 IDC 部署，要考虑如何跨 IDC 对缓存数据进行更新，可以采用直接跨 IDC 读写，也可以采用 DataBus 配合队列机进行不同 IDC 的消息同步，然后由消息处理机进行缓存更新，还可以由各个 IDC 的 DB Trigger 进行缓存更新。\n某些极端场景下，还需要把多种缓存组件进行组合使用，通过缓存异构达到最佳读写性能。\n站在系统层面，要想更好得管理缓存，还要考虑缓存的服务化，考虑缓存体系如何更好得进行集群管理、监控运维等。\n\n缓存设计架构的常见考量点在缓存设计架构的过程中，有一些非常重要的考量点，如下图所示，只有分析清楚了这些考量点，才能设计架构出更佳的缓存体系。\n\n\n读写方式首先是 value 的读写方式。是全部整体读写，还是只部分读写及变更？是否需要内部计算？比如，用户粉丝数，很多普通用户的粉丝有几千到几万，而大 V 的粉丝更是高达几千万甚至过亿，因此，获取粉丝列表肯定不能采用整体读写的方式，只能部分获取。另外在判断某用户是否关注了另外一个用户时，也不需要拉取该用户的全部关注列表，直接在关注列表上进行检查判断，然后返回 True&#x2F;False 或 0&#x2F;1 的方式更为高效。\nKV size然后是不同业务数据缓存 KV 的 size。如果单个业务的 KV size 过大，需要分拆成多个 KV 来缓存。但是，不同缓存数据的 KV size 如果差异过大，也不能缓存在一起，避免缓存效率的低下和相互影响。\nkey 的数量key 的数量也是一个重要考虑因素。如果 key 数量不大，可以在缓存中存下全量数据，把缓存当 DB 存储来用，如果缓存读取 miss，则表明数据不存在，根本不需要再去 DB 查询。如果数据量巨大，则在缓存中尽可能只保留频繁访问的热数据，对于冷数据直接访问 DB。\n读写峰值另外，对缓存数据的读写峰值，如果小于 10万 级别，简单分拆到独立 Cache 池即可。而一旦数据的读写峰值超过 10万 甚至到达 100万 级的QPS，则需要对 Cache 进行分层处理，可以同时使用 Local-Cache 配合远程 cache，甚至远程缓存内部继续分层叠加分池进行处理。微博业务中，大多数核心业务的 Memcached 访问都采用的这种处理方式。\n命中率缓存的命中率对整个服务体系的性能影响甚大。对于核心高并发访问的业务，需要预留足够的容量，确保核心业务缓存维持较高的命中率。比如微博中的 Feed Vector Cache，常年的命中率高达 99.5% 以上。为了持续保持缓存的命中率，缓存体系需要持续监控，及时进行故障处理或故障转移。同时在部分缓存节点异常、命中率下降时，故障转移方案，需要考虑是采用一致性 Hash 分布的访问漂移策略，还是采用数据多层备份策略。\n过期策略\n可以设置较短的过期时间，让冷 key 自动过期；\n也可以让 key 带上时间戳，同时设置较长的过期时间，比如很多业务系统内部有这样一些 key：key_20190801。\n\n平均缓存穿透加载时间平均缓存穿透加载时间在某些业务场景下也很重要，对于一些缓存穿透后，加载时间特别长或者需要复杂计算的数据，而且访问量还比较大的业务数据，要配置更多容量，维持更高的命中率，从而减少穿透到 DB 的概率，来确保整个系统的访问性能。\n缓存可运维性对于缓存的可运维性考虑，则需要考虑缓存体系的集群管理，如何进行一键扩缩容，如何进行缓存组件的升级和变更，如何快速发现并定位问题，如何持续监控报警，最好有一个完善的运维平台，将各种运维工具进行集成。\n缓存安全性对于缓存的安全性考虑，一方面可以限制来源 IP，只允许内网访问，同时对于一些关键性指令，需要增加访问权限，避免被攻击或误操作时，导致重大后果。\n","categories":["总结笔记"],"tags":["缓存设计","旁路缓存","读写穿透","异步缓存写入"]},{"title":"缓存设计中七大经典问题总结","url":"/2021_11_06_cache_7_problems/","content":"在缓存系统的设计架构中，还有很多坑，很多的明枪暗箭，如果设计不当会导致很多严重的后果。设计不当，轻则请求变慢、性能降低，重则会数据不一致、系统可用性降低，甚至会导致缓存雪崩，整个系统无法对外提供服务\n接下来将对缓存设计中的7大经典问题，如下图，进行问题描述、原因分析，并给出日常研发中，可能会出现该问题的业务场景，最后给出这些经典问题的解决方案。本文先学习缓存失效、缓存穿透与缓存雪崩。\n\n\n缓存失效问题描述缓存第一个经典问题是缓存失效。上一课时讲到，服务系统查数据，首先会查缓存，如果缓存数据不存在，就进一步查DB，最后查到数据后回种到缓存并返回。缓存的性能比DB高50～100倍以上，所以我们希望数据查询尽可能命中缓存，这样系统负荷最小，性能最佳。缓存里的数据存储基本上都是以key为索引进行存储和获取的。业务访问时，如果大量的key同时过期，很多缓存数据访问都会miss，进而穿透到DB，DB的压力就会明显上升，由于DB的性能较差，只在缓存的1%～2%以下，这样请求的慢查率会明显上升。这就是缓存失效的问题。\n原因分析导致缓存失效，特别是很多key一起失效的原因，跟我们日常写缓存的过期时间息息相关。\n在写缓存时，我们一般会根据业务的访问特点，给每种业务数据预置一个过期时间，在写缓存时把这个过期时间带上，让缓存数据在这个固定的过期时间后被淘汰。一般情况下，因为缓存数据是逐步写入的，所以也是逐步过期被淘汰的。但在某些场景，一大批数据会被系统主动或被动从DB批量加载，然后写入缓存。这些数据写入缓存时，由于使用相同的过期时间，在经历这个过期时间之后，这批数据就会一起到期，从而被缓存淘汰。此时，对这批数据的所有请求，都会出现缓存失效，从而都穿透到DB，DB由于查询量太大，就很容易压力大增，请求变慢\n业务场景很多业务场景，稍不注意，就出现大量的缓存失效，进而导致系统DB压力大、请求变慢的情况。比如同一批火车票、飞机票，当可以售卖时，系统会一次性加载到缓存，如果缓存写入时，过期时间按照预先设置的过期值，那过期时间到期后，系统就会因缓存失效出现变慢的问题。类似的业务场景还有很多，比如微博业务，会有后台离线系统，持续计算热门微博，每当计算结束，会将这批热门微博批量写入对应的缓存。还比如，很多业务，在部署新IDC或新业务上线时，会进行缓存预热，也会一次性加载大批热数据。\n解决方案对于批量key缓存失效的问题，原因既然是预置的固定过期时间，那解决方案也从这里入手。设计缓存的过期时间时，使用公式：过期时间&#x3D;baes时间+随机时间。即相同业务数据写缓存时，在基础过期时间之上，再加一个随机的过期时间，让数据在未来一段时间内慢慢过期，避免瞬时全部过期，对DB造成过大压力，如下图所示。\n  \n\n缓存穿透问题描述第二个经典问题是缓存穿透。缓存穿透是一个很有意思的问题。因为缓存穿透发生的概率很低，所以一般很难被发现。但是，一旦你发现了，而且量还不小，你可能立即就会经历一个忙碌的夜晚。因为对于正常访问，访问的数据即便不在缓存，也可以通过DB加载回种到缓存。而缓存穿透，则意味着有特殊访客在查询一个不存在的key，导致每次查询都会穿透到DB，如果这个特殊访客再控制一批肉鸡机器，持续访问你系统里不存在的key，就会对DB产生很大的压力，从而影响正常服务。\n原因分析缓存穿透存在的原因，就是因为我们在系统设计时，更多考虑的是正常访问路径，对特殊访问路径、异常访问路径考虑相对欠缺\n缓存访问设计的正常路径，是先访问cache，cache miss后查DB，DB查询到结果后，回种缓存返回。这对于正常的key访问是没有问题的，但是如果用户访问的是一个不存在的key，查DB返回空（即一个NULL），那就不会把这个空写回cache。那以后不管查询多少次这个不存在的key，都会cache miss，都会查询DB。整个系统就会退化成一个“前端+DB“的系统，由于DB的吞吐只在cache的1%~2%以下，如果有特殊访客，大量访问这些不存在的key，就会导致系统的性能严重退化，影响正常用户的访问。\n业务场景缓存穿透的业务场景很多，比如通过不存在的UID访问用户，通过不存在的车次ID查看购票信息。用户输入错误，偶尔几个这种请求问题不大，但如果是大量这种请求，就会对系统影响非常大。\n解决方案那么如何解决这种问题呢？如下图所示。\n\n第一种方案就是，查询这些不存在的数据时，第一次查DB，虽然没查到结果返回NULL，仍然记录这个key到缓存，只是这个key对应的value是一个特殊设置的值。\n第二种方案是，构建一个BloomFilter缓存过滤器，记录全量数据，这样访问数据时，可以直接通过BloomFilter判断这个key是否存在，如果不存在直接返回即可，根本无需查缓存和DB。\n\n \n\n不过这两种方案在设计时仍然有一些要注意的坑。\n\n对于方案一，如果特殊访客持续访问大量的不存在的key，这些key即便只存一个简单的默认值，也会占用大量的缓存空间，导致正常key的命中率下降。所以进一步的改进措施是，对这些不存在的key只存较短的时间，让它们尽快过期；或者将这些不存在的key存在一个独立的公共缓存，从缓存查找时，先查正常的缓存组件，如果miss，则查一下公共的非法key的缓存，如果后者命中，直接返回，否则穿透DB，如果查出来是空，则回种到非法key缓存，否则回种到正常缓存。\n对于方案二，BloomFilter要缓存全量的key，这就要求全量的key数量不大，10亿条数据以内最佳，因为10亿条数据大概要占用1.2GB的内存。也可以用BloomFilter缓存非法key，每次发现一个key是不存在的非法key，就记录到BloomFilter中，这种记录方案，会导致BloomFilter存储的key持续高速增长，为了避免记录key太多而导致误判率增大，需要定期清零处理。\n\nBloomFilterBloomFilter是一个非常有意思的数据结构，不仅仅可以挡住非法key攻击，还可以低成本、高性能地对海量数据进行判断，比如一个系统有数亿用户和百亿级新闻feed，就可以用BloomFilter来判断某个用户是否阅读某条新闻feed。下面来对BloomFilter数据结构做一个分析，如下图所示。\n  \n\nBloomFilter的目的是检测一个元素是否存在于一个集合内。它的原理，是用bit数据组来表示一个集合，对一个key进行多次不同的Hash检测，如果所有Hash对应的bit位都是1，则表明key非常大概率存在，平均单记录占用1.2字节即可达到99%，只要有一次Hash对应的bit位是0，就说明这个key肯定不存在于这个集合内。\nBloomFilter的算法是，首先分配一块内存空间做bit数组，数组的bit位初始值全部设为0，加入元素时，采用k个相互独立的Hash函数计算，然后将元素Hash映射的K个位置全部设置为1。检测key时，仍然用这k个Hash函数计算出k个位置，如果位置全部为1，则表明key存在，否则不存在。\nBloomFilter的优势是，全内存操作，性能很高。另外空间效率非常高，要达到1%的误判率，平均单条记录占用1.2字节即可。而且，平均单条记录每增加0.6字节，还可让误判率继续变为之前的1&#x2F;10，即平均单条记录占用1.8字节，误判率可以达到1&#x2F;1000；平均单条记录占用2.4字节，误判率可以到1&#x2F;10000，以此类推。这里的误判率是指，BloomFilter判断某个key存在，但它实际不存在的概率，因为它存的是key的Hash值，而非key的值，所以有概率存在这样的key，它们内容不同，但多次Hash后的Hash值都相同。对于BloomFilter判断不存在的key ，则是100%不存在的，反证法，如果这个key存在，那它每次Hash后对应的Hash值位置肯定是1，而不会是0。\n缓存雪崩问题描述第三个经典问题是缓存雪崩。系统运行过程中，缓存雪崩是一个非常严重的问题。缓存雪崩是指部分缓存节点不可用，导致整个缓存体系甚至甚至服务系统不可用的情况。缓存雪崩按照缓存是否rehash（即是否漂移）分两种情况：\n\n缓存不支持rehash导致的系统雪崩不可\n缓存支持rehash导致的缓存雪崩不可用\n\n原因分析在上述两种情况中，缓存不进行rehash时产生的雪崩，一般是由于较多缓存节点不可用，请求穿透导致DB也过载不可用，最终整个系统雪崩不可用的。而缓存支持rehash时产生的雪崩，则大多跟流量洪峰有关，流量洪峰到达，引发部分缓存节点过载Crash，然后因rehash扩散到其他缓存节点，最终整个缓存体系异常。\n第一种情况比较容易理解，缓存节点不支持rehash，较多缓存节点不可用时，大量Cache访问会失败，根据缓存读写模型，这些请求会进一步访问DB，而且DB可承载的访问量要远比缓存小的多，请求量过大，就很容易造成DB过载，大量慢查询，最终阻塞甚至Crash，从而导致服务异常。\n第二种情况是怎么回事呢？这是因为缓存分布设计时，很多同学会选择一致性Hash分布方式，同时在部分节点异常时，采用rehash策略，即把异常节点请求平均分散到其他缓存节点。在一般情况下，一致性Hash分布+rehash策略可以很好得运行，但在较大的流量洪峰到临之时，如果大流量key比较集中，正好在某1～2个缓存节点，很容易将这些缓存节点的内存、网卡过载，缓存节点异常Crash，然后这些异常节点下线，这些大流量key请求又被rehash到其他缓存节点，进而导致其他缓存节点也被过载Crash，缓存异常持续扩散，最终导致整个缓存体系异常，无法对外提供服务。\n业务场景缓存雪崩的业务场景并不少见，微博、Twitter等系统在运行的最初若干年都遇到过很多次。比如，微博最初很多业务缓存采用一致性Hash+rehash策略，在突发洪水流量来临时，部分缓存节点过载Crash甚至宕机，然后这些异常节点的请求转到其他缓存节点，又导致其他缓存节点过载异常，最终整个缓存池过载。另外，机架断电，导致业务缓存多个节点宕机，大量请求直接打到DB，也导致DB过载而阻塞，整个系统异常。最后缓存机器复电后，DB重启，数据逐步加热后，系统才逐步恢复正常。\n解决方案预防缓存雪崩，这里给出3个解决方案。\n\n方案一，对业务DB的访问增加读写开关，当发现DB请求变慢、阻塞，慢请求超过阀值时，就会关闭读开关，部分或所有读DB的请求进行failfast立即返回，待DB恢复后再打开读开关，如下图。\n    \n\n方案二，对缓存增加多个副本，缓存异常或请求miss后，再读取其他缓存副本，而且多个缓存副本尽量部署在不同机架，从而确保在任何情况下，缓存系统都会正常对外提供服务。\n\n方案三，对缓存体系进行实时监控，当请求访问的慢速比超过阀值时，及时报警，通过机器替换、服务替换进行及时恢复；也可以通过各种自动故障转移策略，自动关闭异常接口、停止边缘服务、停止部分非核心功能措施，确保在极端场景下，核心功能的正常运行。\n\n\n实际上，微博平台系统，这三种方案都采用了，通过三管齐下，规避缓存雪崩的发生。\n数据不一致问题描述七大缓存经典问题的第四个问题是数据不一致。同一份数据，可能会同时存在DB和缓存之中。那就有可能发生，DB和缓存的数据不一致。如果缓存有多个副本，多个缓存副本里的数据也可能会发生不一致现象\n原因分析不一致的问题大多跟缓存更新异常有关。比如更新DB后，写缓存失败，从而导致缓存中存的是老数据。另外，如果系统采用一致性Hash分布，同时采用rehash自动漂移策略，在节点多次上下线之后，也会产生脏数据。缓存有多个副本时，更新某个副本失败，也会导致这个副本的数据是老数据。\n业务场景导致数据不一致的场景也不少。如下图所示，在缓存机器的带宽被打满，或者机房网络出现波动时，缓存更新失败，新数据没有写入缓存，就会导致缓存和DB的数据不一致。缓存rehash时，某个缓存机器反复异常，多次上下线，更新请求多次rehash。这样，一份数据存在多个节点，且每次rehash只更新某个节点，导致一些缓存节点产生脏数据。\n\n\n解决方案要尽量保证数据的一致性。这里也给出了3个方案，可以根据实际情况进行选择。\n\n第一个方案，cache更新失败后，可以进行重试，如果重试失败，则将失败的key写入队列机服务，待缓存访问恢复后，将这些key从缓存删除。这些key在再次被查询时，重新从DB加载，从而保证数据的一致性。\n第二个方案，缓存时间适当调短，让缓存数据及早过期后，然后从DB重新加载，确保数据的最终一致性。\n第三个方案，不采用rehash漂移策略，而采用缓存分层策略，尽量避免脏数据产生。\n\n\n\n数据并发竞争问题描述第五个经典问题是数据并发竞争。互联网系统，线上流量较大，缓存访问中很容易出现数据并发竞争的现象。数据并发竞争，是指在高并发访问场景，一旦缓存访问没有找到数据，大量请求就会并发查询DB，导致DB压力大增的现象。\n数据并发竞争，主要是由于多个进程&#x2F;线程中，有大量并发请求获取相同的数据，而这个数据key因为正好过期、被剔除等各种原因在缓存中不存在，这些进程&#x2F;线程之间没有任何协调，然后一起并发查询DB，请求那个相同的key，最终导致DB压力大增，如下图。\n\n\n业务场景数据并发竞争在大流量系统也比较常见，比如车票系统，如果某个火车车次缓存信息过期，但仍然有大量用户在查询该车次信息。又比如微博系统中，如果某条微博正好被缓存淘汰，但这条微博仍然有大量的转发、评论、赞。上述情况都会造成该车次信息、该条微博存在并发竞争读取的问题\n解决方案要解决并发竞争，有2种方案。\n\n方案一是使用全局锁。如下图所示，即当缓存请求miss后，先尝试加全局锁，只有加全局锁成功的线程，才可以到DB去加载数据。其他进程&#x2F;线程在读取缓存数据miss时，如果发现这个key有全局锁，就进行等待，待之前的线程将数据从DB回种到缓存后，再从缓存获取。\n\n\n\n\n方案二是，对缓存数据保持多个备份，即便其中一个备份中的数据过期或被剔除了，还可以访问其他备份，从而减少数据并发竞争的情况，如下图。\n\n\n\n\nHot key问题描述第六个经典问题是Hot key。对于大多数互联网系统，数据是分冷热的。比如最近的新闻、新发表的微博被访问的频率最高，而比较久远的之前的新闻、微博被访问的频率就会小很多。而在突发事件发生时，大量用户同时去访问这个突发热点信息，访问这个Hot key，这个突发热点信息所在的缓存节点就很容易出现过载和卡顿现象，甚至会被Crash。\n原因分析Hot key引发缓存系统异常，主要是因为突发热门事件发生时，超大量的请求访问热点事件对应的key，比如微博中数十万、数百万的用户同时去吃一个新瓜。数十万的访问请求同一个key，流量集中打在一个缓存节点机器，这个缓存机器很容易被打到物理网卡、带宽、CPU的极限，从而导致缓存访问变慢、卡顿。\n业务场景引发Hot key的业务场景很多，比如明星结婚、离婚、出轨这种特殊突发事件，比如奥运、春节这些重大活动或节日，还比如秒杀、双12、618等线上促销活动，都很容易出现Hot key的情况。\n解决方案要解决这种极热key的问题，首先要找出这些Hot key来。对于重要节假日、线上促销活动、集中推送这些提前已知的事情，可以提前评估出可能的热key来。而对于突发事件，无法提前评估，可以通过Spark，对应流任务进行实时分析，及时发现新发布的热点key。而对于之前已发出的事情，逐步发酵成为热key的，则可以通过Hadoop对批处理任务离线计算，找出最近历史数据中的高频热key。\n找到热key后，就有很多解决办法了。首先可以将这些热key进行分散处理，比如一个热key名字叫hotkey，可以被分散为hotkey#1、hotkey#2、hotkey#3，……hotkey#n，这n个key分散存在多个缓存节点，然后client端请求时，随机访问其中某个后缀的hotkey，这样就可以把热key的请求打散，避免一个缓存节点过载，如下图所示。\n \n\n其次，也可以key的名字不变，对缓存提前进行多副本+多级结合的缓存架构设计。\n再次，如果热key较多，还可以通过监控体系对缓存的SLA实时监控，通过快速扩容来减少热key的冲击。\n最后，业务端还可以使用本地缓存，将这些热key记录在本地缓存，来减少对远程缓存的冲击。\nBig key问题描述最后一个经典问题是Big key，也就是大Key的问题。大key，是指在缓存访问时，部分Key的Value过大，读写、加载易超时的现象。\n原因分析造成这些大key慢查询的原因很多。如果这些大key占总体数据的比例很小，存Mc，对应的slab较少，导致很容易被频繁剔除，DB反复加载，从而导致查询较慢。如果业务中这种大key很多，而这种key被大量访问，缓存组件的网卡、带宽很容易被打满，也会导致较多的大key慢查询。另外，如果大key缓存的字段较多，每个字段的变更都会引发对这个缓存数据的变更，同时这些key也会被频繁地读取，读写相互影响，也会导致慢查现象。最后，大key一旦被缓存淘汰，DB加载可能需要花费很多时间，这也会导致大key查询慢的问题。\n业务场景大key的业务场景也比较常见。比如互联网系统中需要保存用户最新1万个粉丝的业务，比如一个用户个人信息缓存，包括基本资料、关系图谱计数、发feed统计等。微博的feed内容缓存也很容易出现，一般用户微博在140字以内，但很多用户也会发表1千字甚至更长的微博内容，这些长微博也就成了大key，如下图。\n  \n\n解决方案对于大key，给出3种解决方案。\n\n第一种方案，如果数据存在Mc中，可以设计一个缓存阀值，当value的长度超过阀值，则对内容启用压缩，让KV尽量保持小的size，其次评估大key所占的比例，在Mc启动之初，就立即预写足够数据的大key，让Mc预先分配足够多的trunk size较大的slab。确保后面系统运行时，大key有足够的空间来进行缓存。\n\n\n\n\n第二种方案，如果数据存在Redis中，比如业务数据存set格式，大key对应的set结构有几千几万个元素，这种写入Redis时会消耗很长的时间，导致Redis卡顿。此时，可以扩展新的数据结构，同时让client在这些大key写缓存之前，进行序列化构建，然后通过restore一次性写入，如下图所示。\n\n\n\n\n第三种方案时，如下图所示，将大key分拆为多个key，尽量减少大key的存在。同时由于大key一旦穿透到DB，加载耗时很大，所以可以对这些大key进行特殊照顾，比如设置较长的过期时间，比如缓存内部在淘汰key时，同等条件下，尽量不淘汰这些大key。\n\n\n\n至此，本文关于缓存的7大经典问题全部介绍完了。\n我们要认识到，对于互联网系统，由于实际业务场景复杂，数据量、访问量巨大，需要提前规避缓存使用中的各种坑。你可以通过提前熟悉Cache的经典问题，提前构建防御措施， 避免大量key同时失效，避免不存在key访问的穿透，减少大key、热key的缓存失效，对热key进行分流。你可以采取一系列措施，让访问尽量命中缓存，同时保持数据的一致性。另外，你还可以结合业务模型，提前规划cache系统的SLA，如QPS、响应分布、平均耗时等，实施监控，以方便运维及时应对。在遇到部分节点异常，或者遇到突发流量、极端事件时，也能通过分池分层策略、key分拆等策略，避免故障发生。\n最终，你能在各种复杂场景下，面对高并发、海量访问，面对突发事件和洪峰流量，面对各种网络或机器硬件故障，都能保持服务的高性能和高可用。\n","categories":["总结笔记"],"tags":["缓存雪崩","缓存穿透","缓存失效","数据不一致","数据并发竞争","Hot Key","Big Key"]},{"title":"ThreadLocal分析","url":"/2022_02_10_threadlocal/","content":"ThreadLocal介绍ThreadLocal是什么ThreadLocal本地线程变量,线程自带的变量副本(实现了每一个线程副本都有一个专属的本地变量,主要解决的就是让每一个线程绑定自己的值,自己用自己的,不跟别人争抢。通过使用get()和set()方法,获取默认值或将其值更改为当前线程所存的副本的值从而避免了线程安全的问题)\nsynchronized或者lock,有个管理员,好比,现在大家签到,多个同学(线程),但是只有一只笔,只能同一个时间,只有一个线程(同学)签到,加锁(同步机制是以时间换空间,执行时间不一样,类似于排队)\nThreadLocal,人人有份,每个同学手上都有一支笔,自己用自己的,不用再加锁来维持秩序(同步机制是以空间换时间,为每一个线程都提供了一份变量的副本,从而实现同时访问,互不干扰同时访问,肯定效率高啊)\napi介绍\n\nprotected T initialValue?():initialValue():返回此线程局部变量的当前线程的”初始值”(对于initialValue()较为老旧,jdk1.8又加入了withInitial()方法)\n\nstatic ThreadLocal withInitial?(Supplier supplier):创建线程局部变量\n\nT get?():返回当前线程的此线程局部变量的副本中的值\n\nvoid set?(T value):将当前线程的此线程局部变量的副本设置为指定的值\n\nvoid remove?():删除此线程局部变量的当前线程的值\n\n\nThreadLocal源码分析Thread|ThreadLocal|ThreadLocalMap关系\nThread和ThreadLocal\nThreadLocal和ThreadLocalMap\n三者总概括\n\n\nThread类中有一个ThreadLocal.ThreadLocalMap threadLocals &#x3D; null的变量,这个ThreadLocal相当于是Thread类和ThreadLocalMap的桥梁,在ThreadLocal中有静态内部类ThreadLocalMap,ThreadLocalMap中有Entry数组\n当我们为threadLocal变量赋值,实际上就是以当前threadLocal实例为key,值为value的Entry往这个threadLocalMap中存放\nt.threadLocals &#x3D; new ThreadLocalMap(this, firstValue) 如下这行代码,可以知道每个线程都会创建一个ThreadLocalMap对象,每个线程都有自己的变量副本\n\n核心代码//核心代码说明public void set(T value) &#123;    Thread t = Thread.currentThread();    ThreadLocalMap map = getMap(t);    if (map != null)        map.set(this, value);    else        createMap(t, value);&#125;void createMap(Thread t, T firstValue) &#123;   t.threadLocals = new ThreadLocalMap(this, firstValue);&#125;ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123;    table = new Entry[INITIAL_CAPACITY];    int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);    table[i] = new Entry(firstKey, firstValue);    size = 1;    setThreshold(INITIAL_CAPACITY);&#125;\n\nset方法详解\n首先获取当前线程,并根据当前线程获取一个Map\n如果获取的Map不为空,则将参数设置到Map中(当前ThreadLocal的引用作为key)\n如果Map为空,则给该线程创建 Map,并设置初始值/**     * 设置当前线程对应的ThreadLocal的值     *     * @param value 将要保存在当前线程对应的ThreadLocal的值     */    public void set(T value) &#123;        // 获取当前线程对象        Thread t = Thread.currentThread();        // 获取此线程对象中维护的ThreadLocalMap对象        ThreadLocalMap map = getMap(t);        // 判断map是否存在        if (map != null)            // 存在则调用map.set设置此实体entry            map.set(this, value);        else            // 1)当前线程Thread 不存在ThreadLocalMap对象            // 2)则调用createMap进行ThreadLocalMap对象的初始化            // 3)并将 t(当前线程)和value(t对应的值)作为第一个entry存放至ThreadLocalMap中            createMap(t, value);    &#125; /**     * 获取当前线程Thread对应维护的ThreadLocalMap      *      * @param  t the current thread 当前线程     * @return the map 对应维护的ThreadLocalMap      */    ThreadLocalMap getMap(Thread t) &#123;        return t.threadLocals;    &#125;\t/**     *创建当前线程Thread对应维护的ThreadLocalMap      *     * @param t 当前线程     * @param firstValue 存放到map中第一个entry的值     */\tvoid createMap(Thread t, T firstValue) &#123;        //这里的this是调用此方法的threadLocal        t.threadLocals = new ThreadLocalMap(this, firstValue);    &#125;    \t /*\t  * firstKey : 本ThreadLocal实例(this)\t  * firstValue ： 要保存的线程本地变量\t  */\tThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123;\t        //初始化table\t        table = new ThreadLocal.ThreadLocalMap.Entry[INITIAL_CAPACITY];\t        //计算索引(重点代码)\t        int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);\t        //设置值\t        table[i] = new ThreadLocal.ThreadLocalMap.Entry(firstKey, firstValue);\t        size = 1;\t        //设置阈值\t        setThreshold(INITIAL_CAPACITY);\t    &#125;\n\nget方法详解先获取当前线程的ThreadLocalMap变量,如果存在则返回值,不存在则创建并返回初始值\n/**   * 返回当前线程中保存ThreadLocal的值   * 如果当前线程没有此ThreadLocal变量,   * 则它会通过调用&#123;@link #initialValue&#125; 方法进行初始化值   *   * @return 返回当前线程对应此ThreadLocal的值   */  public T get() &#123;      // 获取当前线程对象      Thread t = Thread.currentThread();      // 获取此线程对象中维护的ThreadLocalMap对象      ThreadLocalMap map = getMap(t);      // 如果此map存在      if (map != null) &#123;          // 以当前的ThreadLocal 为 key,调用getEntry获取对应的存储实体e          ThreadLocalMap.Entry e = map.getEntry(this);          // 对e进行判空           if (e != null) &#123;              @SuppressWarnings(&quot;unchecked&quot;)              // 获取存储实体 e 对应的 value值              // 即为我们想要的当前线程对应此ThreadLocal的值              T result = (T)e.value;              return result;          &#125;      &#125;      /*      \t初始化 : 有两种情况有执行当前代码      \t第一种情况: map不存在,表示此线程没有维护的ThreadLocalMap对象      \t第二种情况: map存在, 但是没有与当前ThreadLocal关联的entry       */      return setInitialValue();  &#125;  /**   * 初始化   *   * @return the initial value 初始化后的值   */  private T setInitialValue() &#123;      // 调用initialValue获取初始化的值      // 此方法可以被子类重写, 如果不重写默认返回null      T value = initialValue();      // 获取当前线程对象      Thread t = Thread.currentThread();      // 获取此线程对象中维护的ThreadLocalMap对象      ThreadLocalMap map = getMap(t);      // 判断map是否存在      if (map != null)          // 存在则调用map.set设置此实体entry          map.set(this, value);      else          // 1)当前线程Thread 不存在ThreadLocalMap对象          // 2)则调用createMap进行ThreadLocalMap对象的初始化          // 3)并将 t(当前线程)和value(t对应的值)作为第一个entry存放至ThreadLocalMap中          createMap(t, value);      // 返回设置的值value      return value;\nremove方法详解\n首先获取当前线程,并根据当前线程获取一个Map\n如果获取的Map不为空,则移除当前ThreadLocal对象对应的entry/**     * 删除当前线程中保存的ThreadLocal对应的实体entry     */     public void remove() &#123;        // 获取当前线程对象中维护的ThreadLocalMap对象         ThreadLocalMap m = getMap(Thread.currentThread());        // 如果此map存在         if (m != null)            // 存在则调用map.remove            // 以当前ThreadLocal为key删除对应的实体entry             m.remove(this);     &#125;\n\nThreadLocal内存泄漏问题为什么源代码用弱引用？\n当function01方法执行完毕后,栈帧销毁强引用 tl 也就没有了。但此时线程的ThreadLocalMap里某个entry的key引用还指向这个对象\n若这个key引用是强引用,就会导致key指向的ThreadLocal对象及v指向的对象不能被gc回收,造成内存泄漏\n若这个key引用是弱引用就大概率会减少内存泄漏的问题(还有一个key为null的雷)。使用弱引用,就可以使ThreadLocal对象在方法执行完毕后顺利被回收且Entry的key引用指向为null\n\nkey为null的entry,原理解析\nThreadLocalMap使用ThreadLocal的弱引用作为key,如果一个ThreadLocal没有外部强引用引用他,那么系统gc的时候,这个ThreadLocal势必会被回收,这样一来,ThreadLocalMap中就会出现key为null的Entry,就没有办法访问这些key为null的Entry的value,如果当前线程再迟迟不结束的话(比如正好用在线程池),这些key为null的Entry的value就会一直存在一条强引用链\n虽然弱引用,保证了key指向的ThreadLocal对象能被及时回收,但是v指向的value对象是需要ThreadLocalMap调用get、set时发现key为null时才会去回收整个entry、value\n因此弱引用不能100%保证内存不泄露。我们要在不使用某个ThreadLocal对象后,手动调用remoev方法来删除它,尤其是在线程池中,不仅仅是内存泄露的问题,因为线程池中的线程是重复使用的,意味着这个线程的ThreadLocalMap对象也是重复使用的,如果我们不手动调用remove方法,那么后面的线程就有可能获取到上个线程遗留下来的value值,造成bug\n如果当前thread运行结束,threadLocal,threadLocalMap, Entry没有引用链可达,在垃圾回收的时候都会被系统进行回收\n但在实际使用中我们有时候会用线程池去维护我们的线程,比如在Executors.newFixedThreadPool()时创建线程的时候,为了复用线程是不会结束的,所以threadLocal内存泄漏就值得我们小心\n出现内存泄漏的真实原因 (1). 没有手动删除这个Entry (2). CurrentThread依然运行\n\nset、get方法会去检查所有键为null的Entry对象\n结论(在finally后面调用remove方法)\nThreadLocal小总结\nThreadLocal本地线程变量,以空间换时间,线程自带的变量副本,人手一份,避免了线程安全问题\n每个线程持有一个只属于自己的专属Map并维护了Thread Local对象与具体实例的映射,该Map由于只被持有它的线程访问,故不存在线程安全以及锁的问题3.ThreadLocalMap的Entry对ThreadLocal的引用为弱引用,避免了ThreadLocal对象无法被回收的问题\n都会通过expungeStaleEntry,cleanSomeSlots, replace StaleEntry这三个方法回收键为 null 的 Entry 对象的值(即为具体实例)以及 Entry 对象本身从而防止内存泄漏,属于安全加固的方法\n用完之后一定要remove操作\n\n使用案例解决SimpleDateFormat线程不安全//线程安全做法package h.xd.util;import java.text.ParseException;import java.text.SimpleDateFormat;import java.time.LocalDateTime;import java.time.format.DateTimeFormatter;import java.util.Date;public class ThreadLocalDateUtils &#123;    public static final ThreadLocal&lt;SimpleDateFormat&gt;sdfThreadLocal=            ThreadLocal.withInitial(()-&gt;new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;));    public static Date parseByThreadLocal(String stringDate) throws ParseException &#123;        return sdfThreadLocal.get().parse(stringDate);    &#125;    //DateTimeFormatter 代替 SimpleDateFormat    public static final DateTimeFormatter DATE_TIME_FORMAT = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;);    public static String formatForDateTime(LocalDateTime localDateTime) &#123;        return DATE_TIME_FORMAT.format(localDateTime);    &#125;    public static LocalDateTime parseForDateTime(String dateString) &#123;        return LocalDateTime.parse(dateString,DATE_TIME_FORMAT);    &#125;    public static void main(String[] args) throws Exception&#123;        for (int i = 1; i &lt;=3; i++) &#123;            new Thread(()-&gt;&#123;                try &#123;                    System.out.println(ThreadLocalDateUtils.parseByThreadLocal(&quot;2021-03-30 11:20:30&quot;));                    System.out.println(ThreadLocalDateUtils.parseForDateTime(&quot;2021-03-30 11:20:30&quot;));                     System.out.println(ThreadLocalDateUtils.formatForDateTime(LocalDateTime.now()));                &#125; catch (Exception e) &#123;                    e.printStackTrace();                &#125;finally &#123;                    ThreadLocalDateUtils.sdfThreadLocal.remove();                &#125;            &#125;,String.valueOf(i)).start();        &#125;    &#125;&#125;\n\n//不安全做法package h.xd.util;import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Date;public class DateUtils &#123;    public static SimpleDateFormat sdf=new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);    /**     解决方案一:加入synchronized,用时间换空间,效率低     */    /**     如果不加会导致线程安全问题,SimpleDateFormat类内部有一个Calendar对象引用,     SimpleDateFormat相关的日期信息,例如sdf.parse(dateStr),sdf.format(date)     诸如此类的方法参数传入的日期相关String,Date等等, 都是交由Calendar引用来储存的.     这样就会导致一个问题如果你的SimpleDateFormat是个static的,那么多个thread之间     就会共享这个SimpleDateFormat,同时也是共享这个Calendar引用(相当于买票案列)     */    //public static synchronized Date parse(String stringDate) throws ParseException &#123;    public static  Date parse(String stringDate) throws ParseException &#123;        System.out.println(sdf.parse(stringDate));        return sdf.parse(stringDate);    &#125;    public static void main(String[] args) throws Exception&#123;        for (int i = 1; i &lt;=3; i++) &#123;            new Thread(()-&gt;&#123;                try &#123;                    DateUtils.parse(&quot;2021-03-30 11:20:30&quot;);                &#125; catch (Exception e) &#123;                    e.printStackTrace();                &#125;            &#125;,String.valueOf(i)).start();        &#125;    &#125;&#125;\n\n解决每个请求一个线程安全的连接问题// TestDao.javapackage com.h.xd.threadlocal;public class TestDao &#123;    private static ThreadLocal&lt;MConnection&gt; connectionThreadLocal = ThreadLocal.withInitial(TestDao::createConnection);    private static MConnection createConnection()&#123;        MConnection mConnection = new MConnection();        System.out.println(&quot;实例化了一个对象： &quot; + mConnection);        return mConnection;    &#125;    public static MConnection getConnection()&#123;        return connectionThreadLocal.get();    &#125;&#125;\n//MConnection.javapackage com.h.xd.threadlocal;public class MConnection &#123;&#125;\n\n//客户端调用，这里用springmvc的一个请求package com.h.xd.controller;import com.h.xd.threadlocal.MConnection;import com.h.xd.threadlocal.TestDao;import lombok.extern.slf4j.Slf4j;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(value = &quot;/thread&quot;)@Slf4jpublic class ThreadController &#123;    @RequestMapping(value = &quot;&quot;)    public void home()&#123;        MConnection connection = TestDao.getConnection();        log.info(&quot;&#123;&#125;&quot;,connection);    &#125;&#125;\n","categories":["应用笔记"],"tags":["Java","Thread","ThreadLocal"]},{"title":"Java泛型梳理","url":"/2022_02_13_java_wild_type/","content":"在java中，泛型算是必须要掌握的一块硬核知识，在很多地方都会用到，这块如果理解了，在阅读其他框架源码的时候会让你更容易一些。\n关于泛型的解析上面，我们需要先了解一些类和接口，这些比较关键，这些都位于java.lang.reflect包中，类图如下：\nreflect包中的一些类Type接口这是一个顶层接口，java中的任何类型都可以用这个来表示，这个接口是Java编程语言中所有类型的公共超接口。这些类型包括原始类型、泛型类型、泛型变量类型、通配符类型、泛型数组类型、数组类型等各种类型。\n这个接口代码比较简单，源码：\npackage java.lang.reflect;/** * Type is the common superinterface for all types in the Java * programming language. These include raw types, parameterized types, * array types, type variables and primitive types. * * @since 1.5 */public interface Type &#123;    /**     * Returns a string describing this type, including information     * about any type parameters.     *     * @implSpec The default implementation calls &#123;@code toString&#125;.     *     * @return a string describing this type     * @since 1.8     */    default String getTypeName() &#123;        return toString();    &#125;&#125;\n\ngetTypeName()，用于返回具体类型的名称，是一个默认方法，默认会调用当前类的toString方法，实现类也可以对这个方法重写。\n\nGenericDeclaration接口所有声明泛型变量的公共接口，这个接口中定义了一个方法：\npackage java.lang.reflect;/** * A common interface for all entities that declare type variables. * * @since 1.5 */public interface GenericDeclaration extends AnnotatedElement &#123;    /**     * Returns an array of &#123;@code TypeVariable&#125; objects that     * represent the type variables declared by the generic     * declaration represented by this &#123;@code GenericDeclaration&#125;     * object, in declaration order.  Returns an array of length 0 if     * the underlying generic declaration declares no type variables.     *     * @return an array of &#123;@code TypeVariable&#125; objects that represent     *     the type variables declared by this generic declaration     * @throws GenericSignatureFormatError if the generic     *     signature of this generic declaration does not conform to     *     the format specified in     *     &lt;cite&gt;The Java&amp;trade; Virtual Machine Specification&lt;/cite&gt;     */    public TypeVariable&lt;?&gt;[] getTypeParameters();&#125;\n\n\ngetTypeParameters(),这个方法用于获取声明的泛型变量类型清单。\n泛型变量可以在类和方法中进行声明，从上面类图中也可以看出来，java中任何类可以使用Class对象表示，方法可以用Method类表示，类图中可以知，Class类和Method类实现了GenericDeclaration接口，所以可以调用他们的getTypeParameters方法获取其声明的泛型参数列表。\n\npublic class Demo1&lt;T1, T2 extends Integer, T3 extends Demo1I1 &amp; Demo1I2&gt;\n\n上面代码表示Demo1这个类中声明了3个泛型变量类型：T1、T2、T3，所以如果去调用这个类的Clas对象中的getTypeParameters方法可以获取到这三个泛型变量的信息。\n\npublic &lt;T1, T2 extends Integer, T3 extends Demo2I1 &amp; Demo2I2&gt; T3 m1(T1 t1, T2 t2, T3 t3, String s) &#123;    return t3;&#125;\n\n上面m1方法中声明了三个泛型类型变量：T1、T2、T3；java中可以方法的任何信息都可以通过Method对象来获取，Mehod类实现了GenericDeclaration接口，所以Method类中实现了GenericDeclaration接口中的getTypeParameters方法，调用这个方法就可以获取m1方法中3个泛型变量类型的信息。\n\nClass类Class类的对象表示JVM中一个类或者接口，每个java对象被加载到jvm中都会表现为一个Class类型的对象，java中的数组也被映射为Class对象，所有元素类型相同且维数相同的数组都共享一个class对象，通过Class对象可以获取类或者接口中的任何信息，比如：类名、类中声明的泛型信息、类的修饰符、类的父类信息、类的接口信息、类中的任何方法信息、类中任何字段信息等等。\n\nClass对象获取方式在程序中我们可以通过3中方式获取Class对象：1.类名.class2.对象.getClass()3.Class.forName(&quot;类或者接口的完整名称&quot;)\n\n常用的方法:\nField[] getFields()这个方法会返回当前类的以及其所有父类、父类的父类中所有public类型的字段。\n\nField[] getDeclaredFields()这个方法会返回当前类中所有字段（和修饰符无关），也就说不管这个字段是public还是private或者是protected，都会返回，有一点需要注意，只返回自己内部定义的字段，不包含其父类中的，这点需要注意，和getFields是有区别的。\n\nMethod[] getMethods()这个方法会返回当前类的以及其所有父类的、父类的父类的、自己实现的接口、父接口继承的接口中的所有public类型的方法，需要注意一下，接口中的方法默认都是public类型的，接口中的方法public修饰符是可以省略的。\n\nMethod[] getDeclaredMethods()返回当前类中定义的所有方法，不管这个方法修饰符是什么类型的，注意只包含自己内部定义的方法，不包含当前类的父类或者其实现的接口中定义的。\n\nType getGenericSuperclass()返回父类的类型信息，如果父类是泛型类型，会返回超类中泛型的详细信息，这个方法比较关键，后面会有详细案例。\n\nTypeVariable&lt;Class&gt;[] getTypeParameters()Class类继承了java.lang.reflect.GenericDeclaration接口，上面这个方法是在GenericDeclaration接口中定义的，Class类中实现了这个接口，用于返回当前类中声明的泛型变量参数列表。\n\n\nMethod类这个类用来表示java中的任何一个方法，通过这个类可以获取java中方法的任何信息，比如：方法的修饰符、方法名称、方法的参数、方法返回值、方法中声明的泛型参数列表等方法的一切信息。\n常用的方法\nString getName()用来获取方法的名称。\n\nType[] getGenericParameterTypes()返回方法的参数信息，如果参数是泛型类型的，会返回泛型的详细信息，这个方法后面会演示。\n\nType getGenericReturnType()返回方法的返回值类型，如果返回值是泛型的，会包含泛型的详细信息。\n\nTypeVariable[] getTypeParameters()Method类继承了java.lang.reflect.GenericDeclaration接口，上面这个方法是在GenericDeclaration接口中定义的，Method类中实现了这个接口，用于返回当前方法中声明的泛型变量参数列表。\n\n\nField类这个类用来表示java中的字段，通过这个类可以获取java中字段的任何信息，比如：字段的修饰符、字段名称、字段类型、泛型字段的类型等字段的一切信息。\n常用的方法\nString getName()获取字段的名称。\n\nClass&lt;?&gt; getType()获取字段类型所属的Class对象。\n\nType getGenericType()获取字段的类型，如果字段是泛型类型的，会返回泛型类型的详细信息；如果字段不是泛型类型的，和getType返回的结果是一样的。\n\nClass&lt;?&gt; getDeclaringClass()获取这个字段是在哪个类中声明的，也就是当前字段所属的类。\n\n\nParameterizedType接口这个接口表示参数化类型，例如List、Map&lt;Integer,String&gt;、UserMapper这种带有泛型的类型。\n常用方法\nType[] getActualTypeArguments()获取泛型类型中的类型列表，就是&lt;&gt;中包含的参数列表，如：List泛型类型列表只有一个是String，而Map&lt;Integer,String&gt;泛型类型中包含2个类型：Integer和String，UserMapper泛型类型为UserModel，实际上就是&lt;和&gt;中间包含的类型列表。\n\nType getRawType()返回参数化类型中的原始类型，比如：List的原始类型为List，UserMapper原始类型为UserMapper，也就是&lt;符号前面的部分。\n\nType[]  getOwnerType()\n返回当前类型所属的类型。例如存在A&lt;T&gt;类，其中定义了内部类InnerA&lt;I&gt;, 则InnerA&lt;I&gt;所属的类型为A&lt;I&gt;，如果是顶层类型则返回null。这种关系比较常见的示例是Map&lt;K,V&gt;接口与Map.Entry&lt;K,V&gt;接口，Map&lt;K,V&gt;接口是Map.Entry&lt;K,V&gt;接口的所有者。\n\nTypeVariable接口这个接口表示的是泛型变量，例如：List中的T就是类型变量；而class C1&lt;T1,T2,T3&gt;{}表示一个类，这个类中定义了3个泛型变量类型，分别是T1、T2和T2，泛型变量在java中使用TypeVariable接口来表示，可以通过这个接口提供的方法获取泛型变量类型的详细信息。\n常用的方法\nType[] getBounds()获取泛型变量类型的上边界，如果未明确什么上边界默认为Object。例如：class Test中K的上边界只有一个，是Person；而class Test&lt;T extend List &amp; Iterable&gt;中T的上边界有2个，是List和Iterable\n\nD getGenericDeclaration()获取声明该泛型变量的原始类型，例如：class Test中的K为泛型变量，这个泛型变量时Test类定义的时候声明的，说明如果调用getGenericDeclaration方法返回的就是Test对应的Class对象。\n\n\n还有方法中也可以定义泛型类型的变量，如果在方法中定义，那么上面这个方法返回的就是定义泛型变量的方法了，返回的就是Method对象。\n\nString getName()获取在源码中定义时的名字，如：class Test就是K；class Test1中就是T。\n\nWildcardType接口表示的是通配符泛型，通配符使用问号表示，例如：? extends Number和? super Integer。\n接口中定义了2个方法。\n\nType[] getUpperBounds()返回泛型变量的上边界列表。\n\nType[] getLowerBounds()返回泛型变量的下边界列表。\n\n\nGenericArrayType接口表示的是数组类型，且数组中的元素是ParameterizedType或者TypeVariable。\n例如：List[]或者T[]。\n这个接口只有一个方法：\n\nType getGenericComponentType()这个方法返回数组的组成元素。\n\n类中定义泛型变量语法:\nclass 类名&lt;泛型变量1,泛型变量2,泛型变量3 extends 上边界1,泛型变量4 extends 上边界类型1 &amp; 上边界类型2 &amp; 上边界类型3&gt;\n\n泛型变量需要在类名后面的括号中定义\n\n每个类中可以定义多个泛型变量，多个泛型变量之间用逗号隔开\n\n泛型变量可以通过extends关键字指定上边界，上边界可以对泛型变量起到了限定的作用，上边界可以指定0到多个，多个之间需要用&amp;符号隔开，如果不指定上边界，默认上边界为Object类型\n\n\n示例代码:\npackage h.xd.type;import java.lang.reflect.Type;import java.lang.reflect.TypeVariable;public class DemoClass&lt;T1, T2 extends Integer, T3 extends DemoClass1 &amp; DemoClass2&gt; &#123;    public static void main(String[] args) &#123;        //获取类的类型参数列表        TypeVariable&lt;Class&lt;DemoClass&gt;&gt;[] typeParameters = DemoClass.class.getTypeParameters();        for (TypeVariable&lt;Class&lt;DemoClass&gt;&gt; typeParameter : typeParameters) &#123;            System.out.println(&quot;变量名称:&quot; + typeParameter.getName());            System.out.println(&quot;这个变量在哪声明的:&quot; + typeParameter.getGenericDeclaration());            Type[] bounds = typeParameter.getBounds();            System.out.println(&quot;这个变量上边界数量:&quot; + bounds.length);            System.out.println(&quot;这个变量上边界清单:&quot;);            for (Type bound : bounds) &#123;                System.out.println(bound.getTypeName());            &#125;            System.out.println(&quot;--------------------&quot;);        &#125;    &#125;&#125;interface DemoClass1&#123;&#125;interface DemoClass2&#123;&#125;\n\n运行结果:\n变量名称:T1这个变量在哪声明的:class h.xd.type.DemoClass这个变量上边界数量:1这个变量上边界清单:java.lang.Object--------------------变量名称:T2这个变量在哪声明的:class h.xd.type.DemoClass这个变量上边界数量:1这个变量上边界清单:java.lang.Integer--------------------变量名称:T3这个变量在哪声明的:class h.xd.type.DemoClass这个变量上边界数量:2这个变量上边界清单:h.xd.type.DemoClass1h.xd.type.DemoClass2--------------------\n\n\n方法中定义泛型变量语法:\n方法修饰符 &lt;泛型变量1,泛型变量2,泛型变量3 extends 上边界1,泛型变量4 extends 上边界类型1 &amp; 上边界类型2 &amp; 上边界类型3&gt; 方法名称(参数1类型 参数1名称,参数2类型 参数2名称)\n\n示例代码:\npackage h.xd.type;import java.lang.reflect.Method;import java.lang.reflect.Type;import java.lang.reflect.TypeVariable;interface DemoFunction1 &#123;&#125;interface DemoFunction2 &#123;&#125;/** * 泛型方法中的泛型变量 */public class DemoFunction &#123;    public &lt;T1, T2 extends Integer, T3 extends DemoFunction1 &amp; DemoFunction2&gt; T3 m1(T1 t1, T2 t2, T3 t3, String s) &#123;        return t3;    &#125;    public static void main(String[] args) &#123;        //获取DemoFunction中声明的所有方法        Method[] methods = DemoFunction.class.getDeclaredMethods();        Method m1 = null;        //找到m1方法        for (Method method : methods) &#123;            if (method.getName().equals(&quot;m1&quot;)) &#123;                m1 = method;                break;            &#125;        &#125;        //获取方法的泛型参数列表        System.out.println(&quot;m1方法参数类型列表信息:----------&quot;);        Type[] genericParameterTypes = m1.getGenericParameterTypes();        for (Type genericParameterType : genericParameterTypes) &#123;            //3个参数都是泛型变量类型的，对应java中的TypeVariable            if (genericParameterType instanceof TypeVariable) &#123;                TypeVariable pt = (TypeVariable) genericParameterType;                System.out.println(&quot;变量类型名称:&quot; + pt.getTypeName());                System.out.println(&quot;变量名称:&quot; + pt.getName());                System.out.println(&quot;这个变量在哪声明的:&quot; + pt.getGenericDeclaration());                Type[] bounds = pt.getBounds();                System.out.println(&quot;这个变量上边界数量:&quot; + bounds.length);                System.out.println(&quot;这个变量上边界清单:&quot;);                for (Type bound : bounds) &#123;                    System.out.println(bound.getTypeName());                &#125;            &#125; else if (genericParameterType instanceof Class) &#123;                Class pt = (Class) genericParameterType;                System.out.println(&quot;参数类型名称:&quot; + pt.getTypeName());                System.out.println(&quot;参数类名:&quot; + pt.getName());            &#125;            System.out.println(&quot;--------------------&quot;);        &#125;        //获取方法的返回值，也是一个泛型变量        System.out.println(&quot;m1方法返回值类型信息:----------&quot;);        Type genericReturnType = m1.getGenericReturnType();        if (genericReturnType instanceof TypeVariable) &#123;            TypeVariable pt = (TypeVariable) genericReturnType;            System.out.println(&quot;变量名称:&quot; + pt.getName());            System.out.println(&quot;这个变量在哪声明的:&quot; + pt.getGenericDeclaration());            Type[] bounds = pt.getBounds();            System.out.println(&quot;这个变量上边界数量:&quot; + bounds.length);            System.out.println(&quot;这个变量上边界清单:&quot;);            for (Type bound : bounds) &#123;                System.out.println(bound.getTypeName());            &#125;            System.out.println(&quot;--------------------&quot;);        &#125;        //获取方法中声明的泛型参数列表        System.out.println(&quot;m1方法中声明的泛型变量类型列表:----------&quot;);        TypeVariable&lt;Method&gt;[] typeParameters = m1.getTypeParameters();        for (TypeVariable&lt;Method&gt; pt : typeParameters) &#123;            System.out.println(&quot;变量类型名称:&quot; + pt.getTypeName());            System.out.println(&quot;变量名称:&quot; + pt.getName());            System.out.println(&quot;这个变量在哪声明的:&quot; + pt.getGenericDeclaration());            Type[] bounds = pt.getBounds();            System.out.println(&quot;这个变量上边界数量:&quot; + bounds.length);            System.out.println(&quot;这个变量上边界清单:&quot;);            for (Type bound : bounds) &#123;                System.out.println(bound.getTypeName());            &#125;            System.out.println(&quot;--------------------&quot;);        &#125;    &#125;&#125;\n\n运行结果:\nm1方法参数类型列表信息:----------变量类型名称:T1变量名称:T1这个变量在哪声明的:public h.xd.type.DemoFunction1 h.xd.type.DemoFunction.m1(java.lang.Object,java.lang.Integer,h.xd.type.DemoFunction1,java.lang.String)这个变量上边界数量:1这个变量上边界清单:java.lang.Object--------------------变量类型名称:T2变量名称:T2这个变量在哪声明的:public h.xd.type.DemoFunction1 h.xd.type.DemoFunction.m1(java.lang.Object,java.lang.Integer,h.xd.type.DemoFunction1,java.lang.String)这个变量上边界数量:1这个变量上边界清单:java.lang.Integer--------------------变量类型名称:T3变量名称:T3这个变量在哪声明的:public h.xd.type.DemoFunction1 h.xd.type.DemoFunction.m1(java.lang.Object,java.lang.Integer,h.xd.type.DemoFunction1,java.lang.String)这个变量上边界数量:2这个变量上边界清单:h.xd.type.DemoFunction1h.xd.type.DemoFunction2--------------------参数类型名称:java.lang.String参数类名:java.lang.String--------------------m1方法返回值类型信息:----------变量名称:T3这个变量在哪声明的:public h.xd.type.DemoFunction1 h.xd.type.DemoFunction.m1(java.lang.Object,java.lang.Integer,h.xd.type.DemoFunction1,java.lang.String)这个变量上边界数量:2这个变量上边界清单:h.xd.type.DemoFunction1h.xd.type.DemoFunction2--------------------m1方法中声明的泛型变量类型列表:----------变量类型名称:T1变量名称:T1这个变量在哪声明的:public h.xd.type.DemoFunction1 h.xd.type.DemoFunction.m1(java.lang.Object,java.lang.Integer,h.xd.type.DemoFunction1,java.lang.String)这个变量上边界数量:1这个变量上边界清单:java.lang.Object--------------------变量类型名称:T2变量名称:T2这个变量在哪声明的:public h.xd.type.DemoFunction1 h.xd.type.DemoFunction.m1(java.lang.Object,java.lang.Integer,h.xd.type.DemoFunction1,java.lang.String)这个变量上边界数量:1这个变量上边界清单:java.lang.Integer--------------------变量类型名称:T3变量名称:T3这个变量在哪声明的:public h.xd.type.DemoFunction1 h.xd.type.DemoFunction.m1(java.lang.Object,java.lang.Integer,h.xd.type.DemoFunction1,java.lang.String)这个变量上边界数量:2这个变量上边界清单:h.xd.type.DemoFunction1h.xd.type.DemoFunction2--------------------\n\n通配符类型通配符在java中 使用?表示，例如：? extends Number和? super Integer。\njava中通配符对应的类型是WildcardType接口，可以通过这个接口来获取通配符具体的各种信息。\n\n通配符上边界通配符具体的类型，可以任意指定，但是我们可以限定通配符的上边界，上边界指定了这个通配符能够表示的最大的范围的类型。\n\n\n比如：？extends Integer，那么?对应的具体类型只能是Integer本身或者其子类型。\n\n\n通配符下边界也可以给通配符指定下边界，下边界定义了通配符能够表示的最小的类型。\n\n\n比如：? super C1，那么?对应的具体类型只能是C1类型或者C1的父类型。\n\npackage h.xd.type;import java.lang.reflect.Method;import java.lang.reflect.ParameterizedType;import java.lang.reflect.Type;import java.lang.reflect.WildcardType;import java.util.List;import java.util.Map;public class DemoWild &#123;    public static class C1 &#123;    &#125;    public static class C2 extends C1 &#123;    &#125;    public static List&lt;?&gt; m1(Map&lt;? super C2, ? extends C1&gt; map) &#123;        return null;    &#125;    public static void main(String[] args) throws NoSuchMethodException &#123;        Method m1 = DemoWild.class.getMethod(&quot;m1&quot;, Map.class);        //获取m1方法参数泛型详细参数信息        System.out.println(&quot;获取m1方法参数泛型详细参数信息&quot;);        Type[] genericParameterTypes = m1.getGenericParameterTypes();        for (Type genericParameterType : genericParameterTypes) &#123;            // m1的参数为Map&lt;? super C2, ? extends C1&gt;，这个是泛型类型的，所以是ParameterizedType接口类型            if (genericParameterType instanceof ParameterizedType) &#123;                ParameterizedType parameterizedType = (ParameterizedType) genericParameterType;                //下面获取Map后面两个尖括号中的泛型参数列表，对应? super C2, ? extends C1这部分的内容，这部分在java中对应WildcardType接口类型                Type[] actualTypeArguments = parameterizedType.getActualTypeArguments();                for (Type actualTypeArgument : actualTypeArguments) &#123;                    if (actualTypeArgument instanceof WildcardType) &#123;                        WildcardType wildcardType = (WildcardType) actualTypeArgument;                        //获取通配符的名称，输出是?                        System.out.println(&quot;通配符类型名称:&quot; + wildcardType.getTypeName());                        //获取通配符的上边界                        Type[] upperBounds = wildcardType.getUpperBounds();                        for (Type upperBound : upperBounds) &#123;                            System.out.println(&quot;通配符上边界类型：&quot; + upperBound.getTypeName());                        &#125;                        //获取通配符的下边界                        Type[] lowerBounds = wildcardType.getLowerBounds();                        for (Type lowerBound : lowerBounds) &#123;                            System.out.println(&quot;通配符下边界类型:&quot; + lowerBound.getTypeName());                        &#125;                        System.out.println(&quot;------------&quot;);                    &#125;                &#125;            &#125;        &#125;        //获取返回值通配符详细信息        System.out.println(&quot;获取m1方法返回值泛型类型详细信息&quot;);        Type genericReturnType = m1.getGenericReturnType();        // m1的返回值是List&lt;?&gt;，这个是个泛型类型，对应ParameterizedType接口，泛型中的具体类型是个通配符类型，通配符对应WildcardType接口类型        if (genericReturnType instanceof ParameterizedType) &#123;             ParameterizedType parameterizedType = (ParameterizedType) genericReturnType;            //下面获取List面两个尖括号中的泛型参数列表，对应?这部分的内容，这个是个通配符类型，这部分在java中对应WildcardType接口            Type[] actualTypeArguments = parameterizedType.getActualTypeArguments();            for (Type actualTypeArgument : actualTypeArguments) &#123;                if (actualTypeArgument instanceof WildcardType) &#123;                    WildcardType wildcardType = (WildcardType) actualTypeArgument;                    //获取通配符的名称，输出是?                    System.out.println(&quot;通配符类型名称:&quot; + wildcardType.getTypeName());                    //获取通配符的上边界                    Type[] upperBounds = wildcardType.getUpperBounds();                    for (Type upperBound : upperBounds) &#123;                        System.out.println(&quot;通配符上边界类型：&quot; + upperBound.getTypeName());                    &#125;                    //获取通配符的下边界                    Type[] lowerBounds = wildcardType.getLowerBounds();                    for (Type lowerBound : lowerBounds) &#123;                        System.out.println(&quot;通配符下边界类型:&quot; + lowerBound.getTypeName());                    &#125;                    System.out.println(&quot;------------&quot;);                &#125;            &#125;        &#125;    &#125;&#125;\n\n运行结果:\n获取m1方法参数泛型详细参数信息通配符类型名称:? super h.xd.type.DemoWild$C2通配符上边界类型：java.lang.Object通配符下边界类型:h.xd.type.DemoWild$C2------------通配符类型名称:? extends h.xd.type.DemoWild$C1通配符上边界类型：h.xd.type.DemoWild$C1------------获取m1方法返回值泛型类型详细信息通配符类型名称:?通配符上边界类型：java.lang.Object------------\n\n泛型数组数组中的元素为泛型，那么这个数组就是泛型类型的数组，泛型数组在java中使用GenericArrayType接口来表示，可以通过这个接口提供的方法获取泛型数组更详细的信息。\n如：List list []; List list [][];\n泛型数组类型的可以作为方法的参数、方法的返回值、泛型类的具体类型、字段的类型等等。\n示例代码:\npackage h.xd.type;import java.lang.reflect.Field;import java.lang.reflect.GenericArrayType;import java.lang.reflect.ParameterizedType;import java.lang.reflect.Type;import java.util.List;public class DemoList &#123;    List&lt;String&gt; list[];    public static void main(String[] args) throws NoSuchFieldException &#123;        Field list = DemoList.class.getDeclaredField(&quot;list&quot;);        //获取字段的泛型类型        Type genericType = list.getGenericType();        //看看字段的具体泛型类型        System.out.println(genericType.getClass());        if (genericType instanceof GenericArrayType) &#123;            GenericArrayType genericArrayType = (GenericArrayType) genericType;            //获取数组的具体类型，具体的类型就是List&lt;String&gt;，这个是个泛型类型，对应java中的ParameterizedType接口            Type genericComponentType = genericArrayType.getGenericComponentType();            System.out.println(genericComponentType.getClass());            if (genericComponentType instanceof ParameterizedType) &#123;                ParameterizedType parameterizedType = (ParameterizedType) genericComponentType;                System.out.println(parameterizedType.getRawType());                //调用getActualTypeArguments()获取List&lt;String&gt;中尖括号中的参数列表                Type[] actualTypeArguments = parameterizedType.getActualTypeArguments();                for (Type actualTypeArgument : actualTypeArguments) &#123;                    System.out.println(actualTypeArgument.getTypeName());                &#125;                System.out.println(parameterizedType.getOwnerType());            &#125;        &#125;    &#125;&#125;\n\n运行结果:\nclass sun.reflect.generics.reflectiveObjects.GenericArrayTypeImplclass sun.reflect.generics.reflectiveObjects.ParameterizedTypeImplinterface java.util.Listjava.lang.Stringnull\n\n综合案例返回结果封装:\n/** * 通用返回结果封装类 * Created by macro on 2019/4/19. */public class CommonResult&lt;T&gt; &#123;    /**     * 状态码     */    private long code;    /**     * 提示信息     */    private String message;    /**     * 数据封装     */    private T data;    protected CommonResult() &#123;    &#125;    protected CommonResult(long code, String message, T data) &#123;        this.code = code;        this.message = message;        this.data = data;    &#125;    /**     * 成功返回结果     *     * @param data 获取的数据     */    public static &lt;T&gt; CommonResult&lt;T&gt; success(T data) &#123;        return new CommonResult&lt;T&gt;(ResultCode.SUCCESS.getCode(), ResultCode.SUCCESS.getMessage(), data);    &#125;    /**     * 成功返回结果     *     * @param data 获取的数据     * @param  message 提示信息     */    public static &lt;T&gt; CommonResult&lt;T&gt; success(T data, String message) &#123;        return new CommonResult&lt;T&gt;(ResultCode.SUCCESS.getCode(), message, data);    &#125;    /**     * 失败返回结果     * @param errorCode 错误码     */    public static &lt;T&gt; CommonResult&lt;T&gt; failed(IErrorCode errorCode) &#123;        return new CommonResult&lt;T&gt;(errorCode.getCode(), errorCode.getMessage(), null);    &#125;    /**     * 失败返回结果     * @param errorCode 错误码     * @param message 错误信息     */    public static &lt;T&gt; CommonResult&lt;T&gt; failed(IErrorCode errorCode,String message) &#123;        return new CommonResult&lt;T&gt;(errorCode.getCode(), message, null);    &#125;    /**     * 失败返回结果     * @param message 提示信息     */    public static &lt;T&gt; CommonResult&lt;T&gt; failed(String message) &#123;        return new CommonResult&lt;T&gt;(ResultCode.FAILED.getCode(), message, null);    &#125;    /**     * 失败返回结果     */    public static &lt;T&gt; CommonResult&lt;T&gt; failed() &#123;        return failed(ResultCode.FAILED);    &#125;    /**     * 参数验证失败返回结果     */    public static &lt;T&gt; CommonResult&lt;T&gt; validateFailed() &#123;        return failed(ResultCode.VALIDATE_FAILED);    &#125;    /**     * 参数验证失败返回结果     * @param message 提示信息     */    public static &lt;T&gt; CommonResult&lt;T&gt; validateFailed(String message) &#123;        return new CommonResult&lt;T&gt;(ResultCode.VALIDATE_FAILED.getCode(), message, null);    &#125;    /**     * 未登录返回结果     */    public static &lt;T&gt; CommonResult&lt;T&gt; unauthorized(T data) &#123;        return new CommonResult&lt;T&gt;(ResultCode.UNAUTHORIZED.getCode(), ResultCode.UNAUTHORIZED.getMessage(), data);    &#125;    /**     * 未授权返回结果     */    public static &lt;T&gt; CommonResult&lt;T&gt; forbidden(T data) &#123;        return new CommonResult&lt;T&gt;(ResultCode.FORBIDDEN.getCode(), ResultCode.FORBIDDEN.getMessage(), data);    &#125;    public long getCode() &#123;        return code;    &#125;    public void setCode(long code) &#123;        this.code = code;    &#125;    public String getMessage() &#123;        return message;    &#125;    public void setMessage(String message) &#123;        this.message = message;    &#125;    public T getData() &#123;        return data;    &#125;    public void setData(T data) &#123;        this.data = data;    &#125;&#125;","categories":["总结笔记"],"tags":["Java","泛型"]},{"title":"Java单例总结","url":"/2022_04_12_java_singleton/","content":"单例模式（Singleton Pattern）是指确保一个类在任何情况下都绝对只有一个实例，并提供一个全局的访问点。\n隐藏其所有的构造方法。\n属于创建型模式。\n单例模式的适用场景确保任何情况下都绝对只有一个实例。\nServletContext、ServletConfig、ApplicationContext、DBPool\n饿汉式package h.xd.java;import java.lang.reflect.Constructor;import java.util.concurrent.TimeUnit;/** * 优点：执行效率高，性能高，没有任何的锁 * 缺点：可能会造成内存浪费、反射单例失效、序列化失效 */public class HungrySingleton &#123;    //static 类加载的时候就创建，final：不可被覆盖。    private static final HungrySingleton hungrysingleton = new HungrySingleton();    private HungrySingleton()&#123;&#125;;    public static HungrySingleton getInstance()&#123;        return hungrysingleton;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        for (int i = 0; i &lt; 20; i++) &#123;            //多线程实例化            new Thread(()-&gt;&#123;                System.out.println(HungrySingleton.getInstance());            &#125;).start();            //多线程反射实例化            new Thread(()-&gt;&#123;                try &#123;                    Constructor&lt;HungrySingleton&gt; declaredConstructor = HungrySingleton.class.getDeclaredConstructor();                    HungrySingleton hungrySingleton = declaredConstructor.newInstance();                    System.out.println(hungrySingleton);                &#125; catch (Exception e) &#123;                    e.printStackTrace();                &#125;            &#125;).start();        &#125;        TimeUnit.SECONDS.sleep(2);    &#125;&#125;\n\n懒汉式package h.xd.java;import java.lang.reflect.Constructor;import java.util.concurrent.TimeUnit;/** * 优点：节约了内存 * 缺点：线程不安全,synchronized性能低， 存在锁等待，反射锁失效、序列化失效 */public class LazySimpleSingleton &#123;    private static LazySimpleSingleton instance;    private LazySimpleSingleton()&#123;&#125;    public static synchronized LazySimpleSingleton getInstance()&#123;        if(instance == null)&#123;            instance = new LazySimpleSingleton();        &#125;        return instance;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        for (int i = 0; i &lt; 20; i++) &#123;            //多线程实例化            new Thread(()-&gt;&#123;                System.out.println(LazySimpleSingleton.getInstance());            &#125;).start();            //多线程反射实例化            new Thread(()-&gt;&#123;                try &#123;                    Constructor&lt;LazySimpleSingleton&gt; declaredConstructor = LazySimpleSingleton.class.getDeclaredConstructor();                    LazySimpleSingleton lazySimpleSingleton = declaredConstructor.newInstance();                    System.out.println(lazySimpleSingleton);                &#125; catch (Exception e) &#123;                    e.printStackTrace();                &#125;            &#125;).start();        &#125;        TimeUnit.SECONDS.sleep(2);    &#125;&#125;\n\n双重校验懒汉式package h.xd.java;import java.lang.reflect.Constructor;import java.util.concurrent.TimeUnit;/** * 双重检查：1、检查是否要阻塞；2、检查是否创建实例。 * 优点：安全且在多线程情况下能保持高性能, * 第一个if判断避免了其他无用线程竞争锁来造成性能浪费， * 第二个if判断能拦截除第一个获得对象锁线程以外的线程。 * 缺点：但是可读性不高，代码不够优雅，反射失效 */public class LazyDoubleCheckSingleton &#123;    //volatile:解决了指令重排序问题（指令执行顺序不一定按代码来执行）。    private volatile static LazyDoubleCheckSingleton instance;    //私有化防实例化    private LazyDoubleCheckSingleton()&#123;&#125;    public static LazyDoubleCheckSingleton getInstance()&#123;        //检查是否需要阻塞        if(instance == null)&#123;            synchronized (LazyDoubleCheckSingleton.class)&#123;                //检查是否需要重新创建实例                if(instance == null)&#123;                    instance = new LazyDoubleCheckSingleton();                    //指令重排序问题                &#125;            &#125;        &#125;        return instance;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        for (int i = 0; i &lt; 20; i++) &#123;            //多线程实例化            new Thread(()-&gt;&#123;                System.out.println(LazyDoubleCheckSingleton.getInstance());            &#125;).start();            //多线程反射实例化            new Thread(()-&gt;&#123;                try &#123;                    Constructor&lt;LazyDoubleCheckSingleton&gt; declaredConstructor = LazyDoubleCheckSingleton.class.getDeclaredConstructor();                    LazyDoubleCheckSingleton lazyDoubleCheckSingleton = declaredConstructor.newInstance();                    System.out.println(lazyDoubleCheckSingleton);                &#125; catch (Exception e) &#123;                    e.printStackTrace();                &#125;            &#125;).start();        &#125;        TimeUnit.SECONDS.sleep(2);    &#125;&#125;\n\n双重校验懒汉防反射package h.xd.java;import java.lang.reflect.Constructor;import java.util.concurrent.TimeUnit;/** * 双重检查：1、检查是否要阻塞；2、检查是否创建实例。 * 优点：安全且在多线程情况下能保持高性能, * 第一个if判断避免了其他无用线程竞争锁来造成性能浪费， * 第二个if判断能拦截除第一个获得对象锁线程以外的线程。 * 一定程度上解决了反射问题，反射会报错 * 缺点：但是可读性不高，代码不够优雅 */public class LazyDoubleCheckSingleton2 &#123;    //volatile:解决了指令重排序问题（指令执行顺序不一定按代码来执行）。    private volatile static LazyDoubleCheckSingleton2 instance;    //私有化防实例化    private LazyDoubleCheckSingleton2()&#123;        if(LazyDoubleCheckSingleton2.instance != null )&#123;            throw new RuntimeException(&quot;不允许非法的访问&quot;);        &#125;    &#125;    public static LazyDoubleCheckSingleton2 getInstance()&#123;        //检查是否需要阻塞        if(instance == null)&#123;            synchronized (LazyDoubleCheckSingleton2.class)&#123;                //检查是否需要重新创建实例                if(instance == null)&#123;                    instance = new LazyDoubleCheckSingleton2();                    //指令重排序问题                &#125;            &#125;        &#125;        return instance;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        for (int i = 0; i &lt; 20; i++) &#123;            //多线程实例化            new Thread(()-&gt;&#123;                System.out.println(LazyDoubleCheckSingleton2.getInstance());            &#125;).start();            //多线程反射实例化            new Thread(()-&gt;&#123;                try &#123;                    Constructor&lt;LazyDoubleCheckSingleton2&gt; declaredConstructor = LazyDoubleCheckSingleton2.class.getDeclaredConstructor();                    LazyDoubleCheckSingleton2 lazyDoubleCheckSingleton2 = declaredConstructor.newInstance();                    System.out.println(lazyDoubleCheckSingleton2);                &#125; catch (Exception e) &#123;                    e.printStackTrace();                &#125;            &#125;).start();        &#125;        TimeUnit.SECONDS.sleep(2);    &#125;&#125;\n\n\n枚举单例package h.xd.java;import java.lang.reflect.Constructor;import java.util.concurrent.TimeUnit;/** * INSTANCE，是单例模式的唯一实例。 * increment,getCount方法永远是一个实例的方法，（方法内部线程不安全，方法是一个） * * 优点： * 使用枚举实现单例模式是线程安全的。 * 在多线程环境中，多个线程可以同时访问单例对象，但是由于枚举的特殊性质，只有一个实例对象被创建，所以不会出现线程安全问题。 * * 使用枚举实现单例模式可以避免序列化和反序列化的问题。 * 在 Java 中，当一个类被序列化并在另一个 JVM 中反序列化时，它会创建一个新的对象。 * 如果使用枚举实现单例模式，则不需要担心这个问题，因为枚举实例是在加载枚举类型时由 JVM 创建的，并且它们是全局可访问的，因此不会出现创建多个实例的情况。 * * 使用枚举实现单例模式可以防止反射攻击。 * 在 Java 中，反射机制可以通过 Class 类来获取对象的构造函数并创建新的对象。 * 如果使用枚举实现单例模式，则可以避免这种攻击，因为枚举类型的构造函数是私有的，不能通过反射来调用。 * * 使用枚举实现单例模式可以使代码更加简洁明了。 * 枚举类型本身就是单例的，因此不需要编写任何特殊的代码来实现单例模式。 * 并且具有有意义的名称和明确定义的值，这可以减少代码量和提高代码的可读性。 * * 缺点：非延时加载 */public enum EnumSingleton &#123;    INSTANCE;    private int count = 0;    public void increment()&#123;        count++;    &#125;    public int getCount()&#123;        return count;    &#125;    public static EnumSingleton getInstance()&#123;        return INSTANCE;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        EnumSingleton.getInstance().increment();        EnumSingleton.getInstance().increment();        for (int i = 0; i &lt; 20; i++) &#123;            //多线程实例化            new Thread(()-&gt;&#123;                System.out.println(EnumSingleton.getInstance().getCount());            &#125;).start();            //多线程反射实例化            new Thread(()-&gt;&#123;                try &#123;                    Constructor&lt;EnumSingleton&gt; declaredConstructor = EnumSingleton.class.getDeclaredConstructor();                    EnumSingleton enumSingleton = declaredConstructor.newInstance();                    System.out.println(enumSingleton.getCount());                &#125; catch (Exception e) &#123;                    e.printStackTrace();                &#125;            &#125;).start();        &#125;        TimeUnit.SECONDS.sleep(2);    &#125;&#125;\n\n内部类单例package h.xd.java;import java.lang.reflect.Constructor;import java.util.concurrent.TimeUnit;/** * 利用了classloader机制来保证初始化 instance 时只有一个线程，线程安全； * 只有通过显式调用 getInstance 方法时，才会显式装载静态内部类，从而实例化instance，延迟加载。 * * 缺点： 反射失效 * */public class InnerSingleton &#123;    private InnerSingleton()&#123;&#125;    private static class SingletonHolder&#123;        private static final InnerSingleton INSTANCE = new InnerSingleton();    &#125;    public static InnerSingleton getInstance()&#123;        return SingletonHolder.INSTANCE;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        for (int i = 0; i &lt; 20; i++) &#123;            //多线程实例化            new Thread(()-&gt;&#123;                System.out.println(InnerSingleton.getInstance());            &#125;).start();            //多线程反射实例化            new Thread(()-&gt;&#123;                try &#123;                    Constructor&lt;InnerSingleton&gt; declaredConstructor = InnerSingleton.class.getDeclaredConstructor();                    InnerSingleton innerSingleton = declaredConstructor.newInstance();                    System.out.println(innerSingleton);                &#125; catch (Exception e) &#123;                    e.printStackTrace();                &#125;            &#125;).start();        &#125;        TimeUnit.SECONDS.sleep(2);    &#125;&#125;\n\n容器思想单例package h.xd.java;import java.lang.reflect.Constructor;import java.util.Map;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.TimeUnit;/** * 容器模型下的单例，利用多线程安全的hashMap  + sync 机制，实现 * 缺点： 反射失效，需要锁 */public class ContainerSingleton &#123;    private ContainerSingleton()&#123;&#125;    private static Map&lt;String,Object&gt; ioc = new ConcurrentHashMap&lt;String, Object&gt;();    public static synchronized Object getInstance(String className)&#123;        Object instance = null;        if(!ioc.containsKey(className))&#123;            try&#123;                instance = Class.forName(className).newInstance();                ioc.put(className,instance);            &#125;catch (Exception e)&#123;                e.printStackTrace();            &#125;            return  instance;        &#125;else &#123;            return ioc.get(className);        &#125;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        for (int i = 0; i &lt; 20; i++) &#123;            //多线程实例化            new Thread(()-&gt;&#123;                System.out.println(ContainerSingleton.getInstance(&quot;h.xd.java.ContainerSingleton&quot;));            &#125;).start();//            多线程反射实例化            new Thread(()-&gt;&#123;                try &#123;                    Constructor&lt;ContainerSingleton&gt; declaredConstructor = ContainerSingleton.class.getDeclaredConstructor();                    ContainerSingleton enumSingleton = declaredConstructor.newInstance();                    System.out.println(enumSingleton);                &#125; catch (Exception e) &#123;                    e.printStackTrace();                &#125;            &#125;).start();        &#125;        TimeUnit.SECONDS.sleep(2);    &#125;&#125;\n\n防序列化单例package h.xd.java;import java.io.*;import java.util.concurrent.TimeUnit;public class SerializableSingleton implements Serializable &#123;    //序列化    //把内存中的对象的状态转化为字节码的形式    //把字节码通过IO输出流，写到磁盘！    //永久的保存下来    public final static  SerializableSingleton INSTANCE = new SerializableSingleton();    private SerializableSingleton()&#123;&#125;    public static SerializableSingleton getInstance()&#123;        return INSTANCE;    &#125;    /**     * 防止序列化，对象重复创建     * @return     */    public Object readResolve()&#123;        return INSTANCE;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        SerializableSingleton instance = SerializableSingleton.getInstance();        FileOutputStream fos = null;        try &#123;            fos = new FileOutputStream(&quot;SerializableSingleton.obj&quot;);            ObjectOutputStream oos = new ObjectOutputStream(fos);            oos.writeObject(instance);            oos.flush();            oos.close();            System.out.println(instance);            for (int i = 0; i &lt; 20; i++) &#123;                //多线程实例化                new Thread(() -&gt; &#123;                    FileInputStream fis = null;                    SerializableSingleton instance1 = null;                    try &#123;                        fis = new FileInputStream(&quot;SerializableSingleton.obj&quot;);                        ObjectInputStream ois = new ObjectInputStream(fis);                        instance1 =(SerializableSingleton) ois.readObject();                        ois.close();                        System.out.println(instance1);                    &#125; catch (Exception e) &#123;                        e.printStackTrace();                    &#125;                &#125;).start();            &#125;            TimeUnit.SECONDS.sleep(2);        &#125;catch (Exception e)&#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\n线程内部只有一个实例的单例package h.xd.java;import java.util.concurrent.TimeUnit;/** * 线程内部，单例， * 缺点：多线程失效、反射失效、序列化失效 */public class ThreadLocalSingleton &#123;    private static final ThreadLocal&lt;ThreadLocalSingleton&gt; INSTANCE =            ThreadLocal.withInitial(ThreadLocalSingleton::new);    private ThreadLocalSingleton()&#123;&#125;    public static ThreadLocalSingleton getInstance()&#123;        return INSTANCE.get();    &#125;    public static void main(String[] args) throws InterruptedException &#123;        for (int i = 0; i &lt; 1; i++) &#123;            //多线程实例化            new Thread(() -&gt; &#123;                System.out.println(ThreadLocalSingleton.getInstance());                System.out.println(ThreadLocalSingleton.getInstance());                System.out.println(ThreadLocalSingleton.getInstance());                System.out.println(ThreadLocalSingleton.getInstance());            &#125;).start();        &#125;        TimeUnit.SECONDS.sleep(2);    &#125;&#125;\n\n单例模式要点\n私有化构造器,防直接实例化\n保证线程安全\n按需选择延迟加载和非延时加载\n防止序列化和反序列化破坏单例\n防御反射攻击单例\n\n","categories":["总结笔记"],"tags":["Java","单例模式"]},{"title":"再次通过行为型模式视角回顾Go","url":"/2022_07_08_go_design_pattern/","content":"行为模式（Behavioral Pattern） 主要关注对象之间的职责分配和通信方式\n行为型模式的核心是思想是通过定义对象之间的交互方式，实现系统功能，降低对象耦合度\n行为型模式-责任链模式避免请求的发送者和接收者之间耦合，将这些对象连成一条链，并沿着链传递请求，知道处理完为止\n例如：Go的Gin框架里面的中间件审批流\n核心思想：\n\n解耦请求发送者和接收者，请求发送者不需要知道具体哪个对象处理请求，只需要将请求发送到链上即可\n动态组合处理逻辑，可以动态地组合处理者，灵活的调整处理顺序或者增加新的处理者\n每个处理者只关系自己的职责\n\npackage chain_of_responsibilityimport (\t&quot;fmt&quot;\t&quot;net/http&quot;)type Context struct &#123;\trequest  *http.Request\tw        http.ResponseWriter\tindex    int\thandlers []HandlerFun&#125;func (c *Context) Next() &#123;\tc.index++\tif len(c.handlers) &gt; c.index &#123;\t\tc.handlers[c.index](c)\t&#125;&#125;func (c *Context) Abort() &#123;\tc.index = len(c.handlers)&#125;type HandlerFun func(ctx *Context)type Engine struct &#123;\thandlers []HandlerFun&#125;func (e *Engine) Use(f HandlerFun) &#123;\te.handlers = append(e.handlers, f)&#125;func (e *Engine) ServeHTTP(w http.ResponseWriter, r *http.Request) &#123;\tcontext := Context&#123;\t\trequest:  r,\t\tw:        w,\t\tindex:    -1,\t\thandlers: e.handlers,\t&#125;\tcontext.Next()&#125;func AuthMiddleware(ctx *Context) &#123;\tfmt.Println(&quot;认证中间件&quot;)&#125;func LogMiddleware(ctx *Context) &#123;\tfmt.Println(&quot;日志中间件&quot;)\tctx.Next()&#125;\n\npackage chain_of_responsibilityimport (\t&quot;fmt&quot;\t&quot;net/http&quot;\t&quot;testing&quot;)func TestHandler(t *testing.T) &#123;\tr := &amp;Engine&#123;&#125;\tr.Use(LogMiddleware)\tr.Use(AuthMiddleware)\tfmt.Println(&quot;web server on : 8080&quot;)\thttp.ListenAndServe(&quot;:8080&quot;, r)&#125;\n\n行为型模式-命令模式将请求封装为一个对象，可以用不同的请求对客户进行参数化，并且支持请求排队，记录日志，撤销操作等功能\n核心思想：\n\n将请求封装为对象\n解耦请求的接收者和发送者\n支持扩展，不修改现有代码\n\n例子：任务队列系统\npackage commandimport &quot;fmt&quot;type Command interface &#123;\tExecute()&#125;type PrintCommand struct &#123;\tContent string&#125;func (p PrintCommand) Execute() &#123;\tfmt.Println(&quot;打印消息&quot;, p.Content)&#125;type SendEmail struct &#123;\tTo      string\tContent string&#125;func (s SendEmail) Execute() &#123;\tfmt.Println(&quot;发送邮件&quot;, s.To, s.Content)&#125;type TaskQueue struct &#123;\tQueue []Command&#125;func NewTaskQueue() *TaskQueue &#123;\treturn &amp;TaskQueue&#123;&#125;&#125;func (tq *TaskQueue) AddCommand(command Command) &#123;\ttq.Queue = append(tq.Queue, command)&#125;func (tq *TaskQueue) Command() &#123;\tfor _, command := range tq.Queue &#123;\t\tcommand.Execute()\t&#125;&#125;\n\npackage commandimport &quot;testing&quot;func TestPrintCommand_Execute(t *testing.T) &#123;\tqueue := NewTaskQueue()\tqueue.AddCommand(&amp;PrintCommand&#123;\t\tContent: &quot;你好&quot;,\t&#125;)\tqueue.AddCommand(&amp;SendEmail&#123;\t\tTo:      &quot;xx@qq.com&quot;,\t\tContent: &quot;hello&quot;,\t&#125;)\tqueue.Command()&#125;\n\n行为型模式-解释器模式定义语言的语法表示，提供解释器来解释语法，通常用于处理类似编程语言，查询语言，规则引擎等场景\n核心思想：\n\n定义语法规则\n解释执行\n\n案例： \n\n抽象语法树AST， 树形结构反映嵌套关系\n数据库查询引擎，mysql的查询解析和执行\n规则引擎，解析和执行规则\n模板引擎，前端开发\n数学表达式计算，解析计算数学\n\npackage interpreterimport (\t&quot;fmt&quot;\t&quot;strings&quot;\t&quot;testing&quot;)func TestFunc(t *testing.T) &#123;\tconst tmpl = `Hello, &#123;&#123;.Name&#125;&#125;! You are &#123;&#123;.Age&#125;&#125; years old.`\ttemplate := ParseTemplate(tmpl)\tfmt.Println(template.tree)\tres := template.Interpreter(&amp;Context&#123;\t\tData: map[string]any&#123;\t\t\t&quot;.Name&quot;: &quot;deepter&quot;,\t\t\t&quot;.Age&quot;:  21,\t\t&#125;,\t&#125;)\tfmt.Println(res)&#125;type Context struct &#123;\tData map[string]any&#125;type Node interface &#123;\tInterpreter(ctx *Context) string&#125;type TextNode struct &#123;\tContent string&#125;func (t TextNode) Interpreter(ctx *Context) string &#123;\treturn t.Content&#125;type VarNode struct &#123;\tKey string&#125;func (t VarNode) Interpreter(ctx *Context) string &#123;\tval, ok := ctx.Data[t.Key]\tif !ok &#123;\t\treturn &quot;&quot;\t&#125;\treturn fmt.Sprintf(&quot;%v&quot;, val)&#125;type Template struct &#123;\ttree []Node&#125;func ParseTemplate(tmpl string) *Template &#123;\tvar template = new(Template)\tvar index = 0\tfor &#123;\t\tstartIndex := strings.Index(tmpl[index:], &quot;&#123;&#123;&quot;)\t\tif startIndex == -1 &#123;\t\t\ttemplate.tree = append(template.tree, &amp;TextNode&#123;\t\t\t\tContent: tmpl[index:],\t\t\t&#125;)\t\t\tbreak\t\t&#125;\t\ttemplate.tree = append(template.tree, &amp;TextNode&#123;\t\t\tContent: tmpl[index : index+startIndex],\t\t&#125;)\t\tendIndex := strings.Index(tmpl[index+startIndex:], &quot;&#125;&#125;&quot;)\t\tif endIndex == -1 &#123;\t\t\tbreak\t\t&#125;\t\tkey := strings.TrimSpace(tmpl[index+startIndex+2 : index+startIndex+endIndex])\t\ttemplate.tree = append(template.tree, &amp;VarNode&#123;\t\t\tKey: key,\t\t&#125;)\t\tindex = index + startIndex + endIndex + 2\t&#125;\treturn template&#125;func (t *Template) Interpreter(ctx *Context) string &#123;\tvar s string\tfor _, node := range t.tree &#123;\t\ts += node.Interpreter(ctx)\t&#125;\treturn s&#125;\n\n行为型模式-迭代器模式提供了一种方法，顺序访问聚合对象中的各个元素，而又不需要暴露该对象的内部表示。\n核心思想是：将遍历逻辑从聚合对象中分离出来，使聚合对象和遍历逻辑可以独立变化\n实际应用场景：\n\n集合类库，如Go的slice、map等集合类型，可以通过迭代器模式提供统一的遍历接口\n数据库查询结果\n文件系统遍历\n树形结构遍历\n\npackage iteratorimport (\t&quot;fmt&quot;\t&quot;testing&quot;)func TestIterator(t *testing.T) &#123;\tbook := []*Book&#123;\t\t&amp;Book&#123;Title: &quot;Go开发&quot;&#125;,\t\t&#123;Title: &quot;前端开发&quot;&#125;,\t\t&#123;Title: &quot;Java开发&quot;&#125;,\t&#125;\titerator := NewBookIterator(book)\tIteratorFunc(iterator)&#125;type Book struct &#123;\tTitle string&#125;type BookIterator struct &#123;\tBooks    []*Book\tposition int&#125;type Iterator interface &#123;\tHasNext() bool\tNext() *Book&#125;func (b *BookIterator) HasNext() bool &#123;\tif b.position &gt;= len(b.Books) &#123;\t\treturn false\t&#125;\treturn true&#125;func (b *BookIterator) Next() *Book &#123;\tif !b.HasNext() &#123;\t\treturn nil\t&#125;\tbook := b.Books[b.position]\tb.position++\treturn book&#125;func IteratorFunc(iterator Iterator) &#123;\tfor iterator.HasNext() &#123;\t\tbook := iterator.Next()\t\tfmt.Println(book.Title)\t&#125;&#125;func NewBookIterator(books []*Book) *BookIterator &#123;\treturn &amp;BookIterator&#123;\t\tBooks:    books,\t\tposition: 0,\t&#125;&#125;\n\n行为型模式-中介者模式引入一个中介者对象来封装一组对象之间的交互。\n将对象之间的复杂交互集中到一个中介者对象中，减少对象间耦合。\n//实现一个用户发送给聊天室其他用户，其他用户收到消息，自己收不到package mediatorimport (\t&quot;fmt&quot;\t&quot;testing&quot;)type User struct &#123;\tName     string\tmediator Mediator&#125;type ChatRoom struct &#123;\tusers []User&#125;type Obj interface &#123;\tSendMsg(string)\tRevMsg(string)&#125;type Mediator interface &#123;\tSendMsg(msg string, user Obj)&#125;func (u User) SendMsg(msg string) &#123;\tfmt.Printf(&quot;用户 %s 发了消息 %s\\n&quot;, u.Name, msg)\tu.mediator.SendMsg(msg, u)&#125;func (u User) RevMsg(msg string) &#123;\tfmt.Printf(&quot;用户 %s 接收到消息 %s\\n&quot;, u.Name, msg)&#125;func (c *ChatRoom) SendMsg(msg string, user Obj) &#123;\tfor _, u := range c.users &#123;\t\tif u == user &#123;\t\t\tcontinue\t\t&#125;\t\tu.RevMsg(msg)\t&#125;&#125;func (c *ChatRoom) Register(user User) &#123;\tc.users = append(c.users, user)&#125;func TestSendMsg(t *testing.T) &#123;\troom := ChatRoom&#123;&#125;\tu1 := User&#123;Name: &quot;ff&quot;, mediator: &amp;room&#125;\tu2 := User&#123;Name: &quot;zs&quot;, mediator: &amp;room&#125;\tu3 := User&#123;Name: &quot;ls&quot;, mediator: &amp;room&#125;\troom.Register(u1)\troom.Register(u2)\troom.Register(u3)\tu1.SendMsg(&quot;你好呀&quot;)\tu2.SendMsg(&quot;你吃了吗&quot;)\tu3.SendMsg(&quot;我吃了&quot;)&#125;\n\n行为型模式-备忘录模式允许在不破坏封装性的前提，捕获外部化一个内部状态，以便稍后可以将该对象恢复到之前的状态。\n核心思想是  将对象状态保存到备忘录中，并在需要时从备忘录恢复状态。\npackage mementoimport (\t&quot;fmt&quot;\t&quot;testing&quot;)type Node interface &#123;&#125;type TextNode struct &#123;\tstate string&#125;func (t *TextNode) SetState(state string) &#123;\tt.state = state&#125;func (t *TextNode) GetState() string &#123;\treturn t.state&#125;func (t *TextNode) Save() Memento &#123;\treturn &amp;TextMemento&#123;\t\tstate: t.state,\t&#125;&#125;type Memento interface &#123;\tGetState() string&#125;type TextMemento struct &#123;\tstate string&#125;func (t *TextMemento) GetState() string &#123;\treturn t.state&#125;type Manage struct &#123;\tstates []Memento&#125;func (m *Manage) Save(t Memento) &#123;\tm.states = append(m.states, t)&#125;func (m *Manage) Back(index int) Memento &#123;\treturn m.states[index]&#125;func TestTextNode(t *testing.T) &#123;\tmanage := Manage&#123;&#125;\ttext := TextNode&#123;&#125;\ttext.SetState(&quot;1&quot;)\tmanage.Save(text.Save())\ttext.SetState(&quot;2&quot;)\tmanage.Save(text.Save())\tfmt.Println(text.GetState())\tfmt.Println(manage.Back(0).GetState())&#125;\n\n行为型模式-观察者模式定义了对象之间一对多依赖关系，当一个对象（被观察者）的状态发生改变时，所有依赖它的对象（观察者）都会收到通知并自动更新。\n有个天气站（被观察者）， 天气数据更新了通知多个显示设备（观察者）更新显示内容\npackage observerimport (\t&quot;fmt&quot;\t&quot;testing&quot;)type Observer interface &#123;\tRevMsg(wd int)&#125;type Subject interface &#123;\tSendMsg(wd int)\tNotify()\tRegisterObserver(Observer)&#125;type User struct &#123;\tName string&#125;func (u User) RevMsg(wd int) &#123;\tfmt.Printf(&quot;%s 现在温度 %d\\n&quot;, u.Name, wd)&#125;type WeatherState struct &#123;\tobservers []Observer\twd        int&#125;func (w *WeatherState) SendMsg(wd int) &#123;\tw.wd = wd\tw.Notify()&#125;func (w *WeatherState) Notify() &#123;\tfor _, observer := range w.observers &#123;\t\tobserver.RevMsg(w.wd)\t&#125;&#125;func (w *WeatherState) RegisterObserver(o Observer) &#123;\tw.observers = append(w.observers, o)&#125;func TestObserver(t *testing.T) &#123;\tzhan := WeatherState&#123;&#125;\tu1 := User&#123;Name: &quot;ff&quot;&#125;\tu2 := User&#123;Name: &quot;zs&quot;&#125;\tzhan.RegisterObserver(u1)\tzhan.RegisterObserver(u2)\tzhan.SendMsg(8)\tzhan.SendMsg(0)&#125;\n\n行为型模式-状态模式在对象内部状态改变时，改变其行为， 状态模式的核心思想是将对象的状态封装成独立的类，并将其对象的行为委托给当前状态对象。\npackage stateimport (\t&quot;fmt&quot;\t&quot;testing&quot;)type State interface &#123;\tSwitch(context *Context)&#125;type Context struct &#123;\tstate State&#125;func (c *Context) SetState(state State) &#123;\tc.state = state&#125;func (c *Context) Switch() &#123;\tc.state.Switch(c)&#125;type OnState struct &#123;&#125;func (OnState) Switch(context *Context) &#123;\tfmt.Println(&quot;开关关闭&quot;)\tcontext.SetState(&amp;OffState&#123;&#125;)&#125;type OffState struct &#123;&#125;func (OffState) Switch(context *Context) &#123;\tfmt.Println(&quot;开关打开&quot;)\tcontext.SetState(&amp;OnState&#123;&#125;)&#125;func TestState(t *testing.T) &#123;\tc := Context&#123;\t\tstate: &amp;OnState&#123;&#125;,\t&#125;\tc.Switch()\tc.Switch()\tc.Switch()&#125;\n\n行为型模式-策略模式定义了一系列算法，并将算法封装起来，是他们可以互相替换。\n核心思想是将算法的使用和算法的实现分离，从而使算法可以独立于客户端而变化。\n通过策略模式，可以运行时动态的选择算法，而不需要修改客户端代码\n优点：\n\n解耦，算法使用和算法分离\n易于扩展，添加策略类\n动态选择算法，不需要改客户端\n\n比如支付系统，支持多种支付方式\npackage strategyimport (\t&quot;fmt&quot;\t&quot;testing&quot;)type Pay interface &#123;\tPay(money int64)&#125;type AliPay struct &#123;&#125;type WeiPay struct &#123;&#125;func (AliPay) Pay(money int64) &#123;\tfmt.Printf(&quot;使用支付宝支付: %d 元\\n&quot;, money)&#125;func (WeiPay) Pay(money int64) &#123;\tfmt.Printf(&quot;使用微信支付: %d 元\\n&quot;, money)&#125;type PayStrategy struct &#123;\tpay Pay&#125;func (p *PayStrategy) SetPay(pay Pay) &#123;\tp.pay = pay&#125;func (p *PayStrategy) Pay(money int64) &#123;\tp.pay.Pay(money)&#125;func TestPay(t *testing.T) &#123;\taliPay := &amp;AliPay&#123;&#125;\tweiPay := &amp;WeiPay&#123;&#125;\tpayStrategy := &amp;PayStrategy&#123;&#125;\tpayStrategy.SetPay(aliPay)\tpayStrategy.Pay(12)\tpayStrategy.SetPay(weiPay)\tpayStrategy.Pay(10)&#125;\n\n行为型模式-模板方法模式定义算法骨架，将某些步骤延迟到子类实现。\n核心思想是将算法通用部分放到父类中，将可变部分交给子类实现。\n通过模板方法模式可以避免代码重复，确保算法结构不变\n使用场景：\n\n框架设计，web请求处理\n工作流引擎\n测试框架\n游戏开发\n\n假如有个饮料制作系统，支持制作咖啡，茶…  咖啡和茶制作过程有一些共同步骤，也有不同步骤\npackage templateimport (\t&quot;fmt&quot;\t&quot;testing&quot;)type Template interface &#123;\tBoilWater()\tBrew()     //冲泡\tAddSugar() //加糖\tHasAddSugar() bool&#125;type Coffee struct &#123;&#125;func (t *Coffee) BoilWater() &#123;\tfmt.Println(&quot;烧水&quot;)&#125;func (t *Coffee) Brew() &#123;\tfmt.Println(&quot;冲泡&quot;)&#125;func (t *Coffee) AddSugar() &#123;\tfmt.Println(&quot;加糖&quot;)&#125;func (t *Coffee) HasAddSugar() bool &#123;\treturn true&#125;type Tea struct &#123;&#125;func (t *Tea) BoilWater() &#123;\tfmt.Println(&quot;烧水&quot;)&#125;func (t *Tea) Brew() &#123;\tfmt.Println(&quot;冲泡&quot;)&#125;func (t *Tea) AddSugar() &#123;\tfmt.Println(&quot;加糖&quot;)&#125;func (t *Tea) HasAddSugar() bool &#123;\treturn false&#125;func MakeTemplate(tmp Template) &#123;\ttmp.BoilWater()\ttmp.Brew()\tif tmp.HasAddSugar() &#123;\t\ttmp.AddSugar()\t&#125;&#125;func TestTemplate(t *testing.T) &#123;\ttea := Tea&#123;&#125;\tcoffee := Coffee&#123;&#125;\tMakeTemplate(&amp;tea)\tMakeTemplate(&amp;coffee)&#125;\n\n行为型模式-访问者模式将算法于对象结构分离。\n核心思想：将算法从对象结构中分离出来是的可以在不修改对象结构情况下定义新得操作\n通过访问者模式，可以将对象结构得元素和作用于这些元素得操作解耦，使得操作可以独立变化\n有点：\n\n解耦，操作和对象结构分离，操作可以独立变化\n扩展性，新增新的访问者即可\n符合开闭原则\n\n假如我们有个文档对象模型，DOM ，包含多种元素，文本，图片，表格等， 我们需要对这些元素进行不通得操作（如导出pdf， 导出html等）\npackage visitorimport (\t&quot;fmt&quot;\t&quot;testing&quot;)type Text struct &#123;\tcontent string&#125;type Element interface &#123;\tAccept(visitor Visitor)&#125;type Image struct &#123;\tsrc string&#125;func (t *Text) Accept(v Visitor) &#123;\tv.VisitText(t)&#125;func (i *Image) Accept(v Visitor) &#123;\tv.VisitImage(i)&#125;type Visitor interface &#123;\tVisitText(*Text)\tVisitImage(*Image)&#125;type PDFVisitor struct &#123;&#125;func (PDFVisitor) VisitText(text *Text) &#123;\tfmt.Println(&quot;pdf获取文本内容：&quot;, text.content)&#125;func (PDFVisitor) VisitImage(image *Image) &#123;\tfmt.Println(&quot;pdf获取图片得src：&quot;, image.src)&#125;type Document struct &#123;\telements []Element&#125;func (d *Document) AddElement(element Element) &#123;\td.elements = append(d.elements, element)&#125;func (d *Document) Accept(v Visitor) &#123;\tfor _, element := range d.elements &#123;\t\telement.Accept(v)\t&#125;&#125;func TestVisitor(t *testing.T) &#123;\tdocument := &amp;Document&#123;&#125;\tdocument.AddElement(&amp;Text&#123;content: &quot;你好&quot;&#125;)\tdocument.AddElement(&amp;Text&#123;content: &quot;吃饭了么&quot;&#125;)\tdocument.AddElement(&amp;Text&#123;content: &quot;xxx&quot;&#125;)\tdocument.AddElement(&amp;Image&#123;src: &quot;abc.png&quot;&#125;)\tpdf := &amp;PDFVisitor&#123;&#125;\tdocument.Accept(pdf)&#125;","categories":["总结笔记"],"tags":["Go","Chain of Responsibility","Command","Interpreter","Iterator","Mediator","Memento","Observer","State","Strategy","Template Method","Visitor"]},{"title":"Clickhouse总结","url":"/2024_01_10_clickhouse/","content":"OLTP与OLAP什么是 OLTP\n全称: Online Transaction Processing（联机事务处理系统）\n特点:\n专注于事务处理\n进行数据的增删改查操作\n典型代表: MySQL、Oracle\n用于网站和系统应用的后端数据库\n存储业务数据（如下单、支付、注册信息）\n支持事务操作，响应时间要求高\n数据量相对较少\n\n\n\nOLTP 的问题\n当数据量达到 TB 或 PB 级别时，传统的 MySQL 性能不足\n数据分析场景需要全盘扫描统计，不适合 OLTP\n\n什么是 OLAP\n全称: Online Analytical Processing（联机分析处理）\n特点:\n专注于复杂分析操作\n更侧重于决策支持\n典型代表: ClickHouse、Doris、StarRocks\n数据量通常为 TB 级别\n不擅长修改操作，数据一致性要求低\n\n\n\nClickHouse 数据库介绍\n简介:\n是俄罗斯的Yandex于2016年开源的列式存储数据库\n使用c++语言编写\n\n\n类型: OLAP 数据库\n特点:\n实时数据仓库，在线分析处理查询\n支持标准 SQL 语句（如 INSERT、SELECT），实时生成分析数据报告\n提供高级查询功能（复合聚合函数、窗口函数、跨表查询）\n支持列式存储、数据分区和线程并行\n\n\n\n列式存储 vs 行式存储\n行式存储:\n将整行数据存储为一个整体\n\n\n列式存储:\n将每一列作为一个数据块存储\n优势: 更高效的统计查询、数据压缩效果好\n\n\n\n数据分区和线程并行\n数据分区:\n按业务逻辑将数据分类，便于查询管理\n示例: 按日期分区\n\n\n线程并行:\n多个 CPU 核心并行查询不同分区\n优势: 降低查询延迟，利用 CPU 资源\n\n\n\n支持丰富的表引擎\n表引擎:\n决定数据存储方式和位置\n支持查询类型和并发访问\n\n\n常用表引擎:\nMergeTree（支持分区和 TTL）\n日志引擎（快速写入小数据）\n集成引擎（实时接入其他数据源）\n\n\n\nClickHouse 的缺点\n由于单条查询使用多核cpu，不支持高并发请求\n对 UPDATE 和 DELETE 操作支持较差\n单个插入性能较低，建议批量插入\n吃硬件，一般物理机安装，单独安装不和业务混部\n\nClickHouse 的适用场景\n适用于数据量大且需要分析的场景\n适合存储已经处理过的大宽表，进行分析，读取大量列中的少量列\n不适合高并发请求、频繁更新和删除的场景\n\nClickHouse安装安装准备\n防火墙设置：关闭防火墙以避免影响安装\n实际工作中需根据需要配置IP和端口限制\nLinux系统文件限制，取消文件限制：否则影响ch性能\n\n\n使用ulimit -a命令查看系统限制\n关注的主要参数：\n打开的文件数\n用户最大进程数\n\n\n修改配置文件&#x2F;etc&#x2F;security&#x2F;limits.conf没修改前：修改:修改后：\n解释配置项：\n用户与用户组的设置\n软限制（soft）与硬限制（hard）的区别\n打开文件数（number of open files）与进程数（number of processes）\n\n\n\n\n安装依赖  linux安装由运维协助，这里不展开记录，下面直接通过docker安装（生产环境不要使用docker，这里只为了学习原理和使用，并非安装所以简化安装）  参考  https://clickhouse.com/docs/install#from-docker-image\n\n安装 linux安装由运维协助，这里不展开记录，下面直接通过docker安装（生产环境不要使用docker，这里只为了学习原理和使用，并非安装所以简化安装）\ndocker pull yandex/clickhouse-server:21.7.3.14docker run --rm -d --name=clickhouse-server \\--ulimit nofile=262144:262144 -p 8123:8123  \\-p 9009:9009 -p 9090:9000 yandex/clickhouse-server:21.7.3.14docker cp clickhouse-server:/etc/clickhouse-server/config.xml ./conf/config.xmldocker cp clickhouse-server:/etc/clickhouse-server/users.xml ./conf/users.xmldocker run -d --name=clickhouse-server \\-p 8123:8123 -p 9009:9009 -p 9090:9000 \\--ulimit nofile=262144:262144 \\-v ./data/:/var/lib/clickhouse/data \\-v ./conf/:/etc/clickhouse-server \\-v ./log/:/var/log \\yandex/clickhouse-server:21.7.3.14设置密码后客户端链接clickhouse-client --user default --password 1234# refer to https://blog.csdn.net/huas_xq/article/details/123574461\n核心目录：\n\n数据在 data目录\n表结构信息在 metadata目录\n\nClickhouse数据类型整形数值\nInt8, Int16, Int32, Int64:\nInt8: 8位（-128 到 127）\nInt16: 16位（-32768 到 32767）\nInt32: 32位（-2147483648 到 2147483647）\nInt64: 64位（-9223372036854775808 到 9223372036854775807）\n\n\n与Java类型类比\nint8对应byte\nint16对应short\nint32对应int\nint64对应long\n\n\n无符号整型:\nUInt8: 0 到 255\nUInt16: 0 到 65535\nUInt32: 0 到 4294967295\nUInt64: 0 到 18446744073709551615\n\n\n\n浮点型\n浮点型的分类\n\nFloat32: 32位（4字节）\nFloat64: 64位（8字节）\n\n\n精度问题\n\n浮点型存储可能会导致精度丢失，尤其在处理货币时应避免使用。\n\n\n布尔类型\n\n使用uint8表示布尔值\n0表示false\n1表示true\n\n\nDecimal类型\n\nDecimal(p, s):\np: 总位数\ns: 小数位数\n\n\n类型示例\ndecimal(32, 5)  整数小数一共9位， 小数后5位 \ndecimal(64, 5), 整数小数一共18位， 小数后5位 \ndecimal(128, 5) 整数小数一共38位， 小数后5位\n\n\n\n\n字符串类型\n\nString: 可变长度字符串。\nFixedString(n): 固定长度字符串，不足部分用空字节填充。\n\n\n枚举类型\n\n定义和使用枚举， Enum8,Enum16\n插入和查询枚举值的示例 CREATE TABLE t_enum (    x Enum8(&#x27;hello&#x27; = 1, &#x27;world&#x27; = 2)) ENGINE = TinyLog;INSERT INTO t_enum VALUES (&#x27;hello&#x27;),(&#x27;world&#x27;),(&#x27;hello&#x27;);SELECT * FROM t_enum;# 转换查询SELECT CAST(x, &#x27;Int8&#x27;) FROM t_enum;\n插入未知类型会报错\n\n\n时间类型\n\nDate: 仅包含年月日。\nDateTime: 包含年月日时分秒。\nDateTime64: 包含亚秒（毫秒）。\n\n\n数组类型\n\nmergeTree表中不能存储多维数组\n使用 Array 表示，支持单层数组。\n例子：Array(UInt8) 表示存储无符号8位整型的数组。SELECT array(1,2) AS x, toTypeName(x);2d9991e86323 :) SELECT array(1,2) AS x, toTypeName(x);SELECT    [1, 2] AS x,    toTypeName(x)┌─x─────┬─toTypeName([1, 2])─┐│ [1,2] │ Array(UInt8)       │└───────┴────────────────────┘1 rows in set. Elapsed: 0.013 sec.\n\n\n其他数据类型介绍其他常用数据类型可查阅ClickHouse官网获取更多信息https://clickhouse.com/docs/zh/sql-reference/data-types\n\n空值处理ClickHouse中的空值存储方式建议使用无意义的数字或字符表示空值, 避免使用NULL比如可以用-1，无意义得值，字符串可以搞空串或者null等\n\n\nClickhouse表引擎概述\n表引擎的定义：类似于MySQL中的InnoDB和MyISAM，不同引擎具有不同的功能和作用。\n表引擎的作用：\n决定数据的存储方式和位置。\n指定如何读写数据。\n\n\n\nClickHouse表引擎的特点\n存储方式和位置\n数据一般存储在本地磁盘上。\nClickHouse不依赖于Hadoop或HDFS计算资源。\n默认配置路径：&#x2F;var&#x2F;lib&#x2F;clickhouse&#x2F;data。\n\n\n支持的查询及语法\n不同引擎支持不同的查询语法。\n例如，某些引擎不支持多维数组存储。\n\n\n并发数据访问\nClickHouse支持多线程并发查询，但并非所有引擎都支持。\n\n\n索引支持\n不同引擎对索引的支持程度不同，索引的目的是提高查询效率。\n\n\n数据复制\n某些引擎支持数据复制，而其他引擎则不支持。\n\n\n引擎名称是大小写敏感的，采用大驼峰命名法。\n\n表引擎TinyLog\n属于日志家族，适合小数据量（小于100万行）。\n特点：\n存储在磁盘上，不支持索引。\n无并发控制，适合简单测试。\n\n\n做一些简单测试，生产环境肯定不会用CREATE table t_tinylog(id String,name String) engine=TinyLog;\n\n表引擎Memory\n基于内存，性能（超过10G&#x2F;s）快但数据易丢失。\n特点：\n不支持索引，适合小数据量测试。\n\n\n做一些简单测试，生产环境肯定不会用\n\nMergeTree系列\nClickHouse的核心引擎，适合生产环境。相当于innodb之于mysql\n包含多个变种，如ReplacingMergeTree和SummingMergeTree，具有不同功能。参考官方文档：https://clickhouse.com/docs/zh/engines/table-engines/mergetree-family\n\n集成引擎集成外部系统，如MySQL和Kafka。外部集成的意义：无需将数据导入ClickHouse，直接查询外部数据源。\nhttps://clickhouse.com/docs/zh/engines/table-engines/integrations\nMergeTree引擎mergeTree家族的第一个引擎——MergeTree。MergeTree引擎本身是一个表引擎。介绍建表语句和嵌表语句。\n参考：https://clickhouse.com/docs/zh/engines/table-engines/mergetree-family/mergetree\n建表语句CREATE TABLE t_order_mt(    id UInt32,    sku_id String,    total_amount Decimal(16,2),    create_time DateTime) engine=MergeTree partition by toYYYYMM(create_time) primary key (id)order by (id,sku_id);\nprimary key是可以重复的，这和mysql不一样order by 是必须的， primary key 不是必须的\n测试数据（多执行几次，多插入一些）：\nINSERT INTO t_order_mt (id, sku_id, total_amount, create_time) VALUES (1, &#x27;SKU001&#x27;, 100.50, &#x27;2023-01-01 10:00:00&#x27;), (1, &#x27;SKU002&#x27;, 200.75, &#x27;2023-01-01 15:30:00&#x27;), (3, &#x27;SKU003&#x27;, 50.20, &#x27;2023-03-20 09:15:00&#x27;), (4, &#x27;SKU004&#x27;, 150.00, &#x27;2023-05-10 14:45:00&#x27;), (5, &#x27;SKU005&#x27;, 300.99, &#x27;2023-05-10 11:20:00&#x27;), (6, &#x27;SKU006&#x27;, 75.55, &#x27;2023-06-30 16:50:00&#x27;);\n查询结果，分区了O(∩_∩)O\n连接配置连接ClickHouse的步骤：使用主机名和端口（默认端口为8123）。默认用户名为default，密码为空。如果驱动未自动下载，需要手动添加驱动文件。\npartition by 分区（可选）不是必须的建表语句\n\n分区的作用主要目的是避免全表扫描。查询语句中加入分区字段的取值，可以优化查询速度。分区的实现方式类似于物理分隔，像是将数据分放在不同的房间。\n\nClickHouse的分区机制ClickHouse的分区是基于本地磁盘，而hive的分区是在HDFS上建立分区目录。如果不写分区，默认会用一个分区，名为“all”，所有数据都在里面。\n\n并行查询单个查询可以多线程同时执行。每个线程处理一个分区的数据。通常按天分区，因为这样可以避免不必要的麻烦。\n\n分区的存储数据存储\n\n稀疏索引索引文件采用的稀疏索引，和kafka的partition一样\n\n分区目录原理\n\n分区目录如上图所示， 第一位分区键，第二位最小区块编号，第三位，最大区块编号，第四位合并层级\n日期类型分区键，最好存日期类型，不像其他数仓，hive存字符串，这样效率高\n其他类型分区目录，如string，float类型分区建，目录名字取hash\n\n\n数据写入与分区合并\n\n每次数据写入会产生一个临时分区，之后需要执行合并操作。\n合并是定期执行的，可以手动触发。\n手动触发指令 OPTIMIZE TABLE t_order_mt FINAL\n可以加一个分区参数 OPTIMIZE TABLE t_order_mt PARTITION &#x27;20230101&#x27; FINAL\n 合并之后，分区目录目录会变，产生合并后的目录，过期数据会自动清理，删除。\n\n\n\nprimary key主键（可选）\n提供了数据的一级索引，但不是唯一约束\n\n主键的设定主要依据查询中的where条件。（一般加载where条件中）\n\nindex granularity直接翻译就是索引粒度，指在稀疏索引中两个相邻索引对应的间隔，Clickhouse中mergeTree默认是 8192，官方不建议修改这个值，除非该列存在大量重复值，比如在一个分区中几万行才有一个不同数据。\n\n稀疏索引索引文件采用的稀疏索引，和kafka的partition一样要求主键必须有序所以必须要有order bt\n\n\n优点：数据量小，查询效率高\norder by(必选)\n分区内排序\n必填 甚至比主键还重要， 因为要建立稀疏索引，且后面去重和汇总也要用到order by\n可以多个字段，但必须是左前坠， 比如(id,sku_id) 要么是id ,要么是id,sku_id，不能是sku_id,id 和sku_id\n\n二级索引\n版本问题20.1.2.4之前，官方标注是实验性的，之后是默认开启的（20年1月份版本）之前版本可以用以下命令设置，之后版本会报错\nset allow_expreimental_data_skipping_indices=1\n二级索引使用在大量重复数据的场景下二级索引不必有序二级索引也叫跳数索引\n\n如何使用\nCREATE TABLE t_order_mt2(    id UInt32,    sku_id String,    total_amount Decimal(16,2),    create_time DateTime,    INDEX a total_amount TYPE minmax GRANULARITY 5) engine=MergeTreepartition by toYYYYMM(create_time)primary key (id)order by (id,sku_id);\n二级索引的类型是 minmax\n\n\nminmax 是最小最大值索引，粒度是5， 也就是5个数据算一个区间， 然后取最小值和最大值。\nINSERT INTO t_order_mt2 (id, sku_id, total_amount, create_time) VALUES (1, &#x27;SKU001&#x27;, 100.50, &#x27;2023-01-01 10:00:00&#x27;), (1, &#x27;SKU002&#x27;, 200.75, &#x27;2023-01-01 15:30:00&#x27;), (3, &#x27;SKU003&#x27;, 50.20, &#x27;2023-03-20 09:15:00&#x27;), (4, &#x27;SKU004&#x27;, 150.00, &#x27;2023-05-10 14:45:00&#x27;), (5, &#x27;SKU005&#x27;, 300.99, &#x27;2023-05-10 11:20:00&#x27;), (6, &#x27;SKU006&#x27;, 75.55, &#x27;2023-06-30 16:50:00&#x27;);\n\nclickhouse-client --send_logs_level=trace &lt;&lt;&lt; &#x27;select * from t_order_mt2 where total_amount &gt; toDecimal32(900,2)&#x27;\n\n使用了二级索引\n数据TTLtime to alive 数据存活时间\n\n对某一列设置ttl， 数据过期之后，会自动删除CREATE TABLE t_order_mt3(    id UInt32,    sku_id String,    total_amount Decimal(16,2) TTL create_time + INTERVAL 10 SECOND,    create_time DateTime,    INDEX a total_amount TYPE minmax GRANULARITY 5) engine=MergeTreepartition by toYYYYMM(create_time)primary key (id)order by (id,sku_id);\n\n时间到期，这一列就会被删除（相当于时间到了，会启动一个合并任务，处理删除）\n\n表级TTLALTER table t_order_mt3 MODIFY TTL create_time + INTERVAL 10 SECOND;\n会根据每行的create_time 字段进行过期删除\n\nTTL不能使用到主键字段\n参考：https://clickhouse.com/docs/zh/engines/table-engines/mergetree-family/mergetree\nReplacingMergeTree 引擎替换合并树他的存储特性完全继承MergeTree，  多了一个去重功能不是根据主键去重，而是根据order by的字段去重\n\n去重时机不是实时去重，只会在同一批插入（新版本）或合并的过程去重。最终一致性，不实时一致\n\n去重范围分区内去重，不能跨分区去重\n\nCREATE TABLE t_order_rmt(    id UInt32,    sku_id String,    total_amount Decimal(16,2),    create_time DateTime) engine=ReplacingMergeTree(create_time)partition by toYYYYMM(create_time)parimary key (id)order by (id,sku_id);\n\nReplacingMergeTree(create_time) 中create_time 表示按照order by的去重之后，保留crate_time最大的数据。\n不指定，默认按照插入顺序来，保留最后插入的。\nSummingMergeTree 引擎预聚合求和合并树分区内聚合按照order by\nCREATE TABLE t_order_smt(    id UInt32,    sku_id String,    total_amount Decimal(16,2),    create_time DateTime) engine=SummingMergeTree(total_amount)partition by toYYYYMM(create_time)primary key (id)order by (id,sku_id);\n以上求和total_amount，是按照gruop by id,sku_id来聚合求和的，  重要的是order_by，如果不指定total_amaount,那么会按照order by求和所有的数字列。\ninsert into t_order_smt values (1,&#x27;sku001&#x27;,100.50,&#x27;2023-01-01 10:00:00&#x27;),(1,&#x27;sku001&#x27;,200.75,&#x27;2023-01-01 15:30:00&#x27;),(3,&#x27;sku003&#x27;,50.20,&#x27;2023-03-20 09:15:00&#x27;),(4,&#x27;sku004&#x27;,150.00,&#x27;2023-05-10 14:45:00&#x27;),(5,&#x27;sku005&#x27;,300.99,&#x27;2023-05-10 11:20:00&#x27;),(6,&#x27;sku006&#x27;,75.55,&#x27;2023-06-30 16:50:00&#x27;);OPTIMIZE TABLE t_order_smt final;\n\n结果，两条被聚合了：\n且crate_time 是最前面的一条（第一行），而不是最后一条（最大）\n只有在同一批次插入时（新版本），或分片合并时才会聚合\n设计聚合表时，最好设置聚合的列，否则序号之类的都会被聚合，没有意义\n查询的时候，还是需要在sql里面写sum(),因为可能还没来得及聚合，体会下预聚合\nClickhouse SQL操作insert和mysql一样从表到表，支持insert into xxx select\nupdate和deleteOLAP的，不叫更新，叫做可变查询， 是ALTER的一种不支持事务\n\n物理删除alter table t_order_mt delete where id = 1;\n逻辑删除alter table t_order_mt update status = 1 where id = 1;\n恢复alter table t_order_mt update status = 0 where id = 1;\n\n这种删除操作比较重，分了两步，新增分区并发旧分区打上逻辑失效标记，直到合并的时候才会释放磁盘空间，一般这种功能不给用户，由管理员完成\n实践中， 可以加_sign标记，_version版本号机制以新增的方式替代删除，缺点就是数据膨胀\n查询操作支持子查询支持CTE Common Table Expression 公用表表达式with子句\n语法支持join，但是实际上避免join，json操作无法使用缓存，所以即使是join ch也会查询两次，且占用内存，且分布式的话内存爆炸\n窗口函数，目前官网表示正在试验阶段\n各种函数查看官网\n多维分析函数不支持自定义函数\nGROUP BY 增加了with rollup上卷 , with cube多维分析,  with totals总计  来计算小计和总计比如按照a,b维度分析，上卷：分析 group by a,b分析 group by a分析 group by ()\n多维分析：分析 group by a,b分析 group by a分析 group by b分析 group by ()\n总计分析：分析 group by a,b分析 group by ()\nalter table t_order_mt delete where 1=1;insert into t_order_mt values (101,&#x27;sku_001&#x27;,1000.00, &#x27;2024-01-01 12:00:00&#x27;),(102,&#x27;sku_002&#x27;,2000.00, &#x27;2024-01-02 12:00:00&#x27;),(103,&#x27;sku_003&#x27;,3000.00, &#x27;2024-01-02 12:00:00&#x27;),(104,&#x27;sku_004&#x27;,4000.00, &#x27;2024-01-03 12:00:00&#x27;),(105,&#x27;sku_005&#x27;,5000.00, &#x27;2024-01-03 12:00:00&#x27;),(106,&#x27;sku_006&#x27;,6000.00, &#x27;2024-01-03 12:00:00&#x27;);select id, sku_id, sum(total_amount) from t_order_mt group by id,sku_id with rollup;\n\nalter操作和mysql基本一致新增字段\nalter table tableName add column newcolname String after col1;\n修改字段类型\nalter table tableName modify column colname String;\n删除字段\nalter table tableName drop column colname;\n\n导出数据clickhouse-client --query &quot;select * from t_order_mt where create_time=&#x27;2024-01-01 12:00:00&#x27;&quot; --output_format_csv_separator=&quot;\\t&quot; --output_format_csv_with_names --output_format_csv_with_names_and_types &gt; /tmp/t_order_mt.csv\n更多格式参考官网\n副本\n互为副本， 平权\n注意点：副本的表引擎都要加Replicated例如：\n\nReplicatedMergeTree\nReplicatedReplacingMergeTree\nReplicatedSummingMergeTree其他可参考官方文档\n\n分片集群clickhouse支持数据分片到不同机器上存储\n\n集群写入流程（3分片2副本共6个节点）\n\ns1 s2 s3 三个分片，r1 r2 每个分片两个副本\n参数  internal_replication   内部副本参数false得话，非内部同步，如图黄色true得话，内部同步（生产一般要打开true），如图绿色\n\n集群读取流程\n\n\n优先选择errors_count小得副本\nerrors_count相同，有随机，顺序，随机（优先第一顺位）host名称近似等四种选择方式\n\n\n集群建表创建本地表：CREATE TABLE st_order_mt on cluster gmall_cluster (    id UInt32,    sku_id String,    total_amount Decimal(16,2),    create_time DateTime)engine=RepilicatedMergeTree(&#x27;/clickhouse/tables/&#123;shard&#125;/st_order_1109&#x27;, &#x27;&#123;replica&#125;&#x27;)patition by toYYYYMMDD(create_time)primary key(id)order by(id,sku_id);\n参数含义：集群名， 集群配置里面得宏定义\n\n本地表得意思是集群每个节点都创建一个表\n创建分布式表：\nCREATE TABLE st_order_mt_all on cluster gmall_cluster (    id UInt32,    sku_id String,    total_amount Decimal(16,2),    create_time DateTime)engine=Distributed(gmall_cluster,default,st_order_mt,hiveHash(sku_id));\n参数含义：集群名称，库名，本地表名，分片键统领本地表，有点视图得意思\n\n插入数据插得是分布式表，实际上存在每一张表INSERT INTO st_order_mt_all values()\n\nClickhouse执行计划官方推荐独立部署，128G硬盘 100G内存，32线程内核\n参考官文档：https://clickhouse.com/docs/zh/sql-reference/statements/explain\n语法\nEXPLAIN [AST | SYNTAX | QUERY TREE | PLAN | PIPELINE | ESTIMATE | TABLE OVERRIDE] [setting = value, ...]    [      SELECT ... |      tableFunction(...) [COLUMNS (...)] [ORDER BY ...] [PARTITION BY ...] [PRIMARY KEY] [SAMPLE BY ...] [TTL ...]    ]    [FORMAT ...]\nEXPLAIN 类型:\n\nAST — 抽象语法树。\nSYNTAX — 经 AST 级别优化后的查询文本。\nQUERY TREE — 经查询树级别优化后的查询树。\nPLAN — 查询执行计划。 （默认） \nPIPELINE — 查询执行流水线。\n\n以上实例说明该查询走了预处理文件，也就是直接读的文件资源，速度比较快。\n以上示例，对查询做了优化\n以上对三元嵌套查询做了优化\n以上对函数查询做了优化\n提升查询性能总结\n选择合适的表引擎， mergeTree是ch常见的引擎，但不意味着mergeTree适合所有的场景。\n\n建表时不要使用Nullable，因为官方已经指出了，且这种类型几乎总是拖累性能，所以建议使用一个特殊字符来表空，比如-1， 字符串null等等\n\n合适的划分分区和索引，分区是必须的，官方建议按天分区，建议自己分区的话单分区不超过100w行数据。\n\n数据变更不要太频繁，避免产生过多的临时分区，加大合并的负担，如果要修改建议少次数，大批量的更新修改。官方建议1秒左右发起一起写入操作，单词操作写入数据量保持2w-5w ，具体根据服务器性能定\n\n使用prewhere代替where，因为where是获取整行然后再过滤，而prewhere直接过滤列\n\n指定列和分区，避免select *， 减少内存消耗\n\n避免构建虚拟列，减少内存消耗比如：select income,age income&#x2F;age as incrate from xxx正例：避免虚拟列，直接写select income,age from xxx\n\n用in代替joinjoin会加载到内存，再计算消耗内存\n\n如果非要join，尽量把大表写在前面，小表写后面，这跟mysql 建议小表驱动大表相反。\n\n\n生产常见问题\n数据一致性问题\n\n\nch强调最终一致性，事务控制天生比较弱，主要源自于合并的机制，新分区合并到旧分区\n\n分布式表尽量避免使用，要用就用副本表， 分布式表网络重试问题丢消息，副本同步机制，再次启动还会同步，更稳定可靠\n\n数据合并时间不确定，不一致问题要注意，  可以定期夜间optimize final， 如果非要一致性，就用_sign _version 来标记自己用乐观锁机制保持一致性（sign标记是否删除，version标记新增）\n\n\n\n多副本表，尽量固定写入节点。因为ch 副本是同权的，  如果随机写，一个挂了依然写成功了，但是数据不对齐了，固定写入一个节点，这样挂了立马可以知道\n\nzookeeper数据丢失导致副本无法启动。\n\n\n","categories":["总结笔记"],"tags":["Clickhouse","OLAP","OLTP","列式存储","数据仓库"]},{"title":"Java 8 新特性一","url":"/2023_12_31_java/","content":"学习必须往深处挖，挖的越深，基础越扎实！\nJava 现在发布的版本很快，每年两个，但是真正会被大规模使用的是 3 年一个的 LTS 版本。\n每 3 年发布一个 LTS（Long-Term Support），长期维护版本。意味着只有Java 8 ，Java 11， Java 17，Java 21 才可能被大规模使用。\n每年发布两个正式版本，分别是 3 月份和 9 月份。\n在 Java 版本中，一个特性的发布都会经历孵化阶段、预览阶段和正式版本。其中孵化和预览可能会跨越多个 Java 版本。所以在介绍 Java 新特性时采用如下这种策略：\n\n每个版本的新特性，都会做一个简单的概述。\n单独出文介绍跟编码相关的新特性，一些如 JVM、性能优化的新特性不单独出文介绍。\n孵化阶段的新特性不出文介绍。\n首次引入为预览特性、新特性增强、首次引入的正式特性，单独出文做详细介绍。\n影响比较大的新特性如果在现阶段没有转正的新特性不单独出文介绍，单独出文的重大特性一般都在 Java 21 版本之前已转为正式特性，例如：\n虚拟线程，Java 19 引入的，在 Java 21 转正，所以在 Java 19 单独出文做详细介绍\n作用域值，Java 20 引入的，但是在 Java 21 还处于预览阶段，所以不做介绍，等将来转正后会详细介绍\n\n\n\nJava 8 新特性一JEP 101：类型推断优化简单理解泛型泛型是Java SE 1.5的新特性，泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。通俗点将就是“类型的变量”。这种类型变量可以用在类、接口和方法的创建中。\n理解Java泛型最简单的方法是把它看成一种便捷语法，能节省你某些Java类型转换(casting)上的操作:\nList box &#x3D; new ArrayList();box.add(new Apple());Apple apple &#x3D;box.get(0);\n上面的代码自身已表达的很清楚: box是一个装有Apple对象的List。get方法返回一个Apple对象实例，这个过程不需要进行类型转换。没有泛型，上面的代码需要写成这样:\nApple apple &#x3D; (Apple)box.get(0);\n泛型的尴尬泛型的最大优点是提供了程序的类型安全同时可以向后兼容，但也有尴尬的地方，就是每次定义时都要写明泛型的类型，这样显示指定不仅感觉有些冗长，最主要是很多程序员不熟悉泛型，因此很多时候不能够给出正确的类型参数，现在通过编译器自动推断泛型的参数类型，能够减少这样的情况，并提高代码可读性。\njava7的泛型类型推断改进在以前的版本中使用泛型类型，需要在声明并赋值的时候，两侧都加上泛型类型。例如:\nMap&lt;String, String&gt; myMap = new HashMap&lt;String, String&gt;();\n\n你可能觉得:老子在声明变量的的时候已经指明了参数类型，为毛还要在初始化对象时再指定? 幸好，在Java SE 7中，这种方式得以改进，现在你可以使用如下语句进行声明并赋值:\nMap&lt;String, String&gt; myMap = new HashMap&lt;&gt;(); //注意后面的&quot;&lt;&gt;&quot;\n\n在这条语句中，编译器会根据变量声明时的泛型类型自动推断出实例化HashMap时的泛型类型。再次提醒一定要注意new HashMap后面的“&lt;&gt;”，只有加上这个“&lt;&gt;”才表示是自动类型推断，否则就是非泛型类型的HashMap，并且在使用编译器编译源代码时会给出一个警告提示。\n但是: Java SE 7在创建泛型实例时的类型推断是有限制的: 只有构造器的参数化类型在上下文中被显著的声明了，才可以使用类型推断，否则不行。例如: 下面的例子在java 7无法正确编译(但现在在java8里面可以编译，因为根据方法参数来自动推断泛型的类型):\nList&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(&quot;A&quot;);// 由于addAll期望获得Collection&lt;? extends String&gt;类型的参数，因此下面的语句无法通过list.addAll(new ArrayList&lt;&gt;());\n\nJava8的泛型类型推断改进java8里面泛型的目标类型推断主要2个:\n1.支持通过方法上下文推断泛型目标类型\n2.支持在方法调用链路当中，泛型类型推断传递到最后一个方法\n让我们看看官网的例子\nclass List&lt;E&gt; &#123;   static &lt;Z&gt; List&lt;Z&gt; nil() &#123; ... &#125;;   static &lt;Z&gt; List&lt;Z&gt; cons(Z head, List&lt;Z&gt; tail) &#123; ... &#125;;   E head() &#123; ... &#125;&#125;\n根据JEP101的特性，我们在调用上面方法的时候可以这样写\n//通过方法赋值的目标参数来自动推断泛型的类型List&lt;String&gt; l = List.nil();//而不是显示的指定类型//List&lt;String&gt; l = List.&lt;String&gt;nil();//通过前面方法参数类型推断泛型的类型List.cons(42, List.nil());//而不是显示的指定类型//List.cons(42, List.&lt;Integer&gt;nil());\n\n以上是JEP101的特性内容了，Java作为静态语言的代表者，可以说类型系统相当丰富。导致类型间互相转换的问题困扰着每个java程序员，通过编译器自动推断类型的东西可以稍微缓解一下类型转换太复杂的问题。 虽然说是小进步，但对于我们天天写代码的程序员，肯定能带来巨大的作用，至少心情更愉悦了\nJEP 104：类型注解从java5开始加入这一特性，发展到现在已然是遍地开花，在很多框架中得到了广泛的使用，用来简化程序中的配置。那充满争议的类型注解究竟是什么? 复杂还是便捷?\n\n在java 8之前，注解只能是在声明的地方所使用，比如类，方法，属性；\n\njava 8里面，注解可以应用在任何地方，比如:\n\n\n创建类实例\nnew @Interned MyObject();\n\n类型映射\nmyString = (@NonNull String) str;\n\nimplements 语句中\nclass UnmodifiableList&lt;T&gt; implements @Readonly List&lt;@Readonly T&gt; &#123; … &#125;\n\nthrow exception声明\nvoid monitorTemperature() throws @Critical TemperatureException &#123; … &#125;\n\n需要注意的是，类型注解只是语法而不是语义，并不会影响java的编译时间，加载时间，以及运行时间，也就是说，编译成class文件的时候并不包含类型注解。\n类型注解的作用先看看下面代码\nCollections.emptyList().add(&quot;One&quot;);int i=Integer.parseInt(&quot;hello&quot;);System.console().readLine();\n\n上面的代码编译是通过的，但运行是会分别报UnsupportedOperationException； NumberFormatException；NullPointerException异常，这些都是runtime error；\n类型注解被用来支持在Java的程序中做强类型检查。配合插件式的check framework，可以在编译的时候检测出runtime error，以提高代码质量。这就是类型注解的作用了。\ncheck framework是第三方工具，配合Java的类型注解效果就是1+1&gt;2。它可以嵌入到javac编译器里面，可以配合ant和maven使用, 地址是http://types.cs.washington.edu/checker-framework/。 check framework可以找到类型注解出现的地方并检查，举个简单的例子:\nimport checkers.nullness.quals.*;public class GetStarted &#123;    void sample() &#123;        @NonNull Object ref = new Object();    &#125;&#125;\n\n使用javac编译上面的类\njavac -processor checkers.nullness.NullnessChecker GetStarted.java\n\n编译是通过，但如果修改成\n@NonNull Object ref = null;\n\nGetStarted.java:5: incompatible types.found   : @Nullable &lt;nulltype&gt;required: @NonNull Object        @NonNull Object ref = null;                              ^1 error\n\n类型注解向下兼容的解决方案如果你不想使用类型注解检测出来错误，则不需要processor，直接javac GetStarted.java是可以编译通过的，这是在java 8 with Type Annotation Support版本里面可以，但java 5,6,7版本都不行，因为javac编译器不知道@NonNull是什么东西，但check framework 有个向下兼容的解决方案，就是将类型注解nonnull用&#x2F;**&#x2F;注释起来，比如上面例子修改为\nimport checkers.nullness.quals.*;public class GetStarted &#123;    void sample() &#123;        /*@NonNull*/ Object ref = null;    &#125;&#125;\n\n这样javac编译器就会忽略掉注释块，但用check framework里面的javac编译器同样能够检测出nonnull错误。 通过类型注解+check framework我们可以看到，现在runtime error可以在编译时候就能找到。\n关于JSR 308JSR 308想要解决在Java 1.5注解中出现的两个问题:\n\n在句法上对注解的限制: 只能把注解写在声明的地方\n类型系统在语义上的限制: 类型系统还做不到预防所有的bug\n\nJSR 308 通过如下方法解决上述两个问题:\n\n对Java语言的句法进行扩充，允许注解出现在更多的位置上。包括: 方法接收器(method receivers，译注: 例public int size() @Readonly { … })，泛型参数，数组，类型转换，类型测试，对象创建，类型参数绑定，类继承和throws子句。其实就是类型注解，现在是java 8的一个特性\n通过引入可插拔的类型系统(pluggable type systems)能够创建功能更强大的注解处理器。类型检查器对带有类型限定注解的源码进行分析，一旦发现不匹配等错误之处就会产生警告信息。其实就是check framework\n\n对JSR308，有人反对，觉得更复杂更静态了，比如\n@NotEmpty List&lt;@NonNull String&gt; strings = new ArrayList&lt;@NonNull String&gt;()&gt;\n\n换成动态语言为\nvar strings = [&quot;one&quot;, &quot;two&quot;];\n\n有人赞成，说到底，代码才是“最根本”的文档。代码中包含的注解清楚表明了代码编写者的意图。当没有及时更新或者有遗漏的时候，恰恰是注解中包含的意图信息，最容易在其他文档中被丢失。而且将运行时的错误转到编译阶段，不但可以加速开发进程，还可以节省测试时检查bug的时间。\n总结并不是人人都喜欢这个特性，特别是动态语言比较流行的今天，所幸，java 8并不强求大家使用这个特性，反对的人可以不使用这一特性，而对代码质量有些要求比较高的人或公司可以采用JSR 308，毕竟代码才是“最基本”的文档，这句话我是赞同的。虽然代码会增多，但可以使你的代码更具有表达意义。对这个特性有何看法，大家各抒己见。。。。\nJEP 107：Stream APIStream API ( java.util.stream) 把真正的函数式编程风格引入到Java中。这是目前为止对Java类库最好的补充，因为Stream API可以极大提供Java程 序员的生产力，让程序员写出高效率、干净、简洁的代码。\nStream 是 Java8 中处理集合的关键抽象概念，它可以指定你希望对集合进行的操作，可以执行非常复杂的查找、过滤和映射数据等操作。使用 Stream API 对集合数据进行操作，就类似于使用 SQL 执行的数据库查询。 也可以使用 Stream API来并行执行操作。简言之，Stream API 提供了一种高效且易于使用的处理数据的方式。\n为什么要使用Stream API？实际开发中，项目中多数数据源都来自于Mysql，Oracle等。但现在数据源可以更多了，有MongDB，Radis等，而这些NoSQL的数据就需要Java层面去处理。\nStream 和 Collection 集合的区别：Collection 是一种静态的内存数据结构，而 Stream 是有关计算的。前者是主要面向内存，存储在内存中，后者主要是面向 CPU，通过 CPU 实现计算。\n什么是 Stream？是数据渠道，用于操作数据源（集合、数组等）所生成的元素序列。 “集合讲的是数据，Stream讲的是计算！”\n注意：\n\nStream关注的是对数据的运算，与CPU打交道，集合关注的是数据的存储，与内存打交道。\nStream 自己不会存储元素。\nStream 不会改变源对象。相反，他们会返回一个持有结果的新Stream。\nStream 操作是延迟执行的。这意味着他们会等到需要结果的时候才执行\n\nStream 操作的三个步骤\n创建 Stream\n\n一个数据源（如：集合、数组），获取一个流。\n\n\n中间操作\n\n一个中间操作链，对数据源的数据进行处理。\n\n\n终止操作(终端操作)\n\n一旦执行终止操作，就执行中间操作链，并产生结果，之后，不会再被使用。\n\n\n\n\n注意：\n\n\n一个中间操作链，对数据源的数据进行处理\n一旦执行终止操作，就执行中间操作链，并产生结果。之后，不会再被使用\n\n\n创建Stream实例\n创建 Stream方式一：通过集合\n\nJava8 中的 Collection 接口被扩展，提供了两个获取流的方法：\n\n\n\n方法\n描述\n\n\n\ndefault Stream stream()\n返回一个顺序流\n\n\ndefault Stream parallelStream()\n返回一个并行流\n\n\n代码演示：\n//创建 Stream方式一：通过集合    @Test    public void test1()&#123;        List&lt;Employee&gt; employees = EmployeeData.getEmployees();//        default Stream&lt;E&gt; stream() : 返回一个顺序流        Stream&lt;Employee&gt; stream = employees.stream();//        default Stream&lt;E&gt; parallelStream() : 返回一个并行流        Stream&lt;Employee&gt; parallelStream = employees.parallelStream();    &#125;\n\n\n创建 Stream方式二：通过数组\n\nJava8 中的 Arrays 的静态方法 stream() 可以获取数组流：\n\n\n\n方法\n描述\n\n\n\nstatic  Stream stream(T[] array)\n返回一个流\n\n\npublic static IntStream stream(int[] array)\n返回一个 int 型流\n\n\npublic static LongStream stream(long[] array)\n返回一个 long 型流\n\n\npublic static DoubleStream stream(double[] array)\n返回一个 double 型流\n\n\n代码演示：\n//创建 Stream方式二：通过数组    @Test    public void test2()&#123;        int[] arr = new int[]&#123;1,2,3,4,5,6&#125;;        //调用Arrays类的static &lt;T&gt; Stream&lt;T&gt; stream(T[] array): 返回一个流        IntStream stream = Arrays.stream(arr);        Employee e1 = new Employee(1001,&quot;Tom&quot;);        Employee e2 = new Employee(1002,&quot;Jerry&quot;);        Employee[] arr1 = new Employee[]&#123;e1,e2&#125;;        Stream&lt;Employee&gt; stream1 = Arrays.stream(arr1);    &#125;\n\n\n创建 Stream方式三：通过Stream的of()\n\n可以调用Stream类静态方法 of(), 通过显示值创建一个流。它可以接收任意数量的参数。\n\n\n\n方法\n描述\n\n\n\nspublic static Stream of(T… values)\n返回一个流\n\n\n代码演示：\n//创建 Stream方式三：通过Stream的of()    @Test    public void test3()&#123;        Stream&lt;Integer&gt; stream = Stream.of(1, 2, 3, 4, 5, 6);    &#125;\n\n\n创建 Stream方式四：创建无限流\n\n可以使用静态方法 Stream.iterate() 和 Stream.generate(), 创建无限流。\n\n\n\n方法\n描述\n\n\n\npublic static Stream iterate(final T seed, final UnaryOperator f)\n迭代\n\n\npublic static Stream generate(Supplier s)\n生成\n\n\n代码演示：\n    //创建 Stream方式四：创建无限流    @Test    public void test4()&#123;//      迭代//      public static&lt;T&gt; Stream&lt;T&gt; iterate(final T seed, final UnaryOperator&lt;T&gt; f)        //遍历前10个偶数        Stream.iterate(0, t -&gt; t + 2).limit(10).forEach(System.out::println);//      生成//      public static&lt;T&gt; Stream&lt;T&gt; generate(Supplier&lt;T&gt; s)        Stream.generate(Math::random).limit(10).forEach(System.out::println);    &#125;\n\nStream 的中间操作多个中间操作可以连接起来形成一个流水线，除非流水线上触发终止 操作，否则中间操作不会执行任何的处理！而在终止操作时一次性全部处理，称为“惰性求值”。\n\n筛选与切片\n\n\n\n\n方法\n描述\n\n\n\nfilter(Predicate p)\n接收 Lambda， 从流中排除某些元素\n\n\ndistinct()\n筛选，通过流所生成元素的 hashCode() 和 equals() 去除重复元素\n\n\nlimit(long maxSize)\n截断流，使其元素不超过给定数量\n\n\nskip(long n)\n跳过元素，返回一个扔掉了前 n个元素的流。若流中元素不足 n个，则返回一个空流。与 limit(n) 互补\n\n\n代码演示：\n//1-筛选与切片    @Test    public void test1()&#123;        List&lt;Employee&gt; list = EmployeeData.getEmployees();//        filter(Predicate p)——接收 Lambda ， 从流中排除某些元素。        Stream&lt;Employee&gt; stream = list.stream();        //练习：查询员工表中薪资大于7000的员工信息        stream.filter(e -&gt; e.getSalary() &gt; 7000).forEach(System.out::println);        System.out.println();//        limit(n)——截断流，使其元素不超过给定数量。        list.stream().limit(3).forEach(System.out::println);        System.out.println();//        skip(n) —— 跳过元素，返回一个扔掉了前 n 个元素的流。若流中元素不足 n 个，则返回一个空流。与 limit(n) 互补        list.stream().skip(3).forEach(System.out::println);        System.out.println();//        distinct()——筛选，通过流所生成元素的 hashCode() 和 equals() 去除重复元素        list.add(new Employee(1010,&quot;刘强东&quot;,40,8000));        list.add(new Employee(1010,&quot;刘强东&quot;,41,8000));        list.add(new Employee(1010,&quot;刘强东&quot;,40,8000));        list.add(new Employee(1010,&quot;刘强东&quot;,40,8000));        list.add(new Employee(1010,&quot;刘强东&quot;,40,8000));//        System.out.println(list);        list.stream().distinct().forEach(System.out::println);    &#125;\n\n\n映射\n\n\n\n\n方法\n描述\n\n\n\nmap(Function f)\n接收一个函数作为参数，该函数会被应用到每个元素上，并将其映射成一个新的元素。\n\n\nmapToDouble(ToDoubleFunction f)\n接收一个函数作为参数，该函数会被应用到每个元素上，产生一个新的 DoubleStream。\n\n\nmapToInt(ToIntFunction f)\n接收一个函数作为参数，该函数会被应用到每个元素上，产生一个新的 IntStream。\n\n\nmapToLong(ToLongFunction f)\n接收一个函数作为参数，该函数会被应用到每个元素上，产生一个新的 LongStream。\n\n\nflatMap(Function f)\n接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流。\n\n\n代码演示：\n //映射    @Test    public void test2()&#123;//        map(Function f)——接收一个函数作为参数，将元素转换成其他形式或提取信息，该函数会被应用到每个元素上，并将其映射成一个新的元素。        List&lt;String&gt; list = Arrays.asList(&quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;, &quot;dd&quot;);        list.stream().map(str -&gt; str.toUpperCase()).forEach(System.out::println);//        练习1：获取员工姓名长度大于3的员工的姓名。        List&lt;Employee&gt; employees = EmployeeData.getEmployees();        Stream&lt;String&gt; namesStream = employees.stream().map(Employee::getName);        namesStream.filter(name -&gt; name.length() &gt; 3).forEach(System.out::println);        System.out.println();        //练习2：        Stream&lt;Stream&lt;Character&gt;&gt; streamStream = list.stream().map(StreamAPITest1::fromStringToStream);        streamStream.forEach(s -&gt;&#123;            s.forEach(System.out::println);        &#125;);        System.out.println();//        flatMap(Function f)——接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流。        Stream&lt;Character&gt; characterStream = list.stream().flatMap(StreamAPITest1::fromStringToStream);        characterStream.forEach(System.out::println);    &#125;    //将字符串中的多个字符构成的集合转换为对应的Stream的实例    public static Stream&lt;Character&gt; fromStringToStream(String str)&#123;//aa        ArrayList&lt;Character&gt; list = new ArrayList&lt;&gt;();        for(Character c : str.toCharArray())&#123;            list.add(c);        &#125;       return list.stream();    &#125;    @Test    public void test3()&#123;        ArrayList list1 = new ArrayList();        list1.add(1);        list1.add(2);        list1.add(3);        ArrayList list2 = new ArrayList();        list2.add(4);        list2.add(5);        list2.add(6);//        list1.add(list2);        list1.addAll(list2);        System.out.println(list1);    &#125;\n\n\n排序\n\n\n\n\n方法\n描述\n\n\n\nsorted()\n产生一个新流，其中按自然顺序排序。\n\n\nsorted(Comparator com)\n产生一个新流，其中按比较器顺序排序。\n\n\n代码演示：\n//3-排序    @Test    public void test4()&#123;//        sorted()——自然排序        List&lt;Integer&gt; list = Arrays.asList(12, 43, 65, 34, 87, 0, -98, 7);        list.stream().sorted().forEach(System.out::println);        //抛异常，原因:Employee没有实现Comparable接口//        List&lt;Employee&gt; employees = EmployeeData.getEmployees();//        employees.stream().sorted().forEach(System.out::println);//        sorted(Comparator com)——定制排序        List&lt;Employee&gt; employees = EmployeeData.getEmployees();        employees.stream().sorted( (e1,e2) -&gt; &#123;           int ageValue = Integer.compare(e1.getAge(),e2.getAge());           if(ageValue != 0)&#123;               return ageValue;           &#125;else&#123;               return -Double.compare(e1.getSalary(),e2.getSalary());           &#125;        &#125;).forEach(System.out::println);    &#125;\n\nStream 的终止操作\n终端操作会从流的流水线生成结果。其结果可以是任何不是流的值，例 如：List、Integer，甚至是 void 。\n\n\n流进行了终止操作后，不能再次使用。\n\n\n匹配与查找\n\n\n\n\n方法\n描述\n\n\n\nallMatch(Predicate p)\n检查是否匹配所有元素。\n\n\nanyMatch(Predicate p)\n检查是否至少匹配一个元素。\n\n\nnoneMatch(Predicate p)\n检查是否没有匹配所有元素\n\n\nfindFirst()\n返回第一个元素\n\n\nfindAny()\n返回当前流中的任意元素\n\n\ncount()\n返回流中元素总数\n\n\nmax(Comparator c)\n返回流中最大值\n\n\nmin(Comparator c)\n返回流中最小值\n\n\nforEach(Consumer c)\n内部迭代(使用 Collection 接口需要用户去做迭代，称为外部迭代。相反，Stream API 使用内部迭代——它帮你把迭代做了)\n\n\n代码演示：\n //1-匹配与查找    @Test    public void test1()&#123;        List&lt;Employee&gt; employees = EmployeeData.getEmployees();//        allMatch(Predicate p)——检查是否匹配所有元素。//          练习：是否所有的员工的年龄都大于18        boolean allMatch = employees.stream().allMatch(e -&gt; e.getAge() &gt; 18);        System.out.println(allMatch);//        anyMatch(Predicate p)——检查是否至少匹配一个元素。//         练习：是否存在员工的工资大于 10000        boolean anyMatch = employees.stream().anyMatch(e -&gt; e.getSalary() &gt; 10000);        System.out.println(anyMatch);//        noneMatch(Predicate p)——检查是否没有匹配的元素。//          练习：是否存在员工姓“雷”        boolean noneMatch = employees.stream().noneMatch(e -&gt; e.getName().startsWith(&quot;雷&quot;));        System.out.println(noneMatch);//        findFirst——返回第一个元素        Optional&lt;Employee&gt; employee = employees.stream().findFirst();        System.out.println(employee);//        findAny——返回当前流中的任意元素        Optional&lt;Employee&gt; employee1 = employees.parallelStream().findAny();        System.out.println(employee1);    &#125;    @Test    public void test2()&#123;        List&lt;Employee&gt; employees = EmployeeData.getEmployees();        // count——返回流中元素的总个数        long count = employees.stream().filter(e -&gt; e.getSalary() &gt; 5000).count();        System.out.println(count);//        max(Comparator c)——返回流中最大值//        练习：返回最高的工资：        Stream&lt;Double&gt; salaryStream = employees.stream().map(e -&gt; e.getSalary());        Optional&lt;Double&gt; maxSalary = salaryStream.max(Double::compare);        System.out.println(maxSalary);//        min(Comparator c)——返回流中最小值//        练习：返回最低工资的员工        Optional&lt;Employee&gt; employee = employees.stream().min((e1, e2) -&gt; Double.compare(e1.getSalary(), e2.getSalary()));        System.out.println(employee);        System.out.println();//        forEach(Consumer c)——内部迭代        employees.stream().forEach(System.out::println);        //使用集合的遍历操作        employees.forEach(System.out::println);    &#125;\n\n\n归约\n\n\n\n\n方法\n描述\n\n\n\nreduce(T iden, BinaryOperator b)\n可以将流中元素反复结合起来，得到一个值。返回 T\n\n\nreduce(BinaryOperator b)\n可以将流中元素反复结合起来，得到一个值。返回 Optional\n\n\n代码演示：\n//2-归约    @Test    public void test3()&#123;//        reduce(T identity, BinaryOperator)——可以将流中元素反复结合起来，得到一个值。返回 T//        练习1：计算1-10的自然数的和        List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5,6,7,8,9,10);        Integer sum = list.stream().reduce(0, Integer::sum);        System.out.println(sum);//        reduce(BinaryOperator) ——可以将流中元素反复结合起来，得到一个值。返回 Optional&lt;T&gt;//        练习2：计算公司所有员工工资的总和        List&lt;Employee&gt; employees = EmployeeData.getEmployees();        Stream&lt;Double&gt; salaryStream = employees.stream().map(Employee::getSalary);//        Optional&lt;Double&gt; sumMoney = salaryStream.reduce(Double::sum);        Optional&lt;Double&gt; sumMoney = salaryStream.reduce((d1,d2) -&gt; d1 + d2);        System.out.println(sumMoney.get());    &#125;\n\n\n收集\n\n\n\n\n方法\n描述\n\n\n\ncollect(Collector c)\n将流转换为其他形式。接收一个 Collector接口的实现，用于给Stream中元素做汇总的方法\n\n\nCollector 接口中方法的实现决定了如何对流执行收集的操作(如收集到 List、Set、Map)。\n另外， Collectors 实用类提供了很多静态方法，可以方便地创建常见收集器实例，具体方法参考文档：https://www.matools.com/api/java8\n代码演示：\n//3-收集    @Test    public void test4()&#123;//        collect(Collector c)——将流转换为其他形式。接收一个 Collector接口的实现，用于给Stream中元素做汇总的方法//        练习1：查找工资大于6000的员工，结果返回为一个List或Set        List&lt;Employee&gt; employees = EmployeeData.getEmployees();        List&lt;Employee&gt; employeeList = employees.stream().filter(e -&gt; e.getSalary() &gt; 6000).collect(Collectors.toList());        employeeList.forEach(System.out::println);        System.out.println();        Set&lt;Employee&gt; employeeSet = employees.stream().filter(e -&gt; e.getSalary() &gt; 6000).collect(Collectors.toSet());        employeeSet.forEach(System.out::println);    &#125;\n\n","categories":["总结笔记"],"tags":["Java8","类型推断","类型注解","Java Stream"]},{"title":"Java 8 新特性二","url":"/2024_01_02_java/","content":"学习必须往深处挖，挖的越深，基础越扎实！\nJava 现在发布的版本很快，每年两个，但是真正会被大规模使用的是 3 年一个的 LTS 版本。\n每 3 年发布一个 LTS（Long-Term Support），长期维护版本。意味着只有Java 8 ，Java 11， Java 17，Java 21 才可能被大规模使用。\n每年发布两个正式版本，分别是 3 月份和 9 月份。\n在 Java 版本中，一个特性的发布都会经历孵化阶段、预览阶段和正式版本。其中孵化和预览可能会跨越多个 Java 版本。所以在介绍 Java 新特性时采用如下这种策略：\n\n每个版本的新特性，都会做一个简单的概述。\n单独出文介绍跟编码相关的新特性，一些如 JVM、性能优化的新特性不单独出文介绍。\n孵化阶段的新特性不出文介绍。\n首次引入为预览特性、新特性增强、首次引入的正式特性，单独出文做详细介绍。\n影响比较大的新特性如果在现阶段没有转正的新特性不单独出文介绍，单独出文的重大特性一般都在 Java 21 版本之前已转为正式特性，例如：\n虚拟线程，Java 19 引入的，在 Java 21 转正，所以在 Java 19 单独出文做详细介绍\n作用域值，Java 20 引入的，但是在 Java 21 还处于预览阶段，所以不做介绍，等将来转正后会详细介绍\n\n\n\nJEP 120：重复注解@Repeatable官方文档:https://openjdk.org/jeps/120\nJava 8 之前如何使用重复注在 Java 8 之前我们是无法在一个类型重复使用多次同一个注解，比如我们常用的 @PropertySource，如果我们在 Java 8 版本以下这样使用：\n@PropertySource(&quot;classpath:config.properties&quot;)@PropertySource(&quot;classpath:application.properties&quot;)public class PropertyTest &#123;&#125;\n\n编译会报错，错误信息是：Duplicate annotation。\n那怎么解决这个问题呢？在 Java 8 之前想到一个方案来解决 Duplicate annotation 错误：新增一个注解 @PropertySources，该注解包裹 @PropertySource，如下：\npublic @interface PropertySources &#123;   PropertySource[] value();&#125;\n\n然后就可以利用 @PropertySources 来完成了：\n@PropertySources(&#123;  @PropertySource(&quot;classpath:config.properties&quot;),  @PropertySource(&quot;classpath:application.properties&quot;)     &#125;)public class PropertyTest &#123;&#125;\n\n利用这种嵌套的方式来规避重复注解的问题，怎么获取呢？\n    @Test    public void  test() &#123;        PropertySources propertySources = PropertyTest.class.getAnnotation(PropertySources.class);        for (PropertySource propertySource : propertySources.value()) &#123;            System.out.println(propertySource.value()[0]);        &#125;    &#125;// 结果......classpath:config.propertiesclasspath:application.properties\n\nJava 8 重复注解 @Repeatable通过上述那种方式确实是可以解决重复注解的问题，但是使用有点儿啰嗦，所以 Java 8 为了解决这个问题引入了注解 @Repeatable 来解决这个问题。\n@Repeatable 注解允许在同一个类型上多次使用相同的注解，它提供了更灵活的注解使用方式。\n下面我们来看看如何使用重复注解。\n\n重复注解声明在使用重复注解之前，需要在自定义注解类型上使用@Repeatable注解，以指定该注解可重复使用的容器注解类型。容器注解类型本身也是一个注解，通常具有一个value属性，其值是一个数组，用于存储重复使用的注解。\n\n@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Repeatable(MyAnnotations.class)        // 声明重复注解public @interface MyAnnotation &#123;    String name() default &quot;&quot;;&#125; /** * 重复注解容器 */@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)public @interface MyAnnotations &#123;    MyAnnotation[] value();&#125; \n\n\n使用重复注解定义了重复注解，我们就可以在一个类型上面使用多个相同的注解，如下：\n\n@MyAnnotation(name = &quot;死磕 Java 并发&quot;)@MyAnnotation(name = &quot;死磕 Netty&quot;)@MyAnnotation(name = &quot;死磕 Redis&quot;)@MyAnnotation(name = &quot;死磕 Java 基础&quot;)@MyAnnotation(name = &quot;死磕 Redis&quot;)public class MyAnnotationTest &#123;&#125;\n\n\n获取重复注解的值使用放射获取元素上面的重复注解，由于我们这里有多个所以需要根据 getAnnotationsByType() 来获取所有重复注解的数组：\n\n@Testpublic void test() &#123;    MyAnnotation[] myAnnotations = MyAnnotationTest.class.getAnnotationsByType(MyAnnotation.class);    for (MyAnnotation myAnnotation : myAnnotations) &#123;        System.out.println(myAnnotation.name());    &#125;&#125;\n\n我们还可以直接获取它的容器注解：\n@Testpublic void test() &#123;    MyAnnotations myAnnotations = MyAnnotationTest.class.getAnnotation(MyAnnotations.class);    for (MyAnnotation myAnnotation : myAnnotations.value()) &#123;        System.out.println(myAnnotation.name());    &#125;&#125;\n\n重复注解很容易就理解了，知道如何自定义注解，然后变换下思路就行了。\nJEP 122：移除Permgen\n官方文档https://openjdk.org/jeps/122\n\n摘要从 Hotspot JVM 中移除永久代，从而不再需要调整永久代的大小。\n\n非目标将类数据共享扩展到应用程序类。减少类元数据所需的内存。启用类元数据的异步收集。\n\n成功指标类元数据、已驻留字符串和类静态变量将从永久代移动到 Java 堆或本地内存中。\n\n\n将从 Hotspot JVM 中移除永久代的代码。\n根据尚未选定的基准测试集测量，应用程序的启动时间和占用空间不会增加超过 1%。\n\n动机这是 JRockit 和 Hotspot 融合工作的一部分。JRockit 客户无需配置永久代（因为 JRockit 没有永久代），并且习惯于不配置永久代。\n\n描述将 Hotspot 中永久代的部分内容移动到 Java 堆，其余部分移动到本地内存。\n\n\nHotspot 对 Java 类（此处称为类元数据）的表示当前存储在 Java 堆的一部分中，该部分称为永久代。此外，已驻留字符串和类静态变量也存储在永久代中。永久代由 Hotspot 管理，并且必须为 Java 应用程序使用的所有类元数据、已驻留字符串和类静态变量提供足够的空间。当加载类时，类元数据和静态变量在永久代中分配，并在卸载类时从永久代中垃圾回收。当永久代进行垃圾回收时，已驻留字符串也会被垃圾回收。\n提议的实现将在本地内存中分配类元数据，并将已驻留字符串和类静态变量移动到 Java 堆。Hotspot 将显式地为类元数据分配和释放本地内存。新类元数据的分配将受可用本地内存量的限制，而不是由-XX:MaxPermSize 的值（无论是默认值还是命令行上指定的值）固定。\n类元数据的本地内存分配将以足够大的块进行，以便能够容纳多个类元数据片段。每个块将与一个类加载器相关联，并且由该类加载器加载的所有类元数据都将由 Hotspot 从该类加载器的块中分配。如有需要，将为类加载器分配额外的块。块的大小将根据应用程序的行为而变化。将选择这些大小以限制内部和外部碎片。当类加载器死亡时，将释放与该类加载器相关联的所有块，从而释放类元数据的空间。在类的生命周期内，类元数据不会被移动。\nJEP 126：Lambda 表达式&amp;函数式接口\n官方文档https://openjdk.org/jeps/126\n\n摘要添加lambda表达式 (闭包) 和支持功能，包括 方法引用、增强的类型推断和虚拟扩展 方法，以Java编程语言和平台。\n\n目标lambda表达式和虚拟扩展的主要功能 方法，以及它们的一组辅助支持功能， 更多平台目标:\n\n\n简化了更抽象的创造和消费， 更高性能的库通过迁移兼容性支持更平滑的库演进除了为Java编程语言添加一个现在常见的功能之外， lambda表达式为改进多核支持提供了可能性 通过启用内部迭代成语。\n围绕lambda的支持语言功能包括虚拟扩展 方法,这将允许接口在源和二进制文件中进化 兼容时尚。\n除了语言更改，协调库和JVM更改 也会发生。\n请注意，活动的和正在进行的 项目LambdaOpenJDK项目 早于JEP进程，相应的JSR也是如此， JSR 335,这是有针对性的 对于Java SE 8 (JSR 336)。\n\n非目标函数类型和一般控制的语言特征 抽象是不将lambda表达式添加到Java的目标。 然而，目的是不排除增加这样的 未来的特点。\n\n动机许多其他常用的面向对象编程语言， 包括托管在JVM上的那些 (例如Groovy、Ruby和 Scala) 和托管在其他虚拟机 (CLR上的C #) 上，包括 支持闭包。因此，Java程序员越来越 熟悉语言功能和编程模型 启用。\n\n\n特别感兴趣的是启用以下成语内部迭代。 数组和集合当前支持外部迭代,在哪里 迭代的控制逻辑位于数据结构之外 被穿越。例如，afor-数组上的每个循环或 集合是外部迭代的一个例子。的语义 forJava中的循环要求严格的串行迭代，这意味着 程序员对标准进行迭代的唯一手段 集合将不允许使用所有可用的内核。\n通过内部迭代，数据结构被传递一段代码 来执行，作为lambda表达式，数据结构为 负责划分计算并报告 结果。由于数据结构熟悉其自身的内部 详细信息，它可能会选择一个更好的调度 通过调整选项进行计算，例如\n备用执行顺序使用线程池的并发执行使用分区和工作窃取的并行执行。的 fork&#x2F;join框架, 在Java SE 7中添加的是一个这样的候选并行执行框架，并且 在广泛的核心范围内提供性能稳定的工作分区 计数。内部迭代样式的一个典型示例是序列 filter-map-reduce操作，例如:\nint maxFooWeight =    collection.filter( /* isFoo Predicate as a lambda */)              .map(    /* Map a Foo to its weight with a lambda */)              .max();  /* Reduction step */\nlambda表达式是具有简洁语法的表达式，用于 表示所需的操作。此样式代替一个或多个 显式for循环，这将不必要的约束迭代 订购收藏品。此外，设计良好的算法可以 不仅可以并行执行这些操作集，而且还可以 将这三个操作聚合到一个并行过程中。\n项目Lambda还包括虚拟扩展方法，这将 解决长期存在的无法添加方法的限制 到广泛使用的接口，因为源兼容性问题。\n通过向现有的集合接口添加扩展方法， 如java.util.Collection和java.util.List,现有 这些类型的实现可以参与新的编程 成语。JDK (和其他地方) 中这些类型的实现可以 重写扩展方法的默认实现 超级接口，以提供更高性能或以其他方式专用 实现。\n\n使用Lambda表达式和匿名内部类\n\nJEP 126：接口的默认方法Java 8 用默认方法与静态方法这两个新概念来扩展接口的声明。默认方法使接口有点像 Traits（Scala 中特征（trait）类似于 Java 中的 Interface，但它可以包含实现代码，也就是目前 Java 8 新增的功能），但与传统的接口又有些不一样，它允许在已有的接口中添加新方法，而同时又保持了与旧版本代码的兼容性。\n默认方法与抽象方法不同之处在于抽象方法必须要求实现，但是默认方法则没有这个要求。相反，每个接口都必须提供一个所谓的默认实现，这样所有的接口实现者将会默认继承它（如果有必要的话，可以覆盖这个默认实现）。让我们看看下面的例子：\npackage h.xd.java8;public class Main &#123;    public static void main(String[] args) &#123;        System.out.println(new DefaultableImpl().notRequired());        System.out.println(new OverridableImpl().notRequired());    &#125;&#125;interface Defaulable &#123;    // Interfaces now allow default methods, the implementer may or    // may not implement (override) them.    default String notRequired() &#123;        return &quot;Default implementation&quot;;    &#125;&#125;class DefaultableImpl implements Defaulable &#123;&#125;class OverridableImpl implements Defaulable &#123;    @Override    public String notRequired() &#123;        return &quot;Overridden implementation&quot;;    &#125;&#125;\n\nDefaulable 接口用关键字 default 声明了一个默认方法 notRequired()，Defaulable 接口的实现者之一 DefaultableImpl 实现了这个接口，并且让默认方法保持原样。Defaulable 接口的另一个实现者 OverridableImpl 用自己的方法覆盖了默认方法。\nJava 8 带来的另一个有趣的特性是接口可以声明（并且可以提供实现）静态方法。例如：\ninterface DefaulableFactory &#123;    // Interfaces now allow static methods    static Defaulable create( Supplier&lt; Defaulable &gt; supplier ) &#123;        return supplier.get();    &#125;&#125;\n\n下面的一小段代码片段把上面的默认方法与静态方法黏合到一起。\npackage h.xd.java8;import java.util.function.Supplier;public class Main &#123;    public static void main( String[] args ) &#123;        Defaulable defaulable = DefaulableFactory.create( DefaultableImpl::new );        System.out.println( defaulable.notRequired() );        defaulable = DefaulableFactory.create( OverridableImpl::new );        System.out.println( defaulable.notRequired() );    &#125;&#125;interface Defaulable &#123;    // Interfaces now allow default methods, the implementer may or    // may not implement (override) them.    default String notRequired() &#123;        return &quot;Default implementation&quot;;    &#125;&#125;class DefaultableImpl implements Defaulable &#123;&#125;class OverridableImpl implements Defaulable &#123;    @Override    public String notRequired() &#123;        return &quot;Overridden implementation&quot;;    &#125;&#125;interface DefaulableFactory &#123;    // Interfaces now allow static methods    static Defaulable create( Supplier&lt; Defaulable &gt; supplier ) &#123;        return supplier.get();    &#125;&#125;\n\n这个程序的控制台输出如下：\nConnected to the target VM, address: &#x27;127.0.0.1:57010&#x27;, transport: &#x27;socket&#x27;Default implementationOverridden implementation\n\n在JVM中，默认方法的实现是非常高效的，并且通过字节码指令为方法调用提供了支持。默认方法允许继续使用现有的Java接口，而同时能够保障正常的编译过程。这方面好的例子是大量的方法被添加到 java.util.Collection 接口中去：stream()，parallelStream()，forEach()，removeIf()，……\n尽管默认方法非常强大，但是在使用默认方法时我们需要小心注意一个地方：在声明一个默认方法前，请仔细思考是不是真的有必要使用默认方法，因为默认方法会带给程序歧义，并且在复杂的继承体系中容易产生编译错误。更多详情请参考官方文档。\nJEP 150：新的日期时间 API &amp;&amp; 日期时间格式化JDK8之前，Java的日期和时间API存在以下问题：\n设计很差：在java.util和java.sql中都有日期类，java.util.Date同时包含日期和时间，而java.sql.Date仅包含日期。此外，用于格式化和解析的类定义在java.text包中。非线程安全：java.util.Date是非线程安全的，所有的日期类都是可变的，这是Java日期类的最大问题之一。时区处理麻烦：日期类并不提供国际化，没有时区支持，虽然后来引入了java.util.Calendar和java.util.TimeZone类，但他们也存在上述所有问题。\n为了解决这些问题，JDK8借鉴了Joda Time的设计，引入了一套全新的日期和时间API，这些API设计合理，线程安全，都位于java.time包中，下面是一些关键类。\nLocalDate：表示日期，包含年月日，格式为 2024-01-02LocalTime：表示时间，包含时分秒，格式为 23:01:28.123456789LocalDateTime：表示日期时间，包含年月日 时分秒，格式为 2024-01-02T23:01:28.123456789DateTimeFormatter：日期时间的格式化类Instant：时间戳，表示时间线上的一个特定瞬间Period：用于计算2个日期（LocalDate）的距离Duration：用于计算2个时间（LocalTime）的距离ZonedDateTime：包含时区的时间\n\nJava使用的日历系统是ISO 8601，它是世界民用历法，也就是通常讲的公历。平年有365天，闰年有366天。\nLocalDate、LocalTime、LocalDateTime类的实例是不可变对象，分别表示ISO 8601日历系统的日期、时间、日期和时间。他们提供了简单的日期或时间，并不包含当前的时间信息，也不包含与时区相关的信息。\nLocalDate日期，格式为：2024-01-02。\n// 获取当前日期LocalDate nowDay = LocalDate.now();// 创建指定日期LocalDate theDay = LocalDate.of(2024, 1, 2);// 获取LocalDateTime对象的日期LocalDate dayFromDateTime = LocalDate.from(LocalDateTime.now());// 解析字符串获取日期LocalDate parsedDay = LocalDate.parse(&quot;2024-01-02&quot;);// 获取LocalDate对象调整后的日期LocalDate nextMonday = theDay.with(TemporalAdjusters.next(DayOfWeek.MONDAY));// 获取日期信息System.out.println(&quot;年：&quot; + nowDay.getYear());System.out.println(&quot;月：&quot; + nowDay.getMonthValue());System.out.println(&quot;日：&quot; + nowDay.getDayOfMonth());System.out.println(&quot;星期：&quot; + nowDay.getDayOfWeek().getValue());// 是否为闰年nowDay.isLeapYear();// 修改日期nowDay.plusYears(1);nowDay.plusMonths(1);nowDay.plusWeeks(1);nowDay.plusDays(2);nowDay.minusYears(1);nowDay.minusMonths(1);nowDay.minusWeeks(1);nowDay.minusDays(2);// 日期比较nowDay.isBefore(tomorrow); // truenowDay.isEqual(tomorrow);  // falsenowDay.isAfter(tomorrow);  // false\n\n\nLocalTime时间，格式为：23:01:28.123456789。\n// 获取当前时间LocalTime now = LocalTime.now();// 创建指定时间LocalTime theTime = LocalTime.of(18, 20, 16);// 获取LocalDateTime对象的时间LocalTime TimeFromDateTime = LocalTime.from(LocalDateTime.now());// 解析字符串获取时间LocalTime parsedTime = LocalTime.parse(&quot;22:25:05&quot;);// 获取LocalTime对象调整后的时间theTime.withHour(20);theTime.withMinute(30);theTime.withMinute(15);// 获取时间信息System.out.println(&quot;时：&quot; + now.getHour());System.out.println(&quot;分：&quot; + now.getMinute());System.out.println(&quot;秒：&quot; + now.getSecond());System.out.println(&quot;纳秒：&quot; + now.getNano());// 修改时间now.plusHours(1);now.plusMinutes(1);now.plusSeconds(10);now.plusNanos(1000);now.minusHours(1);now.minusMinutes(1);now.minusSeconds(10);now.minusNanos(1000);// 时间比较now.isBefore(nextHour); // truenow.isAfter(nextHour);  // falsenow.equals(nextHour);   // false\n\nLocalDateTime日期和时间，格式为：2024-01-02T22:24:05.123456789。\n// 获取当前日期时间LocalDateTime now = LocalDateTime.now();// 创建指定日期时间LocalDateTime theDateTime = LocalDateTime.of(2024, 1, 2, 22, 5, 18);// 根据另一个LocalDateTime对象创建日期时间LocalDateTime dateTimeFromAnother = LocalDateTime.from(LocalDateTime.now());// 解析字符串获取日期时间LocalDateTime parsedDateTime = LocalDateTime.parse(&quot;2024-01-02T22:29:23.787&quot;);LocalDateTime parsedDateTime = LocalDateTime.parse(&quot;2024-01-02 22:29:23&quot;,     DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;));// 获取LocalDateTime对象调整后的日期时间LocalDateTime nextMonth = now.with(TemporalAdjusters.firstDayOfNextMonth());// 获取时间信息System.out.println(&quot;年：&quot; + now.getYear());System.out.println(&quot;月：&quot; + now.getMonthValue());System.out.println(&quot;日：&quot; + now.getDayOfMonth());System.out.println(&quot;星期：&quot; + now.getDayOfWeek().getValue());System.out.println(&quot;时：&quot; + now.getHour());System.out.println(&quot;分：&quot; + now.getMinute());System.out.println(&quot;秒：&quot; + now.getSecond());System.out.println(&quot;纳秒：&quot; + now.getNano());// 格式化LocalDateTimenow.format(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;));// 桉指定时间单位保留精度now = now.truncatedTo(ChronoUnit.HOURS);// 修改LocalDateTimenow.plusYears(1);now.plusMonths(1);now.plusWeeks(1);now.plusDays(2);now.plusHours(1);now.plusMinutes(1);now.plusSeconds(10);now.plusNanos(1000);now.minusYears(1);now.minusMonths(1);now.minusWeeks(1);now.minusDays(2);now.minusHours(1);now.minusMinutes(1);now.minusSeconds(10);now.minusNanos(1000);// LocalDateTime比较now.isBefore(nextHour); // truenow.isEqual(nextHour);  // falsenow.isAfter(nextHour);  // false// LocalDateTime转为ZonedDateTimeZonedDateTime zonedDateTime = now.atZone(ZoneId.of(&quot;+08&quot;));// LocalDateTime转为OffsetDateTimeOffsetDateTime offsetDateTime = now.atOffset(ZoneOffset.ofHours(8));\n\n时间格式化与解析java.time.format.DateTimeFormatter类专门负责日期时间的格式化与解析，这个类是final的，线程安全。\nDateTimeFormatter fmt = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;);// 格式化LocalDateTime为字符串System.out.println(LocalDateTime.now().format(fmt));// 解析时间字符串LocalDateTime parsedDateTime = LocalDateTime.parse(&quot;2024-01-02 10:20:30&quot;, fmt);\n\n时间戳Instant类，时间戳，表示时间线上的一个特定瞬间。内部保存了从1970年1月1日 00:00:00以来的秒和纳秒。\n一般不是给用户使用的，而是方便程序做一些统计。\nInstant instant = Instant.now();// 当前时间戳：2024-01-02T15:51:12.068ZSystem.out.println(&quot;当前时间戳：&quot; + instant);// 1970-01-01 00:00:00 到现在的秒：1716565872System.out.println(&quot;1970-01-01 00:00:00 到现在的秒：&quot; + instant.getEpochSecond());// 1970-01-01 00:00:00 到现在的毫秒：1716565872068System.out.println(&quot;1970-01-01 00:00:00 到现在的毫秒：&quot; + instant.toEpochMilli());// 秒后面的纳秒：68000000System.out.println(&quot;秒后面的纳秒：&quot; + instant.getNano());Instant second = Instant.ofEpochSecond(1716565310);System.out.println(second); // 2024-01-02T15:41:50Z\n\n计算日期、时间差Duration：用于计算2个时间的距离；\nPeriod：用于计算2个日期的距离。\nLocalDateTime now = LocalDateTime.now();LocalDateTime nextMonday = now.with(TemporalAdjusters.next(DayOfWeek.MONDAY));// Duration 计算时间的距离Duration duration = Duration.between(now, nextMonday);System.out.println(&quot;相差的天：&quot; + duration.toDays());System.out.println(&quot;相差的小时：&quot; + duration.toHours());System.out.println(&quot;相差的分钟：&quot; + duration.toMinutes());System.out.println(&quot;相差的秒：&quot; + duration.getSeconds());System.out.println(&quot;相差的毫秒：&quot; + duration.toMillis());LocalDate today = LocalDate.now();LocalDate nextTuesday = today.with(TemporalAdjusters.next(DayOfWeek.TUESDAY));// Period 计算日期的距离Period period = Period.between(today, nextTuesday);System.out.println(&quot;相差的年：&quot; + period.getYears());System.out.println(&quot;相差的月：&quot; + period.getMonths());System.out.println(&quot;相差的天：&quot; + period.getDays());\n\n时间调整器有时候我们可能需要根据一个LocalDateTime获取它调整后的时间，比如“下个月的第2天”，“下个周三”，等等。类似的时间可以通过时间调整器获取。\nTemporalAdjuster：时间调整器接口。\nTemporalAdjusters：该类通过静态方法提供了很多常用的TemporalAdjuster的实现。\n// 将 LocalDateTime 调整到下个月第2天TemporalAdjuster secondDayOfNextMonth = temporal -&gt; &#123;\tLocalDateTime dateTime = (LocalDateTime) temporal;\treturn dateTime.plusMonths(1).withDayOfMonth(2);&#125;;LocalDateTime now = LocalDateTime.now();System.out.println(now); // 2024-01-02T12:17:01.524System.out.println(now.with(secondDayOfNextMonth)); // 2024-02-02T12:17:01.524\n\nJDK自带的时间调整器实现：\n// 当月第1天TemporalAdjusters.firstDayOfMonth()// 当月最后1天TemporalAdjusters.lastDayOfMonth()// 下月第1天TemporalAdjusters.firstDayOfNextMonth()// 当年第1天TemporalAdjusters.firstDayOfYear()// 当年最后1天TemporalAdjusters.lastDayOfYear()// 下年第1天TemporalAdjusters.firstDayOfNextYear()// 当月第1个周几TemporalAdjusters.firstInMonth(DayOfWeek dayOfWeek)// 当月最后1个周几TemporalAdjusters.lastInMonth(DayOfWeek dayOfWeek)// 当前时间之后的下1个周几TemporalAdjusters.next(DayOfWeek dayOfWeek)// 当前时间或者之后的下1个周几TemporalAdjusters.nextOrSame(DayOfWeek dayOfWeek)// 当前时间之前的上1个周几TemporalAdjusters.previous(DayOfWeek dayOfWeek)// 当前时间或者之前的上1个周几TemporalAdjusters.previousOrSame(DayOfWeek dayOfWeek)\n\n时区JDK8加入了对时区的支持，LocalDate、LocalTime、LocalDateTime是不带时区的，带时区的日期时间类分别为：ZonedDateTime。\nZoneId类包含了时区信息，每个时区对应一个ID，格式为“区域&#x2F;城市”，比如：Asia&#x2F;Shanghai。\n东八区代表的ZoneId可通过以下多种方式创建：\nZoneId.of(&quot;Asia/Shanghai&quot;);ZoneId.of(&quot;+8&quot;);ZoneId.of(&quot;+08&quot;);ZoneId.of(&quot;+08:00&quot;);ZoneId.of(&quot;UTC+8&quot;);ZoneId.of(&quot;UTC+08&quot;);ZoneId.of(&quot;UTC+08:00&quot;);\n\nZonedDateTime的使用：\n// 打印所有可用的时区ZoneId.getAvailableZoneIds().forEach(System.out::println);LocalDateTime now = LocalDateTime.now(); // 不带时区的当前时间：2024-01-02T12:42:44.550System.out.println(now);ZonedDateTime zonedNow = ZonedDateTime.now();// 当前时区的当前时间：2024-01-02T12:42:44.550+08:00[Asia/Shanghai]System.out.println(zonedNow);// UTC的当前时间：2024-01-02T04:44:39.496ZZonedDateTime utcNow = ZonedDateTime.now(Clock.systemUTC());System.out.println(utcNow);// UTC时间转为东八区时间：2024-01-02T12:44:39.496+08:00ZonedDateTime utc8Now = utcNow.withZoneSameInstant(ZoneId.of(&quot;+08&quot;));System.out.println(utc8Now);\n\nJEP 174：Nashorn JavaScript 引擎官方文档：https://openjdk.org/jeps/174\njava重执行js脚本的引擎\n摘要设计和实现一个新的轻量级，高性能的实现 的JavaScript，并将其集成到JDK中。新引擎将 通过现有的可用于Java应用程序javax.scriptAPI, 也更一般地通过一个新的命令行工具。\n目标Nashorn将基于ECMAScript-262版5.1语言 规范，并且必须通过ECMAScript-262符合性测试。\nNashorn将支持javax.script(JSR 223) API。\n将提供从JavaScript调用Java代码的支持 为Java调用JavaScript代码。这包括直接映射到 JavaBeans。\nNashorn将定义一个新的命令行工具，jjs,用于评估 “shebang” 脚本中的JavaScript代码，此处文档和编辑 字符串。\nNashorn应用程序的性能和内存使用情况应该是 比犀牛好得多。\nNashorn不会暴露任何额外的安全风险。\n提供的库应在本地化下正确运行。\n错误消息和文档将被国际化。\nJEP 179：方法引用和构造器引用参考lambda表达式介绍\n利用 Optional 解决NullPointerException全新的、标准的 Base64 API","categories":["总结笔记"],"tags":["Java8","Java-@Repeatable"]},{"title":"重温滕王阁","url":"/2017_05_11_tengwanggexu/","content":"读《滕王阁序》，我会在开始时同情王勃的遭遇；然而，读至“老当益壮，宁移白首之心，穷且益坚，不坠青云之志”时，我便渐渐由同情变为了赞赏与佩服。这篇骈文是才华横溢的才子王勃仕途终结之作，面对如此人生困境，他也能即兴诵出这等有气势的句子，实在让人可叹，可敬。今天，记录于此，留待后日继续欣赏。\n\n\n原文王勃\n豫章故郡，洪都新府。星分翼轸(zhěn)，地接衡庐。襟三江而带五湖，控蛮荆而引瓯（ōu）越。物华天宝，龙光射牛斗之墟；人杰地灵，徐孺下陈蕃之榻。雄州雾列，俊采星驰，台隍(huáng)枕夷夏之交，宾主尽东南之美。都督阎公之雅望，棨(qǐ )戟(jǐ)遥临；宇文新州之懿(yì)范，襜(chān )帷(wéi)暂驻。十旬休假，胜友如云；千里逢迎，高朋满座。腾蛟起凤，孟学士之词宗；紫电青霜，王将军之武库。家君作宰，路出名区；童子何知，躬逢胜饯。\n时维九月，序属三秋。潦（lǎo）水尽而寒潭清，烟光凝（ning)而暮山紫。俨(yǎn)骖騑(cān fēi)于上路，访风景于崇阿。临帝子之长洲，得仙人之旧馆。层峦耸翠，上出重霄；飞阁流丹，下临无地。鹤汀（tīng）凫(fú )渚，穷岛屿之萦(yíng)回；桂殿兰宫，即冈峦之体势。\n披绣闼（tà），俯雕甍(méng )。山原旷其盈视，川泽纡(yū)其骇瞩。闾(lǘ)阎(yán) 扑地，钟鸣鼎食之家；舸（gě)舰弥津，青雀黄龙之轴（zhú)。云销雨霁(jì)，彩彻区明（云衢）。落霞与孤鹜齐飞，秋水共长天一色。渔舟唱晚，响穷彭蠡（lǐ ）之滨；雁阵惊寒，声断衡阳之浦。\n遥襟俯畅，逸兴遄(chuán)飞。爽籁发而清风生，纤歌凝而白云遏(è)。睢(suī)园绿竹，气凌彭泽之樽(zūn)；邺(yè)水朱华，光照临川之笔。四美具，二难并。穷睇眄(dì miǎn)于中天，极娱游于暇日。天高地迥，觉宇宙之无穷；兴尽悲来，识盈虚之有数。望长安于日下，目吴会（kuài）于云间。地势极而南溟深，天柱高而北辰远。关山难越，谁悲失路之人；萍水相逢，尽是他乡之客。怀帝阍(hūn)而不见，奉宣室以何年？\n嗟乎！时运不齐，命途多舛(chuǎn)；冯唐易老，李广难封。屈贾谊（yì）于长沙，非无圣主；窜梁(liang)鸿于海曲，岂乏明时？所赖君子见机，达人知命。老当益壮，宁移白首之心；穷且益坚，不坠青云之志。酌贪泉而觉爽，处涸辙（hézhé）而尤欢。北海虽赊（shē），扶摇可接；东隅已逝，桑榆非晚。孟尝高洁，空余报国之情；阮籍猖狂，岂效穷途之哭？\n勃，三尺微命，一介书生，无路请缨，等终军之弱冠（guàn）；有怀投笔，慕宗悫（què）之长风。舍簪（zān）笏（hù）于百龄，奉晨昏于万里。非谢家之宝树，接孟氏之芳邻。他日趋庭，叨(tāo)陪鲤对；今晨捧袂(mèi)，喜托龙门。杨意不逢，抚凌云而自惜；钟期既遇，奏流水以何惭？\n呜呼！胜地不常，盛筵(yán)难再；兰亭已矣，梓(zi)泽(ze)丘墟。临别赠言，幸承恩于伟饯；登高作赋，是所望于群公。敢竭鄙怀，恭疏短引；一言均赋，四韵俱成；请洒潘江，各倾陆海云尔。\n译文汉代的豫章旧郡，现在称洪都府。它处在翼、轸二星的分管区域，与庐山和衡山接壤。以三江为衣襟，以五湖为腰带，控制楚地，连接瓯越。这里地上物产的精华，乃是天的宝物，宝剑的光气直射牛、斗二星之间；人有俊杰是因为地有灵秀之气，徐孺子竟然在太守陈蕃家下榻(世说新语记载，太守陈蕃赏识徐孺子，专门为其在家中设置榻，当徐孺子来的时候，就将榻放下来，徐孺子走了就将榻吊起来，此处应该是称赞滕王阁的东道主欣赏才俊，也有夸赞宾客的成分)。雄伟的州城像雾一样涌起，俊美的人才像流星一样飞驰。城池倚据在荆楚和华夏交接的地方，宴会上客人和主人都是东南一带的俊杰。声望崇高的阎都督公，（使）打着仪仗（的高人）远道而来；德行美好的宇文新州刺史，（让）驾着车马（的雅士）也在此暂时驻扎。正好赶上十日一休的假日，才华出众的朋友多得如云；迎接千里而来的客人，尊贵的朋友坐满宴席。文章的辞彩如蛟龙腾空、凤凰飞起，那是文词宗主孟学士；紫电和清霜这样的宝剑，出自王将军的武库里。家父做交趾县令，我探望父亲路过这个有名的地方；我一个小孩子知道什么，却有幸亲自遇到了这样盛大的宴会。\n时间是九月，季节为深秋。蓄积的雨水已经消尽，潭水寒冷而清澈，烟光雾气凝结，傍晚的山峦呈现出紫色。驾着豪华的马车行驶在高高的道路上，到崇山峻岭中观望风景。来到滕王营建的长洲上，看见他当年修建的楼阁。重叠的峰峦耸起一片苍翠，上达九霄；凌空架起的阁道上，朱红的油彩鲜艳欲滴，从高处往下看，地好像没有了似的。仙鹤野鸭栖止的水边平地和水中小洲，极尽岛屿曲折回环的景致；桂树与木兰建成的宫殿，随着冈峦高低起伏的态势。\n打开精美的阁门，俯瞰雕饰的屋脊，放眼远望辽阔的山原充满视野，迂回的河流湖泊使人看了惊叹。房屋排满地面，有不少官宦人家；船只布满渡口，都装饰着青雀黄龙的头形。云消雨散，阳光普照，天空明朗。落霞与孤独的野鸭一齐飞翔，秋天的江水和辽阔的天空浑然一色。渔船唱着歌傍晚回来，歌声响遍鄱阳湖畔；排成行列的大雁被寒气惊扰，叫声消失在衡阳的水边。\n远望的胸怀顿时舒畅，飘逸的兴致油然而生。排箫发出清脆的声音，引来阵阵清风；纤细的歌声仿佛凝住不散，阻止了白云的飘动。今日的宴会很像是当年睢园竹林的聚会，在座的诗人文士狂饮的气概压过了陶渊明；又有邺水的曹植咏荷花那样的才气，文采可以直射南朝诗人谢灵运。良辰、美景、赏心、乐事，四美都有，贤主、嘉宾，难得却得。放眼远望半空中，在闲暇的日子里尽情欢乐。天高地远，感到宇宙的无边无际；兴致已尽，悲随之来，认识到事物的兴衰成败有定数。远望长安在夕阳下，遥看吴越在云海间。地势偏远，南海深不可测；天柱高耸，北极星远远悬挂。雄关高山难以越过，有谁同情不得志的人?在座的各位如浮萍在水上相聚，都是客居异乡的人。思念皇宫却看不见，等待在宣室召见又是何年?\n唉!命运不顺畅，路途多艰险。冯唐容易老，李广封侯难。把贾谊贬到长沙，并非没有圣明的君主；让梁鸿到海边隐居，难道不是在政治昌明的时代?能够依赖的是君子察觉事物细微的先兆，通达事理的人知道社会人事的规律。老了应当更有壮志，哪能在白发苍苍时改变自己的心志?处境艰难反而更加坚强，不放弃远大崇高的志向。喝了贪泉的水，仍然觉得心清气爽；处在干涸的车辙中，还能乐观开朗。北海虽然遥远，乘着旋风仍可以到达；少年的时光虽然已经消逝，珍惜将来的岁月还不算晚。孟尝品行高洁，却空有一腔报国的热情；怎能效法阮籍狂放不羁，在无路可走时便恸哭而返?\n我，地位低下，一个书生。没有请缨报国的机会，虽然和终军的年龄相同；像班超那样有投笔从戎的胸怀，也仰慕宗悫“乘风破浪”的志愿。宁愿舍弃一生的功名富贵，到万里之外去早晚侍奉父亲。不敢说是谢玄那样的人才，却结识了诸位名家。过些天到父亲那里聆听教诲，一定要像孔鲤那样趋庭有礼，对答如流；今天举袖作揖谒见阎公，好像登上龙门一样。司马相如倘若没有遇到杨得意那样引荐的人，虽有文才也只能独自叹惋。既然遇到钟子期那样的知音，演奏高山流水的乐曲又有什么羞惭呢？\n唉!名胜的地方不能长存，盛大的宴会难以再遇。当年兰亭宴饮集会的盛况已成为陈迹了，繁华的金谷园也成为荒丘废墟。临别赠言，作为有幸参加这次盛宴的纪念；登高作赋，那就指望在座的诸公了。冒昧给大家献丑，恭敬地写下这篇小序，我的一首四韵小诗也已写成。请各位像潘岳、陆机那样，展现如江似海的文才吧。\n作者《滕王阁序》，体裁：辞赋、骈文（魏晋以来产生的一种文体，又称骈俪文。骈文是与散文相对而言的。其主要特点是以四六句式为主，讲究对仗，因句式两两相对，犹如两马并驾齐驱，故被称为骈体。在声韵上，则讲究运用平仄，韵律和谐；修辞上注重藻饰和用典。由于骈文注重形式技巧，故内容的表达往住受到束缚，但运用得当，也能增强文章的艺术效果）；作者：王勃；别名：秋日登洪府滕王阁饯别序；年代：唐朝。\n王勃（649～675年），唐代诗人。字子安。绛州龙门(今山西河津)人。王勃与杨炯、卢照邻、骆宾王以诗文齐名，并称“王杨卢骆”，亦称“初唐四杰”。王勃为隋末大儒王通的孙子（王通是隋末著名学者，号文中子），王通生二子，长名福郊，次名福峙，福峙即王勃之父，曾出任太常博士、雍州司功、交趾县令、六合县令、齐州长史等职。可知王勃生长于书香之家。\n王勃才华早露，未成年即被司刑太常伯刘祥道赞为神童，向朝廷表荐，对策高第，授朝散郎。乾封初(666年)为沛王李贤征为王府侍读，两年后因戏为《檄英王鸡》文，被高宗怒逐出府。随即出游巴蜀。咸亨三年(672年)补虢州参军，因擅杀官奴当诛，遇赦除名。其父亦受累贬为交趾令。上元二年(675年)或三年(676年)，王勃南下探亲，渡海溺水，惊悸而死。其诗力求摆脱齐梁的绮靡诗风，文也有名，著名的《滕王阁序》就出自他之手。\n写作背景滕王阁因滕王李元婴得名。李元婴是唐高祖李渊的幼子，唐太宗李世民的弟弟，骄奢淫逸，品行不端，毫无政绩可言。但他精通歌舞，善画蝴蝶，很有艺术才情。他修建滕王阁，也是为了歌舞享乐的需要。这座江南名楼建于唐朝繁盛时期，又因王勃的一篇《滕王阁序》而很快出名。韩愈在《新修滕王阁记》中说：“愈少时，则闻江南多临观之美，而滕王阁独为第一，有瑰伟绝特之称。”\n《滕王阁序》全称《秋日登洪府滕王阁饯别序》，又名《滕王阁诗序》《宴滕王阁序》，写于何时，有两种说法。唐末五代时人王定保的《唐摭言》说：“王勃著《滕王阁序》，时年十四。”那时，王勃的父亲可能任六合县(今属江苏)令，王勃赴六合经过洪州。又这篇序文中有“童子何知，躬逢胜饯”之语，也可佐证。元代辛文房《唐才子传》认为《滕王阁序》是上元二年(675)王勃前往交趾(在现在越南河内西北)看望父亲(那时他父亲任交趾县令)，路过南昌时所作。从这篇序文内容的博大、辞采的富赡来看，更像是成年作品。“童子”不一定就是指小孩，也可以是表示自己年轻无知的谦词。何况序文中有“无路请缨，等终军之弱冠”的话，“弱冠”是指二十岁。所以，关于写作时间，课文的注释解说采用后一种说法。\n《新唐书·文艺传》记滕王阁诗会为：“九月九日都督大宴滕王阁，宿命其婿作序以夸客，因出纸笔遍请客，莫敢当，至勃，泛然不辞。都督怒，起更衣，遣吏伺其文辄报。一再报，语益奇，乃矍然曰：‘天才也!’请遂成文，极欢罢。”可见当时王勃年轻气盛，才华横溢，挥毫泼墨，语惊四座的情景。\n关于王勃的生卒年，至今尚有歧说。杨炯《王勃集序》说他于唐高宗上元三年（676年）卒，年28岁。据此，王勃应生于唐太宗贞观二十三年（649年）。而王勃《春思赋》载：“咸亨二年（671年），余春秋二十有二。”据此推算，则当生于高宗永徽元年（65O年）。此为王勃自述，当可信，所以现在大多数学者认为王勃生于永徽元年（650年），卒于上元三年（676年），生年27岁。王勃是初唐诗坛上一位非常有才华的诗人，只活了27岁，确实令人痛惜。\n王勃自幼聪慧好学，为时人所公认。《旧唐书》本传谓王勃：“六岁解属文，构思无滞，词情英迈，与兄才藻相类，父友杜易简常称之曰：此王氏三珠树也。”又有杨炯《王勃集序》说：“九岁读颜氏《汉书》，撰《指瑕》十卷。十岁包综六经，成乎期月，悬然天得，自符音训。时师百年之学，旬日兼之，昔人千载之机，立谈可见。”太常伯刘公称王绩为神童。唐高宗麟德元年（664年），王勃上书右相刘祥道，中有“所以慷慨于君侯者，有气存乎心耳”之语，求刘祥道表荐。刘即表荐于朝，王勃乃应麟德三年（666年）制科，对策高第，被授予朝散郎之职。此时的王勃，才14岁，尚是一少年。\n沛王李贤闻王勃之名，召王勃为沛府修撰，十分爱重他。当时诸王经常斗鸡为乐，王勃闹着玩，写了一篇《檄周王鸡》，不料竟因此罹祸，唐高宗认为是使诸王闹矛盾，将王勃赶出沛王府。其实王勃此次受打击，并非真的因《檄周王鸡》而触怒高宗，而是因才高被嫉，所以杨炯《王勃集序》说他“临秀不容，寻反初服”。王勃被赶出沛王府后，便去游蜀，与杨炯等放旷诗酒，驰情于文场。《旧唐书·杨炯传》说：“炯与王勃、卢照邻、骆宾王以文词齐名，海内称为王杨卢骆，亦号为四杰。”\n初唐四杰，在中国文学史上是一个非常著名的集团。作为一个集团，他们反对六朝以来颓废绮丽的风气，提出一些革新意见，开始把诗文从宫廷引向市井，从台阁移到江山和边塞，题材扩大了，风格也较清新刚健，对于革除齐梁余风、开创唐诗新气象，起了重要的作用。讲中国文学史，尤其是唐代文学史，没有不讲到王杨卢骆的。\n王勃所遇到的第二次打击，是在虢州参军任上杀死自己所匿藏的官奴而犯罪。咸亨二年（671年）秋冬或第二年年初，王勃从蜀地返回长安参加科选。他的朋友凌季友当时为虢州司法，说虢州药物丰富，而他知医识药草，便为他在虢州谋得一个小小的参军之职。就在他任虢州参军期间，有个叫曹达的官奴犯罪，他将罪犯藏匿起来，后来又怕走漏风声，便杀死曹达以了其事，结果因此而犯了死罪。幸亏遇大赦，没有被处死。此事甚为蹊跷，王勃为什么要保护罪犯曹达，既藏匿保护又怎能将其杀死。据新旧《唐书》所载，王勃此次被祸，是因情才傲物，为同僚所嫉。官奴曹达事，有人怀疑为同僚设计构陷王勃，或者纯属诬陷，不无道理。总之王勃两次遭受打击，都与他的才华超人有关。\n这次被祸，虽遇赦未丢掉性命，但宣告了他仕途的终结，也连累了他的父亲。王福峙因儿子王勃犯罪，被贬为交趾县令，远谪到南荒之外。王勃远行到交趾去看望父亲，途中溺水而死，从而结束了他年轻的生命。王勃的死，是渡水时遇难不幸而死，还是自杀，无从查考，总归是怀着一腔愁愤离开人世的。\n;王勃诗文俱佳，不愧为四杰之首，在扭转齐梁余风、开创唐诗上功劳尤大，为后世留下了一些不朽名篇。他的五言律诗《送杜少府之任蜀州》，成为中国诗歌史上的杰作，久为人们所传诵，“海内存知己，天涯若比邻”已成为千古名句，至今常被人们引用。而王勃最为人所称道、千百年来被传为佳话的，是他在滕王阁即席所赋《滕王阁序》。对此事，《唐摭言》所记最详。\n上元二年（675年）秋，王勃前往交趾看望父亲，路过南昌时，正赶上都督阎伯屿新修滕王阁成，重阳日在滕王阁大宴宾客。王勃前往拜见，阎都督早闻他的名气，便请他也参加宴会。阎都督此次宴客，是为了向大家夸耀女婿孟学士的才学。让女婿事先准备好一篇序文，在席间当作即兴所作书写给大家看。宴会上，阎都督让人拿出纸笔，假意请诸人为这次盛会作序。大家知道他的用意，所以都推辞不写，而王勃以一个二十几岁的青年晚辈，竟不推辞，接过纸笔，当众挥笔而书。阎都督老大不高兴，拂衣而起，转入帐后，教人去看王勃写些什么。听说王勃开首写道“南昌故都，洪都新府”，都督便说：不过是老生常谈。又闻“星分翼轸，地接衡庐”，沉吟不语。等听到“落霞与孤骛齐飞，秋水共长天一色”，都督不得不叹服道：“此真天才，当垂不朽！”。《唐才子传》则记道：“勃欣然对客操觚，顷刻而就，文不加点，满座大惊。”\n《唐摭言》等书所记，或者有些夸张，但王勃《滕王阁序》，确实为不朽之名篇。王勃于南昌阎都督宴上赋《滕王阁序》的佳话。实乃中国文学史上最为动人的故事。《新唐书》本传说王勃“属文，初不精思，先磨墨数升，则酣饮，引被覆面卧，及寤，援笔成篇，不易一字。”唐人段成式《酉阳杂俎》也说；“王勃每为碑颂，先磨墨数升，引被覆面卧，忽起一笔数之，初不窜点，时人谓之腹稿。”据此可知王勃文思敏捷，滕王阁上即兴而赋千古名篇，并非虚传。王勃作为古代一位极富才华的作家，未及而立之年便逝去，实在是中国文学的一大损失。\n王勃虽然只活了27个春秋，但著述仍很多，曾撰《汉书指瑕》十卷，《周易发挥》五卷，《次论语》十卷，《舟中纂序》五卷，《千岁历》若干卷，可惜皆佚失。今所传者，唯《王子安集》16卷，也非全本。何林天教授点校整理的《重订新校王子安集》，收录了辑自日本的一些佚文，已由山西人民出版社出版\n艺术特色《滕王阁序》是唐人王勃用骈文写的佳作。此文内容丰富，情真意切；对仗工整，声律和谐；手法多变，格调迥异；骈散结合，语言华美。千百年来，一直被世人广为传颂。在高中教材中，此文一直为广大师生所喜爱。这里，仅就个人对文章的一点浅陋理解，将本文的艺术手法作以简要梳理。\n一、文思细密，层层扣题本文原题是《秋日登洪府滕王阁饯别序》，全文谋篇布局，无不统于题目之下。第一段概写洪州地势之雄伟，物产之华美，人才之优秀，宾主之尊贵，紧扣题目“洪府”二字。第二段先叙写清澈幽寒之水，青紫暮色之山；再写仙境般之长洲，桂殿般之楼阁，展示了一幅壮美秀丽的滕王阁秋景图，紧扣题目“秋日” 、“登滕王阁”六字。第三段写滕王阁及周围景色之美，再一次紧扣题目“滕王阁”。第四段集中笔墨写阁中宴会场面，赞文人雅士之气概和风采，特别是“四美俱，二难并”一句，对良辰、美景、赏心、乐事和贤主嘉宾作总结赞美，紧扣题目“饯”。后面三段，笔锋一转，由盛赞良辰美景、文人雅士转为慨叹人生艰难、命运多舛，表达了正视现实、奋发向上的态度。最后交代有幸参加盛会，理当应命作序，紧扣题目“饯”“序”二字。纵观全文，由地及人、由人及景、由景及情，步步递进，层层扣题。\n二、写景状物，手法多变王勃在文中运用灵活多变的手法描山绘水，将读者带入一种绝妙的佳境。    1、景情结合法。文章前半部分侧重写景，生动地展示了滕王阁壮美秀丽的图景，描绘了宴游唱和之欢乐。后半部分触景生情，反复抒发了作客他乡、怀才不遇的感慨，表达了对现实的不满。文中虽流露出相信时命运数的消极思想，但作者正视现实和奋发向上的进取精神在文中无处不在。可谓景中有情，情中见景。    2、色彩变化法。文章不惜笔墨，极力渲染，尽展色彩变化之美。如“紫电”、“青霜”、“耸翠”、“青雀”、“黄龙”、“白云”等，真可谓五光十色，摇曳生辉。特别是“潦水尽而寒潭清，烟光凝而暮山紫”一句，尽力表现出山光水色之色彩变化，上句用色淡雅，下句着色浓重，在对比中突出了秋日景象之色。    3、诗画统一法。文章第三段浓墨重彩地将滕王阁及周围景色推上了美的极致。文中写阁门美、屋宇美、山川美，写遍地宅舍、舸舰迷江、渔舟唱晚，真可谓是山清水秀、国富民强的江南风景图，特别是“落霞与孤鹜齐飞，秋水共长天一色”一句，既具有诗的意境，又兼备画的情调，想时像一幅充满诗意的大自然风景画，读时像一首妙趣绝伦的好诗，真是诗中有画，画中有诗。    4、虚实相间法。作者登高望远，不仅驰目四方，而且思接万里。文中既实写目之所见，又发挥想像，描摹目力难极之景。如为渲染阁中气氛，作者借助联想，让乐声唤来徐徐清风，让歌声阻遏高空行云，让雅士像陶渊明那样畅怀痛饮，让文人像谢灵运那般能诗善写。如此虚实相间，不仅使读者对所写之景有具体真实之感，又使读者视野开阔，目通万里。\n三、含蓄委婉，述志言情在大量的铺陈叙事之后，作者借含蓄委婉的笔法，腾挪跌宕之气势，宴游唱和之欢娱引出人世之艰难，仕途之崎岖，怀才之不遇，抒写了报国无门却奋发向上的执着态度。如第四自然段，兴尽悲来，“望长安于日下，指吴会于云间”委婉地抒发远离京城浪迹天涯之情。接着由关山难越，想到仕途失意，借屈原、贾谊、冯唐、李广的典故，抒发有志难伸的感慨，含蓄地表达了对所谓“圣君”“明时”的不满。“所赖君子安贪”三句，表达不因年华易逝和处境困顿而自暴自弃的精神，又以大鹏自比，表明扶摇直上九霄的凌云壮志。而后又借“失之东隅，收之桑榆”的说法，表明早年虽失意，但拯时匡世之信念并未泯灭。同时又反用“贪泉”“涸辙”“阮籍”之典，说明“出淤泥而不染”、“穷且益坚”之志。作者正是借多样的历史典故，委婉含蓄地述志言情。\n四、词藻华美，语约言丰唐初的骈体文，还有齐梁之余风，辞藻繁多，典故滥用，即以形式上的浮艳来掩盖内容上的空虚，但王勃的《滕王阁序》却用骈文的形式表达丰富的内容，再现了交织于内心的失望与希望、痛苦与追求、落魄与奋进的感情历程，真可谓辞藻华美，语约言丰。其中妙词佳句，今天还脍炙人口，广为流传。如“星分翼轸”、“物华天宝”、“人杰地灵”、“雄州雾列”、“俊采星驰”、“胜友如云”、“高朋满座”、“ 关山难越”、“萍水相逢”、“冯唐易老，李广难封”、“老当益壮”、“穷且益坚”、“不坠青云之志”、“落霞与孤鹜齐飞，秋水共长天一色”……读之如饮醇酒，久而弥笃。典故如陶渊明、曹植、谢灵运、冯唐、李广、贾谊、梁鸿、贪泉、涸辙、北海、阮籍……这些典故并未使人陷入浓云晦雾之中，而是清新疏朗，意味隽永。读之令人荡气回肠，感染力极强。\n总之，《滕王阁序》是古代骈文的精品，它既发挥了骈文特有的铺陈描写手法，又运用形散而神不散的散文之气于骈偶之中。字字绝妙，句句传神，章章生辉，使人读后有身临其境之感，正如都督阎公所言：“此真天才，当垂不朽矣！”它不但以其真实的情感和充实的内容区别于六朝及其以前那些无病呻吟或嘲风弄月者，而且打破了僵死陈旧的骈文格局和陈陈相因的文风，给骈文注入新的血液。\n读后感滕王阁序读后感（一）林中流淌的溪水，面前总会有巨石、横木拦住去路，河道也并非笔直，而是曲曲折折，总是阻止溪水前进。人生也正是这样。人所踏上的道路不是一帆风顺的，而是坎坷密布，荆棘丛生。时运不济，命途多舛。\n在大唐王朝强盛的唐高宗年间，从绛州龙门走出了一位才高八斗的文人。他就是初唐四杰之一的王勃。他才华早露，十四岁时即被授予官职。然而他却在仕途至终因才华横溢而遭受了两次打击。这也宣告了他仕途的终结。\n上元二年，滕王阁上，他即席作赋，写下了千古名篇《滕王阁序》，为历代传颂赞赏。今日，读《滕王阁序》，我会在开始时同情王勃的遭遇。然而，读至“老当益壮，宁移白首之心，穷且益坚，不坠青云之志”时，我便渐渐由同情变为了赞赏与佩服。读罢此文，我深有感触。\n林中的溪水虽身处曲折的河道中，面对拦路的艰难险阻，却毫不畏惧、毫不气馁，只是聚成一股又一股的水流冲向障碍，冲破障碍，流向远方。人在经历了失败、打击、挫折后，需要一种乐观向上的心态，拥有这种心态后，人就会变得不畏困难，像溪水一样勇于面对，勇于承担，勇于挑战，在摔倒之后满怀信心地再度站起，为追寻成功继续前行。\n王勃前往交趾看望自己被贬的父亲途中，心中还怀着两次打击给他留下的阴影。然而在《滕王阁序》却表现出了一种积极的壮怀。“酌贪泉而觉爽，处涸辙以犹欢”使人精神一振，感受到作者那种身处逆境却仍乐观向上的心情。西汉史学家司马迁惨遭酷刑，却最终完成了“史家绝唱”的《史记》。他在《报任安书》中写道盖西伯拘而演《周易》；仲尼厄而作《春秋》；屈原放逐，乃赋《离骚》；左丘失明，厥有《国语》；孙子膑脚，《兵法》修列；不韦迁蜀，世传《吕览》；韩非囚秦，《说难》、《孤愤》。《诗》三百篇，大氐贤圣发愤之所为作也。发明家爱迪生，失败两千多次后方才成功。音乐家贝多芬失聪，仍作出了一生中最伟大的音乐篇章。经历了痛苦的生命才能称其为人，真正的成功者都是从痛苦中超度出来的。古人在逆境，经历失败，这些不仅没有束缚他们的手脚，反而成就了他们的成功。若只是一味地感叹命运的不公，只会停滞不前，碌碌无为终此一生。\n人生失意后，重要的不是别人的雪中送炭，而是自身需要一种积极乐观的态度去面对一切。命运是无情的，即使是叱咤疆场的一代名将李广也没有得到命运之神的眷顾，终身未得封侯，自刎沙场。海伦凯勒曾说过：“对于无可挽回的事，就应想得开点，不要总强求不可能的结果。”真正重要的并不是在一个人的身上发生了什么，而是这个人如何去看待。人不能只为自己的命运叹息，而是应该努力去改变命运。而改变命运就需要有向困难挑战的勇气和永不放弃的信心。而这些就需要心态的乐观。拥有了乐观的心态，人的心胸会变得宽广，不会总因失败而痛苦，心中会产生希望，进而会产生动力，使人继续向成功迈进。心态是成功的基石，正如一位名人所言：“播下一种心态，收获一种思想；播下一种思想，收获一种行为；播下一种行为，收获一种习惯；播下一种习惯，收获一种性格；播下一种性格，收获一种命运。”一切的根源就是一种心态。人如果改变了心态，就能改变他的命运。积极的心态，能使人重新振作，重拾信心；积极的心态，能使人不畏挑战，勇往直前；积极的心态，能使人坚持不懈，持之以恒，积极的心态，能使人超越自我，走向成功。\n北海虽赊，扶摇可接，东隅已逝，桑榆非晚。林中的溪水，终有一天会流到广阔的大洋。人如果永怀积极乐观之心，终会铸成人生的辉煌。\n滕王阁序读后感（二）是夜，独坐于笼中，一盏青灯，半手残卷，摇头晃脑，念念有词，假马拉鬼了半天，也没见一只从天而将，衣袂飘飘的白狐，都是骗子，哪里来的什么白狐，算了，我也不是什么书生，遇不来也罢。\n没来由的瞌睡，怎么这么困呢，想想白天也没干嘛啊，砸路灯，抢银行，打飞机，抢登钓鱼岛，这些也都不是我干的啊。不过在这里还是要向那几个妄图登陆钓鱼岛宣誓主权的英雄们致敬，你们的爱国热血激励了我们的什么什么，尽管已经麻木与主权是为谁而宣，但你们仍旧是英雄。我党呢已经见怪不怪了，按兵不动，坚持敌不动，我不动；敌动了，我抗议的一贯作风，只要不侵犯我党利益一切好说。一不小心又扯远了。\n还是来说说解困，音乐已经不行了，听的都想吐了，就在灵魂即将出窍之际，又看到了这篇奇文，拿来一读，不得了啊，暑气顿消，困意全无啊，顿时神清气爽，夜不能寐啊。\n正是王勃的《滕王阁序》，千古一序，名不虚传啊：\n揽汉唐人文成一序，绝江山美景于片言。\n此序一出，有没有滕王阁都无所谓了，什么文以阁名，阁以文传才是真，这滕王阁本一歌舞之地，现在矗在南昌那的意义也就是为南昌市人民政府挣点钱罢了，要说慕名前去看下我看十有八九，说绝对点肯定会失望的，就像你看新闻联播，跟现实完全不搭界（其实看新闻联播也就节目开始主持人报个日期是靠谱的），这读滕王阁序也是一样啊，里面描写的景色跟现实估计也不好比。\n落霞与孤鹜齐飞，秋水共长天一色。渔舟唱晚，响穷彭蠡之滨；雁阵惊寒，声断衡阳之浦。如这般景色你就是请个高手来也PS不出此等画面，这般意境。况且每个人读出的景色画面也都不一样，完全是精神的享受了。说直白点是在意淫了。\n我怀着无比敬仰的心情，就着拼音注释读了三遍，人一下子就机灵了，不困了，真的\n何以解忧，唯有杜康，何以解困，首推此序啊。\n唉，王勃就是死的太早了。\n滕王阁序读后感（三）滕王阁，是中国古代四大名楼之一（另外三座是岳阳楼、黄鹤楼、蓬莱阁）。而如果没有王勃的这篇千古流传的《膝王阁序》，滕王阁的盛名自然会削减不少。王勃乃“初唐四杰”之一，少年时期便有“神童”之名，其才情在这风华绝代的《膝王阁序》里得到了充分的展现：用词华美瑰丽，用典琳琅满目，行文气势磅礴、收放白如，既歌咏了滕王阁的雄伟壮观、宾主的才华横溢以及滕王阁周围的绝妙胜景，也抒发了自己怀才不遇、愤慈悲凉而又不甘沉沦的屈湘。《滕王阁序》由此奠定了其在中国古代文学史上不朽的地位。\n就是这样一位满腹珠矶的才子，却得不到重用，郁郁寡欢，心情烦闷两个月后，王勃渡海去探望父亲时，不幸溺水身亡。\n王勃的悲剧并不是很个别的现象，自古以来文人就常常成为统治者的工具，甚至仅仅是摆设。即如李白，已经达到了诗歌创作的顶峰，(www.lz13.cn)亦不过在皇帝的赏识下进官当一个御用文人，一个招之即来、抨之即去的“宠物”李白很不满，但又有什么办法呢？除了写下类似‘’仰天大笑出门去，我辈岂是蓬篙人“的诗句来一抒豪情，他并没有什么办法摆脱这种屈辱的地位。\n但几千年来中国文人的悲剧命运仅仅在于统治者吗？显然不是。文人往往自命不凡，的确，在知识普及程度很低的古代，一个饱读诗书的文人是可以在精神层面上俯视芸芸众生的。但这种精神上的距离，在实际生活中也使知识分子与人民大众有了隔膜像白居易那样写诗要让老婆婆也能明白的文人实属风毛麟角。脱离群众的后果是什么呢？上不能为统治者所用，下不屑与劳苦大众为伍。多少文人就这样落得个孤家寡人，潦倒而终。\n还有，文人往往受”学而优则仕“的影响，把做官作为人生理想。殊不知，官场险恶，风云莫测。电视连续剧《铁齿铜牙纪晓岚》中，和坤有一段经典台词：”……纪先生您在文海遨游，而我却在宦海打滚儿。文海偶而有点小风小浪，宦海却永远是血雨腥风。“看，文坛与官场就有这样的差别！有些文人学会了政治权谋，摇身一变成为政治家，如王安石；另一些文人”保持本色“，除了几根硬骨头和一肚皮学问外，别无长处，于是官是做不下去的，如陶渊明。可悲的是，文人对统治者，在野则口诛笔伐，对官场黑暗也深恶痛绝，但朝廷一开始吸纳文人，绝大多数文人又趋之若鹜。明末张献忠举兵人蜀，长刀一挥，血流成河。可张献忠建立的”大西“政权一宣布”开科取士“，立刻有8000多名文人从四面八方赶到成都试图谋取功名，孰料全变成了张军的刀下之鬼。\n千年一叹―中国文人的命运！\n","categories":["哲学思考"],"tags":["滕王阁","王勃","滕王阁序"]},{"title":"Spring、RPC、ORM常用框架总结","url":"/2021_10_21_spring_rpc_orm/","content":"本文主要介绍 Java 中常用的应用框架，重点讲解如下三部分内容。\n\nSpring 框架中的主要知识点；\nNIO 框架 Netty 以及基于 Netty 实现的主流 RPC 框架 Motan、Dubbo 和 gRPC；\nORM 框架 MyBatis。\n\n常用框架汇总先来看常用框架的知识点汇总，如下图所示。\n\n\n如上图所示，左上方是 Spring 系列。很多研发人员把 Spring 看作心目中最好的 Java 项目，没有之一。Spring 系列包含非常多的项目，可以满足 Java 开发中的方方面面。那么来看几个常用的 Spring 框架。\nSpringSpring Framework，也就是我们常说的 Spring 框架，包括了 IoC 依赖注入，Context 上下文、 Bean 管理、SpringMVC 等众多功能模块，其他 Spring 项目比如 Spring Boot 也会依赖 Spring 框架。\nSpring Boot 的目标是简化 Spring 应用和服务的创建、开发与部署，简化了配置文件，使用嵌入式 Web 服务器，含有诸多开箱即用的微服务功能，可以和 Spring Cloud 联合部署。Spring Boot 的核心思想是约定大于配置，应用只需要很少的配置即可，简化了应用开发模式。\nSpring Data 是一个数据访问及操作的工具集，封装了多种数据源的操作能力，包括：JDBC、Redis、MongoDB 等。\nSpring Cloud 是一套完整的微服务解决方案，是一系列不同功能的微服务框架的集合。Spring Cloud 基于 Spring Boot，简化了分布式系统的开发，集成了服务发现、配置管理、消息总线、负载均衡、断路器、数据监控等各种服务治理能力。比如sleuth提供了全链路追踪能力，Netflix套件提供了hystrix熔断器、zuul网关等众多的治理组件。config 组件提供了动态配置能力，bus组件支持使用 RabbitMQ、Kafka、ActiveMQ 等消息队列，实现分布式服务之间的事件通信。\nSpring Security 用于快速构建安全的应用程序和服务，在 Spring Boot 和 Spring Security OAuth2 的基础上，可以快速实现常见安全模型，如单点登录，令牌中继和令牌交换。这里可以了解一下 OAuth2 授权机制和 JWT 认证方式。OAuth2 是一种授权机制，规定了完备的授权、认证流程。JWT 全称是 JSON Web Token，是一种把认证信息包含在 token 中的认证实现，OAuth2 授权机制中就可以应用 JWT 来作为认证的具体实现方法。\nStrutsStruts 是曾经非常火爆的 Web 组合 SSH 中的控制层。我们知道 Web 服务一般都采用 MVC 分层模型构建，就是 Model 层负责内部数据模型，Controller 负责请求的分发控制，View 层负责返回给用户展示的视图。Struts 实现的就是其中控制层的角色。\nStruts 采用 Filter 实现，针对类进行拦截，每次请求就会创建一个 Action。不过使用 Struts 的 SSH 组合已经逐渐被使用 SpringMVC 的 SSM 组合代替，也就是 SpringMVC+Spring+MyBatis的组合，一方面原因是由于 Struts 对几次安全漏洞的处理，让大家对 Struts 的信心受到影响；另一方面，SpringMVC 更加灵活，不需要额外配置，不存在和 Spring 整合等问题，使用更加方便。所以建议以 SSM 框架的学习为主。\nORMORM 就是对象关系匹配，解决面向对象与关系数据库存在的互不匹配的问题。简单来说，就是把关系数据库中的数据转换成面向对象程序中的对象。常用的 ORM 框架有 Hibernate 和 MyBatis，也就是 SSH 组合和 SSM 组合中的 H 与 M。\n来看一下 Hibernate 和 MyBatis 的特点和区别。\n\nHibernate 对数据库结构提供了完整的封装，实现了 POJO 对象与数据库表之间的映射，能够自动生成并执行 SQL 语句。只要定义了 POJO 到数据库表的映射关系，就可以通过 Hibernate 提供的方法完成数据库操作。Hibernate 符合 JPA 规范，就是 Java 持久层 API。\nMyBatis 通过映射配置文件，将 SQL 所需的参数和返回的结果字段映射到指定对象，MyBatis 不会自动生成 SQL，需要自己定义 SQL 语句，不过更方便对 SQL 语句进行优化。\n\n总结起来，Hibernate 配置要比 MyBatis 复杂的多，学习成本也比 MyBatis 高。MyBatis，简单、高效、灵活，但是需要自己维护 SQL；Hibernate 功能强大、全自动、适配不同数据库，但是非常复杂，灵活性稍差。\nNettyNetty 是一个高性能的异步事件驱动的网络通信框架，Netty 对 JDK 原生 NIO 进行封装，简化了网络服务的开发。\n另外，同类型的框架还有 MINA、Grizzly，不过目前使用得相对较少，一般不会在面试题目中出现，可以作为兴趣简单了解。\nRPCRPC 服务，Motan、Dubbo、gRPC 都是比较常用的高性能 RPC 框架，可以提供完善的服务治理能力，Java 版本的通信层都是基于前面提到的 Netty 实现。\n其他框架此外，Jersy 和 RESTEasy 都是可以快速开发 RESTful 服务的框架。与 SpringMVC 相比，这两个框架都是基于 JAX-RS 标准，而 SpringMVC 基于 Servlet，使用自己构建的 API，是两个不同的标准。\nShiro 框架是一个与 Spring Security 类似的开源的权限管理框架，用于访问授权、认证、加密及会话管理。能够支持单机与分布式 session 管理。相比 Security，Shiro更加简单易用\n详解 Spring 框架对于 Spring 框架，讲解中涉及的流程与实现默认都是基于最新的 5.x 版本。先来看 Spring 中的几个重要概念。\nIoCIoC，也就是控制反转，如下图，拿公司招聘岗位来举例。假设一个公司有产品、研发、测试等岗位。如果是公司根据岗位要求，逐个安排人选，如图中向下的箭头，这是正向流程。如果反过来，不用公司来安排候选人，而是由第三方猎头来匹配岗位和候选人，然后进行推荐，如图中向上的箭头，这就是控制反转。\n\n\n在 Spring 中，对象的属性是由对象自己创建的，就是正向流程；如果属性不是对象创建，而是由 Spring 来自动进行装配，就是控制反转。这里的 DI 也就是依赖注入，就是实现控制反转的方式。正向流程导致了对象于对象之间的高耦合，IoC 可以解决对象耦合的问题，有利于功能的复用，能够使程序的结构变得非常灵活\nContext 和 BeanSpring 进行 IoC 实现时使用的两个概念：Context 上下文和 Bean。如下图所示，所有被 Spring 管理的、由 Spring 创建的、用于依赖注入的对象，就叫作一个 Bean。Spring 创建并完成依赖注入后，所有 Bean 统一放在一个叫作 Context 的上下文中进行管理。\n\n\nAOPAOP，就是面向切面编程。如下图所示，一般我们的程序执行流程是从 Controller 层调用 Service 层、然后 Service 层调用 DAO 层访问数据，最后在逐层返回结果。这个是图中向下箭头所示的按程序执行顺序的纵向处理。\n\n\n但是，我们思考这样一个问题，一个系统中会有多个不同的服务，例如用户服务、商品信息服务等等，每个服务的Controller层都需要验证参数，都需要处理异常，如果按照图中红色的部分，对不同服务的纵向处理流程进行横切，在每个切面上完成通用的功能，例如身份认证、验证参数、处理异常等等、这样就不用在每个服务中都写相同的逻辑了，这就是 AOP 思想解决的问题。AOP 以功能进行划分，对服务顺序执行流程中的不同位置进行横切，完成各服务共同需要实现的功能\n组件再来看到 Spring 框架，下图中列出了 Spring 框架主要包含的组件。这张图来自 Spring4.x 的文档。目前最新的 5.x 版本中右面的 Portlet 组件已经被废弃掉，同时增加了用于异步响应式处理的 WebFlux 组件。这里不需要对所有的组件都详细了解，只需要重点了解最常用的几个组件实现，以及知道每个组件用来实现哪一类功能就可以了。\n\n\n图中红框框住的是比较重要的组件，Core 组件是 Spring 所有组件的核心；Bean 组件和 Context 组件我刚才提到了，是实现 IoC 和依赖注入的基础；AOP 组件用来实现面向切面编程；Web 组件包括 SpringMVC，是 Web 服务的控制层实现\n动态代理和静态代理接下来是 Spring 中机制和概念相关的知识点，如下图所示。\n\n\nAOP 的实现是通过代理模式，在调用对象的某个方法时，执行插入的切面逻辑。实现的方式有动态代理，也叫运行时增强，比如 JDK 代理、CGLIB；静态代理是在编译时进行织入或类加载时进行织入，比如 AspectJ。关于 AOP 还需要了解一下对应的 Aspect、pointcut、advice 等注解和具体使用方式。\nPlaceHolder 动态替换PlaceHolder 动态替换主要需要了解替换发生的时间，是在 Bean Definition 创建完成后，Bean 初始化之前，是通过 BeanFactoryPostProcessor 接口实现的。主要实现方式有 PropertyPlaceholderConfigurer 和 PropertySourcesPlaceholderConfigurer。这两个类实现逻辑不一样，Spring Boot 使用 PropertySourcesPlaceholderConfigurer 实现。\n事务事务，需要了解 Spring 中对事务规定的隔离类型和事务传播类型。这里要知道事务的隔离级别是由具体的数据库来实现的，在数据库部分会作详细介绍。事务的传播类型，可以重点了解最常用的 REQUIRED 和 SUPPORTS类型\n核心接口&#x2F;类再来看图右上方需要重点掌握的核心类。\n\nApplicationContext 保存了 IoC 的整个应用上下文，可以通过其中的 BeanFactory 获取到任意到 Bean；\nBeanFactory 主要的作用是根据 Bean Definition 来创建具体的 Bean；\nBeanWrapper 是对 Bean 的包装，一般情况下是在 Spring IoC 内部使用，提供了访问 Bean 的属性值、属性编辑器注册、类型转换等功能，方便 IoC 容器用统一的方式来访问 Bean 的属性；\nFactoryBean 通过 getObject 方法返回实际的 Bean 对象，例如 Motan 框架中 referer 对 service 的动态代理就是通过 FactoryBean 来实现的。\n\nScopeBean 的 Scope 是指 Bean 的作用域，默认情况下是单例模式，这也是使用最多的一种方式；多例模式，即每次从 BeanFactory 中获取 Bean 都会创建一个新的 Bean。Request、Session、Global-session 是在 Web 服务中使用的 Scope。\n\nRequest 每次请求都创建一个实例；\nSession 是在一个会话周期内保证只有一个实例；\nGlobal-session 在 5.x 版本中已经不再使用，同时增加了 Application 和 Websocket 两种Scope，分别保证在一个 ServletContext 与一个 WebSocket 中只创建一个实例。\n\n还可以了解一下 Spring 的事件机制，知道 Spring 定义的五种标准事件，了解如何自定义事件和实现对应的 ApplicationListener 来处理自定义事件。\n应用下面来看 Spring 应用相关的知识点，如下图所示。\n\n\n首先要熟练掌握常用注解的使用。\n\n类型类的注解，包括 Controller、Service 等，可以重点了解一下 Component 和 Bean 注解的区别：\n\n@Component 注解在类上使用表明这个类是个组件类，需要 Spring 为这个类创建 Bean\n@Bean 注解使用在方法上，告诉 Spring 这个方法将会返回一个 Bean 对象，需要把返回的对象注册到 Spring 的应用上下文中。\n\n\n设置类注解可以重点了解 @Autowire 和 @Qualifier 以及 byType、byName 等不同的自动装配机制\n\nWeb 类主要以了解为主，关注 @RequestMapping、@GetMapping、@PostMapping 等路径匹配注解，以及 @PathVariable、@RequestParam 等参数获取注解。\n\n功能类的注解，包括 @ImportResource 引用配置、@ComponentScan 注解自动扫描、@Transactional 事务注解等等，这里不一一介绍了。\n\n\n如上图右边所示，Spring 应用部分，还需要了解配置 Spring 的几种方式：XML 文件配置、注解配置和使用 API 进行配置。\n自动装配机制需要了解按类型匹配进行自动装配，按 Bean 名称进行自动装配，构造器中的自动装配和自动检测等主要的四种方式。\n最后还可以了解一下 List、Set、Map 等集合类属性的配置方式以及内部 Bean 的使用。\nContext 初始化流程如下图所示，左侧是三种类型的 Context：\n\nXML 配置方式的 Context；\nSpring Boot 的 Context；\nWeb 服务的 Context。\n\n\n\n\n不论哪种 Context，创建后都会调用到 AbstractApplicationContext 类的 refresh 方法，流程如下。\n\n首先对刷新进行准备，包括设置开始时间、设置激活状态、初始化 Context 环境中的占位符，这个动作根据子类的需求由子类来执行，然后验证是否缺失必要的 properties。\n刷新并获得内部的 Bean Factory\n对 BeanFactory 进行准备工作，比如设置类加载器和后置处理器、配置不进行自动装配的类型、注册默认的环境 Bean。\n为 Context 的子类提供后置处理 BeanFactory 的扩展能力。如果子类想在 Bean 定义加载完成后，开始初始化上下文之前做一些特殊逻辑，可以复写这个方法。\n执行 Context 中注册的 Bean Factory 后缀处理器。这里有两种后置处理器，一种是可以注册 Bean 的后缀处理器，另一种是针对 BeanFactory 进行处理的后置处理器。执行的顺序是，先按优先级执行可注册 Bean 的处理器，在按优先级执行针对 BeanFactory的处理器。对 Spring Boot 来说，这一步会进行注解 Bean Definition 的解析。流程如图右侧所示，由 ConfigurationClassPostProcessor 触发、由 ClassPathBeanDefinitionScanner 解析并注册到 BeanFactory。\n按优先级顺序在 BeanFactory 中注册 Bean的后缀处理器，Bean 后置处理器可以在 Bean 初始化前、后执行处理。\n初始化消息源，消息源用来支持消息的国际化\n初始化应用事件广播器。事件广播器用来向 ApplicationListener 通知各种应用产生的事件，是一个标准的观察者模式\n是留给子类的扩展步骤，用来让特定的 Context 子类初始化其他的 Bean。\n把实现了 ApplicationListener 的 Bean 注册到事件广播器，并对广播器中的早期未广播事件进行通知。\n冻结所有 Bean 描述信息的修改，实例化非延迟加载的单例 Bean。\n完成上下文的刷新工作，调用 LifecycleProcessor 的 onFresh() 方法以及发布 ContextRefreshedEvent 事件\n在 finally 中，执行第十三步，重置公共的缓存，比如 ReflectionUtils 中的缓存、 AnnotationUtils 中的缓存等等；\n\n至此，Spring 的 Context 初始化完成。由于篇幅和时间的关系，这里介绍了最主要的主流程，建议课后阅读源码来复习这个知识点，补全细节。\nBean 生命周期面试中经常问到 Bean 的生命周期，如下图，我们先看绿色的部分，Bean 的创建过程。\n\n\n\n调用 Bean 的构造方法创建 Bean；\n通过反射调用 setter 方法进行属性的依赖注入\n如果实现 BeanNameAware 接口的话，会设置 Bean 的 name；\n如果实现了 BeanFactoryAware，会把 BeanFactory 设置给 Bean\n如果实现了 ApplicationContextAware，会给 Bean 设置 ApplictionContext；\n如果实现了 BeanPostProcessor 接口，则执行前置处理方法；\n实现了 InitializingBean 接口的话，执行 afterPropertiesSet 方法；\n执行自定义的 init 方法；\n执行 BeanPostProcessor 接口的后置处理方法。\n\n以上就完成了 Bean 的创建过程。而在使用完 Bean 需要销毁时，会先执行 DisposableBean 接口的 destroy 方法，然后在执行自定义的 destroy 方法。这部分也建议阅读源码加深理解\n扩展接口在对 Spring 进行定制化功能扩展时，可以选择一些扩展点，如下图所示。\n\n\n\nBeanFactoryPostProcessor 是 BeanFactory 后置处理器，支持在 BeanFactory 标准初始化完成后，对 BeanFactory 进行一些额外处理。讲 Context 初始化流程时介绍过，这时所有的 Bean 的描述信息已经加载完毕，但是还没有进行 Bean 初始化。例如前面提到的 PropertyPlaceholderConfigurer，就是在这个扩展点上对 Bean 属性中的占位符进行替换。\nBeanDefinitionRegistryPostProcessor，它扩展自BeanFactoryPostProcessor，在执行 BeanFactoryPostProcessor 的功能前，提供了可以添加 Bean Definition 的能力，允许在初始化一般 Bean 前，注册额外的 Bean。例如可以在这里根据 Bean 的 Scope 创建一个新的代理 Bean。\nBeanPostProcessor，提供了在 Bean 初始化之前和之后插入自定义逻辑的能力。与 BeanFactoryPostProcessor 的区别是处理的对象不同，BeanFactoryPostProcessor 是对 BeanFactory 进行处理，BeanPostProcessor 是对 Bean 进行处理。\n\n上面这三个扩展点，可以通过实现 Ordered 和PriorityOrdered 接口来指定执行顺序。实现 PriorityOrdered 接口的 processor 会先于实现 Ordered 接口的执行。\n\nApplicationContextAware，可以获得 ApplicationContext 及其中的 Bean，当需要在代码中动态获取 Bean 时，可以通过实现这个接口来实现。\nInitializingBean，可以在 Bean 初始化完成，所有属性设置完成后执行特定逻辑，例如对自动装配对属性进行验证等。\nDisposableBean，用于在 Bean 被销毁前执行特定的逻辑，例如做一些回收工作等。\nApplicationListener，用来监听 Spring 的标准应用事件或者自定义事件。\n\nSpring Boot下面来看 Spring Boot 相关的知识点，如下图所示。\n\n\n首先是 Spring Boot 启动流程的主要步骤：\n\n要配置 Environment。\n准备 Context 上下文，包括执行 ApplicationContext 的后置处理、初始化 Initializer、通知Listener 处理 ContextPrepared 和 ContextLoaded 事件\n执行 refreshContext，也就是前面介绍过的 AbstractApplicationContext 类的 refresh 方法。\n\n然后要知道在 Spring Boot 中有两种上下文，一种是 bootstrap, 另外一种是 application。其中，bootstrap 是应用程序的父上下文，会先于 applicaton 加载。bootstrap 主要用于从额外的资源来加载配置信息，还可以在本地外部配置文件中解密属性。bootstrap 里面的属性会优先加载，默认也不能被本地相同配置覆盖。\n再来看 Spring Boot 的注解。\n需要知道 @SpringBootApplication 包含了 @ComponentScan、@EnableAutoConfiguration、@SpringBootConfiguration 三个注解，而 @SpringBootConfiguration 注解包含了 @Configuration 注解。也就是 Spring Boot 的自动配置功能。@Conditional 注解就是控制自动配置的生效条件的注解，例如 Bean 或 Class 存在、不存在时进行配置，当满足条件时进行配置等。\n最后，了解一下 Spring Boot 的几个特色模块。\n\nStarter 是 Spring Boot 提供的无缝集成功能的一种方式，使用某个功能时开发者不需要关注各种依赖库的处理，不需要具体的配置信息，由 Spring Boot 自动配置进行 Bean的创建。例如需要使用 Web 功能时，只需要在依赖中引入 Spring-boot-starter-web 即可。\nActuator 是用来对应用程序进行监视和管理，通过 RESTful API 请求来监管、审计、收集应用的运行情况。\nDevTools 提供了一系列开发工具的支持，来提高开发效率。例如热部署能力等。\nCLI 就是命令行接口，是一个命令行工具，支持使用 Groovy 脚本，可以快速搭建 Spring 原型项目。\n\n详解 Netty下面我们来看 Netty 相关的知识点，如下图所示。\n\n\n特点如上图左侧所示，首先了解 Netty 的特点。\n\nNetty 是一个高性能的异步事件驱动的 NIO 框架，它对消息的处理采用串行无锁化设计，提供了对 TCP、UDP 和文件传输的支持。\nNetty 内置了多种 encoder 和 decoder 实现来解决 TCP 粘包问题。\nNetty 处理消息时使用了池化的缓冲池 ByteBufs，提高性能。\n结合内存零 copy 机制，减少了对象的创建，降低了 GC 的压力。\n\n主要概念需要掌握 Netty 中的一些对象概念，比如将 Socket 封装成 Channel 对象，在 Channel 读写消息时，使用 ChannelHandler 对消息进行处理，一组 Handler 顺序链接组成 ChannelPipeline 的责任链模式。一个 Channel 产生的所有事件交给一个单线程的 EventLoop 事件处理器来进行串行处理。而 Bootstrap 对象的主要作用是配置整个 Netty 程序串联起各个组件，是一个 Netty 应用的起点。\n零内存复制要了解 Netty 的内存零 copy 技术。包括使用堆外内存来避免在 Socket 读写时缓冲数据在堆外与堆内进行频繁复制；使用 CompositeByteBuf 来减少多个小的 buffer 合并时产生的内存复制；使用 FileRegion 实现文件传输的零拷贝等。\n粘包与半包要了解 TCP 协议下粘包与半包等产生原因，知道 Netty 提供的多个 decoder 是用什么方式解决这个问题的。例如 FixedLengthFrameDecoder 用来解决固定大小数据包的粘包问题、LineBasedFrameDecoder 适合对文本进行按行分包、DelimiterBasedFrameDecoder 适合按特殊字符作为分包标记的场景、LengthFieldBasedFrameDecoder 可以支持复杂的自定义协议分包等等。\nNetty3 和 Netty4简单了解一下 Netty3 和 Netty4 的区别，其中主要的就是两个版本的线程处理模型完全不同， Netty4 处理得更加优雅。其他的以 Netty4 的特点为主即可。\n线程模型Netty 线程模型采用“服务端监听线程”和“IO 线程”分离的方式，如下图，左侧 Boss 线程组负责监听事件，创建 Socket 并绑定到 Worker 线程组。\n\n\n\nWorker 线程组负责 IO 处理。线程组由 EventLoopGroup 实现，其中包含了多个 EventLoop 事件处理器，每个 EventLoop 包含一个处理线程。通常情况下在 NIO 非阻塞模式下，Netty 为每个 Channel 分配一个 EventLoop，并且它的整个生命周期中的事件都由这个 EventLoop 来处理。一个 EventLoop 可以绑定多个 Channel。\n如上图右侧所示，EventLoop 的处理模型，Netty4 中 Channel 的读写事件都是由 Worker 线程来处理。请求处理中最主要的就是 ChannelPipeline，其中包含了一组 ChannelHandler。这些 Handler 组成了责任链模式，依次对 Channel 中的消息进行处理。一般接收消息时，Pipeline 处理完成会把消息提交到业务线程池进行处理，当业务线程处理完成时，会封装成 Task，提交回 Channel 对应的 EventLoop 来写回返回值。\n详解 RPCRPC 是远程过程调用的简写，RPC 与 HTTP 一样都可以实现远程服务的调用，但是使用方式上有很大的区别。它能够像使用本地方法一样调用远程的方法。\n交互流程如下图所示，来看 RPC 的交互流程。图中绿色的模块是 RPC 中最主要的三个角色。左边的是 Client 端，就是请求的发起方，也可以叫作 Consumer 或者 Referer。右边的模块是 Server 端，就是提供服务实现的一方，也叫作 Provider。\n\n\n为了保持较高的性能，Client 端一般都是直接请求远端的 Server 节点。因此，RPC 框架需要自动的服务注册与发现的能力，上方的绿色的注册中心就是用来动态维护可用服务节点信息的模块。\n图中的箭头代表交互流程。当 Server 提供服务时，向注册中心注册服务信息，告诉注册中心可以提供哪些服务。同时与注册中心保持心跳或者维持长链接，来维持 Server 可用状态，具体方式与注册中心的实现有关，例如 ZK 使用长链接推送方式而 Consul 使用心跳方式。\n如上图所示，当 Client 需要使用服务时，会先向注册中心订阅服务，获得可用的 Server 节点，并保存在 Client 本地。当 Server 节点发生变更时会通知 Client 更新本地 Server 节点信息。Client 按某种负载均衡策略直接请求 Server 使用服务。注意：注册中心只参与服务节点的注册与变更通知，并不会参与具体请求的处理。\n另外一般的 RPC 框架都提供了完整的服务治理能力，因此会有额外的管理模块和信息采集模块来监控、管理服务。如图中灰色的模块所示。\n开源框架来看三款比较有特色的主流 RPC 框架，如下图所示。\n\n\nDubbo 是阿里开源的 RPC 框架，提供完善的服务治理能力，可以快速为 Java 服务提供 RPC 能力。Dubbo 提供了随机、轮询、最少调用优先等多种负载均衡策略，提供对 ZK 等多种注册中心等支持，能够自动完成服务的注册与发现。Dubbo 提供可视化的管理后台，方便对服务状态进行监控和管理。Dubbo 的数据通信默认使用我 Netty 来实现，拥有非常不错的性能。\n微博开源的轻量级服务治理框架 Motan。Motan 的特点是轻量级，提供强大灵活的扩展能力，Motan 提供了多语言支持，目前支持 Java、PHP、Lua、Golang 等多语言交互，目前 Python 和 C++ 的客户端也在研发中。Motan 通过 Agent 代理方式，实现了的跨语言 ServiceMesh 的支持。ServiceMesh 被誉为下一代微服务，在课时 10 还会重点介绍。Motan Java 版本的通信层也是通过 Netty 来实现的，基于 TCP 的私有协议进行通信\nGoogle 开源的 gRPC。gRPC 默认使用 Protobuf 进行消息序列化，非常适合多语言服务之间进行交互。虽然 gRPC 本身支持的服务治理能力并不强，但拥有非常灵活的插件扩展能力，可以方便的实现自定义的服务治理能力。gRPC 基于 HTTP2 协议，能够支持链接复用，并且提供了流式调用能力，也支持从服务端进行推送消息的能力。\n详解 MyBatis特点下面我们来看 ORM 框架 MyBatis，它的知识结构图如下所示。首先要了解它的特点，可以和 Hibernate 来对比进行理解。\n\n\nMyBatis 的优点：\n\nMyBatis 是原生SQL，不像 Hibernate 的 HQL 需要额外的学习成本；\nMyBatis 的 SQL 语句与代码进行了解耦合，这与 Hibernate 是一致的；\nMyBatis 功能简单，学习成本比较低，使用的门槛也非常低，可以快速上手；\nMyBatis SQL调优比较灵活，而 Hibernate，SQL 语句是自动生成的，当有复杂语句需要进行优化时就比较难处理。\n\nMyBatis 的缺点：\n\n相比 Hibernate 这样的全自动 ORM 框架，不能自动生成 SQL 语句，编写 SQL 的工作量比较大，尤其是字段多、关联表多的情况下\n另外一个缺点就是 SQL 语句依赖于具体数据库，导致数据库迁移性差，而 Hibernate 则拥有良好的数据库可移植性。\n\n缓存MyBatis 提供了两级缓存。MyBatis 的一级缓存的存储作用域是 Session，会对同一个 Session 中执行语句的结果进行缓存，来提高再次执行时的效率。MyBatis 内部通过 HashMap 实现存储缓存，一级缓存是默认开启的。\nMyBatis 的二级缓存的作用域是一个 Mapper 的 namespace，在同一个 namespace 中查询 SQL 时可以从缓存中获取数据。二级缓存能够跨 SqlSession 生效，并且可自定义存储源，比如 Ehcache。MyBatis 的二级缓存可以设置剔除策略、刷新间隔、缓存数量等参数来进行优化。\n应用\nMyBatis 提供 #{} 的变量占位符，来支持 SQL 预编译，防止 SQL 注入。\n获取自增主键的 id 可以通过 keyProperty 配置和使用 selectKey 两种方式来实现。\n要记住动态 SQL 常用的几个标签，例如 foreach、where、if、choose、trim 等等。\n\n主要对象需要理解 MyBatis 的主要对象有哪些，它们的作用是什么，举例如下。\n\nSqlSessionFactory 是用来创建 SqlSession 的工厂类，一个 SqlSessionFactory 对应配置文件中的一个环境，也就是一个数据库配置。\n对数据库的操作必须在 SqlSession 中进行，SqlSession 非线程安全，每一次操作完数据库后都要调用 Close 对其进行关闭。\nSqlSession 通过内部的 Executor 来执行增删改查操作。\nStatementHandler 用来处理 SQL 语句预编译，设置参数等。\nParameterHandler 用来设置预编译参数。\nResultSetHandler 用来处理结果集。\nTypeHandler 进行数据库类型和 JavaBean 类型的互相映射。\n\n插件机制MyBatis 的插件机制是通过拦截器组成责任链来对 Executor、StatementHandler、ParameterHandler、ResultSetHandler 这四个作用点进行定制化处理。另外可以了解一下基于插件机制实现的 PageHelper 分页插件\n处理流程如下图所示，MyBatis 的处理流程。\n\n\n在执行 SQL 时，首先会从 SqlSessionFactory 中创建一个新的 SqlSession。\nSQL 语句是通过 SqlSession 中的 Executor 来执行，Executor 根据 SqlSession 传递的参数执行 query() 方法，然后创建一个 StatementHandler 对象，将必要的参数传递给 StatementHandler，由 StatementHandler 来完成对数据库的查询。\nStatementHandler 调用 ParameterHandler 的 setParameters 方法，把用户传递的参数转换成 JDBC Statement 所需要的参数， 调用原生 JDBC 来执行语句。\n最后由 ResultSetHandler 的 handleResultSets 方法将 JDBC 返回的 ResultSet 结果集转换成对象集，并逐级返回结果，完成一次 SQL 语句执行。\n考察点下面是需要注意的面试考察点。\n\n首先要掌握 Spring 的核心概念 IoC、AOP 以及具体的实现方式。\n要重点掌握 SpringContext 的初始化流程、Bean 的生命周期。\n以应用为主，了解常用注解的作用和使用方式。\n要了解一下 Spring Boot 相关的知识点，目前使用 Spring Boot 的项目越来越多，建议根据前面列出的知识点来学习。\n要理解 Netty 的线程模型和消息处理的pipeline机制。\n要理解 RPC 的交互流程及常用 RPC 框架的特点。\n要了解 MyBatis 或者 Hibernate 这样的 ORM 框架解决了什么问题，了解框架的实现原理。\n\n这一节课的内容比较多，前面提到的核心机制、核心流程，建议阅读源码加深理解。提供一个小技巧，在学习时可以通过断点调试的方式，结合给出的流程图来阅读源码。\n加分项\n本课时涉及考察点大多是以应用能力为主的，但是如果你阅读过源码，能突出对底层实现细节的掌握能力，一定会另面试官刮目相看。\n除了应用之外，最好能理解框架的理念，例如理解 Spring 的控制反转与 AOP 思想。\n能够知道框架最新版本的实现和发展方向，保持对新技术的兴趣和敏感。例如了解 Spring 的 Web Flux 响应式编程的实现与应用，关注 Spring Cloud 的应用等等。\n如果能在应用的基础上有调优的经验，会让你在面试时更加突出。例如你有 Netty 的调优经验，知道要尽量减少 IO 线程占用，把可以后置的处理放到业务线程池中进行。\n\n真题汇总最后汇总一些相关的面试真题作为参考，以及需要注意的地方，如下所示。\n\n\n第 1 题，除了说出 SSH 框架是 Struct+Spring+Hibernate，SSM 是指的 Spring MVC+Spring+MyBatis，另外要重点说一下 SpringMVC 和 Struts 的区别，以及 MyBatis 和 Hibernate 的区别。\n第 4 题，要答出是通过 BeanFactoryPostProcessor 后置处理器进行的占位符替换，如果自定义处理，可以扩展 PropertyPlaceholderConfigurer 或 PropertySourcesPlaceholderConfigurer 来实现。\n第 5 题，大致可以分为：从 HandlerMapping 中查找 Handler、执行 Handler、执行完成给适配器返回 ModelAndView、视图解析、返回视图，这些步骤。建议通过调试来阅读源码，补充细节、增加理解\n第 6 题，可以从构造器循环依赖和 setter 循环依赖两部分来回答，构造器循环通过使用创建中 Bean 标示池，来判断是否产生了循环创建；setter 循环依赖通过引入 ObjectFactory 来解决。\n\n\n第 7 题，题目给出的就是执行顺序。\n第 8 题，可以从 Channel、Socket、EventLoop、ChannelPipeline 等对象展开介绍。\n第 9 题，可以从下面几方面回答：\n\n 使用方式，HTTP 使用 Client 方式进行远程调用，RPC 使用动态代理的方式实现远程调用；\n 请求模型，HTTP 一般会经过 DNS 解析、4−7 层代理等中间环节，而 RPC 一般是点对点直连；\n 服务治理能力，RPC 提供更加丰富的服务治理功能，例如熔断、负载均衡等；\n 语言友好性，HTTP 对跨语言服务之间交互更加友好。\n","categories":["总结笔记"],"tags":["Spring","Sringboot","Mybatis","ORM","RPC","Netty"]},{"title":"消息队列与数据库总结","url":"/2021_10_23_msg_mysql/","content":"本文主要讲解消息队列与数据库相关的知识，重点讲解三部分知识点：\n\n Kafka 的架构与消息交互流程；\n 数据库事务的 4 大特性和分类；\n MySQL 相关的内容，比如索引、MySQL 调优等。\n\n\n消息队列与数据库知识点先来看看相关知识点汇总，如下图。首先为了防止歧义进行说明，本课时中提到的“队列“就是指“消息队列“。\n\n\n消息队列来看消息队列的应用场景，也就是队列能解决哪些问题。\n\n 队列可以对应用进行解耦合，应用之间不用直接调用。\n 可以通过队列来传递消息，完成通信。\n 队列也可以用来执行异步任务，任务提交方无需等待结果。\n 队列的另一个作用是削峰填谷，在突发流量时，可以通过队列做缓冲，不会对后端服务产生较大压力，当峰值过去时，可以逐渐消费堆积的数据，填平流量低谷。\n 消息队列一般还提供了一写多读的能力，可以用来做消息的多播与广播。\n\n\n关于队列还需要知道两个主要的消息协议。\n\n JMS 是 Java 的消息服务，规定了 Java 使用消息服务的 API，在前面 Spring 的课时提到过，Spring 提供了支持 JMS 的组件。\n AMQP 是高级消息队列协议，是应用层协议的一个开放标准，AMQP 不从 API 层进行限定，而是直接定义网络交换的数据格式，因此支持跨语言的能力，例如 RabbitMQ 就使用了 AMQP 实现。\n\n\n再来对比几个常用的消息队列。\n\n RabbitMQ\n\n使用 Erlang 开发的开源消息队列，通过 Erlang 的 Actor 模型实现了数据的稳定可靠传输。支持 AMQP、XMPP、SMTP 等多种协议，因此也比较重量级。由于采用 Broker 代理架构，发送给客户端时先在中心队列排队，疑似 RabbitMQ的单机吞吐量在万级，不算很高。\n\n ActiveMQ\n\n可以部署于代理模式和 P2P 模式，支持多种协议，单机吞吐量在万级，但是 ActiveMQ 不够轻巧，对于队列较多的情况支持不是很好。并且有较低概率丢失消息。\n\n RocketMQ\n\n阿里开源的消息中间件，单机能够支持 10w 级的吞吐量，使用 Java 开发，具有高吞吐量、高可用性的特点、适合在大规模分布式系统中应用。\n\n Kafka\n\n\n\n由 Scala 开发的高性能跨语言分布式消息队列，单机吞吐量可以到达 10w 级，消息延迟在 ms 级。Kafka 是完全的分布式系统，Broker、Producer、Consumer 都原生自动支持分布式，依赖于 ZooKeeper 做分布式协调。Kafka 支持一写多读，消息可以被多个客户端消费，消息有可能会重复，但是不会丢失。本课时后面会对 Kafka 的架构进行详细介绍。\n数据库中间件数据库中间件一般提供了读写分离、数据库水平扩展的能力。下面主要介绍两个中间件。\n一是 Sharding-Sphere，它是一个开源的分布式数据库中间件解决方案，由 Sharding-JDBC、Sharding-Proxy、Sharding-Sidecar 这几个独立产品组成，适用不同使用场景。这几个产品都提供标准化的数据分片、读写分离、柔性事务和数据治理功能，可适用于如 Java 同构、异构语言、容器、云原生等各种多样化的应用场景。 目前 Sharding-Sphere 已经进入 Apache 孵化，发展速度很快，可以重点关注。\n二是 Mycat，它也提供了分库分表等能力，Mycat 基于 Proxy 代理模式，后端可以支持 MySQL、Oracle、DB2 等不同数据库实现，不过代理方式对性能会有一定影响\n其他还有一些数据库中间件例如 Vitess 等，使用不算广泛，了解即可\n数据库对于数据库相关知识点，首先需要知道不同类型的数据库。\n关系型数据库常用的关系型数据库主要是 Oracle 和 MySQL。Oracle 功能强大，主要缺点就是贵。MySQL 是互联网行业中最流行的数据库，这不仅仅是因为 MySQL 免费，可以说关系数据库场景中你需要的功能，MySQL 都能很好得满足。后面的详解部分会详细介绍 MySQL 的一些知识点。\nMariaDB 是 MySQL 的分支，由开源社区维护，MariaDB 虽然被看作 MySQL 的替代品，但与 MySQL 相比，它在扩展功能、存储引擎上都有非常好的改进，后续可以关注。\nPostgreSQL也叫 PGSQL，PGSQL 类似于 Oracle 的多进程框架，可以支持高并发的应用场景。PG 几乎支持所有的 SQL 标准，支持类型相当丰富。PG 更加适合严格的企业应用场景，而 MySQL 更适合业务逻辑相对简单、数据可靠性要求较低的互联网场景。\nNoSQLNoSQL，就是 Not only SQL，一般指非关系型数据库。\nRedis 就是非关系型数据库，它提供了持久化能力，支持多种数据类型。Redis 适用于数据变化快且数据大小可预测的场景。\nMongoDB 是一个基于分布式文件存储的数据库，将数据存储为一个文档，数据结构由键值对组成。MongoDB 比较适合表结构不明确，且数据结构可能不断变化的场景，不适合有事务和复杂查询的场景。\nHBase 是建立在 HDFS，也就是 Hadoop 文件系统之上的分布式面向列的数据库，类似于谷歌的大表设计，HBase 可以快速随机访问海量结构化数据。在表中它由行排序，一个表有多个列族以及每一个列族可以有任意数量的列。 HBase 依赖 HDFS 可以实现海量数据的可靠存储，适用于数据量大，写多读少，不需要复杂查询的场景。\nCassandra 是一个高可靠的大规模分布式存储系统。支持分布式的结构化 key-value 存储，以高可用性为主要目标。适合写多的场景，适合做一些简单查询，不适合用来做数据分析统计。\nPika 是一个可持久化的大容量类 Redis 存储服务， 兼容五种主要数据结构的大部分命令。Pika 使用磁盘存储，主要解决 Redis 大容量存储的成本问题。\nNewSQLNewSQL 数据库也越来越被大家关注，NewSQL 是指新一代关系型数据库。比较典型的有TiDB。\nTiDB 是开源的分布式关系数据库，几乎完全兼容 MySQL，能够支持水平弹性扩展、ACID 事务、标准 SQL、MySQL 语法和 MySQL 协议，具有数据强一致的高可用特性。既适合在线事务处理，也适合在线分析处理。\n另外一个比较著名的 NewSQL 是蚂蚁金服的 OceanBase。OB 是可以满足金融级的可靠性和数据一致性要求的数据库系统。需要使用事务，并且数据量比较大的时候，就比较适合使用 OB。不过目前 OB 已经商业化，不再开源。\n最后来看数据库的范式。目前关系数据库有六种范式：第一范式、第二范式、第三范式、巴斯-科德范式（BCNF）、第四范式和第五范式。范式级别越高对数据表的要求越严格。\n\n 要求最低的第一范式只要求表中字段不可用在拆分。\n 第二范式在第一范式的基础上要求每条记录由主键唯一区分，记录中所有属性都依赖于主键。\n 第三范式在第二范式的基础上，要求所有属性必须直接依赖主键，不允许间接依赖。\n\n \n 一般说来，数据库只需满足第三范式就可以了。\n详解 Kafka架构下面来学习 Kafka 的架构。先结合如下的架构图来了解 Kafka 中的几个概念。\n\n\n首先 Kafka 消息队列由三个角色组成，左面的是消息的生产方 Producer；中间是 Kafka 集群， Kafka 集群由多台 Kafka server 组成，每个 Server 称为一个 Broker，也就是消息代理；右面的是消息的消费方 Consumer。\nKafka 中消息是按照 Topic 进行划分的，一个 Topic 就是一个 Queue。在实际应用中，不同业务数据就可以设置为不同的 Topic。一个 Topic 可以有多个消费方，当生产方在某个 Topic 发出一条消息后，所有订阅了这个 Topic 的消费方都可以收到这条消息。\n为了提高并行能力，Kafka 为每个 Topic 维护了多个 Partition 分区，每个分区可以看作一份追加类型的日志。 每个分区中的消息保证 ID 唯一且有序，新消息不断追加到尾部。Partition 实际存储数据时，会对按大小进行分段（Segment），来保证总是对较小的文件进行写操作，提高性能，方便管理。\n如图中间部分，Partition 分布于多个 Broker 上。图中绿色的模块表示 Topic1 被分为了 3 个 Partition。每个 Partition 会被复制多份存在于不同的 Broker 上，如图中红色的模块，这样可以保证主分区出现问题时进行容灾。每个 Broker 可以保存多个 Topic 的多个 Partition。\nKafka 只保证一个分区内的消息有序，不能保证一个 Topic 的不同分区之间的消息有序。为了保证较高的处理效率，所有的消息读写都是在主 Partition 中进行，其他副本分区只会从主分区复制数据。Kafka 会在 ZooKeeper 上针对每个 Topic 维护一个称为 ISR（in-sync replica），就是已同步的副本集。如果某个主分区不可用了，Kafka 就会从 ISR 集合中选择一个副本作为新的主分区。\n消息发布&#x2F;消费流程Kafka 通过对消费方进行分组管理来支持消息一写多读，流程如下图所示。\n\n\n来看图中的例子，这个 Topic 分为 4 个 Partition，就是图中绿色的 P1到 P4，上部的生产方根据规则选择一个 Partition 进行写入，默认规则是轮询策略。也可以由生产方指定 Partition 或者指定 key 来根据 Hash 值选择 Partition。\n消息的发送有三种方式：同步、异步以及 oneway。\n\n 同步模式下后台线程中发送消息时同步获取结果，这也是默认模式。\n 异步的模式允许生产者批量发送数据，可以极大的提高性能，但是会增加丢失数据的风险。\n oneway 模式只发送消息不需要返回发送结果，消息可靠性最低，但是低延迟、高吞吐，适用于对可靠性要求不高的场景。\n\n\n\n来看消息的消费，Consumer 按照 Group 来消费消息，Topic 中的每一条消息可以被多个 Consumer Group 消费，如上图中的 GroupA 和 GroupB。Kafka 确保每个 Partition 在一个 Group 中只能由一个 Consumer 消费。Kafka 通过 Group Coordinator 来管理 Consumer 实际负责消费哪个 Partition，默认支持 Range 和轮询分配。\nKafka 在 ZK 中保存了每个 Topic 中每个 Partition 在不同 Group 的消费偏移量 offset，通过更新偏移量保证每条消息都被消费\n注意：用多线程来读取消息时，一个线程相当于一个 Consumer 实例。当 Consumer 的数量大于分区的数量的时候，有的 Consumer 线程会读取不到数据。\n详解数据库事务特性数据库的特性是面试时考察频率非常高的题目，来看看数据库的 ACID 四大特性，如下图\n\n\n第一个原子性，指事务由原子的操作序列组成，所有操作要么全部成功，要么全部失败回滚。\n第二个事务的一致性，指事务的执行不能破坏数据库数据的完整性和一致性，一个事务在执行之前和执行之后，数据库都必须处以一致性状态。比如在做多表操作时，多个表要么都是事务后新的值，要么都是事务前的旧值\n第三个事务的隔离性，指多个用户并发访问数据库时，数据库为每个用户执行的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。事务的隔离级别在后文中介绍。\n第四个事务的持久性，指一个事务一旦提交并执行成功，那么对数据库中数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。\n并发问题在介绍数据的隔离级别之前，先看看没有隔离性的情况下数据库会出现哪些并发问题，如下图左侧部分所示。\n\n\n脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据，例如，账户 A 转帐给 B 500元，B 余额增加后但事务还没有提交完成，此时如果另外的请求中获取的是 B 增加后的余额，这就发生了脏读，因为事务如果失败回滚时，B 的余额就不应该增加。\n不可重复读是指对于数据库中某个数据，一个事务范围内多次查询返回了不同的数据值，这是由于在多次查询之间，有其他事务修改了数据并进行了提交。\n幻读是指一个事务中执行两次完全相同的查询时，第二次查询所返回的结果集跟第一个查询不相同。与不可重复读的区别在于，不可重复读是对同一条记录，两次读取的值不同。而幻读是记录的增加或删除，导致两次相同条件获取的结果记录数不同。\n隔离级别事务的四种隔离级别可以解决上述几种并发问题。如上图右侧内容所示，由上到下，四种隔离级别由低到高。\n第一个隔离级别是读未提交，也就是可以读取到其他事务未提交的内容，这是最低的隔离级别，这个隔离级别下，前面提到的三种并发问题都有可能发生。\n第二个隔离级别是读已提交，就是只能读取到其他事务已经提交的数据。这个隔离级别可以解决脏读问题。\n第三个隔离级别是可重复读，可以保证整个事务过程中，对同数据的多次读取结果是相同的。这个级别可以解决脏读和不可重复读的问题。MySQL 默认的隔离级别就是可重复读。\n最后一个隔离级别是串行化，这是最高的隔离级别，所有事务操作都依次顺序执行。这个级别会导致并发度下降，性能最差。不过这个级别可以解决前面提到的所有并发问题\n事务分类接下来看事务的分类，如下图。\n\n\n第一个是扁平化事务，在扁平事务中，所有的操作都在同一层次，这也是我们平时使用最多的一种事务。它的主要限制是不能提交或者回滚事务的某一部分，要么都成功，要么都回滚。\n为了解决第一种事务的弊端，就有了第二种带保存点的扁平事务。它允许事务在执行过程中回滚到较早的状态，而不是全部回滚。通过在事务中插入保存点，当操作失败后，可以选择回滚到最近的保存点处。\n第三种事务是链事务，可以看做是第二种事务的变种。它在事务提交时，会将必要的上下文隐式传递给下一个事务，当事务失败时就可以回滚到最近的事务。不过，链事务只能回滚到最近的保存点，而带保存点的扁平化事务是可以回滚到任意的保存点。\n第四种事务是嵌套事务，由顶层事务和子事务构成，类似于树的结构。一般顶层事务负责逻辑管理，子事务负责具体的工作，子事务可以提交，但真正提交要等到父事务提交，如果上层事务回滚，那么所有的子事务都会回滚。\n最后一种类型是分布式事务。是指分布式环境中的扁平化事务。\n常用的分布式事务解决方案如上图右侧所示，下面进行简要介绍。\n第一个分布式事务解决方案是 XA 协议，是保证强一致性的刚性事务。实现方式有两段式提交和三段式提交。两段式提交需要有一个事务协调者来保证所有的事务参与者都完成了第一阶段的准备工作。如果协调者收到所有参与者都准备好的消息，就会通知所有的事务执行第二阶段提交。一般场景下两段式提交已经能够很好得解决分布式事务了，然而两阶段在即使只有一个进程发生故障时，也会导致整个系统存在较长时间的阻塞。三段式提交通过增加 pre-commit 阶段来减少前面提到的系统阻塞的时间。三段式提交很少在实际中使用，简单了解就可以了。\n第二个分布式解决方案是 TCC，是满足最终一致性的柔性事务方案。TCC 采用补偿机制，核心思想是对每个操作，都要注册对应的确认和补偿操作。它分为三个阶段：Try 阶段主要对业务系统进行检测及资源预留；Confirm 阶段对业务系统做确认提交；Cancel 阶段是在业务执行错误，执行回滚，释放预留的资源。\n第三种方案是消息一致性方案。基本思路是将本地操作和发送消息放在一个事务中，保证本地操作和消息发送要么都成功要么都失败。下游应用订阅消息，收到消息后执行对应操作。\n第四种方案可以了解一下阿里云中的全局事务服务 GTS，对应的开源版本是 Fescar。Fescar 基于两段式提交进行改良，剥离了分布式事务方案对数据库在协议支持上的要求。使用 Fescar 的前提是分支事务中涉及的资源，必须是支持 ACID 事务的关系型数据库。分支的提交和回滚机制，都依赖于本地事务来保障。 Fescar 的实现目前还存在一些局限，比如事务隔离级别最高支持到读已提交级别。\n详解 MySQL下面来学习互联网行业使用最为广泛的关系型数据库 MySQL，它的知识点结构图如下所示。\n\n\n常用 SQL 语句对于手写常用 SQL 语句，没有什么特殊的技巧，根据所列的语句类型多做一些练习就好。\n数据类型要知道 MySQL 都提供哪些基本的数据类型，不同数据类型占用的空间大小。可以按给出的分类进行记忆，不一一罗列。\n引擎介绍 MySQL 中主要的存储引擎。\n\nMyISAM 是 MySQL 官方提供的存储引擎，其特点是支持全文索引，查询效率比较高，缺点是不支持事务、使用表级锁。\nInnoDB 在 5.5 版本后成为了 MySQL 的默认存储引擎，特点是支持 ACID 事务、支持外键、支持行级锁提高了并发效率。\nTokuDB 是第三方开发的开源存储引擎，有非常快的写速度，支持数据的压缩存储、可以在线添加索引而不影响读写操作。但是因为压缩的原因，TokuDB 非常适合访问频率不高的数据或历史数据归档，不适合大量读取的场景。\n\n锁MySQL 中的锁，上面也提到了，MyIASAM 使用表级锁，InnoDB 使用行级锁。\n\n表锁开销小，加锁快，不会出现死锁；但是锁的粒度大，发生锁冲突的概率高，并发访问效率比较低。\n行级锁开销大，加锁慢，有可能会出现死锁，不过因为锁定粒度最小，发生锁冲突的概率低，并发访问效率比较高。\n共享锁也就是读锁，其他事务可以读，但不能写。MySQL 可以通过 lock in share mode 语句显示使用共享锁。\n排他锁就是写锁，其他事务不能读取，也不能写。对于 UPDATE、DELETE 和 INSERT 语句，InnoDB 会自动给涉及的数据集加排他锁，或者使用 select for update 显示使用排他锁。\n\n存储过程与函数MySQL 的存储过程与函数都可以避免开发人员重复编写相同的 SQL 语句，并且存储过程和函数都是在 MySQL 服务器中执行的，可以减少客户端和服务器端的数据传输\n存储过程能够实现更复杂的功能，而函数一般用来实现针对性比较强的功能，例如特殊策略求和等。存储过程可以执行包括修改表等一系列数据库操作，而用户定义函数不能用于执行修改全局数据库状态的操作。\n存储过程一般是作为一个独立的部分来执行，而函数可以作为查询语句的一个部分来调用。SQL 语句中不能使用存储过程，但可以使用函数。存储过程一般与数据库实现绑定，使用存储过程会降低程序的可移植性，应谨慎使用。\n新特性此外，可以去了解 MySQL8.0 的一些新特性，例如：\n\n默认字符集格式改为了 UTF-8；\n增加了隐藏索引的功能，隐藏后的索引不会被查询优化器使用，可以使用这个特性用于性能调试；\n支持了通用表表达式，使复杂查询中的嵌入表语句更加清晰；\n新增了窗口函数的概念，可以用来实现新的查询方式。\n\n其中，窗口函数与 SUM、COUNT 等集合函数类似，但不会将多行查询结果合并，而是将结果放在多行中，即窗口函数不需要 GROUP BY。\n索引来看 MySQL 的索引，索引可以大幅增加数据库的查询的性能，在实际业务场景中，或多或少都会使用到。但是索引也是有代价的，首先需要额外的磁盘空间来保存索引；其次，对于插入、更新、删除等操作由于更新索引会增加额外的开销，因此索引比较适合用在读多写少的场景\n首先学习 MySQL 索引类型。\n\n唯一索引，就是索引列中的值必须是唯一的，但是允许出现空值。这种索引一般用来保证数据的唯一性，比如保存账户信息的表，每个账户的 ID 必须保证唯一，如果重复插入相同的账户 ID 时 MySQL 返回异常。\n主键索引是一种特殊的唯一索引，但是它不允许出现空值。\n普通索引，与唯一索引不同，它允许索引列中存在相同的值。例如学生的成绩表，各个学科的分数是允许重复的，就可以使用普通索引。\n联合索引，就是由多个列共同组成的索引。一个表中含有多个单列的索引并不是联合索引，联合索引是对多个列字段按顺序共同组成一个索引。应用联合索引时需要注意最左原则，就是 where 查询条件中的字段必须与索引字段从左到右进行匹配。比如，一个用户信息表，用姓名和年龄组成了联合索引，如果查询条件是“姓名等于张三“，那么满足最左原则；如果查询条件是“年龄大于 20“，由于索引中最左的字段是姓名不是年龄，所以不能使用这个索引。\n全文索引，前面提到了，MyISAM 引擎中实现了这个索引，在 5.6 版本后 InnoDB 引擎也支持了全文索引，并且在 5.7.6 版本后支持了中文索引。全文索引只能在 CHAR、VARCHAR、TEXT 类型字段上使用，底层使用倒排索引实现。要注意对于大数据量的表，生成全文索引会非常消耗时间也非常消耗磁盘空间。\n\n然后来看索引的实现。\nB+ 树实现，B+ 树比较适合用作 &gt; 或 &lt; 这样的范围查询，是 MySQL 中最常使用的一种索引实现。\nR-Tree 是一种用于处理多维数据的数据结构，可以对地理数据进行空间索引。不过实际业务场景中使用的比较少。\nHash 是使用散列表来对数据进行索引，Hash 方式不像 B-Tree 那样需要多次查询才能定位到记录，因此 Hash 索引的效率高于 B-Tree，但是不支持范围查找和排序等功能。实际使用的也比较少。\nFullText 就是前面提到的全文索引，是一种记录关键字与对应文档关系的倒排索引\n调优MySQL 的调优也是研发人员需要掌握的一项技能，一般 MySQL 调优有如下图所示的四个纬度。\n\n\n\n第一个纬度是针对数据库设计、表结构设计以及索引设置纬度进行的优化；\n第二个纬度是对我们业务中使用的 SQL 语句进行优化，例如调整 where 查询条件；\n第三个纬度是对 MySQL 服务的配置进行优化，例如对链接数的管理，对索引缓存、查询缓存、排序缓存等各种缓存大小进行优化；\n第四个纬度是对硬件设备和操作系统设置进行优化，例如调整操作系统参数、禁用 swap、增加内存、升级固态硬盘等等。\n\n这四个纬度从优化的成本角度来讲，从左到右优化成本逐渐升高；从优化效果角度来看，从右到左优化的效果更高。\n对于研发人员来说，前两个纬度与业务息息相关，因此需要重点掌握，后两个纬度更适合 DBA 进行深入学习，简单了解就好。\n那么，重点来看前两个纬度，要点如下图所示。\n\n\n先看到图中左边的模块，关于表结构和索引的优化，应该掌握如下原则。\n\n要在设计表结构时，考虑数据库的水平与垂直扩展能力，提前规划好未来1年的数据量、读写量的增长，规划好分库分表方案。比如设计用户信息表，预计1年后用户数据10亿条，写QPS约5000，读QPS30000，可以设计按UID纬度进行散列，分为4个库每个库32张表，单表数据量控制在KW级别。\n要为字段选择合适的数据类型，在保留扩展能力的前提下，优先选用较小的数据结构。例如保存年龄的字段，要使用TINYINT而不要使用INT。\n可以将字段多的表分解成多个表，必要时增加中间表进行关联。假如一张表有40～50个字段显然不是一个好的设计。\n一般来说，设计关系数据库时需要满足第三范式，但为了满足第三范式，我们可能会拆分出多张表。而在进行查询时需要对多张表进行关联查询，有时为了提高查询效率，会降低范式的要求，在表中保存一定的冗余信息，也叫做反范式。但要注意反范式一定要适度。\n要擅用索引，比如为经常作为查询条件的字段创建索引、创建联合索引时要根据最左原则考虑索引的复用能力，不要重复创建索引；要为保证数据不能重复的字段创建唯一索引等等。不过要注意索引对插入、更新等写操作是有代价的，不要滥用索引，比如像性别这样唯一很差的字段就不适合建立索引。\n列字段尽量设置为not null。MySQL难以对使用null的列进行查询优化，允许null会使索引、索引统计和值更加复杂，允许null值的列需要更多的存储空间，还需要MySQL内部进行特殊处理。\n再看到如图右边所示的模块，对SQL语句进行优化的原则\n要找到最需要优化的SQL语句。要么是使用最频繁的语句，要么是优化后提高最明显的语句，可以通过查询 MySQL的慢查询日志来发现需要进行优化的SQL语句；\n要学会利用 MySQL 提供的分析工具。例如使用 Explain 来分析语句的执行计划，看看是否使用了索引，使用了哪个索引，扫描了多少记录，是否使用文件排序等等。或者利用 Profile 命令来分析某个语句执行过程中各个分步的耗时。\n要注意使用查询语句是要避免使用 SELECT *，而是应该指定具体需要获取的字段。原因一是可以避免查询出不需要使用的字段，二是可以避免查询列字段的元信息。\n是尽量使用 prepared statements，一个是它性能更好，另一个是可以防止 SQL 注入。\n要尽量使用索引扫描来进行排序，也就是尽量在有索引的字段上进行排序操作。\n\n考察点\n必须了解消息队列、数据库的基本原理、使用场景以及常用队列、数据库的特点。比如消息队列适用于异步处理和削峰填谷的场景；Kafka 在提供高可用性的前提下实现了 0 消息丢失的高性能分布式队列服务；MySQL 提供了多种引擎可以支持事务型与非事务型的关系对象库服务等等。\n要了解 Kafka 的架构和消息处理流程，明白 Kafka 是如何通过 Partition 来保证并发能力与冗余灾备的；了解消费组是如何保证每个 Consumer 实例不会获取到重复消息的\n要深刻理解数据库事务的 ACID 特性，了解并发事务可能导致的并发问题和不同的数据库隔离级别如何解决这些并发问题。\n要牢牢掌握常用的 MySQL 语句，比如 WHERE 条件查询语句、JOIN 关联语句、ORDER BY 排序语句等等。还要熟悉常用的自带函数，例如 SUM、COUNT 等等。\n了解 MySQL 数据库不同引擎的特点及不同类型的索引实现。比如知道最常使用的 InnoDB 非常擅长事务处理，MyISAM 比较适合非事务的简单查询场景。比如知道 MySQL 的唯一索引、联合索引、全文索引等不同索引类型，以及最常使用等 B+ 树索引实现等等。\n\n加分项如果想要在面试中获得更好的表现，还应该了解下面这些加分项。\n\n要了解新特性，不论是 Kafka 还是 MySQL，都要了解一下新版本特性。例如 MySQL8.0 中提供了窗口函数来支持新的查询方式；支持通用表表达式，使复杂查询中的嵌入表语句更加清晰等等。\n要知道数据库表设计原则，如果有过线上业务数据库的设计经验就更好了，就能够知道如何对容量进行评估，也知道适当分库分表来保证未来服务的可扩展性，这会对面试起到积极的影响。\n最好有过数据库调优经验，例如明明建立了索引的语句，但是查询效率还是很慢，通过 Explain 分析发现表中有多个索引，MySQL 的优化器选用了错误的索引，导致查询效率偏低，然后通过在 SQL 语句中使用 use index 来指定索引解决。\n有过 Kafka 等主流消息队列使用经验，并且知道应该如何在业务场景下进行调优。例如日志推送的场景，对小概率消息丢失可以容忍，可以设置异步发送消息。而对应金融类业务，需要设置同步发送消息，并设置最高的消息可靠性，把 request.required.acks 参数设置为 -1。\n\n真题汇总\n\n\n第 2 题，可以从消息的发送者保证投递到消息队列、消息对象自身的高可用、消费方处理完成后修改 offset 这三个方面来保证消息的可靠性。这个题目可以结合 Kafka 的消息发送同步、异步，消息可靠性配置来回答。\n第 3 题可以从两个方面解决消息重复：一个是通过对消息处理实现幂等，消除消息重复的影响；另一个是使用 Redis 来进行消息去重，避免重复消息的处理。\n第 4 题可以从创建索引、减少关联查询、优化 SQL 查询条件等方面展开。\n第 6 题可以从 MySQL 调优部分讲解的相关原则这个角度来回答。\n\n","categories":["总结笔记"],"tags":["Kafka","Mysql","Mysql调优"]},{"title":"Nginx总结","url":"/2022_04_13_nginx/","content":"Nginx 是开源、高性能、高可靠的 Web 和反向代理服务器，而且支持热部署，几乎可以做到 7 * 24 小时不间断运行，即使运行几个月也不需要重新启动，还能在不间断服务的情况下对软件版本进行热更新。性能是 Nginx 最重要的考量，其占用内存少、并发能力强、能支持高达 5w 个并发连接数，最重要的是， Nginx 是免费的并可以商业化，配置使用也比较简单。\nNginx 特点高并发、高性能；\n模块化架构使得它的扩展性非常好；\n异步非阻塞的事件驱动模型这点和 Node.js 相似；\n相对于其它服务器来说它可以连续几个月甚至更长而不需要重启服务器使得它具有高可靠性；\n热部署、平滑升级；\n完全开源，生态繁荣；\nNginx 作用Nginx 的最重要的几个使用场景：\n静态资源服务，通过本地文件系统提供服务；\n反向代理服务，延伸出包括缓存、负载均衡等；\nAPI 服务， OpenResty ；\n对于前端来说 Node.js 并不陌生， Nginx 和 Node.js 的很多理念类似， HTTP 服务器、事件驱动、异步非阻塞等，且 Nginx 的大部分功能使用 Node.js 也可以实现，但 Nginx 和 Node.js 并不冲突，都有自己擅长的领域。 Nginx 擅长于底层服务器端资源的处理（静态资源处理转发、反向代理，负载均衡等）， Node.js 更擅长上层具体业务逻辑的处理，两者可以完美组合。\n用一张图表示：\n\nNginx 安装这里基于docker安装：\n# 先起个容器，为了拷贝配置文件docker run -p 80:80 --name mynginx  -d nginx# 拷贝配置docker cp mynginx:/etc/nginx/nginx.conf ./conf/nginx.confdocker cp mynginx:/etc/nginx/conf.d ./conf/conf.ddocker cp mynginx:/usr/share/nginx/html ./html# 删除容器docker stop mynginxdocker rm mynginx# 启动容器docker run -p 80:80 --name mynginx -v $(pwd)/conf/nginx.conf:/etc/nginx/nginx.conf:ro -v $(pwd)/conf/conf.d:/etc/nginx/conf.d:ro -v $(pwd)/logs:/var/log/nginx:rw -v $(pwd)/html:/usr/share/nginx/html:rw -d nginx:latest\n验证地址： http://127.0.0.1/\nWelcome to nginx!If you see this page, the nginx web server is successfully installed and working. Further configuration is required.For online documentation and support please refer to nginx.org.Commercial support is available at nginx.com.Thank you for using nginx.\n\nNginx 核心配置\\nginx\\conf\\nginx.conf\n# main段配置信息user  nginx;                        # 运行用户，默认即是nginx，可以不进行设置worker_processes  auto;             # Nginx 进程数，一般设置为和 CPU 核数一样error_log  /var/log/nginx/error.log notice;         # Nginx 的错误日志存放目录pid        /var/run/nginx.pid;                      # Nginx 服务启动时的 pid 存放位置# events段配置信息events &#123;    use epoll;                      # 使用epoll的I/O模型(如果你不知道Nginx该使用哪种轮询方法，会自动选择一个最适合你操作系统的)    worker_connections  1024;       # 每个进程允许最大并发数&#125;# http段配置信息# 配置使用最频繁的部分，代理、缓存、日志定义等绝大多数功能和第三方模块的配置都在这里设置http &#123;    include       /etc/nginx/mime.types;        # 文件扩展名与类型映射表    default_type  application/octet-stream;     # 默认文件类型    # 设置日志模式    log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;                      &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;                      &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;    # Nginx访问日志存放位置    access_log  /var/log/nginx/access.log  main;    sendfile        on;     # 开启高效传输模式    #tcp_nopush     on;     # 减少网络报文段的数量    keepalive_timeout  65;  # 保持连接的时间，也叫超时时间，单位秒    #gzip  on;    include /etc/nginx/conf.d/*.conf;    # 加载子配置项&#125;\n\n\\nginx\\conf\\conf.d\\default.conf\n# server段配置信息server &#123;    listen       80;        # 配置监听的端口    listen  [::]:80;        # 配置监听的端口    server_name  localhost; # 配置的域名    #access_log  /var/log/nginx/host.access.log  main;    # location段配置信息    location / &#123;        root   /usr/share/nginx/html;       # 网站根目录        index  index.html index.htm;        # 默认首页文件        deny 172.168.22.11;                 # 禁止访问的ip地址，可以为all        allow 172.168.33.44;                # 允许访问的ip地址，可以为all    &#125;    #error_page  404              /404.html;    # 默认40x对应的访问页面    # redirect server error pages to the static page /50x.html    #    error_page   500 502 503 504  /50x.html;    # 默认50x对应的访问页面    location = /50x.html &#123;        root   /usr/share/nginx/html;    &#125;&#125;\n\n\nmain 全局配置，对全局生效；\n\nevents 配置影响 Nginx 服务器与用户的网络连接；\n\nhttp 配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置；\n\nserver 配置虚拟主机的相关参数，一个 http 块中可以有多个 server 块；\n\nlocation 用于配置匹配的 uri ；\n\nupstream 配置后端服务器具体地址，负载均衡配置不可或缺的部分；\n\n\n用一张图清晰的展示它的层级结构：\n\n配置文件 main 段核心参数useruser USERNAME [GROUP]user nginx lion; # 用户是nginx;组是lion\n\npid指定运行 Nginx master 主进程的 pid 文件存放路径。\npid /opt/nginx/logs/nginx.pid # master主进程的的pid存放在nginx.pid的文件\n\nworker_rlimit_nofile_number指定 worker 子进程可以打开的最大文件句柄数。\nworker_rlimit_nofile 20480; # 可以理解成每个worker子进程的最大连接数量。\n\nworker_rlimit_core指定 worker 子进程异常终止后的 core 文件，用于记录分析问题。\nworker_rlimit_core 50M; # 存放大小限制working_directory /opt/nginx/tmp; # 存放目录\n\nworker_processes_number指定 Nginx 启动的 worker 子进程数量。\nworker_processes 4; # 指定具体子进程数量worker_processes auto; # 与当前cpu物理核心数一致\n\nworker_cpu_affinity将每个 worker 子进程与我们的 cpu 物理核心绑定。\nworker_cpu_affinity 0001 0010 0100 1000; # 4个物理核心，4个worker子进程\n\n将每个 worker 子进程与特定 CPU 物理核心绑定，优势在于，避免同一个 worker 子进程在不同的 CPU 核心上切换，缓存失效，降低性能。但其并不能真正的避免进程切换。\nworker_priority指定 worker 子进程的 nice 值，以调整运行 Nginx 的优先级，通常设定为负值，以优先调用 Nginx。\nworker_priority -10; # 120-10=110，110就是最终的优先级\n\nLinux 默认进程的优先级值是120，值越小越优先； nice  定范围为 -20 到 +19 。\n[备注] 应用的默认优先级值是120加上 nice 值等于它最终的值，这个值越小，优先级越高。\nworker_shutdown_timeout指定 worker 子进程优雅退出时的超时时间。\nworker_shutdown_timeout 5s;\n\ntimer_resolutionworker 子进程内部使用的计时器精度，调整时间间隔越大，系统调用越少，有利于性能提升；反之，系统调用越多，性能下降。\ntimer_resolution 100ms;\n在 Linux 系统中，用户需要获取计时器时需要向操作系统内核发送请求，有请求就必然会有开销，因此这个间隔越大开销就越小。\ndaemon指定 Nginx 的运行方式，前台还是后台，前台用于调试，后台用于生产。\ndaemon off; # 默认是on，后台运行模式\n\n配置文件 events 段核心参数useNginx 使用何种事件驱动模型。\nuse method; # 不推荐配置它，让nginx自己选择method 可选值为：select、poll、kqueue、epoll、/dev/poll、eventport\n\nworker_connectionsworker 子进程能够处理的最大并发连接数。\nworker_connections 1024 # 每个子进程的最大连接数为1024\n\naccept_mutex是否打开负载均衡互斥锁。\naccept_mutex on # 默认是off关闭的，这里推荐打开\n\nserver_name 指令指定虚拟主机域名。\nserver_name name1 name2 name3# 示例：server_name www.nginx.com;\n\n域名匹配的四种写法：\n精确匹配： server_name www.nginx.com ;\n左侧通配： server_name *.nginx.com ;\n右侧统配： server_name  www.nginx.* ;\n正则匹配： server_name ~^www.nginx.*$ ;\n匹配优先级：「精确匹配 &gt; 左侧通配符匹配 &gt; 右侧通配符匹配 &gt; 正则表达式匹配」\nserver_name 配置实例：\n\n配置本地  DNS 解析 vim &#x2F;etc&#x2F;hosts （ linux 系统）\n\n# 添加如下内容，其中 121.42.11.34 是阿里云服务器IP地址121.42.11.34 www.nginx-test.com121.42.11.34 mail.nginx-test.com121.42.11.34 www.nginx-test.org121.42.11.34 doc.nginx-test.com121.42.11.34 www.nginx-test.cn121.42.11.34 fe.nginx-test.club\n\n[注意] 这里使用的是虚拟域名进行测试，因此需要配置本地 DNS 解析，如果使用阿里云上购买的域名，则需要在阿里云上设置好域名解析。\n\n配置阿里云 Nginx ，vim &#x2F;etc&#x2F;nginx&#x2F;nginx.conf\n\n# 这里只列举了http端中的sever端配置# 左匹配server &#123; listen 80; server_name *.nginx-test.com; root /usr/share/nginx/html/nginx-test/left-match/; location / &#123;  index index.html; &#125;&#125;# 正则匹配server &#123; listen 80; server_name ~^.*\\.nginx-test\\..*$; root /usr/share/nginx/html/nginx-test/reg-match/; location / &#123;  index index.html; &#125;&#125;# 右匹配server &#123; listen 80; server_name www.nginx-test.*; root /usr/share/nginx/html/nginx-test/right-match/; location / &#123;  index index.html; &#125;&#125;# 完全匹配server &#123; listen 80; server_name www.nginx-test.com; root /usr/share/nginx/html/nginx-test/all-match/; location / &#123;  index index.html; &#125;&#125;\n\n\n访问分析\n\n当访问 www.nginx-test.com 时，都可以被匹配上，因此选择优先级最高的“完全匹配”；\n当访问 mail.nginx-test.com 时，会进行“左匹配”；\n当访问 www.nginx-test.org 时，会进行“右匹配”；\n当访问 doc.nginx-test.com 时，会进行“左匹配”；\n当访问 www.nginx-test.cn 时，会进行“右匹配”；\n当访问 fe.nginx-test.club 时，会进行“正则匹配”；\nroot指定静态资源目录位置，它可以写在 http 、 server 、 location 等配置中。\nroot path例如：location /image &#123; root /opt/nginx/static;&#125;当用户访问 www.test.com/image/1.png 时，实际在服务器找的路径是 /opt/nginx/static/image/1.png\n\n[注意] root 会将定义路径与 URI 叠加， alias 则只取定义路径。\nalias它也是指定静态资源目录位置，它只能写在 location 中。\nlocation /image &#123; alias /opt/nginx/static/image/;&#125;当用户访问 www.test.com/image/1.png 时，实际在服务器找的路径是 /opt/nginx/static/image/1.png\n\n[注意] 使用 alias 末尾一定要添加 &#x2F; ，并且它只能位于 location 中。\nlocation配置路径。\nlocation [ = | ~ | ~* | ^~ ] uri &#123; ...&#125;\n\n匹配规则：\n&#x3D; 精确匹配；\n~ 正则匹配，区分大小写；\n~* 正则匹配，不区分大小写；\n^~ 匹配到即停止搜索；\n匹配优先级： &#x3D;  &gt; ^~  &gt;  ~  &gt; ~*  &gt; 不带任何字符。\n实例：\nserver &#123;  listen 80;  server_name www.nginx-test.com;    # 只有当访问 www.nginx-test.com/match_all/ 时才会匹配到/usr/share/nginx/html/match_all/index.html  location = /match_all/ &#123;      root /usr/share/nginx/html      index index.html  &#125;    # 当访问 www.nginx-test.com/1.jpg 等路径时会去 /usr/share/nginx/images/1.jpg 找对应的资源  location ~ \\.(jpeg|jpg|png|svg)$ &#123;   root /usr/share/nginx/images;  &#125;    # 当访问 www.nginx-test.com/bbs/ 时会匹配上 /usr/share/nginx/html/bbs/index.html  location ^~ /bbs/ &#123;   root /usr/share/nginx/html;    index index.html index.htm;  &#125;&#125;\n\nlocation 中的反斜线location /test &#123; ...&#125;location /test/ &#123; ...&#125;\n\n不带 &#x2F; 当访问 www.nginx-test.com/test 时， Nginx 先找是否有 test 目录，如果有则找 test 目录下的 index.html ；如果没有 test 目录， nginx  则会找是否有 test 文件。\n带 &#x2F; 当访问 www.nginx-test.com/test 时， Nginx 先找是否有 test 目录，如果有则找 test 目录下的 index.html ，如果没有它也不会去找是否存在 test 文件。\nreturn停止处理请求，直接返回响应码或重定向到其他 URL ；执行 return 指令后， location 中后续指令将不会被执行。\nreturn code [text];return code URL;return URL;例如：location / &#123; return 404; # 直接返回状态码&#125;location / &#123; return 404 &quot;pages not found&quot;; # 返回状态码 + 一段文本&#125;location / &#123; return 302 /bbs ; # 返回状态码 + 重定向地址&#125;location / &#123; return https://www.baidu.com ; # 返回重定向地址&#125;\n\nrewrite根据指定正则表达式匹配规则，重写 URL 。\n语法：rewrite 正则表达式 要替换的内容 [flag];上下文：server、location、if示例：rewirte /images/(.*\\.jpg)$ /pic/$1; # $1是前面括号(.*\\.jpg)的反向引用\n\nflag 可选值的含义：\n\nlast 重写后的 URL 发起新请求，再次进入 server 段，重试 location 的中的匹配；\n\nbreak 直接使用重写后的 URL ，不再匹配其它 location 中语句；\n\nredirect 返回302临时重定向；\n\npermanent 返回301永久重定向；\n\n\nserver&#123;  listen 80;  server_name fe.lion.club; # 要在本地hosts文件进行配置  root html;  location /search &#123;   rewrite ^/(.*) https://www.baidu.com redirect;  &#125;    location /images &#123;   rewrite /images/(.*) /pics/$1;  &#125;    location /pics &#123;   rewrite /pics/(.*) /photos/$1;  &#125;    location /photos &#123;    &#125;&#125;\n\n按照这个配置我们来分析：\n\n当访问 fe.lion.club&#x2F;search 时，会自动帮我们重定向到 https://www.baidu.com。\n\n当访问 fe.lion.club&#x2F;images&#x2F;1.jpg 时，第一步重写 URL 为 fe.lion.club&#x2F;pics&#x2F;1.jpg ，找到 pics 的 location ，继续重写 URL 为 fe.lion.club&#x2F;photos&#x2F;1.jpg ，找到 &#x2F;photos 的 location 后，去 html&#x2F;photos 目录下寻找 1.jpg 静态资源。\n\n\nif 指令语法：if (condition) &#123;...&#125;上下文：server、location示例：if($http_user_agent ~ Chrome)&#123;  rewrite /(.*)/browser/$1 break;&#125;\n\ncondition 判断条件：\n\n$variable 仅为变量时，值为空或以0开头字符串都会被当做 false 处理；\n\n&#x3D; 或 !&#x3D; 相等或不等；\n\n~ 正则匹配；\n\n! ~ 非正则匹配；\n\n~* 正则匹配，不区分大小写；\n\n-f 或 ! -f 检测文件存在或不存在；\n\n-d 或 ! -d 检测目录存在或不存在；\n\n-e 或 ! -e 检测文件、目录、符号链接等存在或不存在；\n\n-x 或 ! -x 检测文件可以执行或不可执行；\n\n\n实例：\nserver &#123;  listen 8080;  server_name localhost;  root html;    location / &#123;   if ( $uri = &quot;/images/&quot; )&#123;     rewrite (.*) /pics/ break;    &#125;  &#125;&#125;\n\n当访问 localhost:8080&#x2F;images&#x2F; 时，会进入 if 判断里面执行 rewrite 命令。\nautoindex用户请求以 &#x2F; 结尾时，列出目录结构，可以用于快速搭建静态资源下载网站。\nautoindex.conf 配置信息：\nserver &#123;  listen 80;  server_name fe.lion-test.club;    location /download/ &#123;    root /opt/source;        autoindex on; # 打开 autoindex，，可选参数有 on | off    autoindex_exact_size on; # 修改为off，以KB、MB、GB显示文件大小，默认为on，以bytes显示出⽂件的确切⼤⼩    autoindex_format html; # 以html的方式进行格式化，可选参数有 html | json | xml    autoindex_localtime off; # 显示的⽂件时间为⽂件的服务器时间。默认为off，显示的⽂件时间为GMT时间  &#125;&#125;\n\n当访问 fe.lion.com&#x2F;download&#x2F; 时，会把服务器 &#x2F;opt&#x2F;source&#x2F;download&#x2F; 路径下的文件展示出来，如下图所示：\n\n变量Nginx 提供给使用者的变量非常多，但是终究是一个完整的请求过程所产生数据， Nginx 将这些数据以变量的形式提供给使用者。\n下面列举些项目中常用的变量：\n\n实例演示 var.conf ：\nserver&#123; listen 8081; server_name var.lion-test.club; root /usr/share/nginx/html; location / &#123;  return 200 &quot;remote_addr: $remote_addrremote_port: $remote_portserver_addr: $server_addrserver_port: $server_portserver_protocol: $server_protocolbinary_remote_addr: $binary_remote_addrconnection: $connectionuri: $urirequest_uri: $request_urischeme: $schemerequest_method: $request_methodrequest_length: $request_lengthargs: $argsarg_pid: $arg_pidis_args: $is_argsquery_string: $query_stringhost: $hosthttp_user_agent: $http_user_agenthttp_referer: $http_refererhttp_via: $http_viarequest_time: $request_timehttps: $httpsrequest_filename: $request_filenamedocument_root: $document_root&quot;; &#125;&#125;\n\n当我们访问 http://var.lion-test.club:8081/test?pid=121414&amp;cid=sadasd  时，由于 Nginx 中写了 return 方法，因此 chrome 浏览器会默认为我们下载一个文件，下面展示的就是下载的文件内容：\nremote_addr: 27.16.220.84remote_port: 56838server_addr: 172.17.0.2server_port: 8081server_protocol: HTTP/1.1binary_remote_addr: 茉connection: 126uri: /test/request_uri: /test/?pid=121414&amp;cid=sadasdscheme: httprequest_method: GETrequest_length: 518args: pid=121414&amp;cid=sadasdarg_pid: 121414is_args: ?query_string: pid=121414&amp;cid=sadasdhost: var.lion-test.clubhttp_user_agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36http_referer: http_via: request_time: 0.000https: request_filename: /usr/share/nginx/html/test/document_root: /usr/share/nginx/html\n\nNginx 的配置还有非常多，以上只是罗列了一些常用的配置，在实际项目中还是要学会查阅文档。\nNginx 应用核心概念代理是在服务器和客户端之间假设的一层服务器，代理将接收客户端的请求并将它转发给服务器，然后将服务端的响应转发给客户端。\n不管是正向代理还是反向代理，实现的都是上面的功能。\n\n正向代理正向代理，意思是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。\n正向代理是为我们服务的，即为客户端服务的，客户端可以根据正向代理访问到它本身无法访问到的服务器资源。\n正向代理对我们是透明的，对服务端是非透明的，即服务端并不知道自己收到的是来自代理的访问还是来自真实客户端的访问。\n反向代理反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。\n反向代理是为服务端服务的，反向代理可以帮助服务器接收来自客户端的请求，帮助服务器做请求转发，负载均衡等。\n反向代理对服务端是透明的，对我们是非透明的，即我们并不知道自己访问的是代理服务器，而服务器知道反向代理在为他服务。\n反向代理的优势：\n\n隐藏真实服务器；\n\n负载均衡便于横向扩充后端动态服务；\n\n动静分离，提升系统健壮性；\n\n\n那么“动静分离”是什么？负载均衡又是什么？\n动静分离动静分离是指在 web 服务器架构中，将静态页面与动态页面或者静态内容接口和动态内容接口分开不同系统访问的架构设计方法，进而提示整个服务的访问性和可维护性。\n\n一般来说，都需要将动态资源和静态资源分开，由于 Nginx 的高并发和静态资源缓存等特性，经常将静态资源部署在 Nginx 上。如果请求的是静态资源，直接到静态资源目录获取资源，如果是动态资源的请求，则利用反向代理的原理，把请求转发给对应后台应用去处理，从而实现动静分离。\n使用前后端分离后，可以很大程度提升静态资源的访问速度，即使动态服务不可用，静态资源的访问也不会受到影响。\n负载均衡一般情况下，客户端发送多个请求到服务器，服务器处理请求，其中一部分可能要操作一些资源比如数据库、静态资源等，服务器处理完毕后，再将结果返回给客户端。\n这种模式对于早期的系统来说，功能要求不复杂，且并发请求相对较少的情况下还能胜任，成本也低。随着信息数量不断增长，访问量和数据量飞速增长，以及系统业务复杂度持续增加，这种做法已无法满足要求，并发量特别大时，服务器容易崩。\n很明显这是由于服务器性能的瓶颈造成的问题，除了堆机器之外，最重要的做法就是负载均衡。\n请求爆发式增长的情况下，单个机器性能再强劲也无法满足要求了，这个时候集群的概念产生了，单个服务器解决不了的问题，可以使用多个服务器，然后将请求分发到各个服务器上，将负载分发到不同的服务器，这就是负载均衡，核心是「分摊压力」。 Nginx 实现负载均衡，一般来说指的是将请求转发给服务器集群。\n举个具体的例子，晚高峰乘坐地铁的时候，入站口经常会有地铁工作人员大喇叭“请走 B 口， B 口人少车空….”，这个工作人员的作用就是负载均衡。\n\nNginx 实现负载均衡的策略：\n\n轮询策略：默认情况下采用的策略，将所有客户端请求轮询分配给服务端。这种策略是可以正常工作的，但是如果其中某一台服务器压力太大，出现延迟，会影响所有分配在这台服务器下的用户。\n\n最小连接数策略：将请求优先分配给压力较小的服务器，它可以平衡每个队列的长度，并避免向压力大的服务器添加更多的请求。\n\n最快响应时间策略：优先分配给响应时间最短的服务器。\n\n客户端 ip 绑定策略：来自同一个 ip 的请求永远只分配一台服务器，有效解决了动态网页存在的 session 共享问题。\n\n\nNginx 实战配置在配置反向代理和负载均衡等等功能之前，有两个核心模块是我们必须要掌握的，这两个模块应该说是 Nginx 应用配置中的核心，它们分别是： upstream 、proxy_pass 。\nupstream用于定义上游服务器（指的就是后台提供的应用服务器）的相关信息。\n\n语法：upstream name &#123; ...&#125;上下文：http示例：upstream back_end_server&#123;  server 192.168.100.33:8081&#125;\n\n在 upstream 内可使用的指令：\n\nserver 定义上游服务器地址；\n\nzone 定义共享内存，用于跨 worker 子进程；\n\nkeepalive 对上游服务启用长连接；\n\nkeepalive_requests 一个长连接最多请求 HTTP 的个数；\n\nkeepalive_timeout 空闲情形下，一个长连接的超时时长；\n\nhash 哈希负载均衡算法；\n\nip_hash 依据 IP 进行哈希计算的负载均衡算法；\n\nleast_conn 最少连接数负载均衡算法；\n\nleast_time 最短响应时间负载均衡算法；\n\nrandom 随机负载均衡算法；\n\n\nserver定义上游服务器地址。\n语法：server address [parameters]上下文：upstream\n\nparameters 可选值：\n\nweight&#x3D;number 权重值，默认为1；\n\nmax_conns&#x3D;number 上游服务器的最大并发连接数；\n\nfail_timeout&#x3D;time 服务器不可用的判定时间；\n\nmax_fails&#x3D;numer 服务器不可用的检查次数；\n\nbackup 备份服务器，仅当其他服务器都不可用时才会启用；\n\ndown 标记服务器长期不可用，离线维护；\n\n\nkeepalive限制每个 worker 子进程与上游服务器空闲长连接的最大数量。\nkeepalive connections;上下文：upstream示例：keepalive 16;\n\nkeepalive_requests单个长连接可以处理的最多 HTTP 请求个数。\n语法：keepalive_requests number;默认值：keepalive_requests 100;上下文：upstream\n\nkeepalive_timeout空闲长连接的最长保持时间。\n语法：keepalive_timeout time;默认值：keepalive_timeout 60s;上下文：upstream\n\n配置实例upstream back_end&#123; server 127.0.0.1:8081 weight=3 max_conns=1000 fail_timeout=10s max_fails=2;  keepalive 32;  keepalive_requests 50;  keepalive_timeout 30s;&#125;\n\nproxy_pass用于配置代理服务器。\n语法：proxy_pass URL;上下文：location、if、limit_except示例：proxy_pass http://127.0.0.1:8081proxy_pass http://127.0.0.1:8081/proxy\n\nURL 参数原则\n\nURL 必须以 http 或 https 开头；\n\nURL 中可以携带变量；\n\nURL 中是否带 URI ，会直接影响发往上游请求的 URL ；\n\n\n接下来让我们来看看两种常见的 URL 用法：\n\nproxy_pass http://192.168.100.33:8081\n\nproxy_pass http://192.168.100.33:8081/\n\n\n这两种用法的区别就是带 &#x2F; 和不带 &#x2F; ，在配置代理时它们的区别可大了：\n\n不带 &#x2F; 意味着 Nginx 不会修改用户 URL ，而是直接透传给上游的应用服务器；\n\n带 &#x2F; 意味着 Nginx 会修改用户 URL ，修改方法是将 location 后的 URL 从用户 URL 中删除；\n\n\n不带 &#x2F; 的用法：\nlocation /bbs/&#123;  proxy_pass http://127.0.0.1:8080;&#125;\n\n分析：\n\n用户请求 URL ： &#x2F;bbs&#x2F;abc&#x2F;test.html\n\n请求到达 Nginx 的 URL ： &#x2F;bbs&#x2F;abc&#x2F;test.html\n\n请求到达上游应用服务器的 URL ： &#x2F;bbs&#x2F;abc&#x2F;test.html\n\n\n带 &#x2F; 的用法：\nlocation /bbs/&#123;  proxy_pass http://127.0.0.1:8080/;&#125;\n\n分析：\n\n用户请求 URL ： &#x2F;bbs&#x2F;abc&#x2F;test.html\n\n请求到达 Nginx 的 URL ： &#x2F;bbs&#x2F;abc&#x2F;test.html\n\n请求到达上游应用服务器的 URL ： &#x2F;abc&#x2F;test.html\n\n\n并没有拼接上 &#x2F;bbs ，这点和 root 与 alias 之间的区别是保持一致的。\n配置反向代理这里为了演示更加接近实际，作者准备了两台云服务器，它们的公网 IP 分别是： 121.42.11.34 与 121.5.180.193 。\n我们把 121.42.11.34 服务器作为上游服务器，做如下配置：\n# /etc/nginx/conf.d/proxy.confserver&#123;  listen 8080;  server_name localhost;    location /proxy/ &#123;    root /usr/share/nginx/html/proxy;    index index.html;  &#125;&#125;# /usr/share/nginx/html/proxy/index.html&lt;h1&gt; 121.42.11.34 proxy html &lt;/h1&gt;\n\n配置完成后重启 Nginx 服务器\n把 121.5.180.193 服务器作为代理服务器，做如下配置：\n# /etc/nginx/conf.d/proxy.confupstream back_end &#123;  server 121.42.11.34:8080 weight=2 max_conns=1000 fail_timeout=10s max_fails=3;  keepalive 32;  keepalive_requests 80;  keepalive_timeout 20s;&#125;server &#123;  listen 80;  server_name proxy.lion.club;  location /proxy &#123;   proxy_pass http://back_end/proxy;  &#125;&#125;\n\n本地机器要访问 proxy.lion.club 域名，因此需要配置本地 hosts ，通过命令：vim &#x2F;etc&#x2F;hosts 进入配置文件，添加如下内容：\n121.5.180.193 proxy.lion.club\n\n\n分析：\n\n当访问 proxy.lion.club&#x2F;proxy 时通过 upstream 的配置找到 121.42.11.34:8080 ；\n\n因此访问地址变为 http://121.42.11.34:8080/proxy ；\n\n连接到 121.42.11.34 服务器，找到 8080 端口提供的 server ；\n\n通过 server 找到 &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html&#x2F;proxy&#x2F;index.html 资源，最终展示出来。\n\n\n配置负载均衡配置负载均衡主要是要使用 upstream 指令。\n我们把 121.42.11.34 服务器作为上游服务器，做如下配置（ &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;balance.conf ）：\nserver&#123;  listen 8020;  location / &#123;   return 200 &#x27;return 8020 \\n&#x27;;  &#125;&#125;server&#123;  listen 8030;  location / &#123;   return 200 &#x27;return 8030 \\n&#x27;;  &#125;&#125;server&#123;  listen 8040;  location / &#123;   return 200 &#x27;return 8040 \\n&#x27;;  &#125;&#125;\n\n配置完成后：\n\nnginx -t 检测配置是否正确；\n\nnginx -s reload 重启 Nginx 服务器；\n\n执行 ss -nlt 命令查看端口是否被占用，从而判断 Nginx 服务是否正确启动。\n\n\n把 121.5.180.193 服务器作为代理服务器，做如下配置（ &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;balance.conf ）：\nupstream demo_server &#123;  server 121.42.11.34:8020;  server 121.42.11.34:8030;  server 121.42.11.34:8040;&#125;server &#123;  listen 80;  server_name balance.lion.club;    location /balance/ &#123;   proxy_pass http://demo_server;  &#125;&#125;\n\n配置完成后重启 Nginx 服务器。并且在需要访问的客户端配置好 ip 和域名的映射关系。\n# /etc/hosts121.5.180.193 balance.lion.club\n\n在客户端机器执行 curl http://balance.lion.club/balance/ 命令：\n接下来，我们再来了解下 Nginx 的其它分发策略。\nhash 算法通过制定关键字作为 hash key ，基于 hash 算法映射到特定的上游服务器中。关键字可以包含有变量、字符串。\nupstream demo_server &#123;  hash $request_uri;  server 121.42.11.34:8020;  server 121.42.11.34:8030;  server 121.42.11.34:8040;&#125;server &#123;  listen 80;  server_name balance.lion.club;    location /balance/ &#123;   proxy_pass http://demo_server;  &#125;&#125;\n\nhash $request_uri 表示使用 request_uri 变量作为 hash 的 key 值，只要访问的 URI 保持不变，就会一直分发给同一台服务器。\nip_hash根据客户端的请求 ip 进行判断，只要 ip 地址不变就永远分配到同一台主机。它可以有效解决后台服务器 session 保持的问题。\nupstream demo_server &#123;  ip_hash;  server 121.42.11.34:8020;  server 121.42.11.34:8030;  server 121.42.11.34:8040;&#125;server &#123;  listen 80;  server_name balance.lion.club;    location /balance/ &#123;   proxy_pass http://demo_server;  &#125;&#125;\n\n最少连接数算法各个 worker 子进程通过读取共享内存的数据，来获取后端服务器的信息。来挑选一台当前已建立连接数最少的服务器进行分配请求。\n语法：least_conn;上下文：upstream;\n示例：\nupstream demo_server &#123;  zone test 10M; # zone可以设置共享内存空间的名字和大小  least_conn;  server 121.42.11.34:8020;  server 121.42.11.34:8030;  server 121.42.11.34:8040;&#125;server &#123;  listen 80;  server_name balance.lion.club;    location /balance/ &#123;   proxy_pass http://demo_server;  &#125;&#125;\n\n最后你会发现，负载均衡的配置其实一点都不复杂。\n配置缓存缓存可以非常有效的提升性能，因此不论是客户端（浏览器），还是代理服务器（ Nginx ），乃至上游服务器都多少会涉及到缓存。可见缓存在每个环节都是非常重要的。下面让我们来学习 Nginx 中如何设置缓存策略。\nproxy_cache存储一些之前被访问过、而且可能将要被再次访问的资源，使用户可以直接从代理服务器获得，从而减少上游服务器的压力，加快整个访问速度。\n语法：proxy_cache zone | off ; # zone 是共享内存的名称默认值：proxy_cache off;上下文：http、server、location\n\nproxy_cache_path设置缓存文件的存放路径。\n语法：proxy_cache_path path [level=levels] ...可选参数省略，下面会详细列举默认值：proxy_cache_path off上下文：http\n\n参数含义：\n\npath 缓存文件的存放路径；\n\nlevel path 的目录层级；\n\nkeys_zone 设置共享内存；\n\ninactive 在指定时间内没有被访问，缓存会被清理，默认10分钟；\n\n\nproxy_cache_key设置缓存文件的 key 。\n语法：proxy_cache_key默认值：proxy_cache_key $scheme$proxy_host$request_uri;上下文：http、server、location\n\nproxy_cache_valid配置什么状态码可以被缓存，以及缓存时长。\n语法：proxy_cache_valid [code...] time;上下文：http、server、location配置示例：proxy_cache_valid 200 304 2m;; # 说明对于状态为200和304的缓存文件的缓存时间是2分钟\n\nproxy_no_cache定义相应保存到缓存的条件，如果字符串参数的至少一个值不为空且不等于“ 0”，则将不保存该响应到缓存。\n语法：proxy_no_cache string;上下文：http、server、location示例：proxy_no_cache $http_pragma    $http_authorization;\n\nproxy_cache_bypass定义条件，在该条件下将不会从缓存中获取响应。\n语法：proxy_cache_bypass string;上下文：http、server、location示例：proxy_cache_bypass $http_pragma    $http_authorization;\n\nupstream_cache_status 变量它存储了缓存是否命中的信息，会设置在响应头信息中，在调试中非常有用。\nMISS: 未命中缓存HIT： 命中缓存EXPIRED: 缓存过期STALE: 命中了陈旧缓存REVALIDDATED: Nginx验证陈旧缓存依然有效UPDATING: 内容陈旧，但正在更新BYPASS: X响应从原始服务器获取\n\n配置实例我们把 121.42.11.34 服务器作为上游服务器，做如下配置（ &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;cache.conf ）：\nserver &#123;  listen 1010;  root /usr/share/nginx/html/1010;  location / &#123;   index index.html;  &#125;&#125;server &#123;  listen 1020;  root /usr/share/nginx/html/1020;  location / &#123;   index index.html;  &#125;&#125;\n\n把 121.5.180.193 服务器作为代理服务器，做如下配置（ &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;cache.conf ）：\nproxy_cache_path /etc/nginx/cache_temp levels=2:2 keys_zone=cache_zone:30m max_size=2g inactive=60m use_temp_path=off;upstream cache_server&#123;  server 121.42.11.34:1010;  server 121.42.11.34:1020;&#125;server &#123;  listen 80;  server_name cache.lion.club;  location / &#123;    proxy_cache cache_zone; # 设置缓存内存，上面配置中已经定义好的    proxy_cache_valid 200 5m; # 缓存状态为200的请求，缓存时长为5分钟    proxy_cache_key $request_uri; # 缓存文件的key为请求的URI    add_header Nginx-Cache-Status $upstream_cache_status # 把缓存状态设置为头部信息，响应给客户端    proxy_pass http://cache_server; # 代理转发  &#125;&#125;\n\n缓存就是这样配置，我们可以在 &#x2F;etc&#x2F;nginx&#x2F;cache_temp 路径下找到相应的缓存文件。\n「对于一些实时性要求非常高的页面或数据来说，就不应该去设置缓存，下面来看看如何配置不缓存的内容。」\nserver &#123;  listen 80;  server_name cache.lion.club;  # URI 中后缀为 .txt 或 .text 的设置变量值为 &quot;no cache&quot;  if ($request_uri ~ \\.(txt|text)$) &#123;   set $cache_name &quot;no cache&quot;  &#125;    location / &#123;    proxy_no_cache $cache_name; # 判断该变量是否有值，如果有值则不进行缓存，如果没有值则进行缓存    proxy_cache cache_zone; # 设置缓存内存    proxy_cache_valid 200 5m; # 缓存状态为200的请求，缓存时长为5分钟    proxy_cache_key $request_uri; # 缓存文件的key为请求的URI    add_header Nginx-Cache-Status $upstream_cache_status # 把缓存状态设置为头部信息，响应给客户端    proxy_pass http://cache_server; # 代理转发  &#125;&#125;\n\nHTTPS在学习如何配置 HTTPS 之前，我们先来简单回顾下 HTTPS 的工作流程是怎么样的？它是如何进行加密保证安全的？\nHTTPS 工作流程\n客户端（浏览器）访问 https://www.baidu.com 百度网站；\n\n百度服务器返回 HTTPS 使用的 CA 证书；\n\n浏览器验证 CA 证书是否为合法证书；\n\n验证通过，证书合法，生成一串随机数并使用公钥（证书中提供的）进行加密；\n\n发送公钥加密后的随机数给百度服务器；\n\n百度服务器拿到密文，通过私钥进行解密，获取到随机数（公钥加密，私钥解密，反之也可以）；\n\n百度服务器把要发送给浏览器的内容，使用随机数进行加密后传输给浏览器；\n\n此时浏览器可以使用随机数进行解密，获取到服务器的真实传输内容；\n\n\n这就是 HTTPS 的基本运作原理，使用对称加密和非对称机密配合使用，保证传输内容的安全性。\n配置证书下载证书的压缩文件，里面有个 Nginx  文件夹，把 xxx.crt 和 xxx.key 文件拷贝到服务器目录，再进行如下配置：\nserver &#123;  listen 443 ssl http2 default_server;   # SSL 访问端口号为 443  server_name lion.club;         # 填写绑定证书的域名(我这里是随便写的)  ssl_certificate /etc/nginx/https/lion.club_bundle.crt;   # 证书地址  ssl_certificate_key /etc/nginx/https/lion.club.key;      # 私钥地址  ssl_session_timeout 10m;  ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # 支持ssl协议版本，默认为后三个，主流版本是[TLSv1.2]   location / &#123;    root         /usr/share/nginx/html;    index        index.html index.htm;  &#125;&#125;\n如此配置后就能正常访问 HTTPS 版的网站了。\n配置跨域 CORS同源策略限制了从同一个源加载的文档或脚本如何与来自另一个源的资源进行交互。这是一个用于隔离潜在恶意文件的重要安全机制。通常不允许不同源间的读操作。\n如果两个页面的协议，端口（如果有指定）和域名都相同，则两个页面具有相同的源。\n下面给出了与 URL http://store.company.com/dir/page.html 的源进行对比的示例:\nhttp://store.company.com/dir2/other.html 同源https://store.company.com/secure.html 不同源，协议不同http://store.company.com:81/dir/etc.html 不同源，端口不同http://news.company.com/dir/other.html 不同源，主机不同\n\n不同源会有如下限制：\n\nWeb 数据层面，同源策略限制了不同源的站点读取当前站点的 Cookie 、 IndexDB 、 LocalStorage 等数据。\n\nDOM 层面，同源策略限制了来自不同源的 JavaScript 脚本对当前 DOM 对象读和写的操作。\n\n网络层面，同源策略限制了通过 XMLHttpRequest 等方式将站点的数据发送给不同源的站点。\n\n\nNginx 解决跨域的原理例如：\n\n前端 server 的域名为： fe.server.com\n\n后端服务的域名为： dev.server.com\n\n\n现在我在 fe.server.com 对 dev.server.com 发起请求一定会出现跨域。\n现在我们只需要启动一个 Nginx 服务器，将 server_name 设置为 fe.server.com 然后设置相应的 location 以拦截前端需要跨域的请求，最后将请求代理回 dev.server.com 。如下面的配置：\nserver &#123; listen      80; server_name  fe.server.com; location / &#123;  proxy_pass dev.server.com; &#125;&#125;\n\n这样可以完美绕过浏览器的同源策略： fe.server.com 访问 Nginx 的 fe.server.com 属于同源访问，而 Nginx 对服务端转发的请求不会触发浏览器的同源策略。\n配置开启 gzip 压缩GZIP 是规定的三种标准 HTTP 压缩格式之一。目前绝大多数的网站都在使用 GZIP 传输 HTML 、CSS 、 JavaScript 等资源文件。\n对于文本文件， GZiP 的效果非常明显，开启后传输所需流量大约会降至 1&#x2F;4~1&#x2F;3 。\n并不是每个浏览器都支持 gzip 的，如何知道客户端是否支持 gzip 呢，请求头中的 Accept-Encoding 来标识对压缩的支持。\n\n启用 gzip 同时需要客户端和服务端的支持，如果客户端支持 gzip 的解析，那么只要服务端能够返回 gzip 的文件就可以启用 gzip 了,我们可以通过 Nginx 的配置来让服务端支持 gzip 。下面的 respone 中 content-encoding:gzip ，指服务端开启了 gzip 的压缩方式。\n\n在 &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;  文件夹中新建配置文件 gzip.conf ：\n# # 默认off，是否开启gzipgzip on; # 要采用 gzip 压缩的 MIME 文件类型，其中 text/html 被系统强制启用；gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;# ---- 以上两个参数开启就可以支持Gzip压缩了 ---- ## 默认 off，该模块启用后，Nginx 首先检查是否存在请求静态文件的 gz 结尾的文件，如果有则直接返回该 .gz 文件内容；gzip_static on;# 默认 off，nginx做为反向代理时启用，用于设置启用或禁用从代理服务器上收到相应内容 gzip 压缩；gzip_proxied any;# 用于在响应消息头中添加 Vary：Accept-Encoding，使代理服务器根据请求头中的 Accept-Encoding 识别是否启用 gzip 压缩；gzip_vary on;# gzip 压缩比，压缩级别是 1-9，1 压缩级别最低，9 最高，级别越高压缩率越大，压缩时间越长，建议 4-6；gzip_comp_level 6;# 获取多少内存用于缓存压缩结果，16 8k 表示以 8k*16 为单位获得；gzip_buffers 16 8k;# 允许压缩的页面最小字节数，页面字节数从header头中的 Content-Length 中进行获取。默认值是 0，不管页面多大都压缩。建议设置成大于 1k 的字节数，小于 1k 可能会越压越大；# gzip_min_length 1k;# 默认 1.1，启用 gzip 所需的 HTTP 最低版本；gzip_http_version 1.1;\n\n其实也可以通过前端构建工具例如 webpack 、rollup 等在打生产包时就做好 Gzip 压缩，然后放到 Nginx 服务器中，这样可以减少服务器的开销，加快访问速度。\n关于 Nginx 的实际应用就学习到这里，相信通过掌握了 Nginx 核心配置以及实战配置，之后再遇到什么需求，我们也能轻松应对。接下来，让我们再深入一点学习下 Nginx 的架构。\nNginx 架构进程结构多进程结构 Nginx 的进程模型图：\n\n多进程中的 Nginx 进程架构如下图所示，会有一个父进程（ Master Process ），它会有很多子进程（ Child Processes ）。\n\nMaster Process 用来管理子进程的，其本身并不真正处理用户请求。\n\n某个子进程 down 掉的话，它会向 Master 进程发送一条消息，表明自己不可用了，此时 Master 进程会去新起一个子进程。\n\n某个配置文件被修改了 Master 进程会去通知 work 进程获取新的配置信息，这也就是我们所说的热部署。\n\n子进程间是通过共享内存的方式进行通信的。\n\n\n配置文件重载原理reload 重载配置文件的流程：\n\n向 master 进程发送 HUP 信号（ reload 命令）；\n\nmaster 进程检查配置语法是否正确；\n\nmaster 进程打开监听端口；\n\nmaster 进程使用新的配置文件启动新的 worker 子进程；\n\nmaster 进程向老的 worker 子进程发送 QUIT 信号；\n\n老的 worker 进程关闭监听句柄，处理完当前连接后关闭进程；\n\n整个过程 Nginx 始终处于平稳运行中，实现了平滑升级，用户无感知；\n\n\nNginx 模块化管理机制Nginx 的内部结构是由核心部分和一系列的功能模块所组成。这样划分是为了使得每个模块的功能相对简单，便于开发，同时也便于对系统进行功能扩展。Nginx 的模块是互相独立的,低耦合高内聚。\n\n","categories":["总结笔记"],"tags":["Nginx"]},{"title":"读《平话博弈论》","url":"/2024_05_30_game_theory/","content":"一起来看看博弈论是个什么方法，什么理论，解决什么问题。\n\n\n\n目录  · · · · · ·前言第一章 博弈三要素与囚徒困境民营书店的价格大战我怎样被博弈论吸引如此不公平，取胜概率却相等囚徒困境与博弈三要素从囚徒困境说严格优势策略均衡价格大战和双赢对局为什么主要讨论非合作博弈公共品供给的囚徒困境政治家的囚徒困境基数支付和序数支付美苏争霸的囚徒困境第二章 情侣博弈和协调博弈情侣博弈和纳什均衡情侣博弈的其他例子相对优势策略下划线法视觉友好的对角排列情侣博弈表达的对称性嗜好理性人一定自私自利吗？不该一律贬斥自利行为情侣的拥挤博弈默契是协调的一种方式劣势策略消去法的讨论第三章 简单博弈模型的应用智猪博弈和搭便车行为为什么大股东挑起监督经理的重任猎人博弈和帕累托优势斗鸡博弈和航行规则银行挤兑的成因和预防数据不同，结果各异囚徒困境两败俱伤的隐含条件禁鸣喇叭与交通顺畅串通作弊和风险优势营造克己奉公的制度环境“最惠客待遇”对谁有利风险优势的判定说?风险优势的从属地位风险厌恶的统计和理论第四章 混合策略与均衡筛选扑克牌对色游戏混合策略和纳什定理寻找纳什均衡的反应函数法再说混合策略纳什均衡扑克牌讹诈游戏慕尼黑谈判模拟聚点均衡聚点均衡作为共识均衡聚点均衡的制度设置相关均衡商品品牌的“地域连坐”效应品牌地域连坐的博弈分析抗共谋均衡盯着不散伙的共谋德国世界杯警方的优势策略第五章 零和博弈与霍特林模?零和博弈与非零和博弈均衡的观察与验证纳什均衡与杂货铺定位西方两党政治的稳定性和欺骗性动机和实现不是一回事摊贩为什么都往市场门口挤？学校门口等出租车的争先行为多人博弈的霍特林模型对抗性排序经济学家的对称性偏好第六章 动态博弈和子博弈精炼均衡抓钱游戏你死我活，还是你好我好编排故事，加深理解博弈结果依赖制度设置树型博弈策略组合的粗线表示确定树博弈的纳什均衡树型博弈的子博弈子博弈精炼纳什均衡求解动态博弈的倒推法博弈论向自己出难题实验经济学和行为经济学索引\n\n第一章 博弈三要素与囚徒困境博弈三要素参与者、策略以及博弈所得（支付，盈利）\n囚徒困境两个理性参与者在面对选择时的决策困境。具体情境如下：\n假设有两个犯罪嫌疑人，甲和乙，他们因一起犯罪被警方逮捕，但警方缺乏足够的证据来定罪。于是，警方将他们隔离审讯，并提供给他们一个选择：\n坦白：如果一个人选择坦白并指控另一个人，而另一个人保持沉默，坦白的人将被释放，而沉默的人将入狱五年。沉默：如果两人都选择沉默，由于证据不足，他们将各自入狱一年。互相指控：如果两人都选择坦白，他们将各自入狱三年。\n\n尽管合作（即两人都选择沉默）能带来较轻的惩罚（各入狱一年），但由于缺乏信任和对对方行为的不可预知性，理性的参与者往往会选择坦白，以期望获得更好的个人结果。这导致了一个悖论：如果两人都追求个人利益，最终的结果却是两人都比合作的结果更糟（各入狱三年）。因此，囚徒困境揭示了个体理性选择与集体最优结果之间的矛盾。\n严格优势策略均衡指的是在一个博弈中，参与者选择的策略都是严格优势策略，并且在这种情况下，任何参与者都没有动力单方面改变自己的策略，因为改变策略会导致其收益下降。\n具体来说，严格优势策略是指对于某个参与者而言，不论其他参与者选择什么策略，选择该策略的收益总是大于选择其他任何策略的收益。\n而严格优势策略均衡则是指在这个均衡状态下，所有参与者都选择了自己的严格优势策略，结果形成了一种稳定的局面，任何参与者都不会通过单方面改变策略来提高自己的收益。\n囚徒困境是一种严格优势策略均衡\n其他的囚徒困境模型\n公共品供给的囚徒困境两个邻居张三和李四，他们都可以选择是否修一条路出去。修路的好处是每家都能得到好处，但修路的成本则需要共同承担。如果两家都不修路，大家都得零；如果一家修而另一家不修，修路的一家会亏损，而不修的一家则可以坐享其成。\n\n因此，在缺乏协调的情况下，双方都可能选择不修路，导致最终的结果是无人修路，大家都得不到好处。\n\n这种情形体现了囚徒困境的核心：个体在追求自身利益的同时，忽视了集体利益，最终导致集体的损失。解决公共品供给的囚徒困境，往往需要政府或其他机构的介入，以协调各方的利益，确保公共品的供给。\n\n政治家的囚徒困境描述政治家在面临公共政策决策时所面临的博弈情况。在这个博弈中，政治家们知道如果他们能够合作，共同采取某种政策（例如增加税收或削减开支），将对国家整体利益有利，但由于各自担心对方不合作而导致自己承担更大的政治风险，他们往往选择保持被动，不主动提出合作方案。\n\n在这个博弈中，参与者是民主党和共和党。假设两党都意识到，面对巨额预算赤字，采取合作措施（如增税）将是对国家最有利的选择。然而，任何一方如果主动提出增税，可能会遭到选民的反对，损害自己的政治前途。于是，双方都选择保持沉默，导致最终的结果是没有采取任何行动，赤字问题依然存在。\n这个博弈的支付矩阵可以表示为：如果两党都主动合作，各自的利益会相对较好；如果一方合作而另一方不合作，合作的一方将承担政治代价，而不合作的一方则可能获得更多的选民支持；如果两党都不合作，结果则是对国家和两党的长远利益都是不利的。\n总结来说，政治家的囚徒困境展示了在缺乏信任和合作的情况下，理性政治家可能会选择不合作的策略，尽管合作对整体利益是最有利的。这种现象反映了在政治决策中，个人利益与集体利益之间的矛盾。\n\n美苏争霸的囚徒困境在冷战时期，美国和苏联这两个超级大国在军事和核武器扩张上的相互博弈。在这个博弈中，双方都有两种策略可供选择：一种是扩军发展核武器，另一种是裁军。根据博弈的设定，如果双方都选择扩军，各自的成本都很高，最终的结果是双方都损失；如果双方都选择裁军，则可以避免不必要的开支，达到零成本的状态。\n\n然而，由于在一个弱肉强食的国际环境中，任何一方如果选择裁军而另一方选择扩军，裁军的一方将面临巨大的风险，可能会被对方欺凌和损害。因此，从各自的利益出发，双方都倾向于选择扩军。这样一来，尽管扩军对双方都是不利的选择，但由于缺乏信任和合作的可能性，最终导致了双方都陷入了扩军的困境。\n这个博弈的核心在于，虽然合作裁军是对双方都有利的选择，但由于缺乏信任和对对方行为的担忧，最终导致了双方都选择了对自己不利的扩军策略，形成了一个典型的囚徒困境。通过这一例子，可以深刻理解博弈论中理性主体在面对相互依赖的情况下，如何因自利行为而导致非最优的集体结果。\n第二章 情侣博弈和协调博弈情侣博弈在情侣关系中，双方由于偏好不同而面临的选择困境。这个模型通常涉及到两个人在周末或假期选择活动时的决策，比如一方想看足球，而另一方则希望去看芭蕾舞。尽管双方的偏好不同，但他们最不愿意的事情是各自单独去做自己喜欢的事情，而是希望能够一起度过这段时间。\n在情侣博弈中，双方的满意程度取决于他们的选择。例如，如果两人一起看足球，大海（喜欢足球）会非常高兴，而丽娟（喜欢芭蕾）虽然不太满意，但仍然比各自去看自己喜欢的节目要好。相反，如果两人都去看芭蕾，丽娟会非常开心，而大海则会感到不满意。若两人各自去做自己喜欢的事情，则双方的满意程度都为零。\n\n这一博弈的核心在于纳什均衡的概念，即在某种策略组合下，任何一方都没有单独改变策略的激励，因为这样做不会带来更好的结果。在情侣博弈中，可能存在多个纳什均衡，例如双方一起看足球或一起看芭蕾，这两种选择都是稳定的结果，因为一旦达成这样的选择，双方都不想单独改变策略。\n通过情侣博弈，博弈论可以揭示出在面对不同偏好时，如何通过协调和妥协来实现双方的满意度最大化。这一模型不仅适用于情侣关系，也可以扩展到其他类型的合作关系中，例如朋友、同事或商业伙伴之间的决策。\n纳什均衡纳什均衡是指在一个博弈中，所有参与者在给定其他参与者策略的情况下，选择自己最优策略的状态。在这个均衡状态下，没有任何一个参与者能够通过单方面改变自己的策略而获得更好的结果。\n通过情侣博弈的例子，讲述了纳什均衡的具体表现。比如，大海和丽娟这对情侣在选择周末活动时，可能面临一起看足球或一起看芭蕾的选择。在这种情况下，如果两人都选择了看足球或都选择了看芭蕾，那么他们的满意程度都达到了相对的最优，形成了纳什均衡。在这两个均衡中，任何一方单独改变选择都不会带来更好的结果，反而可能导致满意度下降。\n总结来说，纳什均衡强调的是在一个多方参与的决策环境中，如何在相互依赖的情况下达到一种稳定的策略组合，确保每个参与者的选择都是基于对其他参与者选择的合理预期。\n囚徒困境也是一种纳什均衡。\n情侣博弈的其他例子\n电影选择博弈：假设一对情侣想去看电影，男方喜欢动作片，而女方喜欢爱情片。如果两人都选择自己喜欢的电影，他们可能会各自去看，导致双方的满意度都为零。如果他们选择一起去看某一部电影，比如一部兼具动作和爱情元素的影片，他们的满意度会提高。\n\n度假目的地博弈：情侣计划度假，男方想去海滩，女方想去山脉。如果他们各自选择自己喜欢的地方，可能会导致不满。最佳的选择是一起去一个两人都能接受的目的地，比如一个有海滩和山脉的地方。\n\n晚餐选择博弈：情侣在决定晚餐时，男方想吃快餐，而女方想吃健康餐。如果他们各自坚持自己的选择，可能会导致分开就餐。通过妥协，比如选择一家既提供快餐又有健康选项的餐厅，他们可以达到双方都满意的结果。\n\n购物决策博弈：在购物时，男方可能更倾向于购买电子产品，而女方可能想买衣服。如果他们分开行动，可能会导致各自不满意的选择。通过一起讨论，他们可以找到一个购物中心，既有电子产品也有时尚服装，从而满足双方的需求。\n\n\n这些例子展示了情侣之间在面对不同偏好时如何通过协调与妥协来实现共同的满意度，这正是情侣博弈的核心思想。通过理解和应用博弈论的纳什均衡概念，情侣可以在选择中找到最佳的合作策略。\n情侣博弈表达的对称性嗜好模型中将两个人独自选择不喜欢的活动（如大海独自看芭蕾，丽娟独自看足球）设定为零的满意度，反映了这种对称性：两人各自选择不喜欢的活动会导致双方都不满意，因此更倾向于选择共同的活动，尽管这个活动可能不是各自的最爱。这种对称性使得博弈的结果更具稳定性和可预测性，反映了人际关系中的合作与协调。\n总之，情侣博弈中的对称性嗜好强调了参与者在选择策略时的平衡与一致性，尽管各自的偏好不同，但他们都希望在关系中找到共同的满足点。\n理性不等于自私自利在现代经济学中，理性人的假设并不等同于自私自利。理性人是指那些在既定约束条件下，努力实现自身目标最大化的个体。理性行为的核心在于明确的目标函数，而这个目标函数可以是多种多样的。\n例如，一个人的目标函数可能是个人财富的最大化，这种情况下，他的行为可能看似自私自利。然而，另一些人的目标函数可能是他人幸福和快乐的最大化，比如父母为孩子的幸福而努力，这样的行为就体现了对他人的关心和付出。\n因此，理性人并不必然是自私自利的。相反，许多行为看似不自利，但在理性人的框架下，仍然可以被理解为合理的选择。例如，母亲宁愿自己吃剩饭，也要让孩子享受美食，这种行为反映了她对孩子幸福的追求，而不是单纯的自我利益。\n总之，理性人的行为是多元的，关键在于其目标函数的设定，而非简单地将其归结为自私自利。\n自利行为并非一无是处在现代经济学中，自利行为并不一定是负面的。自利行为是指个体在追求自身利益最大化的过程中，所采取的行动。实际上，理性经济主体的行为是为了在既有的约束条件下，努力实现自己的目标函数的最大化。这样的行为不仅符合个人的利益，也能在一定程度上促进社会的整体发展。\n首先，许多经济活动的推动力源于个体的自利行为。例如，企业为了追求利润最大化，往往会提升产品质量、降低价格，从而使消费者受益。这样的市场竞争机制不仅能促进经济发展，还能提高资源的配置效率。\n其次，自利行为并不意味着对他人的损害。许多时候，个体在追求自身利益的同时，也在为他人创造价值。例如，母亲为孩子的幸福而努力工作，这种行为看似是出于自利，但实际上也体现了对他人的关爱和责任。\n最后，经济学中的“看不见的手”理论表明，个体在追求自身利益的过程中，往往会无意中促进社会的整体福利。因此，完全贬斥自利行为是不合理的。我们应当认识到，自利行为在适当的条件下，能够与他人的利益相结合，形成双赢的局面。\n总之，自利行为并非简单的自私，而是一种复杂的社会现象。在理解和评价自利行为时，我们应考虑其对个人和社会的双重影响，而不是一味地贬斥。\n协调博弈情侣的拥挤博弈情侣的拥挤博弈是一种博弈论中的模型，主要用于描述情侣在特定环境下的决策过程，尤其是在资源有限的情况下如何选择。视频中提到的情境是，假设在一个小公园里只有两张椅子可供情侣休息，而在周末时，有两对情侣希望去公园。这种情况下，每对情侣的选择会影响到彼此的满意程度。\n在这个博弈中，情侣们面临以下选择：\n两对情侣都去公园，导致拥挤，满意程度较低。一对情侣去公园，另一对情侣留在家中，满意程度较高。通过博弈矩阵的分析，可以发现这个博弈有两个纳什均衡：\n一对情侣去公园，另一对情侣留在家中。另一对情侣去公园，第一对情侣留在家中。在这两种情况下，情侣们的满意程度都相对较高，且任何一方都没有单独改变策略的激励，因为这样做不会带来更好的结果。\n这种拥挤博弈的分析揭示了在有限资源下，情侣之间如何协调以实现更好的结果，同时也反映了在社会生活中人们如何通过默契和合作来优化决策。\n默契是协调的一种方式默契被称为协调的一种方式，是因为在多个参与者的博弈中，默契可以帮助他们在没有明确沟通的情况下，自然地达成一致，从而选择一个对所有参与者都有利的策略组合。在博弈论中，特别是在协调博弈中，参与者的目标往往是选择相同的策略，以实现共同的利益。\n例如，在视频中提到的情侣拥挤博弈中，参与者需要在去公园和待在家之间做出选择。如果两对情侣都能形成默契，约定这次由一对情侣去公园而另一对情侣留在家中，下一次再反过来，那么他们就能够避免拥挤，达到各自满意程度的最大化。这种默契的形成，实际上是一种非正式的协调方式，能够使参与者在没有外部干预的情况下，找到一个稳定的均衡点。\n因此，默契不仅是一种社交行为，也是一种有效的策略选择机制，使得参与者能够在复杂的决策环境中，依靠彼此的理解和信任，顺利达成共识，优化各自的收益。\n第三章 简单博弈模型的应用博弈过程中的风险厌恶智猪博弈和搭便车有两只猪——一只大猪和一只小猪，它们被放在一个长笼子里。笼子的一端有一个按钮，按下按钮可以获得相当于十个单位的猪食，但按按钮和跑到食槽所需的劳动消耗相当于两个单位的猪食。问题在于，按钮和食槽分别位于笼子的两端。\n如果两只猪同时按下按钮并跑向食槽，大猪能吃到七个单位的食物，小猪能吃到三个单位的食物。如果大猪按下按钮而小猪先跑到食槽，大猪能吃到六个单位的食物，而小猪能吃到四个单位。如果小猪按下按钮而大猪在食槽旁边，小猪能吃到一个单位的食物，而大猪能吃到九个单位的食物。如果两只猪都不动，什么也得不到。\n\n通过这些选择，智猪博弈展示了参与者在面对利益冲突时的策略选择。大猪由于其体型和优势，通常能够占据食槽，而小猪则往往选择等待，以便享受大猪按按钮后带来的食物。最终，博弈的均衡结果是小猪通过搭便车的方式，坐享其成。\n智猪博弈不仅适用于描述动物行为，还可以用于解释经济学中的搭便车现象和公共品提供的问题，展示了在缺乏协调和合作的情况下，个体如何在博弈中追求自身利益，可能导致的非最优结果。\n为什么大股东挑起监督经理的重任大股东挑起监督经理的重任主要是因为他们在公司中的利益与小股东相比，具有更高的利益攸关程度。在视频中提到，假设公司运营良好，大股东的分红可能增加一千万元，而小股东的分红仅增加一万元。在这种情况下，大股东会更愿意投入时间和资源去监督经理的工作，因为即使花费几万元或十几万元来监督，也能换来近千万元的分红增加，这样的投资回报率是非常高的。\n相对而言，小股东因为监督成本与潜在收益之间的差距，往往缺乏足够的激励去密切监督经理的工作。他们可能会选择“搭便车”，依赖大股东的监督成果而自己不付出相应的努力。因此，在这种博弈中，大股东承担了监督经理的责任，而小股东则相对被动地享受大股东的努力带来的收益。这种现象在经济学中被称为“智猪博弈”，强调了在资源配置和利益分配中的不平等和不同角色的行为差异。\n猎人博弈猎人博弈是一种博弈模型，通常用于描述两个猎人之间的合作与竞争关系。在这个模型中，猎物的获取依赖于猎人的合作，但猎人也可能选择各自独立行动，从而影响各自的收益。\n在猎人博弈中，假设有两个猎人，主要猎物有两种：鹿和兔子。为了捕获鹿，两个猎人必须合作；而如果单独行动，他们只能捕获兔子。具体来说，假设猎人A和猎人B的收益如下：\n\n如果两人合作猎鹿，他们可以捕获一只鹿，并平分猎物，每人获得10天的食物。\n如果两人都选择单独猎兔子，他们各自能捕获4只兔子，每人获得4天的食物。\n如果一人选择猎鹿而另一人选择猎兔，选择猎鹿的猎人将一无所获，而选择猎兔的猎人可以获得4只兔子。\n\n\n在这个博弈中，有两个可能的纳什均衡：\n\n两个猎人都选择合作猎鹿，获得较高的收益。\n两个猎人各自选择猎兔，虽然收益较低，但在没有合作的情况下这是他们的最佳选择。\n\n猎人博弈的核心在于分析合作的利益与个人利益之间的权衡，以及在缺乏信任或协调机制的情况下，参与者可能会选择的行为模式。这一模型可以帮助理解在现实生活中，个体如何在合作与竞争之间做出选择，以及如何通过制度设计来促进合作。\n帕累托优势帕累托优势是经济学中一个重要的概念，用于描述资源配置的效率。在一个经济体中，当一种资源的配置状态达到帕累托优势时，意味着在不损害其他任何人的情况下，无法再改善某个人的境况。换句话说，如果想要改善某一个人的福利，就必须以另一个人的福利为代价。\n在博弈论的背景下，帕累托优势通常与纳什均衡相对立。一个博弈的纳什均衡并不一定是帕累托最优的，可能存在其他状态可以使某些参与者的得益增加而不损害其他参与者的得益。\n例如，在猎人博弈中，如果两个猎人选择合作一起猎鹿，他们的总收益会高于各自单独猎兔的情况。在这种情况下，合作猎鹿的结果就具有帕累托优势，因为两位猎人都能获得更大的收益，而不需要损害对方的利益。\n帕累托优势的概念强调了资源的有效利用和分配的重要性，特别是在公共品的提供和合作博弈中，能够有效地引导参与者寻求共同的利益和最大化整体的福利。\n斗鸡博弈和航行规则斗鸡博弈是一种经典的博弈论模型，其名称源于儿童游戏中，两个孩子在独木桥上相向而行，谁先退让谁就被视为“胆小鬼”。在这个博弈中，两个参与者面临两个选择：勇敢地向前走或者退让。博弈的结果取决于双方的选择，可能出现的结果包括：一方勇敢而另一方退让，勇敢者获胜；双方都退让，皆可保全面子；或者双方都勇敢，导致两败俱伤。\n具体来说，斗鸡博弈的支付矩阵可以表示如下：\n如果一方勇敢而另一方退让，勇敢者得4分，退让者得2分。如果双方都退让，各得3分。如果双方都勇敢，则都得0分。\n\n这个博弈的纳什均衡有两个：其中一方勇敢而另一方退让。\n航行规则则是基于斗鸡博弈的思想，应用于海上航行中船舶交汇的情况。为了避免碰撞，许多国家制定了航行规则，例如：当两艘船相向而行时，双方应各向右偏移一点，以便安全通过。这种制度设置可以看作是对斗鸡博弈的一种规范化，通过明确的规则引导船舶行为，从而减少碰撞的风险。\n在航行规则的博弈中，双方的选择仍然会影响最终的结果，若双方都选择不让行，可能会导致碰撞；若双方都选择让行，则能安全通过。因此，航行规则的制定不仅是为了确保安全，也是为了通过制度引导参与者做出理性的选择，实现双赢的局面。\n银行挤兑的成因和预防在银行挤兑博弈模型中，储户的选择可以分为两种策略：等待到期取款或提前取款。模型的支付矩阵显示，如果双方都选择等待到期取款，他们各自能获得更高的收益（例如每人获得120万元）。然而，如果一方提前取款，而另一方选择等待，提前取款的储户将获得100万元，而等待的储户则可能只能获得40万元，这种情况下，提前取款的储户获得了较大的利益。\n然而，若两位储户都选择提前取款，银行将无法满足他们的需求，导致每人只能获得70万元。因此，这个博弈有两个纳什均衡：一个是双方都选择等待取款，另一个是双方都选择提前取款。\n预防：\n\n提高透明度：通过定期公布银行的财务状况和投资情况，增强储户的信心。\n建立准备金制度：确保银行有足够的流动资金来应对储户的提前取款需求。\n政府担保：政府可以对存款提供保险，增加储户的安全感，从而降低挤兑的可能性。\n\n囚徒困境两败俱伤的隐含条件双方势均力敌，如果一方远远强大于另一方，则情况就不一样了。\n案例：禁鸣喇叭与交通顺畅通过修改支付金额，造成双方的”势均力敌”或者”差距悬殊”避免囚徒困境，形成纳什均衡。可以有效解决现实中的囚徒困境问题。\n风险优势风险优势是博弈论中的一个概念，主要指在不确定的环境中，参与者选择某种策略时能够降低潜在风险的优势。在博弈中，参与者通常会考虑各种可能的结果及其对应的概率，以此来做出理性的决策。\n具体来说，风险优势体现在参与者在面对不确定性时，选择一个相对稳妥的策略，以避免可能的极端损失。例如，在某个博弈中，如果一个参与者选择了一个风险较小的策略，虽然这个策略的收益可能不如高风险策略的潜在收益高，但由于其风险较小，参与者在多次博弈中能够获得更稳定的回报。\n相关的博弈案例：\n\n“最惠客待遇”对谁有利\n禁鸣喇叭与交通顺畅\n营造克己奉公的制度环境\n\n总的来说，风险优势强调在决策过程中，选择能够降低风险的策略，尽管这些策略的收益可能不是最高的，但在不确定的环境中能够提供更大的安全感和稳定性。\n风险优势和帕累托优势帕累托标准和风险标准之间，理论给帕累托优势以优先权，而风险优势只有在局中人面临不知道选哪个均衡的不确定性的时候才变得重要。\n风险厌恶就是边际效用递减规律是一致的，家里几个亿的有钱人，损失10块钱的风险厌恶   小于  月薪2000元的人损失10块钱。 反着说就是边际效用递减：损失10块钱随着收入的增多边际效用递减。\n第四章 混合策略与均衡筛选零和博弈案例：扑克牌对色游戏\n\n每一局对局博弈的结果都是要么你输一根火柴，我赢一根火柴。 但是总支付的和  1+（-1）总是等于0，  这就是零和博弈。\n混合策略和纳什定理扑克牌对色游戏中，有出红牌和黑牌两种纯策略。还有以p的概率出红,以1-p的概率出黑牌的 混合策略。\n纳什定理：如果允许混合策略，那么每个有限同事博弈都有纳什均衡。证明相当困难。\n寻找纳什均衡的反应函数法\n对甲来说： 求期望：U甲（p,q）&#x3D; pq1 + (1-p)*q * (-1) + (1-q)p * (-1) + (1-p)(1-q)*1&#x3D; pq - q + pq - p + pq +1 -p - q +pq&#x3D; 4pq -2p -2q +1&#x3D; 2p(2p-1) - (2p-1)&#x3D; (2p-1)(2p-1)\n所以,参与人乙对于参与人甲的策略，选择的反应函数：\nq &#x3D; 1     如果  p &gt; 1&#x2F;2q&#x3D;[0,1]   如果 p &#x3D; 1&#x2F;2q &#x3D; 0     如果 p&lt; 1&#x2F;2\n反之同理，综合求得\np &#x3D; 1&#x2F;2q &#x3D; 1&#x2F;2就是纳什均衡\n再说混合策略纳什均衡改变支付，纳什均衡求解就会改变，会产生更多的规律~~~~~\n案例：\n\n扑克牌讹诈游戏\n慕尼黑谈判模拟\n\n聚点均衡据点均衡是博弈论中的一个概念，主要由学者谢林提出。它指的是在多重纳什均衡的情况下，参与者通过一些共同的、显而易见的信号或约定，来选择一个特定的均衡作为博弈的结果。这种均衡往往与参与者的社会文化习惯、过去的博弈经历等因素密切相关。\n在实际生活中，参与者可能会利用某些被广泛接受的约定或信号来达成共识，从而选择一个相对稳定的均衡。例如，在情侣博弈中，双方可能会选择一起看球或一起看芭蕾，具体的选择可能受到双方的默契、约定或特定情境的影响。\n据点均衡的关键在于，它能够帮助参与者在众多可能的均衡中，聚焦于一个更有可能实现的结果。这种选择通常是基于共同的理解或社会文化背景，而不仅仅是理性计算的结果。\n总结来说，据点均衡强调的是参与者在面对多重均衡时，如何通过共同信号或约定，选择一个更稳定、更具可预见性的均衡结果。\n\n聚点均衡作为共识均衡\n聚点均衡的制度设置\n\n相关均衡相关均衡是博弈论中的一个重要概念，由奥曼在1974年提出。它的基本思想是参与者通过一个大家都能够观察到的共同信号来选择行动和策略，从而确定博弈的最终结果。\n在相关均衡中，参与者不仅考虑自己的策略选择，还会考虑其他参与者的选择，以及这些选择如何受到共同信号的影响。这种信号可以是事先商定的，也可以是博弈过程中自然产生的信息。例如，参与者可能会根据某种外部条件（如天气、市场情况等）来调整自己的策略。\n相关均衡的关键在于，参与者的策略选择是相互关联的，即他们的决策不仅基于自身的利益，还受到其他参与者的行为和共同信号的影响。这种均衡状态通常比传统的纳什均衡更具稳定性，因为它能更好地反映参与者之间的相互依赖关系。\n总结来说，相关均衡强调了信息共享和策略关联的重要性，能够帮助分析在复杂博弈中如何通过共同信号达成更优的决策。\n\n商品品牌的“地域连坐”效应\n品牌地域连坐的博弈分析\n\n抗共谋均衡抗共谋均衡是博弈论中的一个概念，旨在解决多参与者博弈中可能出现的共谋行为。它的基本思想是，在一个博弈的均衡状态下，不仅要求参与者在该状态下没有单独偏离的激励，还要求他们在集体层面上也没有共谋偏离的激励。\n具体来说，抗共谋均衡的特点包括：\n\n单独偏离无好处：在抗共谋均衡中，任何参与者如果单独改变自己的策略，都不会获得更好的结果。\n\n集体偏离无激励：在抗共谋均衡中，参与者之间的集体偏离策略也没有激励。也就是说，即使多个参与者联合起来改变策略，他们的收益也不会增加。\n\n稳定性：抗共谋均衡比一般的纳什均衡更具稳定性，因为它排除了参与者之间的共谋行为，这种行为可能导致博弈结果的不确定性和不稳定性。\n\n\n通过引入抗共谋均衡的概念，博弈论能够更好地分析和预测在复杂的多参与者环境中，参与者如何选择策略，以及如何避免因共谋而导致的非理性行为。这一概念在经济学、政治学以及其他社会科学领域的研究中具有重要的应用价值。\n\n盯着不散伙的共谋\n德国世界杯警方的优势策略\n\n第五章 零和博弈与霍特林模型零和博弈与非零和博弈零和博弈是指在博弈中，参与者的利益总和始终为零。换句话说，一个参与者的收益恰好等于另一个参与者的损失。在这种博弈中，任何一方的得益必然是另一方的损失。例如，扑克牌对策游戏就是一个典型的零和博弈。在这个游戏中，如果你赢得了一根火柴，那么对手就相应地失去了一根火柴。由此可见，零和博弈强调的是参与者之间的对抗性，任何一方的成功都意味着另一方的失败。\n非零和博弈则是指参与者之间的利益关系并不局限于零和的状态。在这种博弈中，参与者可以通过合作实现双赢或多赢的局面，即所有参与者的得益之和可以大于零。非零和博弈的一个经典例子是囚徒困境。在这个博弈中，如果双方都选择合作，他们都能获得较低的刑期，实现双赢；而如果双方都选择背叛，则最终都将面临更长的刑期，导致双输的局面。\n零和博弈强调的是对抗性和竞争性，而非零和博弈则更注重合作和共赢的可能性。这两种博弈模型帮助我们理解不同情况下的决策行为和策略选择。\n均衡的观察与验证大胆假设，小心验证许多重大的科学发现，都是科学家凭借直觉或者归纳分析出的可能命题，然后严密的科学论证。\n纳什均衡的精髓是，没有一个人有动机单独的偏离当前的策略选择。\n比如假设两个人分100块钱，每个人独立给出自己想要的金额，然后写在纸上给主持人，主持人根据两个人的金额之和是否大于100来判断，如果大于100，双方都一分钱拿不到，如果小于100，都能拿到自己想要的。\n直觉高速我们，50，50 应该是一个纳什均衡。\n确实，局中人在不改变对方50的前提下，想最大化收益，写51则一分钱拿不到，写40则还不如50，所以这就是一个纳什均衡。\n打开格局，任何（a,b） a+b &#x3D; 100都是一个纳什均衡，对不对！！！\n霍特里模型与纳什均衡霍特林模型是博弈论中的一个重要模型，主要用于分析在特定市场环境下的竞争行为，尤其是如何选择最优的地理位置以吸引顾客。该模型由经济学家霍特林提出，通常用于描述两个或多个参与者在一条直线上的位置选择问题。\n在霍特林模型中，假设有两个商家（例如杂货铺）在一条均匀分布的道路上开店，顾客会选择离自己最近的商家购买商品。为了最大化各自的市场份额，两个商家都希望选择一个最优的位置。霍特林模型的关键在于，尽管商家可能希望在道路的两端开店以覆盖更多顾客，但实际的博弈结果往往是两家商家会选择挤在一起，通常是在道路的中间位置。\n具体来说，霍特林模型的纳什均衡状态是，当两家商家都选择在相同的位置时，任何一方单独改变位置都不会获得更大的市场份额。这种现象表明，在竞争中，商家之间的相互作用会导致一种稳定的竞争状态，尽管这种状态可能并不是最优的社会福利配置。\n霍特林模型不仅适用于商业竞争分析，还可以扩展到政治竞争、社会选择等领域，帮助理解不同参与者如何在资源有限的环境中做出策略选择。\n霍特林模型案例：杂货铺定位杂货铺定位问题是博弈论中的一个经典模型，最早由经济学家霍特林提出。这个问题主要探讨在一个居民区内，两个或多个杂货铺如何选择开店位置，以最大化自己的市场份额。\n在这个模型中，假设居民住宅沿着一条公路均匀分布，两个杂货铺（A和B）销售相同的商品，价格也相同。顾客会选择离自己最近的杂货铺进行购物。由于每个杂货铺都希望吸引尽可能多的顾客，他们的目标是尽量靠近对方，以争夺中间顾客的市场份额。\n在理想情况下，两个杂货铺的最佳位置应该分别在公路的四分之一和四分之三的位置，这样可以使每个杂货铺的市场份额各占一半。然而，由于每个杂货铺都希望占据更多的市场份额，它们会相互挤压，最终导致两个杂货铺都选择在公路的中间位置开店。这种情况下，虽然它们都在争取顾客，但最终却都无法实现最优的市场分配，反而增加了顾客的行走距离。\n这一现象展示了博弈论中的纳什均衡，即在某种策略组合下，任何一方单独改变策略都不会获得更好的结果。在杂货铺定位问题中，当两个杂货铺都选择在中间时，任何一方都没有动力去改变自己的位置，因为这样会导致顾客的流失。\n所以只要承认理性人假设，两家挤在中点就是唯一稳定的策略选择，是唯一的纳什均衡。\n霍特林模型案例：西方两党政治的稳定性和欺骗性西方两党政治的稳定性和欺骗性主要体现在两个方面：政治竞争的动态和选民行为的变化。\n首先，从政治竞争的动态来看，西方的两党制通常由两个主要政党主导，如美国的民主党和共和党，英国的保守党和工党。这些政党在选举期间会争取更多的选民支持，因此它们的政策纲领往往会趋向于彼此靠近，以吸引中间选民。这个过程可以用霍特林模型来解释：两个政党为了争夺选票，都会调整自己的政策立场，最终导致两者在政策上几乎没有实质性差异，形成一种竞争中的“挤压”效应。这种现象使得两党在选民眼中看似提供了选择，但实际上政策的差异性却大大降低，从而导致政治的欺骗性。\n其次，从选民行为的角度来看，选民在投票时往往会受到信息的不对称和政治宣传的影响。在选举期间，政党会通过各种手段来吸引选民，往往会夸大自己的政策效果或贬低对手的缺点。这种情况下，选民可能会在选举时做出基于情感或短期利益的选择，而不是基于长远的政策分析。这种现象加剧了政治的欺骗性，因为选民可能会在选举后发现，新的执政党并没有实现其竞选时所承诺的政策。\n因此，西方两党政治的稳定性源于两党之间的竞争和选民的投票行为，而其欺骗性则体现在政策的相似性和选民对政党的期望与实际结果之间的差距。这种现象不仅影响了政治的透明度，也使得选民对政治的信任度降低。\n摊贩都往市场门口挤也是霍特里模型的一种。\n学校门口等出租车的争先行为也是霍特里模型的一种。\n多人博弈的霍特林模型当2人博弈时， 纳什均衡是（1&#x2F;2，1&#x2F;2）当3人博弈时，没有纳什均衡当4人博弈时，纳什均衡是（1&#x2F;4，1&#x2F;4，3&#x2F;4，3&#x2F;4）当5人博弈时，纳什均衡是（1&#x2F;6，1&#x2F;6，3&#x2F;6，5&#x2F;6，5&#x2F;6）…\n对抗性排序你死我活的扑克牌对色游戏博弈出现双赢可能的价格战囚徒困境博弈个体利益与集体利益基本一致的情侣博弈以上有强到弱\n协调博弈协调博弈是一种博弈类型，其中参与者的利益在某种程度上是一致的，合作通常会导致更好的结果。在协调博弈中，参与者之间存在共同的目标，选择相同的策略往往会带来双赢的局面。\n协调博弈可以分为广义和狭义两种：\n\n广义协调博弈：包括所有可能协调出双赢对局的博弈，即使是像囚徒困境那样需要附加条件并且多次重复才能实现双赢的博弈，也算在内。\n\n狭义协调博弈：专指个体利益与集体利益基本一致的博弈。在这种博弈中，合作总是比不合作更有利。例如，在情侣博弈中，双方都希望通过合作实现共同的利益。\n\n\n协调博弈的一个经典例子是交通规则博弈。在没有交通规则的情况下，两个司机如果都靠右行驶，交通就会顺畅，双方各得一分；如果一个司机靠右而另一个司机靠左，则会发生事故，双方都得负分。因此，遵循共同的交通规则可以确保双方都能获得最佳的结果。\n在协调博弈中，虽然参与者可能会面临不同的选择，但通过有效的沟通和合作，他们能够找到最优的策略组合，从而实现双赢。\n第六章 动态博弈和子博弈精炼均衡序贯博弈什么是序贯博弈序贯博弈是博弈论中的一种博弈形式，主要特点是参与者的决策是按照时间顺序进行的，而不是同时作出决策。在序贯博弈中，某些参与者在其他参与者做出决策后再进行决策，这种决策的先后顺序会影响博弈的结果。\n“抓钱博弈”就是一个典型的序贯博弈示例。在这个博弈中，参与者甲和乙轮流做出决策，甲首先决定是否拿走面前的金额，如果他选择不拿，接下来乙会做出决策，依此类推。每一轮的决策不仅依赖于当前的选择，还受到之前决策的影响。\n序贯博弈通常用树形图表示，每个节点代表一个决策点，参与者在这些节点上选择策略。树形表示法可以清晰地展示出每个参与者的决策顺序和可能的结果，帮助分析博弈中的纳什均衡和子博弈精炼均衡等概念。\n贯博弈强调决策的时间顺序和信息的流动，能够更好地反映现实生活中许多决策过程的复杂性。\n抓钱博弈，不通规则制度，结果不通，说明博弈结果依赖制度设置。\n实验经济学和行为经济学许多经济学实验都是从博弈论开始。\n","categories":["读书笔记"],"tags":["博弈论","Game Theory"]},{"title":"Redis总结","url":"/2022_05_01_redis/","content":"Redis是基于内存数据库，操作效率高，提供丰富的数据结构（Redis底层对数据结构还做了优化），可用作数据库，缓存，消息中间件等。本文从数据结构，到集群，到常见问题逐步深入了解Redis。\n高性能\n单线程模型\n\n基于内存操作\n\nepoll多路复用模型\n\n高效的数据存储结构\n\n\n\nredis的单线程指的是数据处理使用的单线程，实际上它主要包含\n\nIO线程：处理网络消息收发\n主线程：处理数据读写操作，包括事务、Lua脚本等\n持久化线程：执行RDB或AOF时，使用持久化线程处理，避免主线程的阻塞\n过期键清理线程：用于定期清理过期键\n\n\n至于redis为什么使用单线程处理数据，是因为redis基于内存操作，并且有高效的数据类型，它的性能瓶颈并不在CPU计算，主要在于网络IO，而网络IO在后来的版本中也被独立出来了IO线程，因此它能快速处理数据，单线程反而避免了多线程所带来的并发和资源争抢的问题。\n全局数据存储Redis底层存储基于全局Hash表，存储结构和Java的HashMap类似（数组+链表方式）\n\nrehashRedis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2。一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash\n\n给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；\n\n把哈希表 1 中的数据重新进行打散映射到hash表2中；这个过程采用渐进式hash 即拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries\n\n释放哈希表 1 的空间。\n\n\n数据类型查看存储编码类型：object encoding key\n127.0.0.1:6379[1]&gt; keys *1) &quot;1&quot;127.0.0.1:6379[1]&gt; OBJECT ENCODING 1&quot;int&quot;127.0.0.1:6379[1]&gt;\n\n1. stringstring是最常用的类型，它的底层存储结构是SDS\n\n存储结构redis的string分三种情况对对象编码，目的是为了节省内存空间：\nrobj *tryObjectEncodingEx(robj *o, int try_trim)\n\n\nif: value长度小于20字节且可以转换为整数（long类型），编码为OBJ_ENCODING_INT，其中若数字在0到10000之间，还可以使用内存共享的数字对象\n\nelse if: 若value长度小于OBJ_ENCODING_EMBSTR_SIZE_LIMIT（44字节），编码为OBJ_ENCODING_EMBSTR\n\nelse: 保持编码为OBJ_ENCODING_RAW\n\n\n常用命令SET key valueMSET key value [key value ...]SETNX key value #常用作分布式锁GET keyMGET key [key ...]DEL key [key ...]EXPIRE key secondsINCR keyDECR keyINCRBY key incrementDECRBY key increment\n\n常用场景\n简单键值对\n自增计数器\n\nINCR作为主键的问题\n缺陷：若数据量大的情况下，大量使用INCR来自增主键会让redis的自增操作频繁，影响redis的正常使用\n\n优化：每台服务可以使用INCRBY一次性获取一百或者一千或者多少个id段来慢慢分配，这样能大量减少redis的incr命令所带来的消耗\n\n\n2. list\n存储结构redis的list首先会按紧凑列表存储（listPack），当紧凑列表的长度达到list_max_listpack_size之后，会转换为双向链表\n// 1.LPUSH/RPUSH/LPUSHX/RPUSHX这些命令的统一入口void pushGenericCommand(client *c, int where, int xx)// 2.追加元素，并尝试转换紧凑列表void listTypeTryConversionAppend(robj *o, robj **argv, int start, int end, beforeConvertCB fn, void *data)// 3.尝试转换紧凑列表static void listTypeTryConversionRaw(robj *o, list_conv_type lct, robj **argv, int start, int end, beforeConvertCB fn, void *data)// 4.尝试转换紧凑列表// 若紧凑列表的长度达到list_max_listpack_size之后，则转换static void listTypeTryConvertQuicklist(robj *o, int shrinking, beforeConvertCB fn, void *data)\n\n当redis进行list元素移除时\n// 1.移除list元素的统一入口void listElementsRemoved(client *c, robj *key, int where, robj *o, long count, int signal, int *deleted)// 2.尝试转换void listTypeTryConversion(robj *o, list_conv_type lct, beforeConvertCB fn, void *data)// 3.尝试转换static void listTypeTryConversionRaw(robj *o, list_conv_type lct, robj **argv, int start, int end, beforeConvertCB fn, void *data)// 4.尝试转换双向链表// 若双向链表中只剩一个节点，且是压缩节点，则对双向链表转换为紧凑列表static void listTypeTryConvertQuicklist(robj *o, int shrinking, beforeConvertCB fn, void *data)\n\n以下参数可在redis.conf配置\nlist_max_listpack_size：默认-2\n常用命令LPUSH key value [value ...]RPUSH key value [value ...]LPOP keyRPOP keyLRANGE key start stopBLPOP key [key ...] timeout #从key列表头弹出一个元素，若没有元素，则阻塞等待timeout秒，0则一直阻塞等待BRPOP key [key ...] timeout #从key列表尾弹出一个元素，若没有元素，则阻塞等待timeout秒，0则一直阻塞等待\n\n组合数据结构\n根据list的特性，可以组成实现以下常用的数据结构\n\nStack（栈）：LPUSH + LPOP\n\nQueue（队列）：LPUSH + RPOP\n\nBlocking MQ（阻塞队列）：LPUSH + BRPOP\n\n\nredis实现数据结构的意义在于分布式环境的实现\n常用场景\n缓存有序列表结构\n\n构建分布式数据结构（栈、队列等）\n\n\n3. hash\n存储结构redis的hash首先会按紧凑列表存储（listPack），当紧凑列表的长度达到hash_max_listpack_entries或添加的元素大小超过hash_max_listpack_value之后，会转换为Hash表\n// 1.添加hash元素void hsetCommand(client *c)void hsetnxCommand(client *c)// 2.尝试转换Hash表// 若紧凑列表的长度达到hash_max_listpack_entries// 或添加的元素大小超过hash_max_listpack_value// 则进行转换void hashTypeTryConversion(robj *o, robj **argv, int start, int end)// 3.尝试转换Hash表void hashTypeConvert(robj *o, int enc)// 4.转换Hash表void hashTypeConvertListpack(robj *o, int enc)\n\n以下参数可在redis.conf配置\n\nhash_max_listpack_value：默认64\n\n\nhash_max_listpack_entries：默认512\n\n常用命令HSET key field valueHSETNX key field valueHMSET key field value [field value ...]HGET key fieldHMGET key field [field ...]HDEL key field [field ...]HLEN keyHGETALL keyHINCRBY key field increment\n\n常用场景对象缓存\n4. set\n存储结构\nredis的set添加元素时，若存储对象是整形数字且集合小于set_max_intset_entries，则存储为OBJ_ENCODING_INTSET，若集合长度小于set_max_listpack_entries时，存储为紧凑列表。否则，存储为Hash表\n\n// 1.添加set元素void saddCommand(client *c)// 2.1.创建set表// 若存储对象是整形数字且集合小于set_max_listpack_entries，则存储为OBJ_ENCODING_INTSET// 若集合长度小于set_max_listpack_entries时，存储为紧凑列表// 否则存储为Hash表robj *setTypeCreate(sds value, size_t size_hint)// 2.2 尝试转换set表// 如果编码是OBJ_ENCODING_LISTPACK（紧凑列表），且集合长度大于set_max_listpack_entries// 或编码是OBJ_ENCODING_INTSET（整形集合），且集合长度大于set_max_intset_entries// 则进行转换为Hash表void setTypeMaybeConvert(robj *set, size_t size_hint)// 2.3 添加元素int setTypeAdd(robj *subject, sds value)int setTypeAddAux(robj *set, char *str, size_t len, int64_t llval, int str_is_sds)// 2.4 若整形数组添加元素，长度超过set_max_intset_entries，则转换为Hash表static void maybeConvertIntset(robj *subject)\n\n以下参数可在redis.conf配置\n\nset_max_intset_entries：默认512\n\n\nset_max_listpack_entries：默认128\n\n常用命令SADD key member [member ...]SREM key member [member ...]SMEMBERS keySCARD keySISMEMBERS key memberSRANDMEMBER key [count]SPOP key [count]SRANDOMEMBER key [count]SINTER key [key ...] #交集运算SINTERSTORE destination key [key ...] #将交集结果存入新集合destinationSUNION key [key ...] #并集运算SUNIONSTORE destination key [key ...] #将并集结果存入新集合destinationSDIFF key [key ...] #差集运算SDIFFSTORE destination key [key ...] #将差集结果存入新集合destination\n\n常用场景\n缓存无序集合\n\n需要求交集并集差集的场景\n\n\n5. sorted set\n存储结构根据情况可能创建紧凑列表或跳表\n// 1.添加元素void zaddCommand(client *c)void zaddGenericCommand(client *c, int flags)// 2.1 创建元素// 若集合长度&lt;=zset_max_listpack_entries 并且值的长度&lt;=zset_max_listpack_value，则创建紧凑列表// 否则创建跳表节点robj *zsetTypeCreate(size_t size_hint, size_t val_len_hint)// 2.2 添加元素// 若集合是紧凑列表，且集合元素超过zset_max_listpack_entries// 或当前添加的元素长度超过zset_max_listpack_value// 则将紧凑列表转换为跳表int zsetAdd(robj *zobj, double score, sds ele, int in_flags, int *out_flags, double *newscore)\n\n以下参数可在redis.conf配置\n\nzset_max_listpack_entries：默认128\n\n\nzset_max_listpack_value：默认64\n\n跳表仅在以下情况转换回压缩列表\n\n使用命令georadius时，判断元素长度若小于等于zset_max_listpack_entries，并且最大元素的长度小于等于zset_max_listpack_value\n\nvoid georadiusGeneric(client *c, int srcKeyIndex, int flags)\n\n\n使用命令zunion&#x2F;zinter&#x2F;zdiff命令（求并集交集差集）时，判断元素长度若小于等于zset_max_listpack_entries，并且最大元素的长度小于等于zset_max_listpack_value\n\nvoid zunionInterDiffGenericCommand(client *c, robj *dstkey, int numkeysIndex, int op, int cardinality_only)\n\n常用命令ZADD key score member [[score member]...]ZREM key member [member ...]ZSCORE key memberZINCRBY key increment memberZCARD keyZRANGE key start stop [WITHSCORES]ZREVRANGE key start stop [WITHSCORES]ZUNIONSTORE destkey numkeys key [key ...] # 并集计算ZINTERSTORE destkey numkeys key [key ...] # 交集计算\n\n常用场景排行榜\n底层数据结构RedisObject&#123;   unsigned type:4;//类型 五种对象类型   unsigned encoding:4;//编码   void *ptr;//指向底层实现数据结构的指针   int refcount;//引用计数   unsigned lru:24;//记录最后一次被命令程序访问的时间&#125;robj;\n\n\ntype ：表示对象的类型，占4个比特；目前包括REDIS_STRING(字符串)、REDIS_LIST (列表)、REDIS_HASH(哈希)、REDIS_SET(集合)、REDIS_ZSET(有序集合)。\n\nencoding：占4个比特，Redis支持的每种类型，都有至少两种内部编码，例如对于字符串，有int、embstr、raw三种编码。通过encoding属性，Redis可以根据不同的使用场景来为对象设置不同的编码，大大提高了Redis的灵活性和效率。以列表对象为例，有紧凑列表和双端链表两种编码方式；如果列表中的元素较少，Redis倾向于使用紧凑列表进行存储，因为紧凑列表占用内存更少，而且比双端链表可以更快载入；当列表对象元素较多时，紧凑列表就会转化为更适合存储大量元素的双端链表。\n\nptr：指针指向具体的数据。\n\nrefcount：记录的是该对象被引用的次数，类型为整型。主要用于对象的引用计数和内存回收。Redis中被多次使用的对象(refcount&gt;1)，称为共享对象。Redis为了节省内存，当有一些对象重复出现时，新的程序不会创建新的对象，而是仍然使用原来的对象。这个被重复使用的对象，就是共享对象。目前共享对象仅支持整数值的字符串对象。共享对象只能是整数值的字符串对象，但是5种类型都可能使用共享对象。Redis服务器在初始化时，会创建10000个字符串对象，值分别是0~9999的整数值；\n\nlru：Redis 对象头中的 lru 字段，在 LRU 算法下和 LFU 算法下使用方式并不相同。\n\n在 LRU 算法中，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。\n\n在 LFU 算法中，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，低 8bit 存储 logc(Logistic Counter)。\n\n一个redisObject对象的大小为16字节：4bit+4bit+24bit+4Byte+8Byte&#x3D;16Byte\n\n\nSDS 简单动态字符串(Simple Dynamic String)typedef char *sds;struct __attribute__ ((__packed__)) sdshdr5 &#123; // 对应的字符串长度小于 1&lt;&lt;5 32字节   unsigned char flags; /* 3 lsb of type, and 5 msb of string length intembstr*/   char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr8 &#123; // 对应的字符串长度小于 1&lt;&lt;8 256   uint8_t len; /* used */ //目前字符创的长度 用1字节存储   uint8_t alloc; //已经分配的总长度 用1字节存储   unsigned char flags; //flag用3bit来标明类型，类型后续解释，其余5bit目前没有使用 embstr raw   char buf[]; //柔性数组，以&#x27;\\0&#x27;结尾&#125;;struct __attribute__ ((__packed__)) sdshdr16 &#123; // 对应的字符串长度小于 1&lt;&lt;16   uint16_t len; /*已使用长度，用2字节存储*/   uint16_t alloc; /* 总长度，用2字节存储*/   unsigned char flags; /* 3 lsb of type, 5 unused bits */   char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr32 &#123; // 对应的字符串长度小于 1&lt;&lt;32   uint32_t len; /*已使用长度，用4字节存储*/   uint32_t alloc; /* 总长度，用4字节存储*/   unsigned char flags;/* 低3位存储类型, 高5位预留 */   char buf[];/*柔性数组，存放实际内容*/&#125;;struct __attribute__ ((__packed__)) sdshdr64 &#123; // 对应的字符串长度小于 1&lt;&lt;64   uint64_t len; /*已使用长度，用8字节存储*/   uint64_t alloc; /* 总长度，用8字节存储*/   unsigned char flags; /* 低3位存储类型, 高5位预留 */   char buf[];/*柔性数组，存放实际内容*/&#125;;\n\n字符串类型的内部编码有3种:\n\nint：8个字节的长整型。字符串值是整型时，这个值使用long整型表示。\n\nembstr：**&lt;&#x3D;44字节的字符串。embstr与raw都使用redisObject和sds保存数据，区别在于，embstr的使用只分配一次内存空间（因此redisObject和sds是连续的），而raw需要分配两次内存空间（分别为redisObject和sds分配空间）。因此与raw相比，embstr的好处在于创建时少分配一次空间，删除时少释放一次空间，以及对象的所有数据连在一起，寻找方便。而embstr的坏处也很明显，如果字符串的长度增加需要重新分配内存时，整个redisObject和sds都需要重新分配空间**，因此redis中的embstr实现为只读。\n\nraw：大于44个字节的字符串\n\n\nembstr和raw进行区分的长度，是44；是因为redisObject的长度是16字节，sds的长度是4+字符串长度；因此当字符串长度是44时，embstr的长度正好是16+4+44 &#x3D;64，jemalloc正好可以分配64字节的内存单元。\n压缩列表zipListziplist 被设计成一种内存紧凑型的数据结构，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地节省内存开销。\nziplist 是一个特殊双向链表，不像普通的链表使用前后指针关联在一起，它是存储在连续内存上的。\n/* 创建一个空的 ziplist. */unsigned char *ziplistNew(void) &#123;    unsigned int bytes = ZIPLIST_HEADER_SIZE+ZIPLIST_END_SIZE;    unsigned char *zl = zmalloc(bytes);    ZIPLIST_BYTES(zl) = intrev32ifbe(bytes);    ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(ZIPLIST_HEADER_SIZE);    ZIPLIST_LENGTH(zl) = 0;    zl[bytes-1] = ZIP_END;    return zl;&#125;\n\n\n\nzlbytes: 32 位无符号整型，记录 ziplist 整个结构体的占用空间大小。当然了也包括 zlbytes 本身。这个结构有个很大的用处，就是当需要修改 ziplist 时候不需要遍历即可知道其本身的大小。这和SDS中记录字符串的长度有相似之处。\n\nzltail: 32 位无符号整型, 记录整个 ziplist 中最后一个 entry 的偏移量。所以在尾部进行 POP 操作时候不需要先遍历一次。\n\nzllen: 16 位无符号整型, 记录 entry 的数量， 所以只能表示 2^16。但是 Redis 作了特殊的处理：当实体数超过 2^16 ,该值被固定为 2^16 - 1。所以这种时候要知道所有实体的数量就必须要遍历整个结构了。\n\nentry: 真正存数据的结构。\n\nzlend: 8 位无符号整型, 固定为 255 (0xFF)。为 ziplist 的结束标识。\n\n\nzipList缺陷\nziplist 在更新或者新增时候，如空间不够则需要对整个列表进行重新分配。当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降。\nziplist 节点的 prevlen 属性会根据前一个节点的长度进行不同的空间大小分配：\n\n如果前一个节点的长度小于 254 字节，那么 prevlen 属性需要用 1 字节的空间来保存这个长度值。\n\n如果前一个节点的长度大于等于 254 字节，那么 prevlen 属性需要用 5 字节的空间来保存这个长度值。\n\n\n假设有这样的一个 ziplist，每个节点都是等于 253 字节的。新增了一个大于等于 254 字节的新节点，由于之前的节点 prevlen 长度是 1 个字节。\n为了要记录新增节点的长度所以需要对节点 1 进行扩展，由于节点 1 本身就是 253 字节，再加上扩展为 5 字节的 pervlen 则长度超过了 254 字节，这时候下一个节点又要进行扩展了\n\nzipList特性\n\nziplist 为了节省内存，采用了紧凑的连续存储。所以在修改操作下并不能像一般的链表那么容易，需要从新分配新的内存，然后复制到新的空间。\n\nziplist 是一个双向链表，可以在时间复杂度为 O(1) 从下头部、尾部进行 pop 或 push。\n\n新增或更新元素可能会出现连锁更新现象。\n\n不能保存过多的元素，否则查询效率就会降低。\n\n\n紧凑列表listPackRedis7.0之后采用listPack全面替代zipList\n在 Redis5.0 出现了 listpack，目的是替代压缩列表，其最大特点是 listpack 中每个节点不再包含前一个节点的长度，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。\nunsigned char *lpNew(size_t capacity) &#123;    unsigned char *lp = lp_malloc(capacity &gt; LP_HDR_SIZE+1 ? capacity : LP_HDR_SIZE+1);    if (lp == NULL) return NULL;    lpSetTotalBytes(lp,LP_HDR_SIZE+1);    lpSetNumElements(lp,0);    lp[LP_HDR_SIZE] = LP_EOF;    return lp;&#125;\n\n\nlistpack 中每个节点不再包含前一个节点的长度，避免连锁更新的隐患发生。\n\nlistpack 相对于 ziplist，没有了指向末尾节点地址的偏移量，解决 ziplist 内存长度限制的问题。但一个 listpack 最大内存使用不能超过 1GB。\n\n\n跳表数组：查询快，插入删除慢 链表：查询慢，插入删除快 跳表：跳表是基于链表的一个优化，在链表的插入删除快的特性之上，也增加了它的查询效率。它是将有序链表改造为支持折半查找算法，它的插入、删除、查询都很快\n\n跳表缺陷：需要额外空间来建立索引层，以空间换时间，因此zset一开始是以紧凑列表存储，后续才会转换为跳表\n\n跳表的创建（添加元素时）\n\n\n\n当前zset不存在时，若添加元素时集合长度达到zset_max_listpack_entries，或添加的最后一个元素的大小超过zset_max_listpack_value，则直接创建跳表，跳表头结点创建最大层数（ZSKIPLIST_MAXLEVEL：32）的索引，并插入跳表当前添加的元素\n当前zset存在时，判断若元素长度超过zset_max_listpack_entries，则将紧凑列表转换为跳表，跳表头结点创建最大层数（ZSKIPLIST_MAXLEVEL：32）的索引，然后把其他元素依次插入跳表\n\n\n\n跳表的查询 从起始节点开始，通过多级索引进行折半查找，最终找到需要的数据\n\n跳表的插入 先通过折半查找找到节点对应要插入的链表位置，然后通过随机得到一个要插入的节点的索引层数，然后插入节点，并构建对应的多级索引\n\n跳表的删除 先通过折半查找找到要删除的节点的链表位置，删除节点，并删除对应的多级索引\n\n\n淘汰策略\nnoeviction（默认策略）：不会删除任何数据，拒绝所有写入操作并返回客户端错误消息（error）OOM command not allowed when used memory，此时 Redis 只响应删和读操作；\n\nallkeys-lru：从所有 key 中使用 LRU（Least Recently Used）算法进行淘汰（LRU 算法：最近最少使用算法）；\n\nallkeys-lfu：从所有 key 中使用 LFU（Least Frequently Used）算法进行淘汰（LFU 算法：最不常用算法，根据使用频率计算，4.0 版本新增）；\n\nvolatile-lru：从设置了过期时间的 key 中使用 LRU 算法进行淘汰；\n\nvolatile-lfu：从设置了过期时间的 key 中使用 LFU 算法进行淘汰；\n\nallkeys-random：从所有 key 中随机淘汰数据；\n\nvolatile-random：从设置了过期时间的 key 中随机淘汰数据；\n\nvolatile-ttl：在设置了过期时间的key中，淘汰过期时间剩余最短的\n\n\nRedis的LRU实现由于Redis 主要运行在单个线程中，它采用的是一种近似的 LRU 算法，而不是传统的完全 LRU 算法（没有把所有key组织为链表）。这种实现方式在保证性能的同时，仍然能够有效地识别并淘汰最近最少使用的键。当 Redis 进行内存淘汰时，会使用随机采样的方式来淘汰数据，它是随机取 5 个值（此值可配置），然后淘汰最久没有使用的那个。\nRedis的LFU实现Redis 在访问 key 时，对 logc进行变化：\n\n先按照上次访问距离当前的时长，来对 logc 进行衰减；\n\n再按照一定概率增加 logc 的值\n\n\nredis.conf 提供了两个配置项，用于调整 LFU 算法从而控制 logc 的增长和衰减：\n\nlfu-decay-time 用于调整 logc 的衰减速度，它是一个以分钟为单位的数值，默认值为1，lfu-decay-time 值越大，衰减越慢；\n\nlfu-log-factor 用于调整 logc 的增长速度，lfu-log-factor 值越大，logc 增长越慢\n\n\n删除策略redis的key过期删除策略采用惰性删除+定期删除实现：\n\n惰性删除：不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key\n\nRedis 的惰性删除策略由 db.c 文件中的 expireIfNeeded 函数实现，代码如下：\nint expireIfNeeded(redisDb *db, robj *key) &#123;    // 判断 key 是否过期    if (!keyIsExpired(db,key)) return 0;    ....    /* 删除过期键 */    ....    // 如果 server.lazyfree_lazy_expire 为 1 表示异步删除，反之同步删除；    return server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) :                                         dbSyncDelete(db,key);&#125;\n\n定期删除：定期删除策略的做法是，每隔一段时间随机从数据库中取出一定数量的 key 进行检查，并删除其中的过期key\n\n在 Redis 中，默认每秒进行 10 次过期检查一次数据库，此配置可通过 Redis 的配置文件 redis.conf 进行配置，配置键为 hz 它的默认值是 hz 10；定期删除的实现在 expire.c 文件下的 activeExpireCycle 函数中，其中随机抽查的数量由 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 定义的，它是写死在代码中的，数值是 20；也就是说，数据库每轮抽查时，会随机选择 20 个 key 判断是否过期。\n管道Pipelineredis提供pipeline，可以让客户端一次发送一连串的命令给服务器执行，然后再返回执行结果\n\n应用场景：\n\n\n需要多次执行一连串的redis命令，且命令之间没有依赖的场景\n\n• 缺陷：\n\n\n不保证原子性，pipeline拿到命令只管串行执行，不管执行成功与否，也没有回滚机制\n\n\n\n\npipeline在执行过程中无法知道执行结果，只有全部执行结束才会返回全部结果\n\n\n\n\npipeline也不宜一次性发送过多命令，尽管节省了IO，但在redis端也依然会进行执行队列顺序执行\n\n\n使用示例/** * 一次io获取个值 * * @param redisKeyEnum * @param ids * @param clz * @param &lt;T&gt; * @param &lt;E&gt; * @return */public &lt;T, E extends T&gt; List&lt;T&gt; multiGet(RedisKeyEnum redisKeyEnum, List&lt;String&gt; ids, Class&lt;E&gt; clz) &#123;    ShardRedisConnectionFactory factory = getShardRedisConnectionFactory(redisKeyEnum);    ShardedJedis shardedJedis = factory.getConnection();    return execute(factory, shardedJedis, new Supplier&lt;List&lt;T&gt;&gt;() &#123;        @Override        public List&lt;T&gt; get() &#123;            // 1.获取管道            ShardedJedisPipeline pipeline = shardedJedis.pipelined();            List&lt;T&gt; list = new ArrayList&lt;&gt;();            List&lt;Response&lt;String&gt;&gt; respList = new ArrayList&lt;&gt;();            for (String id : ids) &#123;                String key = getKey(redisKeyEnum, id);                // 2.通过管道执行命令                Response&lt;String&gt; resp = pipeline.get(key);                respList.add(resp);            &#125;            // 3.统一提交命令            pipeline.sync();            for (Response&lt;String&gt; resp : respList) &#123;                // 4.遍历获取全部的命令执行返回结果                String result = resp.get();                if (result == null) &#123;                    continue;                &#125;                if (clz.equals(String.class)) &#123;                    list.add((E) result);                &#125; else &#123;                    list.add(JsonUtil.json2Obj(result, clz));                &#125;            &#125;            return list;        &#125;    &#125;);&#125;\n\n事务Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。\n事务的命令：\n\nMULTI ：开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令系列。\n\nEXEC：执行事务中的所有操作命令。\n\nDISCARD：取消事务，放弃执行事务块中的所有命令。\n\nWATCH：监视一个或多个key,如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令。\n\nUNWATCH：取消WATCH对所有key的监视。\n\n\nredis事务在编译错误可以回滚，而运行时错误不能回滚，简单说，redis事务不支持回滚\nRedis的持久化redis提供了两种持久化的方式，分别是RDB（Redis DataBase）和AOF（Append Only File）。\n\nRDB，简而言之，就是在不同的时间点，将redis存储的数据生成快照并存储到磁盘等介质上；\n\nAOF，则是换了一个角度来实现持久化，那就是将redis执行过的所有写指令记录下来，在下次redis重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。AOF类似MySQL的binlog\n\n\n其实RDB和AOF两种方式也可以同时使用，在这种情况下，如果redis重启的话，则会优先采用AOF方式来进行数据恢复，这是因为AOF方式的数据恢复完整度更高。\n如果你没有数据持久化的需求，也完全可以关闭RDB和AOF方式，这样的话，redis将变成一个纯内存数据库\n1. AOFAOF日志是一种追加式持久化方式，它记录了每个写操作命令，以追加的方式将命令写入AOF文件。通过重新执行AOF文件中的命令，可以重建出数据在内存中的状态。AOF日志提供了更精确的持久化，适用于需要更高数据安全性和实时性的场景。\n优点：\n\nAOF日志可以实现更精确的数据持久化，每个写操作都会被记录。\n\n在AOF文件中，数据可以更好地恢复，因为它保存了所有的写操作历史。\n\nAOF日志适用于需要实时恢复数据的场景，如秒级数据恢复要求。\n\n\n缺点：\n\nAOF日志相对于RDB快照来说，可能会占用更多的磁盘空间，因为它是记录每个写操作的文本文件。\n\nAOF日志在恢复大数据集时可能会比RDB快照慢，因为需要逐条执行写操作。\n\n\n根据不同的需求，可以选择RDB快照、AOF日志或两者结合使用。你可以根据数据的重要性、恢复速度要求以及磁盘空间限制来选择合适的持久化方式。有时候，也可以通过同时使用两种方式来提供更高的数据保护级别。\n2. RDBRDB快照是一种全量持久化方式，它会周期性地将内存中的数据以二进制格式保存到磁盘上的RDB文件。RDB文件是一个经过压缩的二进制文件，包含了数据库在某个时间点的数据快照。RDB快照有助于实现紧凑的数据存储，适合用于备份和恢复。\n优点：\n\nRDB快照在恢复大数据集时速度较快，因为它是全量的数据快照。\n\n由于RDB文件是压缩的二进制文件，它在磁盘上的存储空间相对较小。\n\n适用于数据备份和灾难恢复。\n\n\n缺点：\n\nRDB快照是周期性的全量持久化，可能导致某个时间点之后的数据丢失。\n\n在保存快照时，Redis服务器会阻塞，可能对系统性能造成影响。\n\n\n发布订阅Redis提供了基于“发布&#x2F;订阅”模式的消息机制。此种模式下，消息发布者和订阅者不进行直接通信，发布者客户端向指定的频道（channel） 发布消息，订阅该频道的每个客户端都可以收到该消息。结构如下：\n\n该消息通信模式可用于模块间的解耦\n# 订阅消息 subscribe channel [channel ...]# 发布消息publish channel &quot;hello&quot;# 按模式订阅频道psubscribe pattern [pattern ...]# 退订频道unsubscribe pattern [pattern ...]# 按模式退订频道punsubscribe pattern [pattern ...]\nRedis发布订阅与消息队列的区别\n消息队列可以支持多种消息协议，但 Redis 没有提供对这些协议的支持；\n\n消息队列可以提供持久化功能，但 Redis无法对消息持久化存储，一旦消息被发送，如果没有订阅者接收，那么消息就会丢失；\n\n消息队列可以提供消息传输保障，当客户端连接超时或事务回滚等情况发生时，消息会被重新发送给客户端，Redis 没有提供消息传输保障。\n\n发布订阅消息量过多过频繁，也会占用redis的内存空间，挤占业务逻辑key的空间（可以通过放到不同redis解决）\n\n\nRedis集群模式redis集群主要有三种模式：主从复制，哨兵模式和Cluster\n主从复制主从复制模式中包含一个主数据库实例（master）与一个或多个从数据库实例（slave）\n\n工作机制\nslave启动后，向master发送SYNC命令，master接收到SYNC命令后通过bgsave保存快照，并使用缓冲区记录保存快照这段时间内执行的写命令\n\nmaster将保存的快照文件发送给slave，并继续记录执行的写命令\n\nslave接收到快照文件后，加载快照文件，载入数据\n\nmaster快照发送完后开始向slave发送缓冲区的写命令，slave接收命令并执行，完成复制初始化\n\nmaster每次执行一个写命令都会同步发送给slave，保持master与slave之间数据的一致性\n\n\n主从复制配置replicaof 127.0.0.1 6379 # master的ip，port masterauth 123456 # master的密码 replica-serve-stale-data no # 如果slave无法与master同步，设置成slave不可读，方便监控脚本发现问题\n\n优缺点优点：\n\nmaster能自动将数据同步到slave，可以进行读写分离，分担master的读压力\n\nmaster、slave之间的同步是以非阻塞的方式进行的，同步期间，客户端仍然可以提交查询或更新请求\n\n\n缺点：\n\n不具备自动容错与恢复功能，master或slave的宕机都可能导致客户端请求失败，需要等待机器重启或手动切换客户端IP才能恢复\n\nmaster宕机，如果宕机前数据没有同步完，则切换IP后会存在数据不一致的问题\n\n难以支持在线扩容，Redis的容量受限于单机配置\n\n\n哨兵模式主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。\n哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。\n\n这里的哨兵有两个作用\n\n通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。\n\n当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。\n\n\n然而一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。\n\n哨兵配置1.主从服务器配置\n# 使得Redis服务器可以跨网络访问bind 0.0.0.0# 设置密码requirepass &quot;123456&quot;# 指定主服务器，注意：有关slaveof的配置只是配置从服务器，主服务器不需要配置slaveof 192.168.11.128 6379# 主服务器密码，注意：有关slaveof的配置只是配置从服务器，主服务器不需要配置masterauth 123456\n\n2.配置哨兵 在Redis安装目录下有一个sentinel.conf文件，copy一份进行修改\n# 禁止保护模式protected-mode no# 配置监听的主服务器，这里sentinel monitor代表监控，mymaster代表服务器的名称，可以自定义，192.168.11.128代表监控的主服务器，6379代表端口，2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作。sentinel monitor mymaster 192.168.11.128 6379 2# sentinel author-pass定义服务的密码，mymaster是服务名称，123456是Redis服务器密码# sentinel auth-pass &lt;master-name&gt; &lt;password&gt;sentinel auth-pass mymaster 123456\n\n3.启动服务器和哨兵\n# 启动Redis服务器进程./redis-server ../redis.conf# 启动哨兵进程./redis-sentinel ../sentinel.conf\n\nCluster模式哨兵模式解决了主从复制不能自动故障转移，达不到高可用的问题，但还是存在难以在线扩容，Redis容量受限于单机配置的问题。\nCluster模式实现了Redis的分布式存储，即每台节点存储不同的内容，来解决在线扩容的问题\n\nCluster特点\n无中心结构：所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽\n\n分布式存储：Redis Cluster将数据分散存储在多个节点上，每个节点负责存储和处理其中的一部分数据。这种分布式存储方式允许集群处理更大的数据集，并提供更高的性能和可扩展性。\n\n数据复制：每个主节点都有一个或多个从节点，从节点会自动复制主节点上的数据。数据复制可以提供数据的冗余备份，并在主节点故障时自动切换到从节点，以保证系统的可用性。\n\n自动分片和故障转移：Redis Cluster会自动将数据分片到不同的节点上，同时提供自动化的故障检测和故障转移机制。当节点发生故障或下线时，集群会自动检测并进行相应的故障转移操作（投票机制：节点的fail是通过集群中超过半数的节点检测失效时才生效），以保持数据的可用性和一致性。\n\n节点间通信：Redis Cluster中的节点之间通过内部通信协议进行交互，共同协作完成数据的分片、复制和故障转移等操作。节点间通信的协议和算法确保了数据的正确性和一致性。\n\n\n工作机制\n在Redis的每个节点上，都有一个插槽（slot），取值范围为0-16383\n\n当我们存取key的时候，Redis会根据CRC16的算法得出一个结果，然后把结果对16384求余数，这样每个key都会对应一个编号在0-16383之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作\n\n为了保证高可用，Cluster模式也引入主从复制模式，一个主节点对应一个或者多个从节点，当主节点宕机的时候，就会启用从节点\n\n当其它主节点ping一个主节点A时，如果半数以上的主节点与A通信超时，那么认为主节点A宕机了。如果主节点A和它的从节点都宕机了，那么该集群就无法再提供服务了\n\n\nCluster模式集群节点最小配置6个节点(3主3从，因为需要半数以上)，其中主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。\nCluster部署redis.conf配置：\nport 7100 # 本示例6个节点端口分别为7100,7200,7300,7400,7500,7600 daemonize yes # r后台运行 pidfile /var/run/redis_7100.pid # pidfile文件对应7100,7200,7300,7400,7500,7600 cluster-enabled yes # 开启集群模式 masterauth passw0rd # 如果设置了密码，需要指定master密码cluster-config-file nodes_7100.conf # 集群的配置文件，同样对应7100,7200等六个节点cluster-node-timeout 15000 # 请求超时 默认15秒，可自行设置 \n\n启动redis：\n[root@dev-server-1 cluster]# redis-server redis_7100.conf[root@dev-server-1 cluster]# redis-server redis_7200.conf\n\n组成集群：\nredis-cli --cluster create --cluster-replicas 1 127.0.0.1:7100 127.0.0.1:7200 127.0.0.1:7300 127.0.0.1:7400 127.0.0.1:7500 127.0.0.1:7600 -a passw0rd\n\n–cluster-replicas：表示副本数量，也就是从服务器数量，因为我们一共6个服务器，这里设置1个副本，那么Redis会收到消息，一个主服务器有一个副本从服务器，那么会计算得出：三主三从。\nCluster注意点\n数据分片和哈希槽：Redis Cluster 使用数据分片和哈希槽来实现数据的分布式存储。每个节点负责一部分哈希槽，确保数据在集群中均匀分布。在设计应用程序时，需要考虑数据的分片规则和哈希槽的分配，以便正确地将数据路由到相应的节点。\n\n节点的故障和扩展：Redis Cluster 具有高可用性和可伸缩性。当节点发生故障或需要扩展集群时，需要正确处理节点的添加和删除。故障节点会被自动检测和替换，而添加节点需要进行集群重新分片的操作。\n\n客户端的重定向：Redis Cluster 在处理键的读写操作时可能会返回重定向错误（MOVED 或 ASK）。应用程序需要正确处理这些错误，根据重定向信息更新路由表，并将操作重定向到正确的节点上。\n\n数据一致性的保证：由于 Redis Cluster 使用异步复制进行数据同步，所以在节点故障和网络分区恢复期间，可能会发生数据不一致的情况。应用程序需要考虑数据一致性的问题，并根据具体业务需求采取适当的措施。\n\n客户端连接的负载均衡：在连接 Redis Cluster 时，应该使用适当的负载均衡策略，将请求均匀地分布到集群中的各个节点上，以避免单个节点过载或出现热点访问。\n\n事务和原子性操作：Redis Cluster 中的事务操作只能在单个节点上执行，无法跨越多个节点。如果需要执行跨节点的原子性操作，可以使用 Lua 脚本来实现。\n\n集群监控和管理：对 Redis Cluster 进行监控和管理是很重要的。可以使用 Redis 自带的命令行工具或第三方监控工具来监控集群的状态、性能指标和节点健康状况，以及执行管理操作，如节点添加、删除和重新分片等。\n\n\nRedis常见问题当使用redis作为数据库的缓存层时，会经常遇见这几种问题，以下是这些问题的描述以及对应的解决方案\n缓存穿透概念：请求过来之后，访问不存在的数据，redis中查询不到，则穿透到数据库进行查询\n现象：大量穿透访问造成redis命中率下降，数据库压力飙升\n解决方案：\n\n空值缓存：如果一个查询的数据返回空，仍然把这个结果缓存到redis，以缓解数据库的查询压力\n\n布隆过滤器：布隆过滤器由一个很长的二进制数组结合n个hash算法计算出n个数组下标，将这些数据下标置为1。在查找数据时，再次通过n个hash算法计算出数组下标，如果这些下标的值为1，表示该值可能存在(存在hash冲突的原因)，如果为0，则表示该值一定不存在。因此，布隆过滤器中存在，数据不一定存在，但若布隆过滤器中不存在，则数据一定不存在，依靠此特性可以过滤掉一定的空值数据\n\n\n缓存击穿概念：请求访问的key对应的数据存在，但key在redis中已过期，则访问击穿到数据库\n现象：若大批请求中访问的key均过期，那么redis正常运行，但数据库的瞬时并发压力会飙升\n解决方案：\n\n热点数据永不过期：热点数据可以一直在redis中请求到，不会过期，则不会出现缓存击穿现象\n\n使用互斥锁：当访问redis的key过期之后，在请求数据库重新加载数据之前，先获取互斥锁（单进程可以synchronized，分布式使用分布式锁），获取到锁的请求加载数据并放进缓存，没有获取到锁的请求可以进行重试，重试之后便能重新获取到redis中的数据\n\n\n缓存雪崩概念：同一时间大批量key同时过期，造成瞬时对这些key的请求全部击穿到数据库；或redis服务不可用（宕机）\n缓存雪崩与缓存击穿的区别在于：缓存击穿是单个热点数据过期，而缓存雪崩是大批量热点数据过期\n现象：大量热点数据的查询请求会增加数据库瞬时压力\n解决方案：\n\n设置随机过期时间：避免大量key的过期时间过于集中，可以通过随机算法均匀分布key的过期时间点\n\n热点数据永不过期：可以和缓存击穿一样让热点数据不过期\n\n搭建高可用redis服务：针对redis服务不可用，可以对redis进行分布式部署，并实现故障转移（如redis哨兵模式）\n\n控制系统负载：实现熔断限流或服务降级，让系统负载在可控范围内\n\n\n大key问题概念：redis中存在占用内存空间较多的key，其中包含多种情况，如string类型的value值过大，hash类型的所有成员总值过大，zset的成员数量过大等。大key的具体值的界定，要根据实际业务情况判断。\n现象：大key对业务会产生多方面的影响：\n\nredis内存占用过高：大key可能导致内存空间不足，从而触发redis的内存淘汰策略。\n\n阻塞其他操作：对某些大key操作可能导致redis实例阻塞，例如使用Del命令删除key等。\n\n网络拥塞：大key在网络传输中更消耗带宽，可能造成机器内部网络带宽打满。\n\n主从同步延迟：大key在redis进行主从同步时也更容易导致同步延迟，影响数据一致性。\n\n\n原因：\n\n业务设计不合理：在业务设计上，没有考虑大数据量问题，导致一个key存储了大量的数据\n\n未定期清理数据：没有合适的删除机制或过期机制，造成value不断增加\n\n业务逻辑问题：业务逻辑bug导致key的value只增不减\n\n\n排查：\n\nSCAN命令：通过redis的scan命令逐步遍历数据库中的所有key，通过比较大小，站到占用内存较多的大key\n\nbigkeys参数：使用redis-cli命令客户端，连接Redis服务的时候，加上 —bigkeys 参数，可以扫描每种数据类型数量最大的key。\n\n\nredis-cli -h 127.0.0.1 -p 6379 —bigkeys\n\n\nRedis RDB Tools工具：使用开源工具Redis RDB Tools，分析RDB文件，扫描出Redis大key。\n\n例如：输出占用内存大于1kb，排名前3的keys。\nrdb —commond memory —bytes 1024 —largest 3 dump.rbd\n\n\nRedis云商提供的工具：现在基本使用云商提供的redis实例，其本身也提供一定的方法能快速定位大key\n\n解决方案：\n\n大key拆分：可以根据实际业务场景，拆分多个小key，确保value大小在合理范围内\n\n大key清理：redis4.0之后可以使用unlink命令以非阻塞方式安全的删除大key\n\n合理设置过期时间：设置过期时间可以让数据自动失效清理，一定程度避免大key的长时间存在。\n\n合理设置淘汰策略：redis中使用合适的淘汰策略，能在redis内存不足时，淘汰数据，防止大key长时间占用内存\n\n数据压缩：使用string类型，可以对value通过压缩算法进行压缩。可以用gzip，bzip2等常用算法压缩和解压。需要注意的是，这种方法会增加CPU的开销以及处理的响应延迟，同时也增加逻辑代码的复杂性\n\n\n热key问题概念：redis中某个key的访问次数比较多且明显多于其他key，则这个key被定义为热key\n现象：\n\nRedis的CPU占用过高，效率降低，影响其他业务\n\n若热key请求超出redis处理能力，会造成redis宕机，请求击穿到数据库，影响数据库性能\n\n\n原因：某个热点数据访问量暴增，如重大的热搜事件、参与秒杀的商品\n排查：\n\nhotkeys参数：Redis 4.0.3 版本中新增了 hotkeys 参数，该参数能够返回所有 key 的被访问次数（使用前提：redis淘汰策略设置为lfu）\n\nredis-cli -p 6379 --hotkeys\n\n\nMONITOR命令：MONITOR 命令是 Redis 提供的一种实时查看 Redis 的所有操作的方式，可以用于临时监控 Redis 实例的操作情况，包括读写、删除等操作。该命令对 Redis 性能的影响比较大，因此禁止长时间开启 MONITOR（生产环境中建议谨慎使用该命令）\n\n根据业务情况分析：根据实际业务场景分析，可以提前预估可能出现的热key现象，比如秒杀活动的商品数据等\n\n云商redis工具：云服务一般会提供redis的热key分析工具，合理利用，发现热key\n\n\n解决方案：\n\n热key拆分：设计一定的规则，给热key增加后缀，变成多个key，结合Redis Cluster模式，能分散到不同的节点。会带来业务复杂度，以及可能产生数据一致性问题\n\n二级缓存：在应用和redis中间再引入一层缓存层，如本地缓存，来缓解redis压力\n\n热key单独集群部署：针对热key单独做集群部署，和其他业务key进行隔离\n\n\n","categories":["总结笔记"],"tags":["Redis"]},{"title":"Elasticsearch总结","url":"/2023_12_28_es/","content":"结构化数据和非结构化数据\n结构化数据：也称作行数据，是由二维表结构来逻辑表达和实现的数据，严格地遵循数据格式与长度规范，主要通过关系型数据库进行存储和管理。指具有固定格式或有限长度的数据，如数据库，元数据等。\n\n非结构化数据：又可称为全文数据，不定长或无固定格式，不适于由数据库二维表来表现，包括所有格式的办公文档、XML、HTML、Word 文档，邮件，各类报表、图片和咅频、视频信息等。\n\n说明：如果要更细致的区分的话，XML、HTML 可划分为半结构化数据。因为它们也具有自己特定的标签格式，所以既可以根据需要按结构化数据来处理，也可抽取出纯文本按非结构化数据来处理。\n\n\n数据的搜索根据两种数据分类，搜索也相应的分为两种：\n\n结构化数据搜索\n非结构化数据搜索\n\n对于结构化数据，因为它们具有特定的结构，所以我们一般都是可以通过关系型数据库（MySQL，Oracle 等）的二维表（Table）的方式存储和搜索，也可以建立索引。\n对于非结构化数据，也即对全文数据的搜索主要有两种方法：\n\n顺序扫描：\n\n通过文字名称也可了解到它的大概搜索方式，即按照顺序扫描的方式查询特定的关键字。\n例如给你一张报纸，让你找到该报纸中“平安”的文字在哪些地方出现过。你肯定需要从头到尾把报纸阅读扫描一遍然后标记出关键字在哪些版块出现过以及它的出现位置。\n这种方式无疑是最耗时的最低效的，如果报纸排版字体小，而且版块较多甚至有多份报纸，等你扫描完你的眼睛也差不多了。\n\n全文搜索：\n\n对非结构化数据顺序扫描很慢，我们是否可以进行优化？把我们的非结构化数据想办法弄得有一定结构不就行了吗？\n将非结构化数据中的一部分信息提取出来，重新组织，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。\n这种方式就构成了全文检索的基本思路。这部分从非结构化数据中提取出的然后重新组织的信息，我们称之为索引。\n这种方式的主要工作量在前期索引的创建，但是对于后期搜索却是快速高效的。\nLucene简介通过对生活中数据的类型作了一个简短了解之后，我们知道关系型数据库的 SQL 检索是处理不了这种非结构化数据的。\n这种非结构化数据的处理需要依赖全文搜索，而目前市场上开放源代码的最好全文检索引擎工具包就属于 Apache 的 Lucene了。\n但是 Lucene 只是一个工具包，它不是一个完整的全文检索引擎。Lucene 的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。\n目前以 Lucene 为基础建立的开源可用全文搜索引擎主要是 Solr 和 Elasticsearch。\nSolr 和 Elasticsearch 都是比较成熟的全文搜索引擎，能完成的功能和性能也基本一样。\n但是 ES 本身就具有分布式的特性和易安装使用的特点，而 Solr 的分布式需要借助第三方来实现，例如通过使用 ZooKeeper 来达到分布式协调管理。\n不管是 Solr 还是 Elasticsearch 底层都是依赖于 Lucene，而 Lucene 能实现全文搜索主要是因为它实现了倒排索引的查询结构。\n如何理解倒排索引呢？假如现有三份数据文档，文档的内容如下分别是：\nJava is the best programming language.PHP is the best programming language.Javascript is the best programming language.\n\n为了创建倒排索引，我们通过分词器将每个文档的内容域拆分成单独的词（我们称它为词条或 Term），创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。\n结果如下所示：\nTerm          Doc_1    Doc_2   Doc_3-------------------------------------Java        |   X   |        |is          |   X   |   X    |   Xthe         |   X   |   X    |   Xbest        |   X   |   X    |   Xprogramming |   x   |   X    |   Xlanguage    |   X   |   X    |   XPHP         |       |   X    |Javascript  |       |        |   X-------------------------------------\n\n这种结构由文档中所有不重复词的列表构成，对于其中每个词都有一个文档列表与之关联。\n这种由属性值来确定记录的位置的结构就是倒排索引。带有倒排索引的文件我们称为倒排文件。\n我们将上面的内容转换为图的形式来说明倒排索引的结构信息，如下图所示：\n其中主要有如下几个核心术语需要理解：\n\n词条（Term）：索引里面最小的存储和查询单元，对于英文来说是一个单词，对于中文来说一般指分词后的一个词。\n\n词典（Term Dictionary）：或字典，是词条 Term 的集合。搜索引擎的通常索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。\n\n倒排表（Post list）：一个文档通常由多个词组成，倒排表记录的是某个词在哪些文档里出现过以及出现的位置。每条记录称为一个倒排项（Posting）。倒排表记录的不单是文档编号，还存储了词频等信息。\n\n倒排文件（Inverted File）：所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件被称之为倒排文件，倒排文件是存储倒排索引的物理文件。\n\n\n从上图我们可以了解到倒排索引主要由两个部分组成：\n\n词典\n倒排文件\n\n词典和倒排表是 Lucene 中很重要的两种数据结构，是实现快速检索的重要基石。词典和倒排文件是分两部分存储的，词典在内存中而倒排文件存储在磁盘上。\nES 核心概念ES 是使用 Java 编写的一种开源搜索引擎，它在内部使用 Lucene 做索引与搜索，通过对 Lucene 的封装，隐藏了 Lucene 的复杂性，取而代之的提供一套简单一致的 RESTful API。\n然而，Elasticsearch 不仅仅是 Lucene，并且也不仅仅只是一个全文搜索引擎。 \n它可以被下面这样准确的形容：\n\n一个分布式的实时文档存储，每个字段可以被索引与搜索。\n\n一个分布式实时分析搜索引擎。\n\n\n能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据。\n官网对 Elasticsearch 的介绍是 Elasticsearch 是一个分布式、可扩展、近实时的搜索与数据分析引擎。\nES 集群（Cluster）ES 的集群搭建很简单，不需要依赖第三方协调管理组件，自身内部就实现了集群的管理功能。\nES 集群由一个或多个 Elasticsearch 节点组成，每个节点配置相同的 cluster.name 即可加入集群，默认值为 “elasticsearch”。\n确保不同的环境中使用不同的集群名称，否则最终会导致节点加入错误的集群。\n一个 Elasticsearch 服务启动实例就是一个节点（Node）。节点通过 node.name 来设置节点名称，如果不设置则在启动时给节点分配一个随机通用唯一标识符作为名称。\n发现机制那么有一个问题，ES 内部是如何通过一个相同的设置 cluster.name 就能将不同的节点连接到同一个集群的？答案是 Zen Discovery。\nZen Discovery 是 Elasticsearch 的内置默认发现模块（发现模块的职责是发现集群中的节点以及选举 Master 节点）。\n它提供单播和基于文件的发现，并且可以扩展为通过插件支持云环境和其他形式的发现。\nZen Discovery 与其他模块集成，例如，节点之间的所有通信都使用 Transport 模块完成。节点使用发现机制通过 Ping 的方式查找其他节点。\nElasticsearch 默认被配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。\n如果集群的节点运行在不同的机器上，使用单播，你可以为 Elasticsearch 提供一些它应该去尝试连接的节点列表。\n当一个节点联系到单播列表中的成员时，它就会得到整个集群所有节点的状态，然后它会联系 Master 节点，并加入集群。\n这意味着单播列表不需要包含集群中的所有节点， 它只是需要足够的节点，当一个新节点联系上其中一个并且说上话就可以了。\n如果你使用 Master 候选节点作为单播列表，你只要列出三个就可以了。这个配置在 elasticsearch.yml 文件中：\ndiscovery.zen.ping.unicast.hosts: [&quot;host1&quot;, &quot;host2:port&quot;]\n\n节点启动后先 Ping ，如果 discovery.zen.ping.unicast.hosts 有设置，则 Ping 设置中的 Host ，否则尝试 ping localhost 的几个端口。\nElasticsearch 支持同一个主机启动多个节点，Ping 的 Response 会包含该节点的基本信息以及该节点认为的 Master 节点。\n选举开始，先从各节点认为的 Master 中选，规则很简单，按照 ID 的字典序排序，取第一个。如果各节点都没有认为的 Master ，则从所有节点中选择，规则同上。\n这里有个限制条件就是 discovery.zen.minimum_master_nodes ，如果节点数达不到最小值的限制，则循环上述过程，直到节点数足够可以开始选举。\n最后选举结果是肯定能选举出一个 Master ，如果只有一个 Local 节点那就选出的是自己。\n如果当前节点是 Master ，则开始等待节点数达到 discovery.zen.minimum_master_nodes，然后提供服务。\n如果当前节点不是 Master ，则尝试加入 Master 。Elasticsearch 将以上服务发现以及选主的流程叫做 Zen Discovery 。\n由于它支持任意数目的集群（ 1- N ），所以不能像 Zookeeper 那样限制节点必须是奇数，也就无法用投票的机制来选主，而是通过一个规则。\n只要所有的节点都遵循同样的规则，得到的信息都是对等的，选出来的主节点肯定是一致的。\n但分布式系统的问题就出在信息不对等的情况，这时候很容易出现脑裂（Split-Brain）的问题。\n大多数解决方案就是设置一个 Quorum 值，要求可用节点必须大于 Quorum（一般是超过半数节点），才能对外提供服务。\n而 Elasticsearch 中，这个 Quorum 的配置就是 discovery.zen.minimum_master_nodes 。\n节点的角色每个节点既可以是候选主节点也可以是数据节点，通过在配置文件 ..&#x2F;config&#x2F;elasticsearch.yml 中设置即可，默认都为 true。\nnode.master: true  //是否候选主节点node.data: true    //是否数据节点\n\n数据节点负责数据的存储和相关的操作，例如对数据进行增、删、改、查和聚合等操作，所以数据节点（Data 节点）对机器配置要求比较高，对 CPU、内存和 I&#x2F;O 的消耗很大。\n通常随着集群的扩大，需要增加更多的数据节点来提高性能和可用性。\n候选主节点可以被选举为主节点（Master 节点），集群中只有候选主节点才有选举权和被选举权，其他节点不参与选举的工作。\n主节点负责创建索引、删除索引、跟踪哪些节点是群集的一部分，并决定哪些分片分配给相关的节点、追踪集群中节点的状态等，稳定的主节点对集群的健康是非常重要的。\n\n一个节点既可以是候选主节点也可以是数据节点，但是由于数据节点对 CPU、内存核 I&#x2F;O 消耗都很大。\n所以如果某个节点既是数据节点又是主节点，那么可能会对主节点产生影响从而对整个集群的状态产生影响。\n因此为了提高集群的健康性，我们应该对 Elasticsearch 集群中的节点做好角色上的划分和隔离。可以使用几个配置较低的机器群作为候选主节点群。\n主节点和其他节点之间通过 Ping 的方式互检查，主节点负责 Ping 所有其他节点，判断是否有节点已经挂掉。其他节点也通过 Ping 的方式判断主节点是否处于可用状态。\n虽然对节点做了角色区分，但是用户的请求可以发往任何一个节点，并由该节点负责分发请求、收集结果等操作，而不需要主节点转发。\n这种节点可称之为协调节点，协调节点是不需要指定和配置的，集群中的任何节点都可以充当协调节点的角色。\n脑裂现象同时如果由于网络或其他原因导致集群中选举出多个 Master 节点，使得数据更新时出现不一致，这种现象称之为脑裂，即集群中不同的节点对于 Master 的选择出现了分歧，出现了多个 Master 竞争。\n“脑裂”问题可能有以下几个原因造成：\n\n网络问题：集群间的网络延迟导致一些节点访问不到 Master，认为 Master 挂掉了从而选举出新的 Master，并对 Master 上的分片和副本标红，分配新的主分片。\n\n节点负载：主节点的角色既为 Master 又为 Data，访问量较大时可能会导致 ES 停止响应（假死状态）造成大面积延迟，此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点。\n\n内存回收：主节点的角色既为 Master 又为 Data，当 Data 节点上的 ES 进程占用的内存较大，引发 JVM 的大规模内存回收，造成 ES 进程失去响应。\n\n\n为了避免脑裂现象的发生，我们可以从原因着手通过以下几个方面来做出优化措施：\n\n适当调大响应时间，减少误判。\n\n通过参数 discovery.zen.ping_timeout 设置节点状态的响应时间，默认为 3s，可以适当调大。如果 Master 在该响应时间的范围内没有做出响应应答，判断该节点已经挂掉了。调大参数（如 6s，discovery.zen.ping_timeout:6），可适当减少误判。\n\n\n选举触发。\n\n我们需要在候选集群中的节点的配置文件中设置参数 discovery.zen.munimum_master_nodes 的值。这个参数表示在选举主节点时需要参与选举的候选主节点的节点数，默认值是 1，官方建议取值(master_eligibel_nodes&#x2F;2)+1，其中 master_eligibel_nodes 为候选主节点的个数。这样做既能防止脑裂现象的发生，也能最大限度地提升集群的高可用性，因为只要不少于 discovery.zen.munimum_master_nodes 个候选节点存活，选举工作就能正常进行。当小于这个值的时候，无法触发选举行为，集群无法使用，不会造成分片混乱的情况。\n\n\n角色分离。\n\n即是上面我们提到的候选主节点和数据节点进行角色分离，这样可以减轻主节点的负担，防止主节点的假死状态发生，减少对主节点“已死”的误判。\n\n\n\n分片（Shards）ES 支持 PB 级全文搜索，当索引上的数据量太大的时候，ES 通过水平拆分的方式将一个索引上的数据拆分出来分配到不同的数据块上，拆分出来的数据库块称之为一个分片。\n这类似于 MySQL 的分库分表，只不过 MySQL 分库分表需要借助第三方组件而 ES 内部自身实现了此功能。\n在一个多分片的索引中写入数据时，通过路由来确定具体写入哪一个分片中，所以在创建索引的时候需要指定分片的数量，并且分片的数量一旦确定就不能修改。\n分片的数量和下面介绍的副本数量都是可以通过创建索引时的 Settings 来配置，ES 默认为一个索引创建 5 个主分片, 并分别为每个分片创建一个副本。\nPUT /myIndex&#123;   &quot;settings&quot; : &#123;      &quot;number_of_shards&quot; : 5,      &quot;number_of_replicas&quot; : 1   &#125;&#125;\n\nES 通过分片的功能使得索引在规模上和性能上都得到提升，每个分片都是 Lucene 中的一个索引文件，每个分片必须有一个主分片和零到多个副本。\n副本（Replicas）副本就是对分片的 Copy，每个主分片都有一个或多个副本分片，当主分片异常时，副本可以提供数据的查询等操作。\n主分片和对应的副本分片是不会在同一个节点上的，所以副本分片数的最大值是 N-1（其中 N 为节点数）。\n对文档的新建、索引和删除请求都是写操作，必须在主分片上面完成之后才能被复制到相关的副本分片。\nES 为了提高写入的能力这个过程是并发写的，同时为了解决并发写的过程中数据冲突的问题，ES 通过乐观锁的方式控制，每个文档都有一个 _version （版本）号，当文档被修改时版本号递增。\n一旦所有的副本分片都报告写成功才会向协调节点报告成功，协调节点向客户端报告成功。\n\n从上图可以看出为了达到高可用，Master 节点会避免将主分片和副本分片放在同一个节点上。\n假设这时节点 Node1 服务宕机了或者网络不可用了，那么主节点上主分片 S0 也就不可用了。\n幸运的是还存在另外两个节点能正常工作，这时 ES 会重新选举新的主节点，而且这两个节点上存在我们所需要的 S0 的所有数据。\n我们会将 S0 的副本分片提升为主分片，这个提升主分片的过程是瞬间发生的。此时集群的状态将会为  Yellow。\n为什么我们集群状态是 Yellow 而不是 Green 呢？虽然我们拥有所有的 2 个主分片，但是同时设置了每个主分片需要对应两份副本分片，而此时只存在一份副本分片。所以集群不能为 Green 的状态。\n如果我们同样关闭了 Node2 ，我们的程序依然可以保持在不丢失任何数据的情况下运行，因为 Node3 为每一个分片都保留着一份副本。\n如果我们重新启动 Node1 ，集群可以将缺失的副本分片再次进行分配，那么集群的状态又将恢复到原来的正常状态。\n如果 Node1 依然拥有着之前的分片，它将尝试去重用它们，只不过这时 Node1 节点上的分片不再是主分片而是副本分片了，如果期间有更改的数据只需要从主分片上复制修改的数据文件即可。\n小结将数据分片是为了提高可处理数据的容量和易于进行水平扩展，为分片做副本是为了提高集群的稳定性和提高并发量。\n副本是乘法，越多消耗越大，但也越保险。分片是除法，分片越多，单分片数据就越少也越分散。\n副本越多，集群的可用性就越高，但是由于每个分片都相当于一个 Lucene 的索引文件，会占用一定的文件句柄、内存及 CPU。\n并且分片间的数据同步也会占用一定的网络带宽，所以索引的分片数和副本数也不是越多越好。\n映射（Mapping）映射是用于定义 ES 对索引中字段的存储类型、分词方式和是否存储等信息，就像数据库中的 Schema ，描述了文档可能具有的字段或属性、每个字段的数据类型。\n只不过关系型数据库建表时必须指定字段类型，而 ES 对于字段类型可以不指定然后动态对字段类型猜测，也可以在创建索引时具体指定字段的类型。\n对字段类型根据数据格式自动识别的映射称之为动态映射（Dynamic Mapping），我们创建索引时具体定义字段类型的映射称之为静态映射或显示映射（Explicit Mapping）。\n在讲解动态映射和静态映射的使用前，我们先来了解下 ES 中的数据有哪些字段类型？之后我们再讲解为什么我们创建索引时需要建立静态映射而不使用动态映射。\nES（v6.8）中字段数据类型主要有以下几类：\n\nText 用于索引全文值的字段，例如电子邮件正文或产品说明。这些字段是被分词的，它们通过分词器传递 ，以在被索引之前将字符串转换为单个术语的列表。\n分析过程允许 Elasticsearch 搜索单个单词中每个完整的文本字段。文本字段不用于排序，很少用于聚合。\nKeyword 用于索引结构化内容的字段，例如电子邮件地址，主机名，状态代码，邮政编码或标签。它们通常用于过滤，排序，和聚合。Keyword 字段只能按其确切值进行搜索。\n通过对字段类型的了解我们知道有些字段需要明确定义的，例如某个字段是 Text 类型还是 Keyword 类型差别是很大的，时间字段也许我们需要指定它的时间格式，还有一些字段我们需要指定特定的分词器等等。\n如果采用动态映射是不能精确做到这些的，自动识别常常会与我们期望的有些差异。\n所以创建索引的时候一个完整的格式应该是指定分片和副本数以及 Mapping 的定义，如下：\nPUT my_index &#123;   &quot;settings&quot; : &#123;      &quot;number_of_shards&quot; : 5,      &quot;number_of_replicas&quot; : 1   &#125;  &quot;mappings&quot;: &#123;    &quot;_doc&quot;: &#123;       &quot;properties&quot;: &#123;         &quot;title&quot;:    &#123; &quot;type&quot;: &quot;text&quot;  &#125;,         &quot;name&quot;:     &#123; &quot;type&quot;: &quot;text&quot;  &#125;,         &quot;age&quot;:      &#123; &quot;type&quot;: &quot;integer&quot; &#125;,          &quot;created&quot;:  &#123;          &quot;type&quot;:   &quot;date&quot;,           &quot;format&quot;: &quot;strict_date_optional_time||epoch_millis&quot;        &#125;      &#125;    &#125;  &#125;&#125;\n\nES 的基本使用在决定使用 Elasticsearch 的时候首先要考虑的是版本问题，Elasticsearch （排除 0.x 和 1.x）目前有如下常用的稳定的主版本：2.x，5.x，6.x，7.x（current）。\n你可能会发现没有 3.x 和 4.x，ES 从 2.4.6 直接跳到了 5.0.0。其实是为了 ELK（ElasticSearch，Logstash，Kibana）技术栈的版本统一，免的给用户带来混乱。\n在 Elasticsearch 是 2.x （2.x 的最后一版 2.4.6 的发布时间是 July 25, 2017） 的情况下，Kibana 已经是 4.x（Kibana 4.6.5 的发布时间是 July 25, 2017）。\n那么在 Kibana 的下一主版本肯定是 5.x 了，所以 Elasticsearch 直接将自己的主版本发布为 5.0.0 了。\n统一之后，我们选版本就不会犹豫困惑了，我们选定 Elasticsearch 的版本后再选择相同版本的 Kibana 就行了，不用担忧版本不兼容的问题。\nElasticsearch 是使用 Java 构建，所以除了注意 ELK 技术的版本统一，我们在选择 Elasticsearch 的版本的时候还需要注意 JDK 的版本。\n因为每个大版本所依赖的 JDK 版本也不同，目前 7.2 版本已经可以支持 JDK11。\n解压安装\n\n下载和解压 Elasticsearch，无需安装解压后即可用，解压后目录如上图：\n\n\nbin：二进制系统指令目录，包含启动命令和安装插件命令等。\n\nconfig：配置文件目录。\n\nlib：依赖包目录。\n\nlogs：日志文件目录。\n\nmodules：模块库，例如 x-pack 的模块。\n\nplugins：插件目录。\n\n\n\n安装目录下运行 bin&#x2F;elasticsearch 来启动 ES。\n\n默认在 9200 端口运行，请求 curl http://localhost:9200/ 或者浏览器输入 http://localhost:9200，得到一个 JSON 对象，其中包含当前节点、集群、版本等信息。\n\n\n&#123;  &quot;name&quot; : &quot;U7fp3O9&quot;,  &quot;cluster_name&quot; : &quot;elasticsearch&quot;,  &quot;cluster_uuid&quot; : &quot;-Rj8jGQvRIelGd9ckicUOA&quot;,  &quot;version&quot; : &#123;    &quot;number&quot; : &quot;6.8.1&quot;,    &quot;build_flavor&quot; : &quot;default&quot;,    &quot;build_type&quot; : &quot;zip&quot;,    &quot;build_hash&quot; : &quot;1fad4e1&quot;,    &quot;build_date&quot; : &quot;2019-06-18T13:16:52.517138Z&quot;,    &quot;build_snapshot&quot; : false,    &quot;lucene_version&quot; : &quot;7.7.0&quot;,    &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;,    &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot;  &#125;,  &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125;\ndocker安装# 创建网络、拉镜像，启动，测试验证docker network create es-netdocker network lsdocker pull elasticsearch:7.12.1docker run --network es-net -p 9200:9200 -p 9300:9300 -e &quot;discovery.type=single-node&quot; -e ES_JAVA_OPTS=&quot;-Xms512m -Xmx512m&quot; --name=&quot;es&quot; --cpuset-cpus=&quot;1&quot; -v es-plugins:/usr/share/elasticsearch/plugins --privileged -d elasticsearch:7.12.1http://192.168.134.132:9200/# kibana安装docker run -d --name kibana -e ELASTICSEARCH_HOSTS=http://es:9200 --network=es-net -p 5601:5601 kibana:7.12.1\n\n集群健康状态要检查群集运行状况，我们可以在 Kibana 控制台中运行以下命令 GET &#x2F;_cluster&#x2F;health，得到如下信息：\n&#123;  &quot;cluster_name&quot; : &quot;docker-cluster&quot;,  &quot;status&quot; : &quot;yellow&quot;,  &quot;timed_out&quot; : false,  &quot;number_of_nodes&quot; : 1,  &quot;number_of_data_nodes&quot; : 1,  &quot;active_primary_shards&quot; : 11,  &quot;active_shards&quot; : 11,  &quot;relocating_shards&quot; : 0,  &quot;initializing_shards&quot; : 0,  &quot;unassigned_shards&quot; : 1,  &quot;delayed_unassigned_shards&quot; : 0,  &quot;number_of_pending_tasks&quot; : 0,  &quot;number_of_in_flight_fetch&quot; : 0,  &quot;task_max_waiting_in_queue_millis&quot; : 0,  &quot;active_shards_percent_as_number&quot; : 91.66666666666666&#125;\n\n集群状态通过 绿，黄，红 来标识：\n\n绿色：集群健康完好，一切功能齐全正常，所有分片和副本都可以正常工作。\n\n黄色：预警状态，所有主分片功能正常，但至少有一个副本是不能正常工作的。此时集群是可以正常工作的，但是高可用性在某种程度上会受影响。\n\n红色：集群不可正常使用。某个或某些分片及其副本异常不可用，这时集群的查询操作还能执行，但是返回的结果会不准确。对于分配到这个分片的写入请求将会报错，最终会导致数据的丢失。\n\n\n当集群状态为红色时，它将会继续从可用的分片提供搜索请求服务，但是你需要尽快修复那些未分配的分片。\nES 机制原理ES 的基本概念和基本操作介绍完了之后，我们可能还有很多疑惑：\n\n它们内部是如何运行的？\n\n主分片和副本分片是如何同步的？\n\n创建索引的流程是什么样的？\n\nES 如何将索引数据分配到不同的分片上的？以及这些索引数据是如何存储的？\n\n为什么说 ES 是近实时搜索引擎而文档的 CRUD (创建-读取-更新-删除) 操作是实时的？\n\n以及 Elasticsearch 是怎样保证更新被持久化在断电时也不丢失数据？\n\n还有为什么删除文档不会立刻释放空间？\n\n\n带着这些疑问我们进入接下来的内容。\n写索引原理下图描述了 3 个节点的集群，共拥有 12 个分片，其中有 4 个主分片（S0、S1、S2、S3）和 8 个副本分片（R0、R1、R2、R3），每个主分片对应两个副本分片，节点 1 是主节点（Master 节点）负责整个集群的状态。\n\n写索引是只能写在主分片上，然后同步到副本分片。这里有四个主分片，一条数据 ES 是根据什么规则写到特定分片上的呢？\n这条索引数据为什么被写到 S0 上而不写到 S1 或 S2 上？那条数据为什么又被写到 S3 上而不写到 S0 上了？\n首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。\n实际上，这个过程是根据下面这个公式决定的：\nshard = hash(routing) % number_of_primary_shards\n\nRouting 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。\nRouting 通过 Hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到余数。\n这个在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。\n这就解释了为什么我们要在创建索引的时候就确定好主分片的数量并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。\n由于在 ES 集群中每个节点通过上面的计算公式都知道集群中的文档的存放位置，所以每个节点都有处理读写请求的能力。\n在一个写请求被发送到某个节点后，该节点即为前面说过的协调节点，协调节点会根据路由公式计算出需要写到哪个分片上，再将请求转发到该分片的主分片节点上。\n\n假如此时数据通过路由计算公式取余后得到的值是 shard&#x3D;hash(routing)%4&#x3D;0。\n则具体流程如下：\n\n客户端向 ES1 节点（协调节点）发送写请求，通过路由计算公式得到值为 0，则当前数据应被写到主分片 S0 上。\n\nES1 节点将请求转发到 S0 主分片所在的节点 ES3，ES3 接受请求并写入到磁盘。\n\n并发将数据复制到两个副本分片 R0 上，其中通过乐观并发控制数据的冲突。一旦所有的副本分片都报告成功，则节点 ES3 将向协调节点报告成功，协调节点向客户端报告成功。\n\n\n存储原理上面介绍了在 ES 内部索引的写处理流程，这个流程是在 ES 的内存中执行的，数据被分配到特定的分片和副本上之后，最终是存储到磁盘上的，这样在断电的时候就不会丢失数据。\n具体的存储路径可在配置文件 ..&#x2F;config&#x2F;elasticsearch.yml 中进行设置，默认存储在安装目录的 Data 文件夹下。\n建议不要使用默认值，因为若 ES 进行了升级，则有可能导致数据全部丢失：\npath.data: /path/to/data  //索引数据path.logs: /path/to/logs  //日志记录\n\n分段存储索引文档以段的形式存储在磁盘上，何为段？索引文件被拆分为多个子文件，则每个子文件叫作段，每一个段本身都是一个倒排索引，并且段具有不变性，一旦索引的数据被写入硬盘，就不可再修改。\n在底层采用了分段的存储模式，使它在读写时几乎完全避免了锁的出现，大大提升了读写性能。\n段被写入到磁盘后会生成一个提交点，提交点是一个用来记录所有提交后段信息的文件。\n一个段一旦拥有了提交点，就说明这个段只有读的权限，失去了写的权限。相反，当段在内存中时，就只有写的权限，而不具备读数据的权限，意味着不能被检索。\n段的概念提出主要是因为：在早期全文检索中为整个文档集合建立了一个很大的倒排索引，并将其写入磁盘中。\n如果索引有更新，就需要重新全量创建一个索引来替换原来的索引。这种方式在数据量很大时效率很低，并且由于创建一次索引的成本很高，所以对数据的更新不能过于频繁，也就不能保证时效性。\n索引文件分段存储并且不可修改，那么新增、更新和删除如何处理呢？\n\n新增，新增很好处理，由于数据是新的，所以只需要对当前文档新增一个段就可以了。\n\n删除，由于不可修改，所以对于删除操作，不会把文档从旧的段中移除而是通过新增一个 .del 文件，文件中会列出这些被删除文档的段信息。这个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。\n\n更新，不能修改旧的段来进行反映文档的更新，其实更新相当于是删除和新增这两个动作组成。会将旧的文档在 .del 文件中标记删除，然后文档的新版本被索引到一个新的段中。可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就会被移除。\n\n\n段被设定为不可修改具有一定的优势也有一定的缺点，优势主要表现在：\n\n不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。\n\n一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。\n\n其它缓存(像 Filter 缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。\n\n写入单个大的倒排索引允许数据被压缩，减少磁盘 I&#x2F;O 和需要被缓存到内存的索引的使用量。\n\n\n段的不变性的缺点如下：\n\n当对旧数据进行删除时，旧数据不会马上被删除，而是在 .del 文件中被标记为删除。而旧数据只能等到段更新时才能被移除，这样会造成大量的空间浪费。\n\n若有一条数据频繁的更新，每次更新都是新增新的标记旧的，则会有大量的空间浪费。\n\n每次新增数据时都需要新增一个段来存储数据。当段的数量太多时，对服务器的资源例如文件句柄的消耗会非常大。\n\n在查询的结果中包含所有的结果集，需要排除被标记删除的旧数据，这增加了查询的负担。\n\n\n延迟写策略介绍完了存储的形式，那么索引写入到磁盘的过程是怎样的？是否是直接调 Fsync 物理性地写入磁盘？\n答案是显而易见的，如果是直接写入到磁盘上，磁盘的 I&#x2F;O 消耗上会严重影响性能。\n那么当写数据量大的时候会造成 ES 停顿卡死，查询也无法做到快速响应。如果真是这样 ES 也就不会称之为近实时全文搜索引擎了。\n为了提升写的性能，ES 并没有每新增一条数据就增加一个段到磁盘上，而是采用延迟写的策略。\n每当有新增的数据时，就将其先写入到内存中，在内存和磁盘之间是文件系统缓存。\n当达到默认的时间（1 秒钟）或者内存的数据达到一定量时，会触发一次刷新（Refresh），将内存中的数据生成到一个新的段上并缓存到文件缓存系统 上，稍后再被刷新到磁盘中并生成提交点。\n这里的内存使用的是 ES 的 JVM 内存，而文件缓存系统使用的是操作系统的内存。\n新的数据会继续的被写入内存，但内存中的数据并不是以段的形式存储的，因此不能提供检索功能。\n由内存刷新到文件缓存系统的时候会生成新的段，并将段打开以供搜索使用，而不需要等到被刷新到磁盘。\n在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做 Refresh （即内存刷新到文件缓存系统）。\n默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch 是近实时搜索，因为文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。\n我们也可以手动触发 Refresh，POST &#x2F;_refresh 刷新所有索引，POST &#x2F;nba&#x2F;_refresh 刷新指定的索引。\nTips：尽管刷新是比提交轻量很多的操作，它还是会有性能开销。当写测试的时候， 手动刷新很有用，但是不要在生产&gt;环境下每次索引一个文档都去手动刷新。而且并不是所有的情况都需要每秒刷新。\n可能你正在使用 Elasticsearch 索引大量的日志文件， 你可能想优化索引速度而不是&gt;近实时搜索。\n这时可以在创建索引时在 Settings 中通过调大 refresh_interval &#x3D; “30s” 的值 ， 降低每个索引的刷新频率，设值时需要注意后面带上时间单位，否则默认是毫秒。当 refresh_interval&#x3D;-1 时表示关闭索引的自动刷新。\n虽然通过延时写的策略可以减少数据往磁盘上写的次数提升了整体的写入能力，但是我们知道文件缓存系统也是内存空间，属于操作系统的内存，只要是内存都存在断电或异常情况下丢失数据的危险。\n为了避免丢失数据，Elasticsearch 添加了事务日志（Translog），事务日志记录了所有还没有持久化到磁盘的数据。\n\n添加了事务日志后整个写索引的流程如上图所示：\n\n一个新文档被索引之后，先被写入到内存中，但是为了防止数据的丢失，会追加一份数据到事务日志中。不断有新的文档被写入到内存，同时也都会记录到事务日志中。这时新数据还不能被检索和查询。\n\n当达到默认的刷新时间或内存中的数据达到一定量后，会触发一次  Refresh，将内存中的数据以一个新段形式刷新到文件缓存系统中并清空内存。这时虽然新段未被提交到磁盘，但是可以提供文档的检索功能且不能被修改。\n\n随着新文档索引不断被写入，当日志数据大小超过 512M 或者时间超过 30 分钟时，会触发一次 Flush。内存中的数据被写入到一个新段同时被写入到文件缓存系统，文件系统缓存中数据通过 Fsync 刷新到磁盘中，生成提交点，日志文件被删除，创建一个空的新日志。\n\n\n通过这种方式当断电或需要重启时，ES 不仅要根据提交点去加载已经持久化过的段，还需要工具 Translog 里的记录，把未持久化的数据重新持久化到磁盘上，避免了数据丢失的可能。\n段合并由于自动刷新流程每秒会创建一个新的段 ，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦。\n每一个段都会消耗文件句柄、内存和 CPU 运行周期。更重要的是，每个搜索请求都必须轮流检查每个段然后合并查询结果，所以段越多，搜索也就越慢。\nElasticsearch 通过在后台定期进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。\n段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档不会被拷贝到新的大段中。合并的过程中不会中断索引和搜索。\n\n段合并在进行索引和搜索时会自动进行，合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中，这些段既可以是未提交的也可以是已提交的。\n合并结束后老的段会被删除，新的段被 Flush 到磁盘，同时写入一个包含新段且排除旧的和较小的段的新提交点，新的段被打开可以用来搜索。\n段合并的计算量庞大， 而且还要吃掉大量磁盘 I&#x2F;O，段合并会拖累写入速率，如果任其发展会影响搜索性能。\nElasticsearch 在默认情况下会对合并流程进行资源限制，所以搜索仍然有足够的资源很好地执行。\n性能优化存储设备磁盘在现代服务器上通常都是瓶颈。Elasticsearch 重度使用磁盘，你的磁盘能处理的吞吐量越大，你的节点就越稳定。\n这里有一些优化磁盘 I&#x2F;O 的技巧：\n\n使用 SSD。就像其他地方提过的， 他们比机械磁盘优秀多了。\n\n使用 RAID 0。条带化 RAID 会提高磁盘 I&#x2F;O，代价显然就是当一块硬盘故障时整个就故障了。不要使用镜像或者奇偶校验 RAID 因为副本已经提供了这个功能。\n\n另外，使用多块硬盘，并允许 Elasticsearch 通过多个 path.data 目录配置把数据条带化分配到它们上面。\n\n不要使用远程挂载的存储，比如 NFS 或者 SMB&#x2F;CIFS。这个引入的延迟对性能来说完全是背道而驰的。\n\n如果你用的是 EC2，当心 EBS。即便是基于 SSD 的 EBS，通常也比本地实例的存储要慢。\n\n\n内部索引优化\nElasticsearch 为了能快速找到某个 Term，先将所有的 Term 排个序，然后根据二分法查找 Term，时间复杂度为 logN，就像通过字典查找一样，这就是 Term Dictionary。\n现在再看起来，似乎和传统数据库通过 B-Tree 的方式类似。但是如果 Term 太多，Term Dictionary 也会很大，放内存不现实，于是有了 Term Index。\n就像字典里的索引页一样，A 开头的有哪些 Term，分别在哪页，可以理解 Term Index是一棵树。\n这棵树不会包含所有的 Term，它包含的是 Term 的一些前缀。通过 Term Index 可以快速地定位到 Term Dictionary 的某个 Offset，然后从这个位置再往后顺序查找。\n在内存中用 FST 方式压缩 Term Index，FST 以字节的方式存储所有的 Term，这种压缩方式可以有效的缩减存储空间，使得 Term Index 足以放进内存，但这种方式也会导致查找时需要更多的 CPU 资源。\n对于存储在磁盘上的倒排表同样也采用了压缩技术减少存储所占用的空间。\n调整配置参数调整配置参数建议如下：\n\n给每个文档指定有序的具有压缩良好的序列模式 ID，避免随机的 UUID-4 这样的 ID，这样的 ID 压缩比很低，会明显拖慢 Lucene。\n\n对于那些不需要聚合和排序的索引字段禁用 Doc values。Doc Values 是有序的基于 document&#x3D;&gt;field value 的映射列表。\n\n不需要做模糊检索的字段使用 Keyword 类型代替 Text 类型，这样可以避免在建立索引前对这些文本进行分词。\n\n如果你的搜索结果不需要近实时的准确度，考虑把每个索引的 index.refresh_interval 改到 30s 。如果你是在做大批量导入，导入期间你可以通过设置这个值为 -1 关掉刷新，还可以通过设置 index.number_of_replicas: 0 关闭副本。别忘记在完工的时候重新开启它。\n\n避免深度分页查询建议使用 Scroll 进行分页查询。普通分页查询时，会创建一个 from+size 的空优先队列，每个分片会返回 from+size 条数据，默认只包含文档 ID 和得分 Score 给协调节点。如果有 N 个分片，则协调节点再对（from+size）×n 条数据进行二次排序，然后选择需要被取回的文档。当 from 很大时，排序过程会变得很沉重，占用 CPU 资源严重。\n\n减少映射字段，只提供需要检索，聚合或排序的字段。其他字段可存在其他存储设备上，例如 Hbase，在 ES 中得到结果后再去 Hbase 查询这些字段。\n\n创建索引和查询时指定路由 Routing 值，这样可以精确到具体的分片查询，提升查询效率。路由的选择需要注意数据的分布均衡。\n\n\nJVM 调优JVM 调优建议如下：\n\n确保堆内存最小值（ Xms ）与最大值（ Xmx ）的大小是相同的，防止程序在运行时改变堆内存大小。Elasticsearch 默认安装后设置的堆内存是 1GB。可通过 ..&#x2F;config&#x2F;jvm.option 文件进行配置，但是最好不要超过物理内存的50%和超过 32GB。\n\nGC 默认采用 CMS 的方式，并发但是有 STW 的问题，可以考虑使用 G1 收集器。\n\nES 非常依赖文件系统缓存（Filesystem Cache），快速搜索。一般来说，应该至少确保物理上有一半的可用内存分配到文件系统缓存。\n\n\n在spring中使用复合查询maven依赖项：\n&lt;parent&gt;    &lt;!-- Springboot依赖 --&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.5.6&lt;/version&gt;    &lt;relativePath/&gt;&lt;/parent&gt; &lt;!--Spring Boot Web--&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;        &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt;        &lt;version&gt;7.12.1&lt;/version&gt;    &lt;/dependency&gt;\nconfg类：\n@Configurationpublic class Elasticsearch &#123;    @Bean    public RestHighLevelClient esClient()&#123;        return new RestHighLevelClient(                RestClient.builder(                        new HttpHost(&quot;localhost&quot;,9200, &quot;http&quot;)                )        );    &#125;&#125;\n\n在es中创建如下索引：\n/** * 以下创建person索引， * 一个分片，每分片一个副本，总分片数量为2     PUT /person    &#123;    &quot;settings&quot;: &#123;    &quot;number_of_shards&quot;: 1,    &quot;number_of_replicas&quot;: 1    &#125;,    &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;    &quot;id&quot;: &#123;    &quot;type&quot;: &quot;long&quot;    &#125;,    &quot;name&quot;: &#123;    &quot;type&quot;: &quot;keyword&quot;    &#125;,    &quot;code&quot;: &#123;    &quot;type&quot;: &quot;keyword&quot;    &#125;,    &quot;phone&quot;: &#123;    &quot;type&quot;: &quot;keyword&quot;    &#125;,    &quot;birth&quot;: &#123;    &quot;type&quot;: &quot;date&quot;    &#125;,    &quot;lastIp&quot;: &#123;    &quot;type&quot;: &quot;keyword&quot;    &#125;,    &quot;url&quot;: &#123;    &quot;type&quot;: &quot;keyword&quot;    &#125;,    &quot;protocol&quot;: &#123;    &quot;type&quot;: &quot;keyword&quot;    &#125;,    &quot;address&quot;: &#123;    &quot;type&quot;: &quot;text&quot;,    &quot;analyzer&quot;: &quot;ik_max_word&quot;    &#125;,    &quot;zeroCode&quot;: &#123;    &quot;type&quot;: &quot;keyword&quot;    &#125;,    &quot;description&quot;: &#123;    &quot;type&quot;: &quot;text&quot;    , &quot;analyzer&quot;: &quot;ik_max_word&quot;    &#125;,    &quot;email&quot;: &#123;    &quot;type&quot;: &quot;keyword&quot;    &#125;    &#125;    &#125;    &#125;    */\n\n创建controller:\n@RestController@RequestMapping(value = &quot;/es&quot;)@Slf4jpublic class EsController &#123;    @Autowired    private RestHighLevelClient esClient;\t/**     复合查询     http://localhost:8080/es/search?pageNo=10000&amp;pageSize=1     http://localhost:8080/es/search?pageNo=1&amp;pageSize=1&amp;includes=id&amp;includes=name&amp;excludes=name     http://localhost:8080/es/search?pageNo=1&amp;pageSize=5&amp;includes=id&amp;includes=name&amp;includes=protocol&amp;includes=address&amp;excludes=name&amp;protocol=http     http://localhost:8080/es/search?pageNo=1&amp;pageSize=2&amp;includes=id&amp;includes=name&amp;includes=protocol&amp;includes=code&amp;protocol=ws&amp;id=10011     http://localhost:8080/es/search?pageNo=1&amp;pageSize=2&amp;includes=id&amp;includes=name&amp;includes=protocol&amp;includes=code&amp;includes=description&amp;protocol=ws&amp;description=宝玉     http://localhost:8080/es/search?pageNo=1&amp;pageSize=2&amp;includes=id&amp;includes=name&amp;includes=protocol&amp;includes=code&amp;includes=description&amp;description=宝玉&amp;idStart=4&amp;idStop=10000     * @param deepRequest     * @return     */    @RequestMapping(value = &quot;search&quot;)    public String searchFromEs(DeepRequest deepRequest)&#123;        log.info(&quot;start--&gt;&quot;);        long l = System.currentTimeMillis();        Page page = txtService.searchFromEs(deepRequest);        log.info(&quot;stop,cost--&gt; &quot;+ (System.currentTimeMillis() - l));        return JSONUtil.toJsonPrettyStr(page);    &#125;&#125;\n\n\n创建service层代码：\n@Service@Slf4jpublic class TxtService &#123;public Page searchFromEs(DeepRequest deepRequest) &#123;        Page page = new Page();        try &#123;            SearchRequest searchRequest = new SearchRequest(&quot;person&quot;);            page.setPageNo(deepRequest.getPageNo());            page.setPageSize(deepRequest.getPageSize());            buildParams(deepRequest, searchRequest);            Integer start = 0;            if(deepRequest.getPageNo() != null &amp;&amp; deepRequest.getPageSize() != null)&#123;                start = (deepRequest.getPageNo() - 1) * deepRequest.getPageSize();            &#125;            searchRequest.source().from(start);            if(deepRequest.getPageSize() != null)&#123;                searchRequest.source().size(deepRequest.getPageSize());            &#125;else &#123;                searchRequest.source().size(10);                page.setPageSize(10);            &#125;            SearchHits hits = null;            TotalHits totalHits = null;            SearchResponse search = esClient.search(searchRequest, RequestOptions.DEFAULT);            hits = search.getHits();            totalHits = hits.getTotalHits();            List&lt;Person&gt; lists = new ArrayList&lt;&gt;();            SearchHit[] hitLists = hits.getHits();            for (SearchHit doc:hitLists)&#123;                String sourceAsString = doc.getSourceAsString();                Person person = JSONUtil.toBean(sourceAsString, Person.class);                Object[] sortValues = doc.getSortValues();                if(sortValues.length != 0)&#123;                    person.setDistance(sortValues[0].toString());                &#125;                lists.add(person);            &#125;            page.setTotal(totalHits.value);            page.setData(lists);        &#125;catch (Exception e)&#123;            e.printStackTrace();        &#125;        return page;    &#125;&#125; private void buildParams(DeepRequest deepRequest, SearchRequest searchRequest) &#123;        SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();        if(!CollectionUtils.isEmpty(deepRequest.getIncludes())                || !CollectionUtils.isEmpty(deepRequest.getExcludes()))&#123;            String [] includes = new String[CollectionUtils.isEmpty(deepRequest.getIncludes()) ? 0: deepRequest.getIncludes().size()];            if(!CollectionUtils.isEmpty(deepRequest.getIncludes()))&#123;                for (int i = 0; i &lt; deepRequest.getIncludes().size(); i++) &#123;                    includes[i] = deepRequest.getIncludes().get(i);                &#125;            &#125;            String [] excludes = new String[CollectionUtils.isEmpty(deepRequest.getExcludes())? 0: deepRequest.getExcludes().size()];            if(!CollectionUtils.isEmpty(deepRequest.getExcludes()))&#123;                for (int i = 0; i &lt; deepRequest.getExcludes().size(); i++) &#123;                    excludes[i] = deepRequest.getExcludes().get(i);                &#125;            &#125;            searchSourceBuilder.fetchSource(includes,excludes);        &#125;        if(deepRequest.getDescription() != null)&#123;            MatchQueryBuilder matchQueryBuilder = QueryBuilders.matchQuery(&quot;description&quot;, deepRequest.getDescription());            matchQueryBuilder.operator(Operator.OR);            searchSourceBuilder.query(matchQueryBuilder);        &#125;        if(deepRequest.getId() != null)&#123;            TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(&quot;id&quot;, deepRequest.getId());            searchSourceBuilder.query(termQueryBuilder);        &#125;        if(deepRequest.getCode() != null)&#123;            TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(&quot;code&quot;, deepRequest.getCode());            searchSourceBuilder.query(termQueryBuilder);        &#125;        if(deepRequest.getProtocol() != null)&#123;            TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(&quot;protocol&quot;, deepRequest.getProtocol());            searchSourceBuilder.query(termQueryBuilder);        &#125;        if(deepRequest.getIdStart() != null &amp;&amp; deepRequest.getIdStop() != null)&#123;            RangeQueryBuilder id = QueryBuilders.rangeQuery(&quot;id&quot;);            id.gte(deepRequest.getIdStart());            id.lte(deepRequest.getIdStop());            searchSourceBuilder.query(id);        &#125;                searchRequest.source(searchSourceBuilder);    &#125;\n\n在kibana中使用## 查看所有索引状态GET /_cat/indices?v## 查看节点健康情况GET /_cluster/health## 创建索引PUT /person&#123;  &quot;settings&quot;: &#123;    &quot;number_of_shards&quot;: 1,    &quot;number_of_replicas&quot;: 1  &#125;,  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;id&quot;: &#123;        &quot;type&quot;: &quot;long&quot;      &#125;,      &quot;name&quot;: &#123;        &quot;type&quot;: &quot;keyword&quot;      &#125;,      &quot;code&quot;: &#123;        &quot;type&quot;: &quot;keyword&quot;      &#125;,      &quot;phone&quot;: &#123;        &quot;type&quot;: &quot;keyword&quot;      &#125;,      &quot;birth&quot;: &#123;        &quot;type&quot;: &quot;date&quot;      &#125;,      &quot;lastIp&quot;: &#123;        &quot;type&quot;: &quot;keyword&quot;      &#125;,      &quot;url&quot;: &#123;        &quot;type&quot;: &quot;keyword&quot;      &#125;,      &quot;protocol&quot;: &#123;        &quot;type&quot;: &quot;keyword&quot;      &#125;,      &quot;address&quot;: &#123;        &quot;type&quot;: &quot;text&quot;,        &quot;analyzer&quot;: &quot;ik_max_word&quot;      &#125;,      &quot;zeroCode&quot;: &#123;        &quot;type&quot;: &quot;keyword&quot;      &#125;,      &quot;description&quot;: &#123;        &quot;type&quot;: &quot;text&quot;        , &quot;analyzer&quot;: &quot;ik_max_word&quot;      &#125;,      &quot;email&quot;: &#123;        &quot;type&quot;: &quot;keyword&quot;      &#125;    &#125;  &#125;&#125;## 查看索引结构GET /person/_mapping## 删除索引DELETE /person## 排序分叶GET /person/_search&#123;  &quot;track_total_hits&quot;: true,   &quot;from&quot;: 9999  ,&quot;size&quot;: 1  ,&quot;sort&quot;: [    &#123;      &quot;id&quot;: &#123;        &quot;order&quot;: &quot;asc&quot;      &#125;    &#125;  ]&#125;## 滚动查询GET /person/_search?scroll=1m&#123;  &quot;track_total_hits&quot;: true  ,&quot;size&quot;: 3  ,&quot;sort&quot;: [    &#123;      &quot;id&quot;: &#123;        &quot;order&quot;: &quot;asc&quot;      &#125;    &#125;  ]&#125;## 滚动查询GET /_search/scroll&#123;  &quot;scroll_id&quot;: &quot;FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFmh4WEdITUxaUzNTdXFPRkU3eDhtNncAAAAAAAAArRZoMFlXU29HSFJUT1FDTUU3NlpsQV93&quot;  ,&quot;scroll&quot;: &quot;1m&quot;&#125;## 分词GET /_analyze&#123; &quot;analyzer&quot;:&quot;ik_max_word&quot;, &quot;text&quot;:&quot;我是中国人&quot; &#125;GET /_analyze &#123; &quot;analyzer&quot;:&quot;ik_smart&quot;, &quot;text&quot;:&quot;我是中国人&quot; &#125;## 按照分词搜索GET /person/_search&#123;   &quot;from&quot;: 0,    &quot;size&quot;: 2,    &quot;query&quot;: &#123;   &quot;match&quot;: &#123;     &quot;description&quot;: &quot;宝玉&quot;      &#125;   &#125;  &#125;## in查询  GET /person/_search &#123;   &quot;query&quot;: &#123;     &quot;terms&quot;: &#123;       &quot;id&quot;: [         &quot;1&quot;,&quot;2&quot;,&quot;3&quot;         ]     &#125;   &#125; &#125;## 区间查询  GET /person/_search &#123;   &quot;query&quot;: &#123;     &quot;range&quot;: &#123;       &quot;id&quot;: &#123;         &quot;gte&quot;: 10,         &quot;lte&quot;: 20       &#125;     &#125;   &#125; &#125;## 分组统计  GET /person/_search &#123;   &quot;aggs&quot;: &#123;     &quot;protocol_agg&quot;: &#123;       &quot;terms&quot;: &#123;         &quot;field&quot;: &quot;protocol&quot;,         &quot;size&quot;: 10       &#125;     &#125;,     &quot;name_agg&quot;:&#123;        &quot;terms&quot;: &#123;          &quot;field&quot;: &quot;name&quot;,          &quot;size&quot;: 10        &#125;            &#125;   &#125;,   &quot;size&quot;: 1 &#125;\n\n","categories":["总结笔记"],"tags":["Elasticsearch"]},{"title":"Lambda表达式和匿名内部类","url":"/2021_04_16_lambda/","content":"Java Lambda表达式的一个重要用法是简化某些匿名内部类（Anonymous Classes）的写法。实际上Lambda表达式并不仅仅是匿名内部类的语法糖，JVM内部是通过invokedynamic指令来实现Lambda表达式的。Java Lambda表达式虽然可以简化某些匿名内部类，但Lambda表达式并不能取代所有的匿名内部类，只能用来取代函数接口（Functional Interface）的简写。\n\n\n一、Lambda表达式和匿名内部类1.取代某些匿名内部类例子1：无参函数的简写如果需要新建一个线程，一种常见的写法是这样：\n// JDK7 匿名内部类写法new Thread(new Runnable()&#123;// 接口名\t@Override\tpublic void run()&#123;// 方法名\t\tSystem.out.println(&quot;Thread run()&quot;);\t&#125;&#125;).start();\n\n上述代码给Tread类传递了一个匿名的Runnable对象，重载Runnable接口的run()方法来实现相应逻辑。这是JDK7以及之前的常见写法。匿名内部类省去了为类起名字的烦恼，但还是不够简化，在Java 8中可以简化为如下形式：\n// JDK8 Lambda表达式写法new Thread(\t\t() -&gt; System.out.println(&quot;Thread run()&quot;)// 省略接口名和方法名).start();\n\n上述代码跟匿名内部类的作用是一样的，但比匿名内部类更进一步。这里连接口名和函数名都一同省掉了，写起来更加神清气爽。如果函数体有多行，可以用大括号括起来，就像这样：\n// JDK8 Lambda表达式代码块写法new Thread(        () -&gt; &#123;            System.out.print(&quot;Hello&quot;);            System.out.println(&quot; Hoolee&quot;);        &#125;).start();\n\n\n例子2：带参函数的简写如果要给一个字符串列表通过自定义比较器，按照字符串长度进行排序，Java 7的书写形式如下：\n// JDK7 匿名内部类写法List&lt;String&gt; list = Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;);Collections.sort(list, new Comparator&lt;String&gt;()&#123;// 接口名    @Override    public int compare(String s1, String s2)&#123;// 方法名        if(s1 == null)            return -1;        if(s2 == null)            return 1;        return s1.length()-s2.length();    &#125;&#125;);\n上述代码通过内部类重载了Comparator接口的compare()方法，实现比较逻辑。采用Lambda表达式可简写如下：\n// JDK8 Lambda表达式写法List&lt;String&gt; list = Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;);Collections.sort(list, (s1, s2) -&gt;&#123;// 省略参数表的类型    if(s1 == null)        return -1;    if(s2 == null)        return 1;    return s1.length()-s2.length();&#125;);\n上述代码跟匿名内部类的作用是一样的。除了省略了接口名和方法名，代码中把参数表的类型也省略了。这得益于javac的类型推断机制，编译器能够根据上下文信息推断出参数的类型，当然也有推断失败的时候，这时就需要手动指明参数类型了。注意，Java是强类型语言，每个变量和对象都必需有明确的类型。\n2.什么情况下简写也许你已经想到了，能够使用Lambda的依据是必须有相应的函数接口（函数接口，是指内部只有一个抽象方法的接口）。这一点跟Java是强类型语言吻合，也就是说你并不能在代码的任何地方任性的写Lambda表达式。实际上Lambda的类型就是对应函数接口的类型。Lambda表达式另一个依据是类型推断机制，在上下文信息足够的情况下，编译器可以推断出参数表的类型，而不需要显式指名。Lambda表达更多合法的书写形式如下：\n// Lambda表达式的书写形式Runnable run = () -&gt; System.out.println(&quot;Hello World&quot;);// 1ActionListener listener = event -&gt; System.out.println(&quot;button clicked&quot;);// 2Runnable multiLine = () -&gt; &#123;// 3 代码块    System.out.print(&quot;Hello&quot;);    System.out.println(&quot; Hoolee&quot;);&#125;;BinaryOperator&lt;Long&gt; add = (Long x, Long y) -&gt; x + y;// 4BinaryOperator&lt;Long&gt; addImplicit = (x, y) -&gt; x + y;// 5 类型推断\n\n上述代码中，1展示了无参函数的简写；2处展示了有参函数的简写，以及类型推断机制；3是代码块的写法；4和5再次展示了类型推断机制。\n3.自定义一个函数接口自定义函数接口很容易，只需要编写一个只有一个抽象方法的接口即可。\n// 自定义函数接口@FunctionalInterfacepublic interface ConsumerInterface&lt;T&gt;&#123;\tvoid accept(T t);&#125;\n\n上面代码中的@FunctionalInterface是可选的，但加上该标注编译器会帮你检查接口是否符合函数接口规范。就像加入@Override标注会检查是否重载了函数一样。\n有了上述接口定义，就可以写出类似如下的代码：\nConsumerInterface&lt;String&gt; consumer = str -&gt; System.out.println(str);\n进一步的，还可以这样使用：\nclass MyStream&lt;T&gt;&#123;\tprivate List&lt;T&gt; list;    ...\tpublic void myForEach(ConsumerInterface&lt;T&gt; consumer)&#123;// 1\t\tfor(T t : list)&#123;\t\t\tconsumer.accept(t);\t\t&#125;\t&#125;&#125;MyStream&lt;String&gt; stream = new MyStream&lt;String&gt;();stream.myForEach(str -&gt; System.out.println(str));// 使用自定义函数接口书写Lambda表达式\n\n4. 匿名内部类实现经过第一篇的的介绍，我们看到Lambda表达式似乎只是为了简化匿名内部类书写，这看起来仅仅通过语法糖在编译阶段把所有的Lambda表达式替换成匿名内部类就可以了。但实时并非如此。在JVM层面，Lambda表达式和匿名内部类有着明显的差别。\n匿名内部类仍然是一个类，只是不需要程序员显示指定类名，编译器会自动为该类取名。因此如果有如下形式的代码，编译之后将会产生两个class文件：\npublic class MainAnonymousClass &#123;\tpublic static void main(String[] args) &#123;\t\tnew Thread(new Runnable()&#123;\t\t\t@Override\t\t\tpublic void run()&#123;\t\t\t\tSystem.out.println(&quot;Anonymous Class Thread run()&quot;);\t\t\t&#125;\t\t&#125;).start();;\t&#125;&#125;\n编译之后文件分布如下，两个class文件分别是主类和匿名内部类产生的：\n\n进一步分析主类MainAnonymousClass.class的字节码，可发现其创建了匿名内部类的对象：\n// javap -c MainAnonymousClass.classpublic class MainAnonymousClass &#123;  ...  public static void main(java.lang.String[]);    Code:       0: new           #2                  // class java/lang/Thread       3: dup       4: new           #3                  // class MainAnonymousClass$1 /*创建内部类对象*/       7: dup       8: invokespecial #4                  // Method MainAnonymousClass$1.&quot;&lt;init&gt;&quot;:()V      11: invokespecial #5                  // Method java/lang/Thread.&quot;&lt;init&gt;&quot;:(Ljava/lang/Runnable;)V      14: invokevirtual #6                  // Method java/lang/Thread.start:()V      17: return&#125;\n5.Lambda表达式实现Lambda表达式通过invokedynamic指令实现，书写Lambda表达式不会产生新的类。如果有如下代码，编译之后只有一个class文件：\npublic class MainLambda &#123;\tpublic static void main(String[] args) &#123;\t\tnew Thread(\t\t\t\t() -&gt; System.out.println(&quot;Lambda Thread run()&quot;)\t\t\t).start();;\t&#125;&#125;\n编译之后的结果：\n\n通过javap反编译命名，我们更能看出Lambda表达式内部表示的不同：\n// javap -c -p MainLambda.classpublic class MainLambda &#123;  ...  public static void main(java.lang.String[]);    Code:       0: new           #2                  // class java/lang/Thread       3: dup       4: invokedynamic #3,  0              // InvokeDynamic #0:run:()Ljava/lang/Runnable; /*使用invokedynamic指令调用*/       9: invokespecial #4                  // Method java/lang/Thread.&quot;&lt;init&gt;&quot;:(Ljava/lang/Runnable;)V      12: invokevirtual #5                  // Method java/lang/Thread.start:()V      15: return  private static void lambda$main$0();  /*Lambda表达式被封装成主类的私有方法*/    Code:       0: getstatic     #6                  // Field java/lang/System.out:Ljava/io/PrintStream;       3: ldc           #7                  // String Lambda Thread run()       5: invokevirtual #8                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V       8: return&#125;\n\n反编译之后我们发现Lambda表达式被封装成了主类的一个私有方法，并通过invokedynamic指令进行调用。\n推论，this引用的意义既然Lambda表达式不是内部类的简写，那么Lambda内部的this引用也就跟内部类对象没什么关系了。在Lambda表达式中this的意义跟在表达式外部完全一样。因此下列代码将输出两遍Hello Hoolee，而不是两个引用地址。\npublic class Hello &#123;\tRunnable r1 = () -&gt; &#123; System.out.println(this); &#125;;\tRunnable r2 = () -&gt; &#123; System.out.println(toString()); &#125;;\tpublic static void main(String[] args) &#123;\t\tnew Hello().r1.run();\t\tnew Hello().r2.run();\t&#125;\tpublic String toString() &#123; return &quot;Hello Hoolee&quot;; &#125;&#125;\n\n\n二、集合API我们先从最熟悉的*Java集合框架(Java Collections Framework, JCF)*开始说起。\n为引入Lambda表达式，Java8新增了java.util.function包，里面包含常用的函数接口，这是Lambda表达式的基础，Java集合框架也新增部分接口，以便与Lambda表达式对接。\n首先回顾一下Java集合框架的接口继承结构：\n\n上图中绿色标注的接口类，表示在Java8中加入了新的接口方法，当然由于继承关系，他们相应的子类也都会继承这些新方法。下表详细列举了这些方法。\n\n\n\n接口名\nJava8新加入的方法\n\n\n\nCollection\nremoveIf() spliterator() stream() parallelStream() forEach()\n\n\nList\nreplaceAll() sort()\n\n\nMap\ngetOrDefault() forEach() replaceAll() putIfAbsent() remove() replace() computeIfAbsent() computeIfPresent() compute() merge()\n\n\n这些新加入的方法大部分要用到java.util.function包下的接口，这意味着这些方法大部分都跟Lambda表达式相关。我们将逐一学习这些方法。\n1.Collection中的新方法如上所示，接口Collection和List新加入了一些方法，我们以是List的子类ArrayList为例来说明。了解Java7ArrayList实现原理，将有助于理解下文。\nforEach()该方法的签名为void forEach(Consumer&lt;? super E&gt; action)，作用是对容器中的每个元素执行action指定的动作，其中Consumer是个函数接口，里面只有一个待实现方法void accept(T t)（后面我们会看到，这个方法叫什么根本不重要，你甚至不需要记忆它的名字）。\n需求：假设有一个字符串列表，需要打印出其中所有长度大于3的字符串.\nJava7及以前我们可以用增强的for循环实现：\n// 使用曾强for循环迭代ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;));for(String str : list)&#123;    if(str.length()&gt;3)        System.out.println(str);&#125;\n\n现在使用forEach()方法结合匿名内部类，可以这样实现：\n// 使用forEach()结合匿名内部类迭代ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;));list.forEach(new Consumer&lt;String&gt;()&#123;    @Override    public void accept(String str)&#123;        if(str.length()&gt;3)            System.out.println(str);    &#125;&#125;);\n上述代码调用forEach()方法，并使用匿名内部类实现Comsumer接口。到目前为止我们没看到这种设计有什么好处，但是不要忘记Lambda表达式，使用Lambda表达式实现如下：\n// 使用forEach()结合Lambda表达式迭代ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;));list.forEach( str -&gt; &#123;        if(str.length()&gt;3)            System.out.println(str);    &#125;);\n上述代码给forEach()方法传入一个Lambda表达式，我们不需要知道accept()方法，也不需要知道Consumer接口，类型推导帮我们做了一切。\nremoveIf()该方法签名为boolean removeIf(Predicate&lt;? super E&gt; filter)，作用是删除容器中所有满足filter指定条件的元素，其中Predicate是一个函数接口，里面只有一个待实现方法boolean test(T t)，同样的这个方法的名字根本不重要，因为用的时候不需要书写这个名字。\n需求：假设有一个字符串列表，需要删除其中所有长度大于3的字符串。\n我们知道如果需要在迭代过程冲对容器进行删除操作必须使用迭代器，否则会抛出ConcurrentModificationException，所以上述任务传统的写法是：\n// 使用迭代器删除列表元素ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;));Iterator&lt;String&gt; it = list.iterator();while(it.hasNext())&#123;    if(it.next().length()&gt;3) // 删除长度大于3的元素        it.remove();&#125;\n\n现在使用removeIf()方法结合匿名内部类，我们可是这样实现：\n// 使用removeIf()结合匿名名内部类实现ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;));list.removeIf(new Predicate&lt;String&gt;()&#123; // 删除长度大于3的元素    @Override    public boolean test(String str)&#123;        return str.length()&gt;3;    &#125;&#125;);\n上述代码使用removeIf()方法，并使用匿名内部类实现Precicate接口。相信你已经想到用Lambda表达式该怎么写了：\n// 使用removeIf()结合Lambda表达式实现ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;));list.removeIf(str -&gt; str.length()&gt;3); // 删除长度大于3的元素\n使用Lambda表达式不需要记忆Predicate接口名，也不需要记忆test()方法名，只需要知道此处需要一个返回布尔类型的Lambda表达式就行了。\nreplaceAll()该方法签名为void replaceAll(UnaryOperator&lt;E&gt; operator)，作用是对每个元素执行operator指定的操作，并用操作结果来替换原来的元素。其中UnaryOperator是一个函数接口，里面只有一个待实现函数T apply(T t)。\n需求：假设有一个字符串列表，将其中所有长度大于3的元素转换成大写，其余元素不变。\nJava7及之前似乎没有优雅的办法：\n// 使用下标实现元素替换ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;));for(int i=0; i&lt;list.size(); i++)&#123;    String str = list.get(i);    if(str.length()&gt;3)        list.set(i, str.toUpperCase());&#125;\n\n使用replaceAll()方法结合匿名内部类可以实现如下：\n// 使用匿名内部类实现ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;));list.replaceAll(new UnaryOperator&lt;String&gt;()&#123;    @Override    public String apply(String str)&#123;        if(str.length()&gt;3)            return str.toUpperCase();        return str;    &#125;&#125;);\n上述代码调用replaceAll()方法，并使用匿名内部类实现UnaryOperator接口。我们知道可以用更为简洁的Lambda表达式实现：\n// 使用Lambda表达式实现ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;));list.replaceAll(str -&gt; &#123;    if(str.length()&gt;3)        return str.toUpperCase();    return str;&#125;);\nsort()该方法定义在List接口中，方法签名为void sort(Comparator&lt;? super E&gt; c)，该方法根据c指定的比较规则对容器元素进行排序。Comparator接口我们并不陌生，其中有一个方法int compare(T o1, T o2)需要实现，显然该接口是个函数接口。\n需求：假设有一个字符串列表，按照字符串长度增序对元素排序。\n由于Java7以及之前sort()方法在Collections工具类中，所以代码要这样写：\n// Collections.sort()方法ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;));Collections.sort(list, new Comparator&lt;String&gt;()&#123;    @Override    public int compare(String str1, String str2)&#123;        return str1.length()-str2.length();    &#125;&#125;);\n\n现在可以直接使用List.sort()方法，结合Lambda表达式，可以这样写：\n// List.sort()方法结合Lambda表达式ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;));list.sort((str1, str2) -&gt; str1.length()-str2.length());\n\nspliterator()方法签名为Spliterator&lt;E&gt; spliterator()，该方法返回容器的可拆分迭代器。从名字来看该方法跟iterator()方法有点像，我们知道Iterator是用来迭代容器的，Spliterator也有类似作用，但二者有如下不同：\n\nSpliterator既可以像Iterator那样逐个迭代，也可以批量迭代。批量迭代可以降低迭代的开销。\nSpliterator是可拆分的，一个Spliterator可以通过调用Spliterator&lt;T&gt; trySplit()方法来尝试分成两个。一个是this，另一个是新返回的那个，这两个迭代器代表的元素没有重叠。\n\n可通过（多次）调用Spliterator.trySplit()方法来分解负载，以便多线程处理。\nstream()和parallelStream()stream()和parallelStream()分别返回该容器的Stream视图表示，不同之处在于parallelStream()返回并行的Stream。**Stream是Java函数式编程的核心类**，我们会在后面章节中学习。\n2.Map中的新方法相比Collection，Map中加入了更多的方法，我们以HashMap为例来逐一探秘。了解Java7HashMap实现原理，将有助于理解下文。\nforEach()该方法签名为void forEach(BiConsumer&lt;? super K,? super V&gt; action)，作用是对Map中的每个映射执行action指定的操作，其中BiConsumer是一个函数接口，里面有一个待实现方法void accept(T t, U u)。BinConsumer接口名字和accept()方法名字都不重要，请不要记忆他们。\n需求：假设有一个数字到对应英文单词的Map，请输出Map中的所有映射关系．\nJava7以及之前经典的代码如下：\n// Java7以及之前迭代MapHashMap&lt;Integer, String&gt; map = new HashMap&lt;&gt;();map.put(1, &quot;one&quot;);map.put(2, &quot;two&quot;);map.put(3, &quot;three&quot;);for(Map.Entry&lt;Integer, String&gt; entry : map.entrySet())&#123;    System.out.println(entry.getKey() + &quot;=&quot; + entry.getValue());&#125;\n\n使用Map.forEach()方法，结合匿名内部类，代码如下：\n// 使用forEach()结合匿名内部类迭代MapHashMap&lt;Integer, String&gt; map = new HashMap&lt;&gt;();map.put(1, &quot;one&quot;);map.put(2, &quot;two&quot;);map.put(3, &quot;three&quot;);map.forEach(new BiConsumer&lt;Integer, String&gt;()&#123;    @Override    public void accept(Integer k, String v)&#123;        System.out.println(k + &quot;=&quot; + v);    &#125;&#125;);\n上述代码调用forEach()方法，并使用匿名内部类实现BiConsumer接口。当然，实际场景中没人使用匿名内部类写法，因为有Lambda表达式：\n// 使用forEach()结合Lambda表达式迭代MapHashMap&lt;Integer, String&gt; map = new HashMap&lt;&gt;();map.put(1, &quot;one&quot;);map.put(2, &quot;two&quot;);map.put(3, &quot;three&quot;);map.forEach((k, v) -&gt; System.out.println(k + &quot;=&quot; + v));&#125;\n\ngetOrDefault()该方法跟Lambda表达式没关系，但是很有用。方法签名为V getOrDefault(Object key, V defaultValue)，作用是**按照给定的key查询Map中对应的value，如果没有找到则返回defaultValue**。使用该方法程序员可以省去查询指定键值是否存在的麻烦．\n需求；假设有一个数字到对应英文单词的Map，输出4对应的英文单词，如果不存在则输出NoValue\n// 查询Map中指定的值，不存在时使用默认值HashMap&lt;Integer, String&gt; map = new HashMap&lt;&gt;();map.put(1, &quot;one&quot;);map.put(2, &quot;two&quot;);map.put(3, &quot;three&quot;);// Java7以及之前做法if(map.containsKey(4))&#123; // 1    System.out.println(map.get(4));&#125;else&#123;    System.out.println(&quot;NoValue&quot;);&#125;// Java8使用Map.getOrDefault()System.out.println(map.getOrDefault(4, &quot;NoValue&quot;)); // 2\nputIfAbsent()该方法跟Lambda表达式没关系，但是很有用。方法签名为V putIfAbsent(K key, V value)，作用是只有在不存在key值的映射或映射值为null时，才将value指定的值放入到Map中，否则不对Map做更改．该方法将条件判断和赋值合二为一，使用起来更加方便．\nremove()我们都知道Map中有一个remove(Object key)方法，来根据指定key值删除Map中的映射关系；Java8新增了remove(Object key, Object value)方法，只有在当前Map中**key正好映射到value时**才删除该映射，否则什么也不做．\nreplace()在Java7及以前，要想替换Map中的映射关系可通过put(K key, V value)方法实现，该方法总是会用新值替换原来的值．为了更精确的控制替换行为，Java8在Map中加入了两个replace()方法，分别如下：\n\nreplace(K key, V value)，只有在当前Map中**key的映射存在时**才用value去替换原来的值，否则什么也不做．\nreplace(K key, V oldValue, V newValue)，只有在当前Map中**key的映射存在且等于oldValue时**才用newValue去替换原来的值，否则什么也不做．\n\nreplaceAll()该方法签名为replaceAll(BiFunction&lt;? super K,? super V,? extends V&gt; function)，作用是对Map中的每个映射执行function指定的操作，并用function的执行结果替换原来的value，其中BiFunction是一个函数接口，里面有一个待实现方法R apply(T t, U u)．不要被如此多的函数接口吓到，因为使用的时候根本不需要知道他们的名字．\n需求：假设有一个数字到对应英文单词的Map，请将原来映射关系中的单词都转换成大写．\nJava7以及之前经典的代码如下：\n// Java7以及之前替换所有Map中所有映射关系HashMap&lt;Integer, String&gt; map = new HashMap&lt;&gt;();map.put(1, &quot;one&quot;);map.put(2, &quot;two&quot;);map.put(3, &quot;three&quot;);for(Map.Entry&lt;Integer, String&gt; entry : map.entrySet())&#123;    entry.setValue(entry.getValue().toUpperCase());&#125;\n\n使用replaceAll()方法结合匿名内部类，实现如下：\n// 使用replaceAll()结合匿名内部类实现HashMap&lt;Integer, String&gt; map = new HashMap&lt;&gt;();map.put(1, &quot;one&quot;);map.put(2, &quot;two&quot;);map.put(3, &quot;three&quot;);map.replaceAll(new BiFunction&lt;Integer, String, String&gt;()&#123;    @Override    public String apply(Integer k, String v)&#123;        return v.toUpperCase();    &#125;&#125;);\n上述代码调用replaceAll()方法，并使用匿名内部类实现BiFunction接口。更进一步的，使用Lambda表达式实现如下：\n// 使用replaceAll()结合Lambda表达式实现HashMap&lt;Integer, String&gt; map = new HashMap&lt;&gt;();map.put(1, &quot;one&quot;);map.put(2, &quot;two&quot;);map.put(3, &quot;three&quot;);map.replaceAll((k, v) -&gt; v.toUpperCase());\n\n简洁到让人难以置信．\nmerge()该方法签名为merge(K key, V value, BiFunction&lt;? super V,? super V,? extends V&gt; remappingFunction)，作用是：\n\n如果Map中key对应的映射不存在或者为null，则将value（不能是null）关联到key上；\n否则执行remappingFunction，如果执行结果非null则用该结果跟key关联，否则在Map中删除key的映射．\n\n参数中BiFunction函数接口前面已经介绍过，里面有一个待实现方法R apply(T t, U u)．\nmerge()方法虽然语义有些复杂，但该方法的用方式很明确，一个比较常见的场景是将新的错误信息拼接到原来的信息上，比如：\nmap.merge(key, newMsg, (v1, v2) -&gt; v1+v2);\n\ncompute()该方法签名为compute(K key, BiFunction&lt;? super K,? super V,? extends V&gt; remappingFunction)，作用是把remappingFunction的计算结果关联到key上，如果计算结果为null，则在Map中删除key的映射．\n要实现上述merge()方法中错误信息拼接的例子，使用compute()代码如下：\nmap.compute(key, (k,v) -&gt; v==null ? newMsg : v.concat(newMsg));\n\ncomputeIfAbsent()该方法签名为V computeIfAbsent(K key, Function&lt;? super K,? extends V&gt; mappingFunction)，作用是：只有在当前Map中不存在key值的映射或映射值为null时，才调用mappingFunction，并在mappingFunction执行结果非null时，将结果跟key关联．\nFunction是一个函数接口，里面有一个待实现方法R apply(T t)．\ncomputeIfAbsent()常用来对Map的某个key值建立初始化映射．比如我们要实现一个多值映射，Map的定义可能是Map&lt;K,Set&lt;V&gt;&gt;，要向Map中放入新值，可通过如下代码实现：\nMap&lt;Integer, Set&lt;String&gt;&gt; map = new HashMap&lt;&gt;();// Java7及以前的实现方式if(map.containsKey(1))&#123;    map.get(1).add(&quot;one&quot;);&#125;else&#123;    Set&lt;String&gt; valueSet = new HashSet&lt;String&gt;();    valueSet.add(&quot;one&quot;);    map.put(1, valueSet);&#125;// Java8的实现方式map.computeIfAbsent(1, v -&gt; new HashSet&lt;String&gt;()).add(&quot;yi&quot;);\n\n使用computeIfAbsent()将条件判断和添加操作合二为一，使代码更加简洁．\ncomputeIfPresent()该方法签名为V computeIfPresent(K key, BiFunction&lt;? super K,? super V,? extends V&gt; remappingFunction)，作用跟computeIfAbsent()相反，即，只有在当前Map中存在key值的映射且非null时，才调用remappingFunction，如果remappingFunction执行结果为null，则删除key的映射，否则使用该结果替换key原来的映射．\n这个函数的功能跟如下代码是等效的：\n// Java7及以前跟computeIfPresent()等效的代码if (map.get(key) != null) &#123;    V oldValue = map.get(key);    V newValue = remappingFunction.apply(key, oldValue);    if (newValue != null)        map.put(key, newValue);    else        map.remove(key);    return newValue;&#125;return null;\n\n\n3.总结\nJava8为容器新增一些有用的方法，这些方法有些是为完善原有功能，有些是为引入函数式编程，学习和使用这些方法有助于我们写出更加简洁有效的代码．\n函数接口虽然很多，但绝大多数时候我们根本不需要知道它们的名字，书写Lambda表达式时类型推断帮我们做了一切．\n\n三、Streams API你可能没意识到Java对函数式编程的重视程度，看看Java 8加入函数式编程扩充多少功能就清楚了。Java 8之所以费这么大功夫引入函数式编程，原因有二：\n\n代码简洁函数式编程写出的代码简洁且意图明确，使用stream接口让你从此告别for循环。\n多核友好，Java函数式编程使得编写并行程序从未如此简单，你需要的全部就是调用一下parallel()方法。\n\n这一节我们学习stream，也就是Java函数式编程的主角。对于Java 7来说stream完全是个陌生东西，stream并不是某种数据结构，它只是数据源的一种视图。这里的数据源可以是一个数组，Java容器或I&#x2F;O channel等。正因如此要得到一个stream通常不会手动创建，而是调用对应的工具方法，比如：\n\n调用Collection.stream()或者Collection.parallelStream()方法\n调用Arrays.stream(T[] array)方法\n\n常见的stream接口继承关系如图：\n\n\n图中4种stream接口继承自BaseStream，其中IntStream, LongStream, DoubleStream对应三种基本类型（int, long, double，注意不是包装类型），Stream对应所有剩余类型的stream视图。为不同数据类型设置不同stream接口，可以1.提高性能，2.增加特定接口函数。\n\n\n\n\n你可能会奇怪为什么不把IntStream等设计成Stream的子接口？毕竟这接口中的方法名大部分是一样的。答案是这些方法的名字虽然相同，但是返回类型不同，如果设计成父子接口关系，这些方法将不能共存，因为Java不允许只有返回类型不同的方法重载。\n虽然大部分情况下stream是容器调用Collection.stream()方法得到的，但stream和collections有以下不同：\n\n无存储。stream不是一种数据结构，它只是某种数据源的一个视图，数据源可以是一个数组，Java容器或I&#x2F;O channel等。\n为函数式编程而生。对stream的任何修改都不会修改背后的数据源，比如对stream执行过滤操作并不会删除被过滤的元素，而是会产生一个不包含被过滤元素的新stream。\n惰式执行。stream上的操作并不会立即执行，只有等到用户真正需要结果的时候才会执行。\n可消费性。stream只能被“消费”一次，一旦遍历过就会失效，就像容器的迭代器那样，想要再次遍历必须重新生成。\n\n对stream的操作分为为两类，**中间操作(intermediate operations)和结束操作(terminal operations)**，二者特点是：\n\n__中间操作总是会惰式执行__，调用中间操作只会生成一个标记了该操作的新stream，仅此而已。\n__结束操作会触发实际计算__，计算发生时会把所有中间操作积攒的操作以pipeline的方式执行，这样可以减少迭代次数。计算完成之后stream就会失效。\n\n如果你熟悉Apache Spark RDD，对stream的这个特点应该不陌生。\n下表汇总了Stream接口的部分常见方法：\n\n\n\n操作类型\n接口方法\n\n\n\n中间操作\nconcat() distinct() filter() flatMap() limit() map() peek()  skip() sorted() parallel() sequential() unordered()\n\n\n结束操作\nallMatch() anyMatch() collect() count() findAny() findFirst()  forEach() forEachOrdered() max() min() noneMatch() reduce() toArray()\n\n\n区分中间操作和结束操作最简单的方法，就是看方法的返回值，返回值为stream的大都是中间操作，否则是结束操作。\n1.stream方法使用stream跟函数接口关系非常紧密，没有函数接口stream就无法工作。回顾一下：__函数接口是指内部只有一个抽象方法的接口__。通常函数接口出现的地方都可以使用Lambda表达式，所以不必记忆函数接口的名字。\nforEach()我们对forEach()方法并不陌生，在Collection中我们已经见过。方法签名为void forEach(Consumer&lt;? super E&gt; action)，作用是对容器中的每个元素执行action指定的动作，也就是对元素进行遍历。\n// 使用Stream.forEach()迭代Stream&lt;String&gt; stream = Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;);stream.forEach(str -&gt; System.out.println(str));\n由于forEach()是结束方法，上述代码会立即执行，输出所有字符串。\nfilter()\n\n函数原型为Stream&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate)，作用是返回一个只包含满足predicate条件元素的Stream。\n// 保留长度等于3的字符串Stream&lt;String&gt; stream= Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;);stream.filter(str -&gt; str.length()==3)    .forEach(str -&gt; System.out.println(str));\n\n上述代码将输出为长度等于3的字符串you和too。注意，由于filter()是个中间操作，如果只调用filter()不会有实际计算，因此也不会输出任何信息。\ndistinct()\n\n函数原型为Stream&lt;T&gt; distinct()，作用是返回一个去除重复元素之后的Stream。\nStream&lt;String&gt; stream= Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;, &quot;too&quot;);stream.distinct()    .forEach(str -&gt; System.out.println(str));\n\n上述代码会输出去掉一个too之后的其余字符串。\n\nsorted()排序函数有两个，一个是用自然顺序排序，一个是使用自定义比较器排序，函数原型分别为Stream&lt;T&gt;　sorted()和Stream&lt;T&gt;　sorted(Comparator&lt;? super T&gt; comparator)。\nStream&lt;String&gt; stream= Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;);stream.sorted((str1, str2) -&gt; str1.length()-str2.length())    .forEach(str -&gt; System.out.println(str));\n\n上述代码将输出按照长度升序排序后的字符串，结果完全在预料之中。\nmap()\n\n函数原型为&lt;R&gt; Stream&lt;R&gt; map(Function&lt;? super T,? extends R&gt; mapper)，作用是返回一个对当前所有元素执行执行mapper之后的结果组成的Stream。直观的说，就是对每个元素按照某种操作进行转换，转换前后Stream中元素的个数不会改变，但元素的类型取决于转换之后的类型。\nStream&lt;String&gt; stream　= Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;);stream.map(str -&gt; str.toUpperCase())    .forEach(str -&gt; System.out.println(str));\n上述代码将输出原字符串的大写形式。\nflatMap()\n\n函数原型为&lt;R&gt; Stream&lt;R&gt; flatMap(Function&lt;? super T,? extends Stream&lt;? extends R&gt;&gt; mapper)，作用是对每个元素执行mapper指定的操作，并用所有mapper返回的Stream中的元素组成一个新的Stream作为最终返回结果。说起来太拗口，通俗的讲flatMap()的作用就相当于把原stream中的所有元素都”摊平”之后组成的Stream，转换前后元素的个数和类型都可能会改变。\nStream&lt;List&lt;Integer&gt;&gt; stream = Stream.of(Arrays.asList(1,2), Arrays.asList(3, 4, 5));stream.flatMap(list -&gt; list.stream())    .forEach(i -&gt; System.out.println(i));\n\n上述代码中，原来的stream中有两个元素，分别是两个List&lt;Integer&gt;，执行flatMap()之后，将每个List都“摊平”成了一个个的数字，所以会新产生一个由5个数字组成的Stream。所以最终将输出1~5这5个数字。\n2.多面手reduce()接下来我们将仍然以Stream为例，介绍流的规约操作。\n规约操作（reduction operation）又被称作折叠操作（fold），是通过某个连接动作将所有元素汇总成一个汇总结果的过程。元素求和、求最大值或最小值、求出元素总个数、将所有元素转换成一个列表或集合，都属于规约操作。Stream类库有两个通用的规约操作reduce()和collect()，也有一些为简化书写而设计的专用规约操作，比如sum()、max()、min()、count()等。\n最大或最小值这类规约操作很好理解（至少方法语义上是这样），我们着重介绍reduce()和collect()，这是比较有魔法的地方。\nreduce操作可以实现从一组元素中生成一个值，sum()、max()、min()、count()等都是reduce操作，将他们单独设为函数只是因为常用。reduce()的方法定义有三种重写形式：\n\nOptional&lt;T&gt; reduce(BinaryOperator&lt;T&gt; accumulator)\nT reduce(T identity, BinaryOperator&lt;T&gt; accumulator)\n&lt;U&gt; U reduce(U identity, BiFunction&lt;U,? super T,U&gt; accumulator, BinaryOperator&lt;U&gt; combiner)\n\n虽然函数定义越来越长，但语义不曾改变，多的参数只是为了指明初始值（参数identity），或者是指定并行执行时多个部分结果的合并方式（参数combiner）。reduce()最常用的场景就是从一堆值中生成一个值。用这么复杂的函数去求一个最大或最小值，你是不是觉得设计者有病。其实不然，因为“大”和“小”或者“求和”有时会有不同的语义。\n需求：从一组单词中找出最长的单词。这里“大”的含义就是“长”。\n// 找出最长的单词Stream&lt;String&gt; stream = Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;);Optional&lt;String&gt; longest = stream.reduce((s1, s2) -&gt; s1.length()&gt;=s2.length() ? s1 : s2);//Optional&lt;String&gt; longest = stream.max((s1, s2) -&gt; s1.length()-s2.length());System.out.println(longest.get());\n上述代码会选出最长的单词love，其中Optional是（一个）值的容器，使用它可以避免null值的麻烦。当然可以使用Stream.max(Comparator&lt;? super T&gt; comparator)方法来达到同等效果，但reduce()自有其存在的理由。\n\n\n需求：求出一组单词的长度之和。这是个“求和”操作，操作对象输入类型是String，而结果类型是Integer。\n// 求单词长度之和Stream&lt;String&gt; stream = Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;);Integer lengthSum = stream.reduce(0,　// 初始值　// (1)        (sum, str) -&gt; sum+str.length(), // 累加器 // (2)        (a, b) -&gt; a+b);　// 部分和拼接器，并行执行时才会用到 // (3)// int lengthSum = stream.mapToInt(str -&gt; str.length()).sum();System.out.println(lengthSum);\n上述代码标号(2)处将i. 字符串映射成长度，ii. 并和当前累加和相加。这显然是两步操作，使用reduce()函数将这两步合二为一，更有助于提升性能。如果想要使用map()和sum()组合来达到上述目的，也是可以的。\nreduce()擅长的是生成一个值，如果想要从Stream生成一个集合或者Map等复杂的对象该怎么办呢？终极武器collect()横空出世！\n3. 终极武器collect()不夸张的讲，如果你发现某个功能在Stream接口中没找到，十有八九可以通过collect()方法实现。collect()是Stream接口方法中最灵活的一个，学会它才算真正入门Java函数式编程。先看几个热身的小例子：\n// 将Stream转换成容器或MapStream&lt;String&gt; stream = Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;);List&lt;String&gt; list = stream.collect(Collectors.toList()); // (1)// Set&lt;String&gt; set = stream.collect(Collectors.toSet()); // (2)// Map&lt;String, Integer&gt; map = stream.collect(Collectors.toMap(Function.identity(), String::length)); // (3)\n上述代码分别列举了如何将Stream转换成List、Set和Map。虽然代码语义很明确，可是我们仍然会有几个疑问：\n\nFunction.identity()是干什么的？\nString::length是什么意思？\nCollectors是个什么东西？\n\n4.接口的静态方法和默认方法Function是一个接口，那么Function.identity()是什么意思呢？这要从两方面解释：\n\nJava 8允许在接口中加入具体方法。接口中的具体方法有两种，default方法和static方法，identity()就是Function接口的一个静态方法。\nFunction.identity()返回一个输出跟输入一样的Lambda表达式对象，等价于形如t -&gt; t形式的Lambda表达式。\n\n上面的解释是不是让你疑问更多？不要问我为什么接口中可以有具体方法，也不要告诉我你觉得t -&gt; t比identity()方法更直观。我会告诉你接口中的default方法是一个无奈之举，在Java 7及之前要想在定义好的接口中加入新的抽象方法是很困难甚至不可能的，因为所有实现了该接口的类都要重新实现。试想在Collection接口中加入一个stream()抽象方法会怎样？default方法就是用来解决这个尴尬问题的，直接在接口中实现新加入的方法。既然已经引入了default方法，为何不再加入static方法来避免专门的工具类呢！\n5.方法引用诸如String::length的语法形式叫做方法引用（method references），这种语法用来替代某些特定形式Lambda表达式。如果Lambda表达式的全部内容就是调用一个已有的方法，那么可以用方法引用来替代Lambda表达式。方法引用可以细分为四类：\n\n\n\n方法引用类别\n举例\n\n\n\n引用静态方法\nInteger::sum\n\n\n引用某个对象的方法\nlist::add\n\n\n引用某个类的方法\nString::length\n\n\n引用构造方法\nHashMap::new\n\n\n我们会在后面的例子中使用方法引用。\n6.收集器相信前面繁琐的内容已彻底打消了你学习Java函数式编程的热情，不过很遗憾，下面的内容更繁琐。但这不能怪Stream类库，因为要实现的功能本身很复杂。\n\n\n收集器（Collector）是为Stream.collect()方法量身打造的工具接口（类）。考虑一下将一个Stream转换成一个容器（或者Map）需要做哪些工作？我们至少需要两样东西：\n\n目标容器是什么？是ArrayList还是HashSet，或者是个TreeMap。\n新元素如何添加到容器中？是List.add()还是Map.put()。\n\n如果并行的进行规约，还需要告诉collect() 3. 多个部分结果如何合并成一个。\n结合以上分析，collect()方法定义为&lt;R&gt; R collect(Supplier&lt;R&gt; supplier, BiConsumer&lt;R,? super T&gt; accumulator, BiConsumer&lt;R,R&gt; combiner)，三个参数依次对应上述三条分析。不过每次调用collect()都要传入这三个参数太麻烦，收集器Collector就是对这三个参数的简单封装,所以collect()的另一定义为&lt;R,A&gt; R collect(Collector&lt;? super T,A,R&gt; collector)。Collectors工具类可通过静态方法生成各种常用的Collector。举例来说，如果要将Stream规约成List可以通过如下两种方式实现：\n//　将Stream规约成ListStream&lt;String&gt; stream = Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;);List&lt;String&gt; list = stream.collect(ArrayList::new, ArrayList::add, ArrayList::addAll);// 方式１//List&lt;String&gt; list = stream.collect(Collectors.toList());// 方式2System.out.println(list);\n通常情况下我们不需要手动指定collect()的三个参数，而是调用collect(Collector&lt;? super T,A,R&gt; collector)方法，并且参数中的Collector对象大都是直接通过Collectors工具类获得。实际上传入的收集器的行为决定了collect()的行为。\n7.使用collect()生成Collection前面已经提到通过collect()方法将Stream转换成容器的方法，这里再汇总一下。将Stream转换成List或Set是比较常见的操作，所以Collectors工具已经为我们提供了对应的收集器，通过如下代码即可完成：\n// 将Stream转换成List或SetStream&lt;String&gt; stream = Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;, &quot;too&quot;);List&lt;String&gt; list = stream.collect(Collectors.toList()); // (1)Set&lt;String&gt; set = stream.collect(Collectors.toSet()); // (2)\n上述代码能够满足大部分需求，但由于返回结果是接口类型，我们并不知道类库实际选择的容器类型是什么，有时候我们可能会想要人为指定容器的实际类型，这个需求可通过Collectors.toCollection(Supplier&lt;C&gt; collectionFactory)方法完成。\n// 使用toCollection()指定规约容器的类型ArrayList&lt;String&gt; arrayList = stream.collect(Collectors.toCollection(ArrayList::new));// (3)HashSet&lt;String&gt; hashSet = stream.collect(Collectors.toCollection(HashSet::new));// (4)\n上述代码(3)处指定规约结果是ArrayList，而(4)处指定规约结果为HashSet。一切如你所愿。\n8.使用collect()生成Map前面已经说过Stream背后依赖于某种数据源，数据源可以是数组、容器等，但不能是Map。反过来从Stream生成Map是可以的，但我们要想清楚Map的key和value分别代表什么，根本原因是我们要想清楚要干什么。通常在三种情况下collect()的结果会是Map：\n\n使用Collectors.toMap()生成的收集器，用户需要指定如何生成Map的key和value。\n使用Collectors.partitioningBy()生成的收集器，对元素进行二分区操作时用到。\n使用Collectors.groupingBy()生成的收集器，对元素做group操作时用到。\n\n情况1：使用toMap()生成的收集器，这种情况是最直接的，前面例子中已提到，这是和Collectors.toCollection()并列的方法。如下代码展示将学生列表转换成由&lt;学生，GPA&gt;组成的Map。非常直观，无需多言。\n// 使用toMap()统计学生GPAMap&lt;Student, Double&gt; studentToGPA =     students.stream().collect(Collectors.toMap(Function.identity(),// 如何生成key                                     student -&gt; computeGPA(student)));// 如何生成value\n情况2：使用partitioningBy()生成的收集器，这种情况适用于将Stream中的元素依据某个二值逻辑（满足条件，或不满足）分成互补相交的两部分，比如男女性别、成绩及格与否等。下列代码展示将学生分成成绩及格或不及格的两部分。\n// Partition students into passing and failingMap&lt;Boolean, List&lt;Student&gt;&gt; passingFailing = students.stream()         .collect(Collectors.partitioningBy(s -&gt; s.getGrade() &gt;= PASS_THRESHOLD));\n情况3：使用groupingBy()生成的收集器，这是比较灵活的一种情况。跟SQL中的group by语句类似，这里的groupingBy()也是按照某个属性对数据进行分组，属性相同的元素会被对应到Map的同一个key上。下列代码展示将员工按照部门进行分组：\n// Group employees by departmentMap&lt;Department, List&lt;Employee&gt;&gt; byDept = employees.stream()            .collect(Collectors.groupingBy(Employee::getDepartment));\n以上只是分组的最基本用法，有些时候仅仅分组是不够的。在SQL中使用group by是为了协助其他查询，比如1. 先将员工按照部门分组，2. 然后统计每个部门员工的人数。Java类库设计者也考虑到了这种情况，增强版的groupingBy()能够满足这种需求。增强版的groupingBy()允许我们对元素分组之后再执行某种运算，比如求和、计数、平均值、类型转换等。这种先将元素分组的收集器叫做上游收集器，之后执行其他运算的收集器叫做下游收集器(downstream Collector)。\n// 使用下游收集器统计每个部门的人数Map&lt;Department, Integer&gt; totalByDept = employees.stream()                    .collect(Collectors.groupingBy(Employee::getDepartment,                                                   Collectors.counting()));// 下游收集器\n上面代码的逻辑是不是越看越像SQL？高度非结构化。还有更狠的，下游收集器还可以包含更下游的收集器，这绝不是为了炫技而增加的把戏，而是实际场景需要。考虑将员工按照部门分组的场景，如果我们想得到每个员工的名字（字符串），而不是一个个Employee对象，可通过如下方式做到：\n// 按照部门对员工分布组，并只保留员工的名字Map&lt;Department, List&lt;String&gt;&gt; byDept = employees.stream()                .collect(Collectors.groupingBy(Employee::getDepartment,                        Collectors.mapping(Employee::getName,// 下游收集器                                Collectors.toList())));// 更下游的收集器\n如果看到这里你还没有对Java函数式编程失去信心，恭喜你，你已经顺利成为Java函数式编程大师了。\n9.使用collect()做字符串join这个肯定是大家喜闻乐见的功能，字符串拼接时使用Collectors.joining()生成的收集器，从此告别for循环。Collectors.joining()方法有三种重写形式，分别对应三种不同的拼接方式。无需多言，代码过目难忘。\n// 使用Collectors.joining()拼接字符串Stream&lt;String&gt; stream = Stream.of(&quot;I&quot;, &quot;love&quot;, &quot;you&quot;);//String joined = stream.collect(Collectors.joining());// &quot;Iloveyou&quot;//String joined = stream.collect(Collectors.joining(&quot;,&quot;));// &quot;I,love,you&quot;String joined = stream.collect(Collectors.joining(&quot;,&quot;, &quot;&#123;&quot;, &quot;&#125;&quot;));// &quot;&#123;I,love,you&#125;&quot;\n10.collect()还可以做更多除了可以使用Collectors工具类已经封装好的收集器，我们还可以自定义收集器，或者直接调用collect(Supplier&lt;R&gt; supplier, BiConsumer&lt;R,? super T&gt; accumulator, BiConsumer&lt;R,R&gt; combiner)方法，收集任何形式你想要的信息。不过Collectors工具类应该能满足我们的绝大部分需求，手动实现之间请先看看文档。\n四、Stream Pipelines前面我们已经学会如何使用Stream API，用起来真的很爽，但简洁的方法下面似乎隐藏着无尽的秘密，如此强大的API是如何实现的呢？比如Pipeline是怎么执行的，每次方法调用都会导致一次迭代吗？自动并行又是怎么做到的，线程个数是多少？接下来我们学习Stream流水线的原理，这是Stream实现的关键所在。\n首先回顾一下容器执行Lambda表达式的方式，以ArrayList.forEach()方法为例，具体代码如下：\n// ArrayList.forEach()public void forEach(Consumer&lt;? super E&gt; action) &#123;    ...    for (int i=0; modCount == expectedModCount &amp;&amp; i &lt; size; i++) &#123;        action.accept(elementData[i]);// 回调方法    &#125;    ...&#125;\n\n我们看到ArrayList.forEach()方法的主要逻辑就是一个for循环，在该for循环里不断调用action.accept()回调方法完成对元素的遍历。这完全没有什么新奇之处，回调方法在Java GUI的监听器中广泛使用。Lambda表达式的作用就是相当于一个回调方法，这很好理解。\nStream API中大量使用Lambda表达式作为回调方法，但这并不是关键。理解Stream我们更关心的是另外两个问题：流水线和自动并行。使用Stream或许很容易写入如下形式的代码：\nint longestStringLengthStartingWithA        = strings.stream()              .filter(s -&gt; s.startsWith(&quot;A&quot;))              .mapToInt(String::length)              .max();\n\n上述代码求出以字母A开头的字符串的最大长度，一种直白的方式是为每一次函数调用都执一次迭代，这样做能够实现功能，但效率上肯定是无法接受的。类库的实现着使用流水线（Pipeline）的方式巧妙的避免了多次迭代，其基本思想是在一次迭代中尽可能多的执行用户指定的操作。为讲解方便我们汇总了Stream的所有操作。\nStream操作分类中间操作(Intermediate operations)无状态(Stateless)unordered() filter() map() mapToInt() mapToLong() mapToDouble() flatMap() flatMapToInt() flatMapToLong() flatMapToDouble() peek()有状态(Stateful)distinct() sorted() sorted() limit() skip() 结束操作(Terminal operations)非短路操作forEach() forEachOrdered() toArray() reduce() collect() max() min() count()短路操作(short-circuiting)anyMatch() allMatch() noneMatch() findFirst() findAny()\n\nStream上的所有操作分为两类：中间操作和结束操作，中间操作只是一种标记，只有结束操作才会触发实际计算。中间操作又可以分为无状态的(Stateless)和有状态的(Stateful)，无状态中间操作是指元素的处理不受前面元素的影响，而有状态的中间操作必须等到所有元素处理之后才知道最终结果，比如排序是有状态操作，在读取所有元素之前并不能确定排序结果；结束操作又可以分为短路操作和非短路操作，短路操作是指不用处理全部元素就可以返回结果，比如找到第一个满足条件的元素。之所以要进行如此精细的划分，是因为底层对每一种情况的处理方式不同。为了更好的理解流的中间操作和终端操作，可以通过下面的两段代码来看他们的执行过程。\nIntStream.range(1, 10)   .peek(x -&gt; System.out.print(&quot;\\nA&quot; + x))   .limit(3)   .peek(x -&gt; System.out.print(&quot;B&quot; + x))   .forEach(x -&gt; System.out.print(&quot;C&quot; + x));\n输出为：A1B1C1A2B2C2A3B3C3中间操作是懒惰的，也就是中间操作不会对数据做任何操作，直到遇到了最终操作。而最终操作，都是比较热情的。他们会往前回溯所有的中间操作。也就是当执行到最后的forEach操作的时候，它会回溯到它的上一步中间操作，上一步中间操作，又会回溯到上上一步的中间操作，…，直到最初的第一步。第一次forEach执行的时候，会回溯peek 操作，然后peek会回溯更上一步的limit操作，然后limit会回溯更上一步的peek操作，顶层没有操作了，开始自上向下开始执行，输出：A1B1C1第二次forEach执行的时候，然后会回溯peek 操作，然后peek会回溯更上一步的limit操作，然后limit会回溯更上一步的peek操作，顶层没有操作了，开始自上向下开始执行，输出：A2B2C2\n…当第四次forEach执行的时候，然后会回溯peek 操作，然后peek会回溯更上一步的limit操作，到limit的时候，发现limit(3)这个job已经完成，这里就相当于循环里面的break操作，跳出来终止循环。\n再来看第二段代码：\nIntStream.range(1, 10)   .peek(x -&gt; System.out.print(&quot;\\nA&quot; + x))   .skip(6)   .peek(x -&gt; System.out.print(&quot;B&quot; + x))   .forEach(x -&gt; System.out.print(&quot;C&quot; + x));\n输出为：A1A2A3A4A5A6A7B7C7A8B8C8A9B9C9第一次forEach执行的时候，会回溯peek操作，然后peek会回溯更上一步的skip操作，skip回溯到上一步的peek操作，顶层没有操作了，开始自上向下开始执行，执行到skip的时候，因为执行到skip，这个操作的意思就是跳过，下面的都不要执行了，也就是就相当于循环里面的continue，结束本次循环。输出：A1\n第二次forEach执行的时候，会回溯peek操作，然后peek会回溯更上一步的skip操作，skip回溯到上一步的peek操作，顶层没有操作了，开始自上向下开始执行，执行到skip的时候，发现这是第二次skip，结束本次循环。输出：A2\n…\n第七次forEach执行的时候，会回溯peek操作，然后peek会回溯更上一步的skip操作，skip回溯到上一步的peek操作，顶层没有操作了，开始自上向下开始执行，执行到skip的时候，发现这是第七次skip，已经大于6了，它已经执行完了skip(6)的job了。这次skip就直接跳过，继续执行下面的操作。输出：A7B7C7\n…直到循环结束。\n1.一种直白的实现方式\n\n仍然考虑上述求最长字符串的程序，一种直白的流水线实现方式是为每一次函数调用都执一次迭代，并将处理中间结果放到某种数据结构中（比如数组，容器等）。具体说来，就是调用filter()方法后立即执行，选出所有以A开头的字符串并放到一个列表list1中，之后让list1传递给mapToInt()方法并立即执行，生成的结果放到list2中，最后遍历list2找出最大的数字作为最终结果。程序的执行流程如如所示：\n这样做实现起来非常简单直观，但有两个明显的弊端：\n\n迭代次数多。迭代次数跟函数调用的次数相等。\n频繁产生中间结果。每次函数调用都产生一次中间结果，存储开销无法接受。\n\n这些弊端使得效率底下，根本无法接受。如果不使用Stream API我们都知道上述代码该如何在一次迭代中完成，大致是如下形式：\nint longest = 0;for(String str : strings)&#123;    if(str.startsWith(&quot;A&quot;))&#123;// 1. filter(), 保留以A开头的字符串        int len = str.length();// 2. mapToInt(), 转换成长度        longest = Math.max(len, longest);// 3. max(), 保留最长的长度    &#125;&#125;\n\n采用这种方式我们不但减少了迭代次数，也避免了存储中间结果，显然这就是流水线，因为我们把三个操作放在了一次迭代当中。只要我们事先知道用户意图，总是能够采用上述方式实现跟Stream API等价的功能，但问题是Stream类库的设计者并不知道用户的意图是什么。如何在无法假设用户行为的前提下实现流水线，是类库的设计者要考虑的问题。\n2.Stream流水线解决方案我们大致能够想到，应该采用某种方式记录用户每一步的操作，当用户调用结束操作时将之前记录的操作叠加到一起在一次迭代中全部执行掉。沿着这个思路，有几个问题需要解决：\n\n用户的操作如何记录？\n操作如何叠加？\n叠加之后的操作如何执行？\n执行后的结果（如果有）在哪里？\n\n操作如何记录\n\n注意这里使用的是“操作(operation)”一词，指的是“Stream中间操作”的操作，很多Stream操作会需要一个回调函数（Lambda表达式），因此一个完整的操作是&lt;*数据来源，操作，回调函数*&gt;构成的三元组。Stream中使用Stage的概念来描述一个完整的操作，并用某种实例化后的PipelineHelper来代表Stage，将具有先后顺序的各个Stage连到一起，就构成了整个流水线。跟Stream相关类和接口的继承关系图示。\n还有IntPipeline, LongPipeline, DoublePipeline没在图中画出，这三个类专门为三种基本类型（不是包装类型）而定制的，跟ReferencePipeline是并列关系。图中Head用于表示第一个Stage，即调用调用诸如Collection.stream()方法产生的Stage，很显然这个Stage里不包含任何操作；StatelessOp和StatefulOp分别表示无状态和有状态的Stage，对应于无状态和有状态的中间操作。\nStream流水线组织结构示意图如下：\n\n\n图中通过Collection.stream()方法得到Head也就是stage0，紧接着调用一系列的中间操作，不断产生新的Stream。这些Stream对象以双向链表的形式组织在一起，构成整个流水线，由于每个Stage都记录了前一个Stage和本次的操作以及回调函数，依靠这种结构就能建立起对数据源的所有操作。这就是Stream记录操作的方式。\n操作如何叠加以上只是解决了操作记录的问题，要想让流水线起到应有的作用我们需要一种将所有操作叠加到一起的方案。你可能会觉得这很简单，只需要从流水线的head开始依次执行每一步的操作（包括回调函数）就行了。这听起来似乎是可行的，但是你忽略了前面的Stage并不知道后面Stage到底执行了哪种操作，以及回调函数是哪种形式。换句话说，只有当前Stage本身才知道该如何执行自己包含的动作。这就需要有某种协议来协调相邻Stage之间的调用关系。\n这种协议由Sink接口完成，Sink接口包含的方法如下表所示：\n方法名作用void begin(long size)开始遍历元素之前调用该方法，通知Sink做好准备。void end()所有元素遍历完成之后调用，通知Sink没有更多的元素了。boolean cancellationRequested()是否可以结束操作，可以让短路操作尽早结束。void accept(T t)遍历元素时调用，接受一个待处理元素，并对元素进行处理。Stage把自己包含的操作和回调方法封装到该方法里，前一个Stage只需要调用当前Stage.accept(T t)方法就行了。\n\n有了上面的协议，相邻Stage之间调用就很方便了，每个Stage都会将自己的操作封装到一个Sink里，前一个Stage只需调用后一个Stage的accept()方法即可，并不需要知道其内部是如何处理的。当然对于有状态的操作，Sink的begin()和end()方法也是必须实现的。比如Stream.sorted()是一个有状态的中间操作，其对应的Sink.begin()方法可能创建一个盛放结果的容器，而accept()方法负责将元素添加到该容器，最后end()负责对容器进行排序。对于短路操作，Sink.cancellationRequested()也是必须实现的，比如Stream.findFirst()是短路操作，只要找到一个元素，cancellationRequested()就应该返回true，以便调用者尽快结束查找。Sink的四个接口方法常常相互协作，共同完成计算任务。实际上Stream API内部实现的的本质，就是如何重写Sink的这四个接口方法。\n有了Sink对操作的包装，Stage之间的调用问题就解决了，执行时只需要从流水线的head开始对数据源依次调用每个Stage对应的Sink.{begin(), accept(), cancellationRequested(), end()}方法就可以了。一种可能的Sink.accept()方法流程是这样的：\nvoid accept(U u)&#123;    1. 使用当前Sink包装的回调函数处理u    2. 将处理结果传递给流水线下游的Sink&#125;\n\nSink接口的其他几个方法也是按照这种[处理-&gt;转发]的模型实现。下面我们结合具体例子看看Stream的中间操作是如何将自身的操作包装成Sink以及Sink是如何将处理结果转发给下一个Sink的。先看Stream.map()方法：\n// Stream.map()，调用该方法将产生一个新的Streampublic final &lt;R&gt; Stream&lt;R&gt; map(Function&lt;? super P_OUT, ? extends R&gt; mapper) &#123;    ...    return new StatelessOp&lt;P_OUT, R&gt;(this, StreamShape.REFERENCE,                                 StreamOpFlag.NOT_SORTED | StreamOpFlag.NOT_DISTINCT) &#123;        @Override /*opWripSink()方法返回由回调函数包装而成Sink*/        Sink&lt;P_OUT&gt; opWrapSink(int flags, Sink&lt;R&gt; downstream) &#123;            return new Sink.ChainedReference&lt;P_OUT, R&gt;(downstream) &#123;                @Override                public void accept(P_OUT u) &#123;                    R r = mapper.apply(u);// 1. 使用当前Sink包装的回调函数mapper处理u                    downstream.accept(r);// 2. 将处理结果传递给流水线下游的Sink                &#125;            &#125;;        &#125;    &#125;;&#125;\n\n上述代码看似复杂，其实逻辑很简单，就是将回调函数mapper包装到一个Sink当中。由于Stream.map()是一个无状态的中间操作，所以map()方法返回了一个StatelessOp内部类对象（一个新的Stream），调用这个新Stream的opWripSink()方法将得到一个包装了当前回调函数的Sink。\n再来看一个复杂一点的例子。Stream.sorted()方法将对Stream中的元素进行排序，显然这是一个有状态的中间操作，因为读取所有元素之前是没法得到最终顺序的。抛开模板代码直接进入问题本质，sorted()方法是如何将操作封装成Sink的呢？sorted()一种可能封装的Sink代码如下：\n// Stream.sort()方法用到的Sink实现class RefSortingSink&lt;T&gt; extends AbstractRefSortingSink&lt;T&gt; &#123;    private ArrayList&lt;T&gt; list;// 存放用于排序的元素    RefSortingSink(Sink&lt;? super T&gt; downstream, Comparator&lt;? super T&gt; comparator) &#123;        super(downstream, comparator);    &#125;    @Override    public void begin(long size) &#123;        ...        // 创建一个存放排序元素的列表        list = (size &gt;= 0) ? new ArrayList&lt;T&gt;((int) size) : new ArrayList&lt;T&gt;();    &#125;    @Override    public void end() &#123;        list.sort(comparator);// 只有元素全部接收之后才能开始排序        downstream.begin(list.size());        if (!cancellationWasRequested) &#123;// 下游Sink不包含短路操作            list.forEach(downstream::accept);// 2. 将处理结果传递给流水线下游的Sink        &#125;        else &#123;// 下游Sink包含短路操作            for (T t : list) &#123;// 每次都调用cancellationRequested()询问是否可以结束处理。                if (downstream.cancellationRequested()) break;                downstream.accept(t);// 2. 将处理结果传递给流水线下游的Sink            &#125;        &#125;        downstream.end();        list = null;    &#125;    @Override    public void accept(T t) &#123;        list.add(t);// 1. 使用当前Sink包装动作处理t，只是简单的将元素添加到中间列表当中    &#125;&#125;\n\n上述代码完美的展现了Sink的四个接口方法是如何协同工作的：\n\n首先begin()方法告诉Sink参与排序的元素个数，方便确定中间结果容器的的大小；\n之后通过accept()方法将元素添加到中间结果当中，最终执行时调用者会不断调用该方法，直到遍历所有元素；\n最后end()方法告诉Sink所有元素遍历完毕，启动排序步骤，排序完成后将结果传递给下游的Sink；\n如果下游的Sink是短路操作，将结果传递给下游时不断询问下游cancellationRequested()是否可以结束处理。\n\n叠加之后的操作如何执行\n\nSink完美封装了Stream每一步操作，并给出了[处理-&gt;转发]的模式来叠加操作。这一连串的齿轮已经咬合，就差最后一步拨动齿轮启动执行。是什么启动这一连串的操作呢？也许你已经想到了启动的原始动力就是结束操作(Terminal Operation)，一旦调用某个结束操作，就会触发整个流水线的执行。\n结束操作之后不能再有别的操作，所以结束操作不会创建新的流水线阶段(Stage)，直观的说就是流水线的链表不会在往后延伸了。结束操作会创建一个包装了自己操作的Sink，这也是流水线中最后一个Sink，这个Sink只需要处理数据而不需要将结果传递给下游的Sink（因为没有下游）。对于Sink的[处理-&gt;转发]模型，结束操作的Sink就是调用链的出口。\n我们再来考察一下上游的Sink是如何找到下游Sink的。一种可选的方案是在PipelineHelper中设置一个Sink字段，在流水线中找到下游Stage并访问Sink字段即可。但Stream类库的设计者没有这么做，而是设置了一个Sink AbstractPipeline.opWrapSink(int flags, Sink downstream)方法来得到Sink，该方法的作用是返回一个新的包含了当前Stage代表的操作以及能够将结果传递给downstream的Sink对象。为什么要产生一个新对象而不是返回一个Sink字段？这是因为使用opWrapSink()可以将当前操作与下游Sink（上文中的downstream参数）结合成新Sink。试想只要从流水线的最后一个Stage开始，不断调用上一个Stage的opWrapSink()方法直到最开始（不包括stage0，因为stage0代表数据源，不包含操作），就可以得到一个代表了流水线上所有操作的Sink，用代码表示就是这样：\n// AbstractPipeline.wrapSink()// 从下游向上游不断包装Sink。如果最初传入的sink代表结束操作，// 函数返回时就可以得到一个代表了流水线上所有操作的Sink。final &lt;P_IN&gt; Sink&lt;P_IN&gt; wrapSink(Sink&lt;E_OUT&gt; sink) &#123;    ...    for (AbstractPipeline p=AbstractPipeline.this; p.depth &gt; 0; p=p.previousStage) &#123;        sink = p.opWrapSink(p.previousStage.combinedFlags, sink);    &#125;    return (Sink&lt;P_IN&gt;) sink;&#125;\n\n现在流水线上从开始到结束的所有的操作都被包装到了一个Sink里，执行这个Sink就相当于执行整个流水线，执行Sink的代码如下：\n// AbstractPipeline.copyInto(), 对spliterator代表的数据执行wrappedSink代表的操作。final &lt;P_IN&gt; void copyInto(Sink&lt;P_IN&gt; wrappedSink, Spliterator&lt;P_IN&gt; spliterator) &#123;    ...    if (!StreamOpFlag.SHORT_CIRCUIT.isKnown(getStreamAndOpFlags())) &#123;        wrappedSink.begin(spliterator.getExactSizeIfKnown());// 通知开始遍历        spliterator.forEachRemaining(wrappedSink);// 迭代        wrappedSink.end();// 通知遍历结束    &#125;    ...&#125;\n\n上述代码首先调用wrappedSink.begin()方法告诉Sink数据即将到来，然后调用spliterator.forEachRemaining()方法对数据进行迭代（Spliterator是容器的一种迭代器，参阅），最后调用wrappedSink.end()方法通知Sink数据处理结束。逻辑如此清晰。\n执行后的结果在哪里最后一个问题是流水线上所有操作都执行后，用户所需要的结果（如果有）在哪里？首先要说明的是不是所有的Stream结束操作都需要返回结果，有些操作只是为了使用其副作用(Side-effects)，比如使用Stream.forEach()方法将结果打印出来就是常见的使用副作用的场景（事实上，除了打印之外其他场景都应避免使用副作用），对于真正需要返回结果的结束操作结果存在哪里呢？\n\n特别说明：副作用不应该被滥用，也许你会觉得在Stream.forEach()里进行元素收集是个不错的选择，就像下面代码中那样，但遗憾的是这样使用的正确性和效率都无法保证，因为Stream可能会并行执行。大多数使用副作用的地方都可以使用归约操作更安全和有效的完成。\n\n// 错误的收集方式ArrayList&lt;String&gt; results = new ArrayList&lt;&gt;();stream.filter(s -&gt; pattern.matcher(s).matches())      .forEach(s -&gt; results.add(s));  // Unnecessary use of side-effects!// 正确的收集方式List&lt;String&gt;results =     stream.filter(s -&gt; pattern.matcher(s).matches())             .collect(Collectors.toList());  // No side-effects!\n\n回到流水线执行结果的问题上来，需要返回结果的流水线结果存在哪里呢？这要分不同的情况讨论，下表给出了各种有返回结果的Stream结束操作。\n返回类型对应的结束操作booleananyMatch() allMatch() noneMatch()OptionalfindFirst() findAny()归约结果reduce() collect()数组toArray()\n\n\n对于表中返回boolean或者Optional的操作（Optional是存放 一个 值的容器）的操作，由于值返回一个值，只需要在对应的Sink中记录这个值，等到执行结束时返回就可以了。\n对于归约操作，最终结果放在用户调用时指定的容器中（容器类型通过收集器指定）。collect(), reduce(), max(), min()都是归约操作，虽然max()和min()也是返回一个Optional，但事实上底层是通过调用reduce()方法实现的。\n对于返回是数组的情况，毫无疑问的结果会放在数组当中。这么说当然是对的，但在最终返回数组之前，结果其实是存储在一种叫做Node的数据结构中的。Node是一种多叉树结构，元素存储在树的叶子当中，并且一个叶子节点可以存放多个元素。这样做是为了并行执行方便。关于Node的具体结构，我们会在下一节探究Stream如何并行执行时给出详细说明。\n\n3.结语本节详细介绍了Stream流水线的组织方式和执行过程，学习本文将有助于理解原理并写出正确的Stream代码，同时打消你对Stream API效率方面的顾虑。如你所见，Stream API实现如此巧妙，即使我们使用外部迭代手动编写等价代码，也未必更加高效。\n注：留下本文所用的JDK版本，以便有考究癖的人考证：\n$ java -versionjava version &quot;1.8.0_101&quot;Java(TM) SE Runtime Environment (build 1.8.0_101-b13)Java HotSpot(TM) Server VM (build 25.101-b13, mixed mode)\n\n\n\n\n\n五、parallelStream 介绍我们已经对Stream有过很多的了解，对其原理及常见使用方法已经也有了一定的认识。流在处理数据进行一些迭代操作的时候确认很方便，但是在执行一些耗时或是占用资源很高的任务时候，串行化的流无法带来速度&#x2F;性能上的提升，并不能满足我们的需要，通常我们会使用多线程来并行或是分片分解执行任务，而在Stream中也提供了这样的并行方法，那就是使用parallelStream()方法或者是使用stream().parallel()来转化为并行流。开箱即用的并行流的使用看起来如此简单，然后我们就可能会忍不住思考，并行流的实现原理是怎样的？它的使用会给我们带来多大的性能提升？我们可以在什么场景下使用以及使用时应该注意些什么？\n首先我们看一下Java 的并行 API 演变历程基本如下：\n\n1.0-1.4 中的 java.lang.Thread\n5.0 中的 java.util.concurrent\n6.0 中的 Phasers 等\n7.0 中的 Fork&#x2F;Join 框架\n8.0 中的 Lambda\n\n1.parallelStream是什么？先看一下Collection接口提供的并行流方法\n/** * Returns a possibly parallel &#123;@code Stream&#125; with this collection as its * source.  It is allowable for this method to return a sequential stream. * * &lt;p&gt;This method should be overridden when the &#123;@link #spliterator()&#125; * method cannot return a spliterator that is &#123;@code IMMUTABLE&#125;, * &#123;@code CONCURRENT&#125;, or &lt;em&gt;late-binding&lt;/em&gt;. (See &#123;@link #spliterator()&#125; * for details.) * * @implSpec * The default implementation creates a parallel &#123;@code Stream&#125; from the * collection&#x27;s &#123;@code Spliterator&#125;. * * @return a possibly parallel &#123;@code Stream&#125; over the elements in this * collection * @since 1.8 */default Stream&lt;E&gt; parallelStream() &#123;    return StreamSupport.stream(spliterator(), true);&#125;\n注意其中的代码注释的返回值 @return a possibly parallel 一句说明调用了这个方法，只是可能会返回一个并行的流，流是否能并行执行还受到其他一些条件的约束。parallelStream其实就是一个并行执行的流，它通过默认的ForkJoinPool，可能提高你的多线程任务的速度。引用Custom thread pool in Java 8 parallel stream上面的两段话：\n\nThe parallel streams use the default ForkJoinPool.commonPool which by default has one less threads as you have processors, as returned by Runtime.getRuntime().availableProcessors() (This means that parallel streams use all your processors because they also use the main thread)。\n\n做个实验来证明上面这句话的真实性：\npublic static void main(String[] args) &#123;    IntStream list = IntStream.range(0, 10);    Set&lt;Thread&gt; threadSet = new HashSet&lt;&gt;();    //开始并行执行    list.parallel().forEach(i -&gt; &#123;        Thread thread = Thread.currentThread();        System.err.println(&quot;integer：&quot; + i + &quot;，&quot; + &quot;currentThread:&quot; + thread.getName());        threadSet.add(thread);    &#125;);    System.out.println(&quot;all threads：&quot; + Joiner.on(&quot;，&quot;).join(threadSet.stream().map(Thread::getName).collect(Collectors.toList())));&#125;\n\n\n从运行结果里面我们可以很清楚的看到parallelStream同时使用了主线程和ForkJoinPool.commonPool创建的线程。值得说明的是这个运行结果并不是唯一的，实际运行的时候可能会得到多个结果，比如：\n\n\n甚至你的运行结果里面只有主线程。\n来源于java 8 实战的书籍的一段话：\n\n并行流内部使用了默认的ForkJoinPool（7.2节会进一步讲到分支&#x2F;合并框架），它默认的线程数量就是你的处理器数量，这个值是由Runtime.getRuntime().available- Processors()得到的。 但是你可以通过系统属性java.util.concurrent.ForkJoinPool.common. parallelism来改变线程池大小，如下所示： System.setProperty(&quot;java.util.concurrent.ForkJoinPool.common.parallelism&quot;,&quot;12&quot;); 这是一个全局设置，因此它将影响代码中所有的并行流。反过来说，目前还无法专为某个 并行流指定这个值。一般而言，让ForkJoinPool的大小等于处理器数量是个不错的默认值， 除非你有很好的理由，否则我们强烈建议你不要修改它。\n\n// 设置全局并行流并发线程数System.setProperty(&quot;java.util.concurrent.ForkJoinPool.common.parallelism&quot;, &quot;12&quot;);System.out.println(ForkJoinPool.getCommonPoolParallelism());// 输出 12System.setProperty(&quot;java.util.concurrent.ForkJoinPool.common.parallelism&quot;, &quot;20&quot;);System.out.println(ForkJoinPool.getCommonPoolParallelism());// 输出 12\n为什么两次的运行结果是一样的呢？上面刚刚说过了这是一个全局设置，java.util.concurrent.ForkJoinPool.common.parallelism是final类型的，整个JVM中只允许设置一次。既然默认的并发线程数不能反复修改，那怎么进行不同线程数量的并发测试呢？答案是：引入ForkJoinPool\nIntStream range = IntStream.range(1, 100000);// 传入parallelismnew ForkJoinPool(parallelism).submit(() -&gt; range.parallel().forEach(System.out::println)).get();\n因此，使用parallelStream时需要注意的一点是，多个parallelStream之间默认使用的是同一个线程池，所以IO操作尽量不要放进parallelStream中，否则会阻塞其他parallelStream。\n\nUsing a ForkJoinPool and submit for a parallel stream does not reliably use all threads. If you look at this ( Parallel stream from a HashSet doesn’t run in parallel ) and this ( Why does the parallel stream not use all the threads of the ForkJoinPool? ), you’ll see the reasoning.\n\n// 获取当前机器CPU处理器的数量System.out.println(Runtime.getRuntime().availableProcessors());// 输出 4// parallelStream默认的并发线程数System.out.println(ForkJoinPool.getCommonPoolParallelism());// 输出 3\n为什么parallelStream默认的并发线程数要比CPU处理器的数量少1个？文章的开始已经提过了。因为最优的策略是每个CPU处理器分配一个线程，然而主线程也算一个线程，所以要占一个名额。这一点可以从源码中看出来：\nstatic final int MAX_CAP      = 0x7fff;        // max #workers - 1// 无参构造函数public ForkJoinPool() &#123;        this(Math.min(MAX_CAP, Runtime.getRuntime().availableProcessors()),             defaultForkJoinWorkerThreadFactory, null, false);&#125;bs-channel\n\n2.从parallelStream认识Fork&#x2F;Join 框架Fork&#x2F;Join 框架的核心是采用分治法的思想，将一个大任务拆分为若干互不依赖的子任务，把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务。同时，为了最大限度地提高并行处理能力，采用了工作窃取算法来运行任务，也就是说当某个线程处理完自己工作队列中的任务后，尝试当其他线程的工作队列中窃取一个任务来执行，直到所有任务处理完毕。所以为了减少线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。\n\nFork&#x2F;Join 的运行流程图\n\n简单地说就是大任务拆分成小任务，分别用不同线程去完成，然后把结果合并后返回。所以第一步是拆分，第二步是分开运算，第三步是合并。这三个步骤分别对应的就是Collector的supplier,accumulator和combiner。\n\n工作窃取算法Fork&#x2F;Join最核心的地方就是利用了现代硬件设备多核,在一个操作时候会有空闲的CPU,那么如何利用好这个空闲的cpu就成了提高性能的关键,而这里我们要提到的工作窃取（work-stealing）算法就是整个Fork&#x2F;Join框架的核心理念,工作窃取（work-stealing）算法是指某个线程从其他队列里窃取任务来执行。  \n\n3.使用parallelStream的利弊使用parallelStream的几个好处：\n\n代码优雅，可以使用lambda表达式，原本几句代码现在一句可以搞定；\n运用多核特性(forkAndJoin)并行处理，大幅提高效率。关于并行流和多线程的性能测试可以看一下下面的几篇博客：并行流适用场景-CPU密集型提交订单性能优化系列之006-普通的Thread多线程改为Java8的parallelStream并发流\n\n然而，任何事物都不是完美的，并行流也不例外，其中最明显的就是使用(parallel)Stream极其不便于代码的跟踪调试，此外并行流带来的不确定性也使得我们对它的使用变得格外谨慎。我们得去了解更多的并行流的相关知识来保证自己能够正确的使用这把双刃剑。\nparallelStream使用时需要注意的点：\n\nparallelStream是线程不安全的；List&lt;Integer&gt; values = new ArrayList&lt;&gt;();IntStream.range(1, 10000).parallel().forEach(values::add);System.out.println(values.size());\nvalues集合大小可能不是10000。集合里面可能会存在null元素或者抛出下标越界的异常信息。原因：List不是线程安全的集合，add方法在多线程环境下会存在并发问题。当执行add方法时，会先将此容器的大小增加。。即size++，然后将传进的元素赋值给新增的elementData[size++]，即新的内存空间。但是此时如果在size++后直接来取这个List,而没有让add完成赋值操作，则会导致此List的长度加一，，但是最后一个元素是空（null），所以在获取它进行计算的时候报了空指针异常。而下标越界还不能仅仅依靠这个来解释，如果你观察发生越界时的数组下标，分别为10、15、22、33、49和73。结合前面讲的数组自动机制，数组初始长度为10，第一次扩容为15&#x3D;10+10&#x2F;2，第二次扩容22&#x3D;15+15&#x2F;2，第三次扩容33&#x3D;22+22&#x2F;2…以此类推，我们不难发现，越界异常都发生在数组扩容之时。grow()方法解释了基于数组的ArrayList是如何扩容的。数组进行扩容时，会将老数组中的元素重新拷贝一份到新的数组中，通过oldCapacity + (oldCapacity &gt;&gt; 1)运算，每次数组容量的增长大约是其原容量的1.5倍。 /** * Increases the capacity to ensure that it can hold at least the * number of elements specified by the minimum capacity argument. * * @param minCapacity the desired minimum capacity */private void grow(int minCapacity) &#123;    // overflow-conscious code    int oldCapacity = elementData.length;    int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);// 1.5倍扩容    if (newCapacity - minCapacity &lt; 0)        newCapacity = minCapacity;    if (newCapacity - MAX_ARRAY_SIZE &gt; 0)        newCapacity = hugeCapacity(minCapacity);    // minCapacity is usually close to size, so this is a win:    elementData = Arrays.copyOf(elementData, newCapacity);// 拷贝旧的数组到新的数组中&#125;/** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return &lt;tt&gt;true&lt;/tt&gt; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123;    ensureCapacityInternal(size + 1);  // Increments modCount!! 检查array容量    elementData[size++] = e;// 赋值，增大Size的值    return true;&#125;\n解决方法：加锁、使用线程安全的集合或者采用collect()或者reduce()操作就是满足线程安全的了。List&lt;Integer&gt; values = new ArrayList&lt;&gt;();for (int i = 0; i &lt; 10000; i++) &#123;    values.add(i);&#125;List&lt;Integer&gt; collect = values.stream().parallel().collect(Collectors.toList());System.out.println(collect.size());\nparallelStream 适用的场景是CPU密集型的，只是做到别浪费CPU，假如本身电脑CPU的负载很大，那还到处用并行流，那并不能起到作用；\n\n\nI&#x2F;O密集型 磁盘I&#x2F;O、网络I&#x2F;O都属于I&#x2F;O操作，这部分操作是较少消耗CPU资源，一般并行流中不适用于I&#x2F;O密集型的操作，就比如使用并流行进行大批量的消息推送，涉及到了大量I&#x2F;O，使用并行流反而慢了很多\nCPU密集型 计算类型就属于CPU密集型了，这种操作并行流就能提高运行效率。\n\n\n不要在多线程中使用parallelStream，原因同上类似，大家都抢着CPU是没有提升效果，反而还会加大线程切换开销；\n会带来不确定性，请确保每条处理无状态且没有关联；\n考虑NQ模型：N可用的数据量，Q针对每个数据元素执行的计算量，乘积 N * Q 越大，就越有可能获得并行提速。N * Q&gt;10000（大概是集合大小超过1000） 就会获得有效提升；\nparallelStream是创建一个并行的Stream,而且它的并行操作是不具备线程传播性的,所以是无法获取ThreadLocal创建的线程变量的值；\n在使用并行流的时候是无法保证元素的顺序的，也就是即使你用了同步集合也只能保证元素都正确但无法保证其中的顺序；\nlambda的执行并不是瞬间完成的，所有使用parallel stream的程序都有可能成为阻塞程序的源头，并且在执行过程中程序中的其他部分将无法访问这些workers，这意味着任何依赖parallel streams的程序在什么别的东西占用着common ForkJoinPool时将会变得不可预知并且暗藏危机。\n\n六、Stream性能测验我们已经对Stream API的用法聊了这么多了，用起简洁直观，但性能到底怎么样呢？会不会有很高的性能损失？本节我们对Stream API的性能一探究竟。\n为保证测试结果真实可信，我们将JVM运行在-server模式下，测试数据在GB量级，测试机器采用常见的商用服务器，配置如下：\nOSCentOS 6.7 x86_64CPUIntel Xeon X5675, 12M Cache 3.06 GHz, 6 Cores 12 Threads内存96GBJDKjava version 1.8.0_91, Java HotSpot(TM) 64-Bit Server VM\n\n测试所用代码在这里，测试结果汇总.\n1.测试方法和测试数据性能测试并不是容易的事，Java性能测试更费劲，因为虚拟机对性能的影响很大，JVM对性能的影响有两方面：\n\nGC的影响。GC的行为是Java中很不好控制的一块，为增加确定性，我们手动指定使用CMS收集器，并使用10GB固定大小的堆内存。具体到JVM参数就是-XX:+UseConcMarkSweepGC -Xms10G -Xmx10G\nJIT(Just-In-Time)即时编译技术。即时编译技术会将热点代码在JVM运行的过程中编译成本地代码，测试时我们会先对程序预热，触发对测试函数的即时编译。相关的JVM参数是-XX:CompileThreshold=10000。\n\nStream并行执行时用到ForkJoinPool.commonPool()得到的线程池，为控制并行度我们使用Linux的taskset命令指定JVM可用的核数。\n测试数据由程序随机生成。为防止一次测试带来的抖动，测试4次求出平均时间作为运行时间。\n2.实验一 基本类型迭代测试内容：找出整型数组中的最小值。对比for循环外部迭代和Stream API内部迭代性能。\n测试程序IntTest，测试结果如下图：\n\n\n图中展示的是for循环外部迭代耗时为基准的时间比值。分析如下：\n\n对于基本类型Stream串行迭代的性能开销明显高于外部迭代开销（两倍）；\nStream并行迭代的性能比串行迭代和外部迭代都好。\n\n并行迭代性能跟可利用的核数有关，上图中的并行迭代使用了全部12个核，为考察使用核数对性能的影响，我们专门测试了不同核数下的Stream并行迭代效果：\n\n\n分析，对于基本类型：\n\n使用Stream并行API在单核情况下性能很差，比Stream串行API的性能还差；\n随着使用核数的增加，Stream并行效果逐渐变好，比使用for循环外部迭代的性能还好。\n\n以上两个测试说明，对于基本类型的简单迭代，Stream串行迭代性能更差，但多核情况下Stream迭代时性能较好。\n3.实验二 对象迭代再来看对象的迭代效果。\n测试内容：找出字符串列表中最小的元素（自然顺序），对比for循环外部迭代和Stream API内部迭代性能。\n测试程序StringTest，测试结果如下图：\n\n\n结果分析如下：\n\n对于对象类型Stream串行迭代的性能开销仍然高于外部迭代开销（1.5倍），但差距没有基本类型那么大。\nStream并行迭代的性能比串行迭代和外部迭代都好。\n\n再来单独考察Stream并行迭代效果：\n\n\n分析，对于对象类型：\n\n使用Stream并行API在单核情况下性能比for循环外部迭代差；\n随着使用核数的增加，Stream并行效果逐渐变好，多核带来的效果明显。\n\n以上两个测试说明，对于对象类型的简单迭代，Stream串行迭代性能更差，但多核情况下Stream迭代时性能较好。\n4.实验三 复杂对象归约从实验一、二的结果来看，Stream串行执行的效果都比外部迭代差（很多），是不是说明Stream真的不行了？先别下结论，我们再来考察一下更复杂的操作。\n测试内容：给定订单列表，统计每个用户的总交易额。对比使用外部迭代手动实现和Stream API之间的性能。\n我们将订单简化为&lt;userName, price, timeStamp&gt;构成的元组，并用Order对象来表示。测试程序ReductionTest，测试结果如下图：\n\n\n分析，对于复杂的归约操作：\n\nStream API的性能普遍好于外部手动迭代，并行Stream效果更佳；\n\n再来考察并行度对并行效果的影响，测试结果如下：\n\n\n分析，对于复杂的归约操作：\n\n使用Stream并行归约在单核情况下性能比串行归约以及手动归约都要差，简单说就是最差的；\n随着使用核数的增加，Stream并行效果逐渐变好，多核带来的效果明显。\n\n以上两个实验说明，对于复杂的归约操作，Stream串行归约效果好于手动归约，在多核情况下，并行归约效果更佳。我们有理由相信，对于其他复杂的操作，Stream API也能表现出相似的性能表现。\n5.结论上述三个实验的结果可以总结如下：\n\n对于简单操作，比如最简单的遍历，Stream串行API性能明显差于显示迭代，但并行的Stream API能够发挥多核特性。\n对于复杂操作，Stream串行API性能可以和手动实现的效果匹敌，在并行执行时Stream API效果远超手动实现。\n\n所以，如果出于性能考虑，1. 对于简单操作推荐使用外部迭代手动实现，2. 对于复杂操作，推荐使用Stream API， 3. 在多核情况下，推荐使用并行Stream API来发挥多核优势，4.单核情况下不建议使用并行Stream API。\n如果出于代码简洁性考虑，使用Stream API能够写出更短的代码。即使是从性能方面说，尽可能的使用Stream API也另外一个优势，那就是只要Java Stream类库做了升级优化，代码不用做任何修改就能享受到升级带来的好处。\n七、参考文献\nThe Java® Language Specification\nhttp://viralpatel.net/blogs/lambda-expressions-java-tutorial/\n《Java 8函数式编程 [英]沃伯顿》\nhttp://cr.openjdk.java.net/~briangoetz/lambda/lambda-state-final.html\nhttps://docs.oracle.com/javase/8/docs/api/java/util/stream/package-summary.html#package.description\nhttps://docs.oracle.com/javase/tutorial/java/javaOO/methodreferences.html\nhttps://docs.oracle.com/javase/8/docs/api/java/util/stream/Collector.html\nhttps://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html\nhttps://docs.oracle.com/javase/8/docs/api/java/util/stream/Collectors.html\n\n","categories":["总结笔记"],"tags":["Java","Java8","Lambda"]},{"title":"《Lua编程》 第一篇：语言","url":"/2025_04_08_lua/","content":"\nSimple is beautiful\n(本文使用pdf-craft开源工具和大模型生成整理)\n译序“袁承志知道若再谦逊,那就是瞧人不起,展开五行拳,发拳当胸打去。荣彩和旁观三人本来都以为他武功有独到之秘,哪知使出来的竟是武林中最寻常不过的五行拳。敌对三人登时意存轻视,温青脸上不自禁露出失望的神色。\n“荣彩心中暗喜,双拳如风,连抢三下攻势,满拟自己的大力魔爪手江南独步,三四招之间就可破去对方五行拳,那知袁承志轻描淡写的一一化解。再拆数招,荣彩暗暗吃惊,原来对方所使虽是极寻常的拳术,但每一招均是含劲不吐,意在拳先,举手抬足之间隐含极浑厚的内力。”\n——金庸 《碧血剑》\n编程语言之于程序员,若武功招式之于习武之人,招式虽重要,但在于使用之人。胜者之道,武功只行于表,高手用剑,片草只叶亦威力无穷。\n当今武林,派别林立,语言繁杂,林林总总不计其数。主流文化的C&#x2F;C++、Java、C#、VB；偏安一隅的Fortran；动态语言中的Perl、Tcl、Ruby、Forth、Python,以及本书介绍的Lua；····,等等等等。再加上世界上那些不知道躲在哪的晃的奇奇怪怪的hacker捣鼓出来的异想天开的语言,要想将各类语言囊入怀中,不异于痴人说梦。不信可欣赏一下BrainFuck语言’的Hello World程序,语言本身依如其名。\n&gt;+++++++++[&lt;++++++++&gt;-]&lt;.&gt;+++++++[&lt;++++&gt;-]&lt;+.+++++++..+++.[-]&gt;++++++++[&lt;++++&gt;-]&lt;.#&gt;+++++++++++[&lt;+++++&gt;-]&lt;.&gt;++++++++[&lt;+ ++&gt;-]&lt;.+++.------.--------.[-]&gt;++++++++[&lt;++++&gt;-]&lt;+.[-]+++++ +++++.\n\n虽说语言的威力依使用者本身的修为高低而定,但不同语言本身的设计又有不同。若让用Java 写写操作系统内核、Perl 写写驱动程序、C&#x2F;C++写写web 应用,都无异于舍近求远,好刀只用上了刀背。\nLua 本身是以简单优雅为本,着眼于处理那些C不擅长的任务。借助C&#x2F;C++为其扩展,Lua 可闪现无穷魅力。Lua 本身完全遵循 ANSIC而写成,只要有C 编译器的地方,Lua 便可发挥她的力量。Lua 不需要追求Python 那样的大而全的库,太多的累赘,反而会破坏她的优美。\n语言的优美,来自于使用者自己的感悟。Lua 的优雅,也只有使用后才会明白。\n扬起帆,让我们一同踏上Lua的学习之旅······\n本书的翻译,是www.luachina.net中朋友们共同努力的结果。\n注：校对工作在进行。\n目录第一篇 语言第0章 序言0.1序言0.2 Lua的使用者0.3 Lua的相关资源0.4 本书的体例0.5关于本书0.6感谢第1章 起点1.1 Chunks1.2 全局变量1.3 词法约定1.4 命令行方式第2章 类型和值2.1 Nil2.2 Booleans2.3 Numbers2.4 Strings2.5 Functions2.6 Userdata and Threads第3章 表达式3.1 算术运算符3.2 关系运算符3.3 逻辑运算符3.4 连接运算符3.5优先级3.6 表的构造第4章 基本语法4.1 赋值语句4.2局部变量与代码块(block)4.3 控制结构语句4.4 break和return语句第5章函数5.1 返回多个结果值5.2 可变参数5.3命名参数第6章 再论函数6.1闭包6.2非全局函数6.3正确的尾调用(Proper TailCalls)第7章 迭代器与泛型for7.1 迭代器与闭包7.2 范性for的语义7.3无状态的迭代器7.4 多状态的迭代器7.5 真正的迭代器第8章编译·运行·调试8.1 require函数8.2 C Packages8.3 错误8.4 异常和错误处理8.5错误信息和回跟踪(Tracebacks)第9章 协同程序9.1 协同的基础9.2管道和过滤器9.3用作迭代器的协同9.4 非抢占式多线程第10章 完整示例10.1 Lua作为数据描述语言使用10.2 马尔可夫链算法\n第0章序言本章包括作者的序言、文章的体例(convention)以及其它一些“每本书开头都会的内容”\n0.1序言目前很多程序语言都专注于帮你编写成千上万行的代码,所以此类型的语言所提供的包、命名空间、复杂的类型系统及无数的结构,有上千页的文档需要操作者学习。\n而Lua 并不帮你编写大量的代码的程序,相反的,Lua 仅让你用少量的代码解决关键问题。为实现这个目标,像其他语言一样Lua 依赖于其可扩展性。但是与其他语言不同的是,不仅用Lua 编写的软件易于扩展,而且用其他语言比如C&#x2F;C++编写的软件也很容易使用Lua扩展其功能。\n一开始,Lua 就被设计成很容易和传统的C&#x2F;C++整合的语言。这种语言的二元性带来了极大的好处。Lua 是一个小巧而简单的语言,因为Lua 不致力于做C语言已经做得这些任务。Lua 所提供的机制是C不善于的：高级语言、动态结构、简洁、易于测试和调试等。正因为如此,Lua 具有良好的安全保证,自动内存管理,简便的字符串处理功能及其他动态数据的改变。\nLua 不仅是一种易于扩展的语言,也是一种易整合语言(glue language)；Lua 支持情况下,组件使用像C&#x2F;C++等静态的语言编写。但Lua 是我们整合各个组件的粘合剂。又通常情况下,组件(或对象)表现为具体在程序开发过程中很少变化的、占用大量CPU时间的决定性的程序,例如窗口部件和数据结构。对那种在产品的生命周期内变化比较多的应用方向使用Lua可以更方便的适应变化。除了作为整合语言外,Lua自身也是一个功能强大的语言。Lua 不仅可以整合组件,还可以编辑组件甚至完全使用Lua 创建组件。\n除了Lua 外,还有很多类似的脚本语言,例如：Perl、Tcl、Ruby、Forth、Python。虽然其他语言在某些方面与Lua 有着共同的特色,但下面这些特征是Lua 特有的:\n① 可扩展性。Lua 的扩展性非常卓越,以至于很多人把 Lua 用作搭建领域语言的工具(注：比如游戏脚本)。Lua 被设计为易于扩展的,可以通过Lua 代码或者C代码扩展,Lua 的很多功能都是通过外部库来扩展的。Lua 很容易与 C&#x2F;C++、java、fortran、Smalltalk、Ada,以及其他语言接口。\n②简单。Lua 本身简单,小巧；内容少但功能强大,这使得Lua 易于学习,很容易实现一些小的应用。他的完全发布版(代码、手册以及某些平台的二进制文件)！！仅用一张软盘就可以装得下。\n③高效率。Lua 有很高的执行效率,统计表明 Lua 是目前平均效率最高的脚本语言。\n④与平台无关。Lua 几乎可以运行在所有我们听说过的系统上,如 NextStep、OS&#x2F;2、PlayStation II (Sony)、Mac OS-9、OS X、BeOS、MS-DOS、IBMmainframes、EPOC、PalmOS、MCF5206eLITE Evaluation Board、RISCOS,及所有的 Windows 和 Unix。Lua 不是通过使用条件编译实现平台无关,而是完全使用 ANSI(ISO)C,这意味着只要你有ANSIC 编译器你就可以编译并使用Lua。\nLua 大部分强大的功能来自于他的类库,这并非偶然。Lua 的长处之一就是可以通过新类型和函数来扩展其功能。动态类型检查最大限度允许多态出现,并自动简化调用内存管理的接口,因为这样不需要关心谁来分配内存谁来释放内存,也不必担心数据溢出。高级函数和匿名函数均可以接受高级参数,使函数更为通用。\nLua自带一个小规模的类库。在受限系统中使用Lua,如嵌入式系统,我们可以有留需要的函数。记住：Lua是很小的(即使加上全部的标准库)并且在大部分系统下你仍可以不用担心的使用全部的功能。\n0.2 Lua的使用者Lua 使用者分为三大类：使用 Lua 嵌入到其他应用中的、独立使用Lua 的、将 Lua和C混合使用的。\n第一：很多人使用Lua 嵌入在应用程序,比如CGILua(搭建动态网页)、LuaOrb(访问CORBA对象。这些类型用Lua-API注册新函数,创建新类型,通过配置Lua 就可以改变应用宿主语言的行为。通常,这种应用的使用者并不知道Lua是一种独立的语言。例如：CGILua用户一般会认为Lua是一种用于Web 的语言。\n第二：作为一种独立运行的语言,Lua 也是很有用的,主要用于文本处理或者只运行一次的小程序。这种应用Lua主要使用它的标准库来实现,标准库提供模式匹配和其它一些字串处理的功能。我们可以这样认为：Lua是文本处理领域的嵌入式语言。\n第三：还有一些使用者使用其他语言开发,把Lua 当作库使用。这些人大多使用C语言开发,但使用Lua建立简单灵活易于使用的接口。\n本书面向以上三类读者。书的第一部分阐述了语言的本身,展示语言的潜在功能。我们讲述了不同的语言结构,并用一些例子展示如何解决实际问题。这部分既包括基本的语言的控制结构,也包括高级的迭代子和协同。\n第二部分重点放在 Lua 特有的数据结构一—tables 上,讨论了数据结构、持久性、包及面向对象编程,这里我们将看到Lua的真正强大之处。\n第三部分介绍标准库。每个标准库一章：数学库、table 库、string 库、ⅡO 库、OS库、Debug 库。\n最后一部分介绍了 Lua 和 C 接口的 API,这部分介绍在C语言中开发应用而不是Lua 中,应用对于那些打算将Lua 嵌入到C&#x2F;C++中的读者可能会对此部分更感兴趣。\n0.3 Lua的相关资源如果你真得想学一门语言,参考手册是必备的。本书和Lua参考手册互为补充,手册仅仅描述语言本身,因此他既不会告诉你语言的数据结构也不会举例说明,但手册是Lua 的权威性文档,http://www.lua.org 可以得到手册的内容。\n\nLua 用户社区,提供了一些第三方包和文档：http://lua-users.org\n本书的更新勘误表,代码和例子：http://www.inf.puc-rio.br/~roberto/book/\n\n另外本书仅针对Lua 5.0,如果你的版本不同,请查阅Lua 手册或者比较版本间的差异。\n0.4本书的体例&lt;1&gt;字符串使用双引号,比如”literal strings”；单字符使用单引号,比如’a’；模式串也是用单引号,比如’[%w_]*’。\n&lt;2&gt; 符号–&gt;表示语句的输出或者表达式的结果：\n\n&lt;3&gt;符号&lt;–&gt;表示等价,即对于 Lua 来说,用 this 与 that 没有区别。\n\n0.5关于本书开始打算写这本书是1998 年冬天(南半球),那时候Lua 版本是3.1；2000 年v4.0;2003 年 v5.0。\n很明显的是,这些变化给本书带来很大的冲击,有些内容失去了它存在理由,比如关于超值(upvalues)的复杂的解释。一些章节被重写,比如CAPI,另外一些章节被增加进来,比如协同处理。\n不太明显的是,Lua 语言本身的发展对本书的完成也产生了很大的影响。一些语言的变化在本书中并没有被涵盖进来,这并非偶然的。在本书的创作过程中,有的时候在当你想尽力去解释清楚如何使用的前提是你应该觉得使用这个东西很容易,这表明Lua某些地方需要被改进。还有的时候,我顺利的写完某个章节,结果却是没有人能看得懂我写的或者没有人对我在这个章节内表达的观点达成一致。大部分情况下,这是我的过错因为我是个作家,偶尔我也会因此发现语言本身的一些需要改进的缺陷(举例来说,从upvalues 到lexical scoping 的转变是由无意义的尝试所带来的抱怨所引发的,在此书的先前的草稿里,把 upvalues 形容成是lexical scoping 的一种)。\n本书的完成必须服从语言的变化,本书在这个时候完成的原因：\n&lt;1&gt;Lua5.0是一个成熟的版本\n&lt;2&gt;语言变得越来越大,超出了最初本书的目标。此外一个原因是我迫切的想将Lua 介绍给大家让更多的人了解Lua\n0.6感谢在完成本书的过程中,很多人给了我极大的帮助：\nLuiz Henrique de Figueiredo 和 Waldemar Celes 给了我很大的帮助,使得本书能够更好完成,LuizHenrique 也帮助设计了本书的内部。\nNoemi Rodriguez,André Carregal, Diego Nehab,以及 Gavin Wraith 阅读了本书的草稿提出了很多有价值的建议。\nRenato Cerqueira, Carlos Cassino, Tomas Guisasola, Joe Myers 和 Ed Ferguson 也提出了很多重要的建议。\nAlexandre Nakonechnyj负责本书的封面和内部设计。\nRosane Teles 负责CIP数据的准备。\n谢谢他们所有人。\n第1章起点写一个最最简单的程序—Hello World。\nprint(&quot;Hello World&quot;)\n\n假定你把上面这句保存在 hello.lua 文件中,你在命令行只需要:\nprompt&gt; lua hello.lua \n让我们来看一个稍微复杂点的例子:\n\n这个例子定义了一个函数,计算输入参数n 的阶乘；本例要求用户输入一个数字 n,然后打印 n 的阶乘。\n1.1 ChunksChunk 是一系列语句,Lua 执行的每一块语句,比如一个文件或者交互模式下的每-行都是一个Chunk。\n每个语句结尾的分号(;)是可选的,但如果同一行有多个语句最好用；分开\na = 1   b = a*2    -- ugly, but valid \n\n一个Chunk 可以是一个语句,也可以是一系列语句的组合,还可以是函数,Chunk可以很大,在Lua 中几个 MByte 的 Chunk是很常见的。\n你还可以以交互模式运行Lua,不带参数运行Lua:\nLua 5.0  Copyright © 1994-2003 Tecgraf, PUC-Rio &gt;\n\n你键入的每个命令（比如：”Hello World”）在你键入回车之后立即被执行，键入文件结束符可以退出交互模式（Ctrl-D in Unix, Ctrl-Z in DOS&#x2F;Windows），或者调用OS库的os.exit()函数也可以退出。 \n在交互模式下,Lua 通常把每一个行当作一个Chunk,但如果Lua一行不是一个完整的Chunk 时,他会等待继续输入直到得到一个完整的Chunk.在Lua 等待续行时,显示不同的提示符(一般是&gt;&gt;).\n可以通过指定参数让Lua 执行一系列Chunk。例如：假定一个文件 a 内有单个语句x&#x3D;1；另一个文件b 有语句 print(x)\nprompt&gt; lua -la -lb\n\n命令首先在一个 Chunk 内先运行 a 然后运行 b。(注意：-1选项会调用 require,将会在指定的目录下搜索文件,如果环境变量没有设好,上面的命令可能不能正确运行。我们将在 8.1节详细更详细的讨论 the require function)\n-i选项要求Lua运行指定Chunk后进入交互模式\nprompt&gt; lua -i -la -lb\n\n将在一个 Chunk 内先运行 a 然后运行b,最后直接进入交互模式。\n另一个连接外部 Chunk 的方式是使用 dofile 函数,dofile 函数加载文件并执行它.假设有一个文件:\n-- file &#x27;lib1.lua&#x27; function norm (x, y)     local n2 = x^2 + y^2     return math.sqrt(n2) endfunction twice (x)     return 2*x end \n\n在交互模式下:\n&gt; dofile(&quot;lib1.lua&quot;)  -- load your library &gt; n = norm(3.4, 1.0) &gt; print(twice(n))   --&gt; 7.0880180586677 \n\n-i 和 dofile 在调试或者测试 Lua 代码时是很方便的。\n1.2全局变量全局变量不需要声明,给一个变量赋值后即创建了这个全局变量,访问一个没有初始化的全局变量也不会出错,只不过得到的结果是：nil.\nprint(b)  --&gt; nil b = 10  print(b)  --&gt; 10 \n如果你想删除一个全局变量,只需要将变量负值为 nil\nb = nil print(b)  --&gt; nil \n\n这样变量 b 就好像从没被使用过一样.换句话说,当且仅当一个变量不等于 nil 时,这个变量存在。\n1.3词法约定标示符：字母(letter)或者下划线开头的字母、下划线、数字序列.最好不要使用下划线加大写字母的标示符,因为Lua 的保留字也是这样的。Lua 中,letter 的含义是依赖于本地环境的。\n保留字：以下字符为Lua 的保留字,不能当作标识符。\n\n注意：Lua是大小写敏感的.\n注释：单行注释:–\n多行注释：–[[ –]]\n\n1.4命令行方式lua [options] [script [args]]\n-e：直接将命令传入Lua\nprompt&gt; lua -e &quot;print(math.sin(12))&quot; --&gt; -0.53657291800043\n\n-l：加载一个文件.\n-i：进入交互模式.\n_PROMPT内置变量作为交互模式的提示符\nprompt&gt; lua -i -e &quot;_PROMPT=&#x27; lua&gt; &#x27;&quot; lua&gt; \n\nLua 的运行过程,在运行参数之前,Lua 会查找环境变量 LUA_INIT 的值,如果变量存在并且值为@filename,Lua 将加载指定文件。如果变量存在但不是以@开头,Lua假定 filename 为 Lua 代码文件并且运行他。利用这个特性,我们可以通过配置,灵活的设置交互模式的环境。可以加载包,修改提示符和路径,定义自己的函数,修改或者重名名函数等。\n全局变量 arg 存放 Lua 的命令行参数。\nprompt&gt; lua script a b c \n\n在运行以前,Lua 使用所有参数构造 arg 表。脚本名索引为O,脚本的参数从1开始增加。脚本前面的参数从-1开始减少。\nprompt&gt; lua -e &quot;sin=math.sin&quot; script a b \n\narg 表如下:\narg[-3] = &quot;lua&quot; arg[-2] = &quot;-e&quot; arg[-1] = &quot;sin=math.sin&quot; arg[0] = &quot;script&quot; arg[1] = &quot;a&quot; arg[2] = &quot;b&quot; \n\n第2章 类型和值Lua 是动态类型语言,变量不要类型定义。Lua 中有8个基本类型分别为:nil、boolean、number、string、userdata、function、thread 和 table。函数 type 可以测试给定变量或者值的类型。\n\n变量没有预定义的类型,每一个变量都可能包含任一种类型的值。\n\n注意上面最后两行,我们可以使用 function 像使用其他值一样使用(更多的介绍参考第六章)。一般情况下同一变量代表不同类型的值会造成混乱,最好不要用,但是特殊情况下可以带来便利,比如nil。\n2.1 NilLua 中特殊的类型,他只有一个值：nil; ；一个全局变量没有被赋值以前默认值为 nil;给全局变量负 nil 可以删除该变量。\n2.2 Booleans两个取值 false 和 true。但要注意Lua 中所有的值都可以作为条件。在控制结构的条件中除了false 和 nil为假,其他值都为真。所以Lua认为O和空串都是真。\n2.3 Numbers表示实数,Lua 中没有整数。一般有个错误的看法CPU运算浮点数比整数慢。事实不是如此,用实数代替整数不会有什么误差(除非数字大于100,000,000,000,000)。Lua的 numbers 可以处理任何长整数不用担心误差。你也可以在编译Lua 的时候使用长整型或者单精度浮点型代替 numbers,在一些平台硬件不支持浮点数的情况下这个特性是非常有用的,具体的情况请参考Lua发布版所附的详细说明。和其他语言类似,数字常量的小数部分和指数部分都是可选的,数字常量的例子:\n\n2.4 Strings指字符的序列。lua是8位字节,所以字符串可以包含任何数值字符,包括嵌入的0。这意味着你可以存储任意的二进制数据在一个字符串里。Lua 中字符串是不可以修改的,你可以创建一个新的变量存放你要的字符串,如下:\n\nstring 和其他对象一样,Lua 自动进行内存分配和释放,一个 string 可以只包含一个字母也可以包含一本书,Lua 可以高效的处理长字符串,1M 的 string 在Lua 中是很常见的。可以使用单引号或者双引号表示字符串\na = &quot;a line&quot;b = &#x27;another line&#x27;\n\n为了风格统一,最好使用一种,除非两种引号嵌套情况。对于字符串中含有引号的情况还可以使用转义符来表示。Lua 中的转义序列有:\n\n例子：\n&gt; print(&quot;one line\\nnext line\\n\\&quot;in quotes\\&quot;, &#x27;in quotes&#x27;&quot;) one line next line &quot;in quotes&quot;, &#x27;in quotes&#x27; &gt; print(&#x27;a backslash inside quotes: \\&#x27;\\\\\\&#x27;&#x27;) a backslash inside quotes: &#x27;\\&#x27; &gt; print(&quot;a simpler way: &#x27;\\\\&#x27;&quot;) a simpler way: &#x27;\\&#x27;\n\n还可以在字符串中使用\\ddd(ddd 为三位十进制数字)方式表示字母。\n“alo\\n123&quot;“和\\97lo\\10\\04923”是相同的。\n还可以使用[[…]]表示字符串。这种形式的字符串可以包含多行也,可以嵌套且不会解释转义序列,如果第一个字符是换行符会被自动忽略掉。这种形式的字符串用来包含一段代码是非常方便的。\n\n运行时,Lua 会自动在 string 和 numbers 之间自动进行类型转换,当一个字符串使用算术操作符时,string 就会被转成数字。\nprint(&quot;10&quot; + 1)    --&gt; 11 print(&quot;10 + 1&quot;)    --&gt; 10 + 1 print(&quot;-5.3e - 10&quot; * &quot;2&quot;) --&gt; -1.06e-09 print(&quot;hello&quot; + 1)   -- ERROR (cannot convert &quot;hello&quot;) \n\n反过来,当Lua 期望一个 string 而碰到数字时,会将数字转成 string。\n\n..在Lua 中是字符串连接符,当在一个数字后面写..时,必须加上空格以防止被解释错。\n尽管字符串和数字可以自动转换,但两者是不同的,像10&#x3D;&#x3D;”10”这样的比较永远都是错的。如果需要显式将 string 转成数字可以使用函数tonumberO,如果 string 不是正确的数字该函数将返回 nil。\n\n反之,可以调用 tostring()将数字转成字符串,这种转换一直有效:\nprint(tostring(10) == &quot;10&quot;)  --&gt; true print(10 .. &quot;&quot; == &quot;10&quot;)   --&gt; true \n\n2.5 Functions函数是第一类值(和其他变量相同),意味着函数可以存储在变量中,可以作为函数的参数,也可以作为函数的返回值。这个特性给了语言很大的灵活性：一个程序可以重新定义函数增加新的功能或者为了避免运行不可靠代码创建安全运行环境而隐藏函数,此外这特性在Lua 实现面向对象中也起了重要作用(在第16章详细讲述)。\nLua 可以调用 lua 或者C 实现的函数,Lua 所有标准库都是用C 实现的。标准库包括 string 库、table 库、IO库、OS 库、算术库、debug 库。\n2.6 Userdata and Threadsuserdata 可以将C数据存放在Lua 变量中,userdata 在Lua 中除了赋值和相等比较外没有预定义的操作。userdata 用来描述应用程序或者使用C 实现的库创建的新类型。例如：用标准IO 库来描述文件。下面在CAPI章节中我们将详细讨论。\n在第九章讨论协同操作的时候,我们介绍线程。\n第3章表达式Lua 中的表达式包括数字常量、字符串常量、变量、一元和二元运算符、函数调用。还可以是非传统的函数定义和表构造。\n3.1算术运算符二元运算符：+－＊／～(加减乘除幂)\n元运算符：- (负值)\n这些运算符的操作数都是实数。\n3.2关系运算符&lt;   &gt;   &lt;=  &gt;=  ==  ~=\n这些操作符返回结果为 false 或者 true；&#x3D;&#x3D;和~&#x3D;比较两个值,如果两个值类型不同,Lua 认为两者不同；nil 只和自己相等。Lua 通过弓用比较 tables、userdata、functions。也就是说当且仅当两者表示同一个对象时相等。\na = &#123;&#125;; a.x = 1; a.y = 0 b = &#123;&#125;; b.x = 1; b.y = 0 c = a a==c but a~=b \n\nLua 比较数字按传统的数字大小进行,比较字符串按字母的顺序进行,但是字母顺序依赖于本地环境。\n当比较不同类型的值的时候要特别注意:\n\n为了避免不一致的结果,混合比较数字和字符串,Lua 会报错,比如：2&lt;”15”\n3.3逻辑运算符and or not \n逻辑运算符认为 false 和 nil是假(false),其他为真,O也是 true.\nand 和 or 的运算结果不是 true 和 false,而是和它的两个操作数相关。\na and b  -- 如果a为false，则返回a，否则返回b a or  b   -- 如果a为true，则返回a，否则返回b \n例如：\nprint(4 and 5)   --&gt; 5 print(nil and 13)   --&gt; nil print(false and 13)  --&gt; false print(4 or 5)    --&gt; 4 print(false or 5)   --&gt; 5\n\n个很实用的技巧：如果x为 false 或者 nil 则给x赋初始值 v\nx = x or v\n等价于\nif not x then     x = v end\nand 的优先级比 or 高。\nC语言中的三元运算符\nａ?ｂ:ｃ\n\n在Lua 中可以这样实现:\n(a and b) or c\n\nnot 的结果一直返回 false 或者 true\nprint(not nil)   --&gt; true print(not false)   --&gt; true print(not 0)    --&gt; false print(not not nil)  --&gt; false \n\n3.4连接运算符.. --两个点\n\n字符串连接,如果操作数为数字,Lua将数字转成字符串。\n\n3.5优先级从高到低的顺序:\n除了~和..外所有的二元运算符都是左连接的。\n\n3.6表的构造构造器是创建和初始化表的表达式。表是Lua特有的功能强大的东西。最简单的构造函数是,用来创建一个空表。可以直接初始化数组:\n\n不管用何种方式创建table,我们都可以向表中添加或者删除任何类型的域,构造函数仅仅影响表的初始化。\n\n每次调用构造函数,Lua 都会创建一个新的 table,可以使用 table 构造一个 list:\nlist = nil for line in io.lines() do  list = &#123;next=list, value=line&#125; end \n\n这段代码从标准输入读进每行,然后反序形成链表。下面的代码打印链表的内容:\nl = list while l do  print(l.value)  l = l.next end \n\n在同一个构造函数中可以混合列表风格和record 风格进行初始化,如:\npolyline = &#123;color=&quot;blue&quot;, thickness=2, npoints=4,     &#123;x=0,   y=0&#125;,     &#123;x=-10, y=0&#125;,     &#123;x=-10, y=1&#125;,     &#123;x=0,   y=1&#125; &#125; \n\n这个例子也表明我们可以嵌套构造函数来表示复杂的数据结构\nprint(polyline[2].x) --&gt; -10\n\n上面两种构造函数的初始化方式还有限制,比如你不能使用负索引初始化一个表中元素,字符串索引也不能被恰当的表示。下面介绍一种更一般的初始化方式,我们用[expression]显示的表示将被初始化的索引:\nopnames = &#123;[&quot;+&quot;] = &quot;add&quot;, [&quot;-&quot;] = &quot;sub&quot;,     [&quot;*&quot;] = &quot;mul&quot;, [&quot;/&quot;] = &quot;div&quot;&#125; i = 20; s = &quot;-&quot; a = &#123;[i+0] = s, [i+1] = s..s, [i+2] = s..s..s&#125; print(opnames[s])  --&gt; subprint(a[22])   --&gt; ---\n\nlist 风格初始化和 record 风格初始化是这种一般初始化的特例:\n&#123;x=0, y=0&#125;   &lt;--&gt;  &#123;[&quot;x&quot;]=0, [&quot;y&quot;]=0&#125; &#123;&quot;red&quot;, &quot;green&quot;, &quot;blue&quot;&#125;   &lt;--&gt;      &#123;[1]=&quot;red&quot;, [2]=&quot;green&quot;, [3]=&quot;blue&quot;&#125; \n\n如果真的想要数组下标从0开始:\ndays = &#123;[0]=&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;,     &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;&#125; \n\n注意：不推荐数组下标从0开始,否则很多标准库不能使用。\n在构造函数的最后的”,”是可选的,可以方便以后的扩展。\na = &#123;[1]=&quot;red&quot;, [2]=&quot;green&quot;, [3]=&quot;blue&quot;,&#125; \n\n在构造函数中域分隔符逗号(“,”)可以用分号(“;”)替代,通常我们使用分号用来分割不同类型的表元素。\n&#123;x=10, y=45; &quot;one&quot;, &quot;two&quot;, &quot;three&quot;&#125; \n\n第4章基本语法Lua 像C和PASCAL几乎支持所有的传统语句：赋值语句、控制结构语句、函数调用等,同时也支持非传统的多变量赋值、局部变量声明。\n4.1赋值语句赋值是改变一个变量的值和改变表域的最基本的方法。\n\nLua 可以对多个变量同时赋值,变量列表和值列表的各个元素用逗号分开,赋值语句右边的值会依次赋给左边的变量。\na, b = 10, 2*x  &lt;--&gt;  a=10; b=2*x\n\n遇到赋值语句Lua会先计算右边所有的值然后再执行赋值操作,所以我们可以这样进行交换变量的值:\nx, y = y, x      -- swap &#x27;x&#x27; for &#x27;y&#x27; a[i], a[j] = a[j], a[i]   -- swap &#x27;a[i]&#x27; for &#x27;a[i]&#x27; \n\n当变量个数和值的个数不一致时,Lua会一直以变量个数为基础采取以下策略:\na. 变量个数&gt;值的个数    按变量个数补足nil b. 变量个数&lt;值的个数    多余的值会被忽略 \n例如：\na, b, c = 0, 1  print(a,b,c)    --&gt; 0   1   nil a, b = a+1, b+1, b+2  -- value of b+2 is ignored print(a,b)      --&gt; 1   2 a, b, c = 0 print(a,b,c)    --&gt; 0   nil   nil\n\n上面最后一个例子是一个常见的错误情况,注意：如果要对多个变量赋值必须依次对每个变量赋值。\na, b, c = 0, 0, 0 \n\nf()返回两个值，第一个赋给a，第二个赋给b。 \n4.2局部变量与代码块(block)使用local 创建一个局部变量,与全局变量不同,局部变量只在被声明的那个代码块内有效。代码块：指一个控制结构内,一个函数体,或者一个chunk(变量被声明的那个文件或者文本串)。\n\n注意,如果在交互模式下上面的例子可能不能输出期望的结果,因为第二句locali&#x3D;l第二句的i已经超出了他的有效范围。可以将这段代码放在 do.end(相当于c&#x2F;c++的{})块中。\n应该尽可能的使用局部变量,有两个好处：\n\n避免命名冲突\n访问局部变量的速度比全局变量更快\n\n我们给 block 划定一个明确的界限：do..end 内的部分。当你想更好的控制局部变量的作用范围的时候这是很有用的。\n\n4.3控制结构语句控制结构的条件表达式结果可以是任何值,Lua 认为 false 和 nil 为假,其他值为真。\nif语句,有三种形式:\nwhile 语句:\nwhile condition do  statements; end;\nrepeat-until 语句:\n\nfor 语句有两大类:第一,数值 for 循环:\nfor var=exp1,exp2,exp3 do  loop-part end\n\nfor 将用 exp3 作为 step 从 expl(初始值)到 exp2(终止值),执行 loop-part。其中exp3 可以省略,默认 step&#x3D;1\n有几点需要注意:\n\n三个表达式只会被计算一次,并且是在循环开始前。\n\nfor i=1,f(x) do  print(i) end  for i=10,1,-1 do  print(i) end\n\n第一个例子f(x)只会在循环前被调用一次。\n\n控制变量var 是局部变量自动被声明,并且只在循环内有效.\n\nfor i=1,10 do  print(i) end max = i  -- probably wrong! &#x27;i&#x27; here is global \n\n如果需要保留控制变量的值,需要在循环中将其保存\n-- find a value in a list local found = nil for i=1,a.n do  if a[i] == value then   found = i   -- save value of &#x27;i&#x27;   break  end end print(found) \n\n\n循环过程中不要改变控制变量的值,那样做的结果是不可预知的。如果要退出循环,使用 break 语句。\n\n第二, 范型 for 循环:\n前面已经见过一个例子:\n-- print all values of array &#x27;a&#x27;  for i,v in ipairs(a) do print(v) end \n\n范型for遍历迭代子函数返回的每一个值。再看一个遍历表key 的例子:\n-- print all keys of table &#x27;t&#x27; for k in pairs(t) do print(k) end \n\n范型for 和数值for 有两点相同:\n\n控制变量是局部变量\n不要修改控制变量的值\n\n再看一个例子,假定有一个表：\ndays = &#123;&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;&#125; \n\n现在想把对应的名字转换成星期几,一个有效地解决问题的方式是构造一个反向表：\nrevDays = &#123;[&quot;Sunday&quot;] = 1, [&quot;Monday&quot;] = 2,     [&quot;Tuesday&quot;] = 3, [&quot;Wednesday&quot;] = 4,    [&quot;Thursday&quot;] = 5, [&quot;Friday&quot;] = 6,      [&quot;Saturday&quot;] = 7&#125; \n下面就可以很容易获取问题的答案了:\nx = &quot;Tuesday&quot;  print(revDays[x])   --&gt; 3 \n\n我们不需要手工,可以自动构造反向表\nrevDays = &#123;&#125;  for i,v in ipairs(days) do end  \n\n如果你对范型for还有些不清楚在后面的章节我们会继续来学习。\n4.4 break和 return 语句break语句用来退出当前循环(for,repeat,while)。在循环外部不可以使用。\nreturn 用来从函数返回结果,当一个函数自然结束结尾会有一个默认的 return。(这种函数类似pascal的过程)\nLua 语法要求 break 和 return 只能出现在 block 的结尾一句(也就是说：作为 chunk的最后一句,或者在 end 之前,或者 else 前,或者 until 前),例如:\nlocal i = 1 while a[i] do    if a[i] == v then break end     i = i + 1end\n\n有时候为了调试或者其他目的需要在 block 的中间使用 return 或者 break,可以显式的使用 do..end 来实现:\n\n第5章函数函数有两种用途：1.完成指定的任务,这种情况下函数作为调用语句使用；2.计算并返回值,这种情况下函数作为赋值语句的表达式使用。\n语法:\nfunction func_name (arguments-list)  statements-list; end; \n\n调用函数的时候,如果参数列表为空,必须使用()表明是函数调用。\n\n上述规则有一个例外,当函数只有一个参数并且这个参数是字符串或者表构造的时候,()是可选的：\n\nLua 也提供了面向对象方式调用函数的语法,比如 o:foo(x)与 o.foo(o,x)是等价的,后面的章节会详细介绍面向对象内容。\nLua 使用的函数可以是Lua 编写也可以是其他语言编写,对于Lua程序员来说用什么语言实现的函数使用起来都一样。\nLua 函数实参和形参的匹配与赋值语句类似,多余部分被忽略,缺少部分用 nil补足。\n\n5.1返回多个结果值Lua 函数可以返回多个结果值,比如 string.find,其返回匹配串“开始和结束的下标”(如果不存在匹配串返回 nil)。\ns, e = string.find(&quot;hello Lua users&quot;, &quot;Lua&quot;) print(s, e)  --&gt; 7 9\n\nLua 函数中,在return 后列出要返回的值得列表即可返回多值,如:\n\nLua总是调整函数返回值的个数去适用调用环境,当作为一个语句调用函数时,所有返回值被忽略。假设有如下三个函数:\n\n第一,当作为表达式调用函数时,有以下几种情况:\n\n当调用作为表达式最后一个参数或者仅有一个参数时,根据变量个数函数尽可能多地返回多个值,不足补 nil,超出舍去。\n\n其他情况下,函数调用仅返回第一个值 (如果没有返回值为 nil)\nx,y = foo2()    -- x=&#x27;a&#x27;, y=&#x27;b&#x27; x = foo2()     -- x=&#x27;a&#x27;, &#x27;b&#x27; is discarded x,y,z = 10,foo2()   -- x=10, y=&#x27;a&#x27;, z=&#x27;b&#x27;  x,y = foo0()    -- x=nil, y=nil x,y = foo1()    -- x=&#x27;a&#x27;, y=nil x,y,z = foo2()   -- x=&#x27;a&#x27;, y=&#x27;b&#x27;, z=nil x,y = foo2(), 20   -- x=&#x27;a&#x27;, y=20 x,y = foo0(), 20, 30  -- x=&#x27;nil&#x27;, y=20, 30 is discarded \n\n第二,函数调用作为函数参数被调用时,和多值赋值是相同。\n\n第三,函数调用在表构造函数中初始化时,和多值赋值时相同。\na = &#123;foo0()&#125;    -- a = &#123;&#125;    (an empty table) a = &#123;foo1()&#125;    -- a = &#123;&#x27;a&#x27;&#125; a = &#123;foo2()&#125;    -- a = &#123;&#x27;a&#x27;, &#x27;b&#x27;&#125;  a = &#123;foo0(), foo2(), 4&#125; -- a[1] = nil, a[2] = &#x27;a&#x27;, a[3] = 4 \n\n另外,return f()这种类型的返回 f()返回的所有值\nfunction foo (i)  if i == 0 then return foo0()  elseif i == 1 then return foo1()  elseif i == 2 then return foo2()  end end  print(foo(1))   --&gt; a print(foo(2))   --&gt; a  b print(foo(0))   -- (no results) print(foo(3))   -- (no results)\n\n可以使用圆括号强制使调用返回一个值。\nprint((foo0()))  --&gt; nil print((foo1()))  --&gt; a print((foo2()))  --&gt; a\n\n一个return 语句如果使用圆括号将返回值括起来也将导致返回一个值。\n函数多值返回的特殊函数unpack,接受一个数组作为输入参数,返回数组的所有元素。unpack被用来实现范型调用机制,在C语言中可以使用函数指针调用可变的函数,可以声明参数可变的函数,但不能两者同时可变。在Lua 中如果你想调用可变参数的可变函数只需要这样:\nf(unpack(a)) \nunpack返回a所有的元素作为f()的参数 \n\n预定义的 unpack 函数是用C语言实现的,我们也可以用 Lua来完成:\n\n5.2可变参数Lua 函数可以接受可变数目的参数,和C语言类似在函数参数列表中使用三点(..)表示函数有可变的参数。Lua 将函数的参数放在一个叫 arg 的表中,除了参数以外,arg表中还有一个域n表示参数的个数。\n例如,我们可以重写 print 函数:\n\n有时候我们可能需要几个固定参数加上可变参数 \nfunction g (a, b, ...) end  CALL    PARAMETERS  g(3)    a=3, b=nil, arg=&#123;n=0&#125; g(3, 4)   a=3, b=4, arg=&#123;n=0&#125; g(3, 4, 5, 8)  a=3, b=4, arg=&#123;5, 8; n=2&#125;\n\n如上面所示,Lua 会将前面的实参传给函数的固定参数,后面的实参放在 arg 表中。举个具体的例子,如果我们只想要 string.find 返回的第二个值:\n个典型的方法是使用虚变量 (下划线)\nlocal _, x = string.find(s, p) -- now use  &#x27;x&#x27;...\n\n还可以利用可变参数声明一个 select 函数:\n\n有时候需要将函数的可变参数传递给另外的函数调用,可以使用前面我们说过的unpack(arg)返回 arg 表所有的可变参数,Lua 提供了一个文本格式化的函数 string.format(类似 C语言的 sprintf 函数):\nfunction fwrite(fmt, ...)     return io.write(string.format(fmt, unpack(arg))) end\n\n这个例子将文本格式化操作和写操作组合为一个函数。\n5.3命名参数Lua 的函数参数是和位置相关的,调用时实参会按顺序依次传给形参。有时候用名字指定参数是很有用的,比如rename 函数用来给一个文件重命名,有时候我们我们记不清命名前后两个参数的顺序了:\n-- invalid code rename(old=&quot;temp.lua&quot;, new=&quot;temp1.lua&quot;) \n\n上面这段代码是无效的,Lua 可以通过将所有的参数放在一个表中,把表作为函数的唯一参数来实现上面这段伪代码的功能。因为Lua语法支持函数调用时实参可以是表的构造。\nrename&#123;old=&quot;temp.lua&quot;, new=&quot;templ.lua&quot;&#125;\n\n根据这个想法我们重定义了rename:\nfunction rename (arg)  return os.rename(arg.old, arg.new) end\n\n当函数的参数很多的时候,这种函数参数的传递方式很方便的。例如GUI库中创建窗体的函数有很多参数并且大部分参数是可选的,可以用下面这种方式:\nw = Window &#123;  x=0, y=0, width=300, height=200,  title = &quot;Lua&quot;, background=&quot;blue&quot;,  border = true &#125;  function Window (options)  -- check mandatory options  if type(options.title) ~= &quot;string&quot; then   error(&quot;no title&quot;)  elseif type(options.width) ~= &quot;number&quot; then   error(&quot;no width&quot;)  elseif type(options.height) ~= &quot;number&quot; then   error(&quot;no height&quot;)  end   -- everything else is optional  _Window(options.title,   options.x or 0,   -- default value   options.y or 0,   -- default value   options.width, options.height,   options.background or &quot;white&quot;, -- default   options.border   -- default is false (nil)  )\n\n第6章 再论函数Lua 中的函数是带有词法定界（lexical scoping）的第一类值（first-class values）\n第一类值指：在Lua 中函数和其他值(数值、字符串)一样,函数可以被存放在变量中,也可以存放在表中,可以作为函数的参数,还可以作为函数的返回值。\n词法定界指：被嵌套的函数可以访问他外部函数中的变量。这一特性给Lua提供了强大的编程能力。\nLua中关于函数稍微难以理解的是函数也可以没有名字,匿名的。当我们提到函数名(比如 print),实际上是说一个指向函数的变量,像持有其他类型值的变量一样:\n\n既然函数是值,那么表达式也可以创建函数了,Lua中我们经常这样写:\nfunction foo (x) return 2*x end\n\n这实际上是利用Lua 提供的“语法上的甜头”(syntacticsugar)的结果,下面是原本的函数:\nfoo = function (x) return 2*x end\n\n函数定义实际上是一个赋值语句,将类型为 function 的变量赋给一个变量。我们使用&#96;&#96;&#96;lua\nfunction(x)..end\n来定义一个函数和使用{}创建一个表一样。\ntable 标准库提供一个排序函数,接受一个表作为输入参数并且排序表中的元素。这个函数必须能够对不同类型的值(字符串或者数值)按升序或者降序进行排序。Lua不是尽可能多地提供参数来满足这些情况的需要,而是接受一个排序函数作为参数(类似C++的函数对象),排序函数接受两个排序元素作为输入参数,并且返回两者的大小关系,例如:\nnetwork = &#123;  &#123;name = &quot;grauna&quot;, IP = &quot;210.26.30.34&quot;&#125;,  &#123;name = &quot;arraial&quot;, IP = &quot;210.26.30.23&quot;&#125;,  &#123;name = &quot;lua&quot;,  IP = &quot;210.26.23.12&quot;&#125;,  &#123;name = &quot;derain&quot;, IP = &quot;210.26.23.20&quot;&#125;,&#125;\n\n如果我们想通过表的 name 域排序:\ntable.sort(network, function (a,b)  return (a.name &gt; b.name) end) \n\n以其他函数作为参数的函数在Lua 中被称作高级函数,高级函数在Lua 中并没有特权,只是Lua把函数当作第一类函数处理的一个简单的结果。\n下面给出一个绘图函数的例子:\nfunction eraseTerminal()  io.write(&quot;\\27[2J&quot;) end   -- writes an `*&#x27; at column `x&#x27; , row `y&#x27; function mark (x,y)  io.write(string.format(&quot;\\27[%d;%dH*&quot;, y, x)) end  -- Terminal size TermSize = &#123;w = 80, h = 24&#125;  -- plot a function -- (assume that domain and image are in the range [-1,1]) function plot (f)  eraseTerminal()  for i=1,TermSize.w do   local x = (i/TermSize.w)*2 - 1   local y = (f(x) + 1)/2 * TermSize.h   mark(i, y)  end  io.read()  -- wait before spoiling the screen end\n\n要想让这个例子正确的运行,你必须调整你的终端类型和代码中的控制符一致:\nplot(function (x) return math.sin(x*2*math.pi) end)\n\n将在屏幕上输出一个正弦曲线。\n将第一类值函数应用在表中是Lua 实现面向对象和包机制的关键,这部分内容在后面章节介绍。\n6.1闭包当一个函数内部嵌套另一个函数定义时,内部的函数体可以访问外部的函数的局部变量,这种特征我们称作词法定界。虽然这看起来很清楚,事实并非如此,词法定界加上第一类函数在编程语言里是一个功能强大的概念,很少语言提供这种支持。\n下面看一个简单的例子,假定有一个学生姓名的列表和一个学生名和成绩对应的表;现在想根据学生的成绩从高到低对学生进行排序,可以这样做:\nnames = &#123;&quot;Peter&quot;, &quot;Paul&quot;, &quot;Mary&quot;&#125; grades = &#123;Mary = 10, Paul = 7, Peter = 8&#125; table.sort(names, function (n1, n2)  return grades[n1] &gt; grades[n2]    -- compare the grades end) \n\n假定创建一个函数实现此功能:\nfunction sortbygrade (names, grades)  table.sort(names, function (n1, n2)   return grades[n1] &gt; grades[n2]    -- compare the grades  end) end \n\n例子中包含在 sortbygrade 函数内部的 sort 中的匿名函数可以访问 sortbygrade 的参数grades,在匿名函数内部 grades 不是全局变量也不是局部变量,我们称作外部的局部变量(externallocalvariable)或者upvalue。(upvalue 意思有些误导,然而在Lua 中他的存在有历史的根源,还有他比起 external local variable 简短)。\n看下面的代码:\n\n匿名函数使用upvalue i保存他的计数，当我们调用匿名函数的时候i已经超出了作用范围,因为创建i的函数newCounter已经返回了。然而Lua 用闭包的思想正确处理了这种情况。简单的说闭包是一个函数加上它可以正确访问的upvalues。如果我们再次调用 newCounter,将创建一个新的局部变量i,因此我们得到了一个作用在新的变量i上的新闭包。\n\ncl、c2 是建立在同一个函数上,但作用在同一个局部变量的不同实例上的两个不同的闭包。\n技术上来讲,闭包指值而不是指函数,函数仅仅是闭包的一个原型声明；尽管如此,在不会导致混淆的情况下我们继续使用术语函数代指闭包。\n闭包在上下文环境中提供很有用的功能,如前面我们见到的可以作为高级函数(sort)的参数；作为函数嵌套的函数(newCounter)。这一机制使得我们可以在Lua 的函数世界里组合出奇幻的编程技术。闭包也可用在回调函数中,比如在GUI环境中你需要创建一系列button,但用户按下button 时回调函数被调用,可能不同的按钮被按下时需要处理的任务有点区别。具体来讲,一个十进制计算器需要10个相似的按钮,每个按钮对应一个数字,可以使用下面的函数创建他们:\n\n这个例子中我们假定 Button 是一个用来创建新按钮的工具,label 是按钮的标签,action 是按钮被按下时调用的回调函数。(实际上是一个闭包,因为他访问 upvalue digit)。digitButton 完成任务返回后,局部变量 digit超出范围,回调函数仍然可以被调用并且可以访问局部变量 digit。\n闭包在完全不同的上下文中也是很有用途的。因为函数被存储在普通的变量内我们可以很方便的重定义或者预定义函数。通常当你需要原始函数有一个新的实现时可以重定义函数。例如你可以重定义 sin 使其接受一个度数而不是弧度作为参数:\noldSin = math.sin math.sin = function (x)     return oldSin(x*math.pi/180) end \n\n更清楚的方式：\n\n这样我们把原始版本放在一个局部变量内,访问 sin 的唯一方式是通过新版本的函数。\n利用同样的特征我们可以创建一个安全的环境(也称作沙箱,和java 里的沙箱一样),当我们运行一段不信任的代码(比如我们运行网络服务器上获取的代码)时安全的环境是需要的,比如我们可以使用闭包重定义io 库的 open 函数来限制程序打开的文件。\n\n6.2非全局函数Lua 中函数可以作为全局变量也可以作为局部变量,我们已经看到一些例子：函数作为 table 的域(大部分 Lua 标准库使用这种机制来实现的比如 io.read、math.sin)。这种情况下,必须注意函数和表语法:\n\n表和函数放在一起\n\n\n\n使用表构造函数\n\nLib = &#123;  foo = function (x,y) return x + y end,  goo = function (x,y) return x - y end&#125;\n\n\nLua 提供另一种语法方式\n\nLib = &#123;&#125; function Lib.foo (x,y)  return x + y end function Lib.goo (x,y)  return x - y end \n\n当我们将函数保存在一个局部变量内时,我们得到一个局部函数,也就是说局部函数像局部变量一样在一定范围内有效。这种定义在包中是非常有用的：因为Lua把chunk当作函数处理,在 chunk 内可以声明局部函数(仅仅在 chunk 内可见),词法定界保证了包内的其他函数可以调用此函数。下面是声明局部函数的两种方式:\n\n方式一\n\nlocal f = function (...)  ... end  local g = function (...)  ...  f()   -- external local `f&#x27; is visible here  ... end \n\n\n方式二\n\nlocal function f (...)  ... end \n有一点需要注意的是在声明递归局部函数的方式:\n\n上面这种方式导致 Lua 编译时遇到 fact(n-1)并不知道他是局部函数 fact,Lua 会去查找是否有这样的全局函数fact。为了解决这个问题我们必须在定义函数以前先声明:\n\n这样在 fact 内部 fact(n-1)调用是一个局部函数调用,运行时 fact 就可以获取正确的值了。\n但是Lua扩展了他的语法使得可以在直接递归函数定义时使用两种方式都可以。\n在定义非直接递归局部函数时要先声明然后定义才可以:\n\n6.3正确的尾调用(ProperTailCalls)Lua 中函数的另一个有趣的特征是可以正确的处理尾调用(proper tail recursion,些书使用术语“尾递归”,虽然并未涉及到递归的概念)。\n尾调用是一种类似在函数结尾的 goto 调用,当函数最后一个动作是调用另外一个函数时,我们称这种调用尾调用。例如:\n\ng 的调用是尾调用。\n例子中 f调用 g 后不会再做任何事情,这种情况下当被调用函数 g 结束时程序不需要返回到调用者 f；所以尾调用之后程序不需要在栈中保留关于调用者的任何信息。一些编译器比如Lua 解释器利用这种特性在处理尾调用时不使用额外的栈,我们称这种语言支持正确的尾调用。\n由于尾调用不需要使用栈空间,那么尾调用递归的层次可以无限制的。例如下面调用不论n为何值不会导致栈溢出。\nfunction foo (n)     if n &gt; 0 then return foo(n - 1) end end\n\n需要注意的是：必须明确什么是尾调用。\n一些调用者函数调用其他函数后也没有做其他的事情但不属于尾调用。比如:\n\n上面这个例子中 f在调用 g 后,不得不丢弃 g 地返回值,所以不是尾调用,同样的下面几个例子也不时尾调用：\n\nLua 中类似 return g(..)这种格式的调用是尾调用。但是 g 和 g 的参数都可以是复杂表达式,因为Lua会在调用之前计算表达式的值。例如下面的调用是尾调用:\nreturn x[i].foo(x[j] + a*b, i + j) \n\n可以将尾调用理解成一种 goto,在状态机的编程领域尾调用是非常有用的。状态机的应用要求函数记住每一个状态,改变状态只需要 goto(or call)一个特定的函数。我们考虑一个迷宫游戏作为例子：迷宫有很多个房间,每个房间有东西南北四个门,每一步输入一个移动的方向,如果该方向存在即到达该方向对应的房间,否则程序打印警告信息。目标是：从开始的房间到达目的房间。\n这个迷宫游戏是典型的状态机,每个当前的房间是一个状态。我们可以对每个房间写一个函数实现这个迷宫游戏,我们使用尾调用从一个房间移动到另外一个房间。一个四个房间的迷宫代码如下：\nfunction room1 () local move = io.read() if move == &quot;south&quot; then return room3() elseif move == &quot;east&quot; then return room2() else   print(&quot;invalid move&quot;)   return room1()   -- stay in the same room  end end  function room2 ()  local move = io.read()  if move == &quot;south&quot; then   return room4()  elseif move == &quot;west&quot; then   return room1()  else   print(&quot;invalid move&quot;)   return room2()  end end  function room3 ()  local move = io.read()  if move == &quot;north&quot; then   return room1()  elseif move == &quot;east&quot; then   return room4()  else   print(&quot;invalid move&quot;)   return room3()  end end  function room4 ()  print(&quot;congratilations!&quot;) end\n\n我们可以调用rooml0开始这个游戏。\n如果没有正确的尾调用,每次移动都要创建一个栈,多次移动后可能导致栈溢出。但正确的尾调用可以无限制的尾调用,因为每次尾调用只是一个 goto 到另外一个函数并不是传统的函数调用。\n第7章迭代器与泛型for在这一章我们讨论为范性 for 写迭代器,我们从一个简单的迭代器开始,然后我们学习如何通过利用范性for的强大之处写出更高效的迭代器。\n7.1迭代器与闭包迭代器是一种支持指针类型的结构,它可以遍历集合的每一个元素。在Lua 中我们常常使用函数来描述迭代器,每次调用该函数就返回集合的下一个元素。\n迭代器需要保留上一次成功调用的状态和下一次成功调用的状态,也就是他知道来自于哪里和将要前往哪里。闭包提供的机制可以很容易实现这个任务。记住：闭包是个内部函数,它可以访问一个或者多个外部函数的外部局部变量。每次闭包的成功调用后这些外部局部变量都保存他们的值(状态)。当然如果要创建一个闭包必须要创建其外部局部变量。所以一个典型的闭包的结构包含两个函数：一个是闭包自己；另一个是工厂(创建闭包的函数)。\n举一个简单的例子,我们为一个 list 写一个简单的迭代器,与 ipairs(不同的是我们实现的这个迭代器返回元素的值而不是索引下标：\nfunction list_iter (t)     local i = 0     local n = table.getn(t)     return function ()         i = i + 1         if i &lt;= n then return t[i] end     endend\n\n这个例子中 list_iter是一个工厂,每次调用他都会创建一个新的闭包(迭代器本身)。闭包保存内部局部变量(t,i,n),因此每次调用他返回 list 中的下一个元素值,当 list 中没有值时,返回 nil.我们可以在 while 语句中使用这个迭代器:\nt = &#123;10, 20, 30&#125; iter = list_iter(t)  -- creates the iterator while true do     local element = iter() -- calls the iterator     if element == nil then break end     print(element) end\n我们设计的这个迭代器也很容易用于范性for语句 \nt = &#123;10, 20, 30&#125; for element in list_iter(t) do  print(element) end \n\n范性 for 为迭代循环处理所有的薄记(bookkeeping)：首先调用迭代工厂；内部保留迭代函数,因此我们不需要 iter 变量；然后在每一个新的迭代处调用迭代器函数；当迭代器返回 nil时循环结束(后面我们将看到范性 for 能胜任更多的任务)。\n下面看一个稍微高级一点的例子：我们写一个迭代器遍历一个文件内的所有匹配的单词。为了实现目的,我们需要保留两个值：当前行和在当前行的偏移量,我们使用两个外部局部变量 line、pos 保存这两个值。\n\n迭代函数的主体部分调用了 string.find 函数,string.find 在当前行从当前位置开始查找匹配的单词,例子中匹配的单词使用模式’%w+’描述的；如果查找到一个单词,迭代函数更新当前位置 pos 为单词后的第一个位置,并且返回这个单词(string.sub 函数从 lineline 可读返回 nil 结束。\n尽管迭代函数有些复杂,但使用起来是很直观的:\nfor word in allwords() do    print(word)end\n\n通常情况下,迭代函数都难写易用。这不是一个大问题：一般Lua 编程不需要自己定义迭代函数,而是使用语言提供的,除非确实需要自己定义。\n7.2范性for的语义前面我们看到的迭代器有一个缺点：每次调用都需要创建一个闭包,大多数情况下这种做法都没什么问题,例如在 allwords 迭代器中创建一个闭包的代价比起读整个文件来说微不足道,然而在有些情况下创建闭包的代价是不能忍受的。在这些情况下我们可以使用范性 for 本身来保存迭代的状态。\n前面我们看到在循环过程中范性 for 在自己内部保存迭代函数,实际上它保存三个值:迭代函数,状态常量和控制变量.下面详细说明。\n范性 for 的文法如下:\n\n是一个或多个以逗号分割的变量名列表,是一个或多个以逗号分割的表达式列表,通常情况下 exp-list 只有一个值：迭代工厂的调用。\n\n变量列表k,v；表达式列表 pair(t),在很多情况下变量列表也只有一个变量,比如:\nfor line in io.lines() do  io.write(line, &#x27;\\n&#x27;) end\n\n我们称变量列表中第一个变量为控制变量,其值为 nil 时循环结束。\n下面我们看看范性 for的执行过程:\n首先,初始化,计算in 后面表达式的值,表达式应该返回范性 for 需要的三个值:迭代函数,状态常量和控制变量；与多值赋值一样,如果表达式返回的结果个数不足三个会自动用 nil补足,多出部分会被忽略。\n第二,将状态常量和控制变量作为参数调用迭代函数(注意：对于 for 结构来说,状态常量没有用处,仅仅在初始化时获取他的值并传递给迭代函数)。\n第三,将迭代函数返回的值赋给变量列表。\n第四,如果返回的第一个值为 nil循环结束,否则执行循环体。\n第五,回到第二步再次调用迭代函数。\n更精确的来说:\n\n如果我们的迭代函数是f,状态常量是 s,控制变量的初始值是 a0,那么控制变量将循环：al&#x3D;f(s,a0)、a2&#x3D;f(s,al)、·..·,直到 ai&#x3D;nil。\n7.3无状态的迭代器无状态的迭代器是指不保留任何状态的迭代器,因此在循环中我们可以利用无状态迭代器避免创建闭包花费额外的代价。\n每一次迭代,迭代函数都是用两个变量(状态常量和控制变量)的值作为参数被调型的简单的例子是ipairs,他遍历数组的每一个元素。\n\n迭代的状态包括被遍历的表(循环过程中不会改变的状态常量)和当前的索引下标(控制变量),ipairs 和迭代函数都很简单,我们在Lua 中可以这样实现:\nfunction iter (a, i)  i = i + 1  local v = a[i]  if v then   return i, v  end end function ipairs (a)     return iter, a, 0end\n\n当 Lua 调用 ipairs(a)开始循环时,他获取三个值:迭代函数 iter,状态常量 a 和控制变)非)返回 2,a[2]···直到第一个非nil 元素。\nLua 库中实现的 pairs 是一个用 next实现的原始方法:\n\n还可以不使用ipairs直接使用next \nfor k, v in next, t do    ...end\n记住：exp-list 返回结果会被调整为三个,所以 Lua 获取 next、t、nil；确切地说当他调用 pairs 时获取。\n7.4多状态的迭代器很多情况下,迭代器需要保存多个状态信息而不是简单的状态常量和控制变量,最简单的方法是使用闭包,还有一种方法就是将所有的状态信息封装到 table 内,将 table作为迭代器的状态常量,因为这种情况下可以将所有的信息存放在 table 内,所以迭代函数通常不需要第二个参数。\n下面我们重写allwords迭代器,这一次我们不是使用闭包而是使用带有两个域(line,pos)的 table 。\n开始迭代的函数是很简单的,他必须返回迭代函数和初始状态:\n\n真正的处理工作是在迭代函数内完成:\n\n我们应该尽可能的写无状态的迭代器,因为这样循环的时候由 for 来保存状态,不需要创建对象花费的代价小；如果不能用无状态的迭代器实现,应尽可能使用闭包；尽可能不要使用 table 这种方式,因为创建闭包的代价要比创建 table 小,另外Lua 处理闭包要比处理table 速度快些。后面我们还将看到另一种使用协同来创建迭代器的方式,这种方式功能更强但更复杂。\n7.5真正的迭代器迭代器的名字有一些误导,因为它并没有迭代,完成迭代功能的是 for 语句,也许更好的叫法应该是’生成器；但是在其他语言比如java、C++迭代器的说法已经很普遍了,我们也将沿用这种术语。\n有一种方式创建一个在内部完成迭代的迭代器。这样当我们使用迭代器的时候就不需要使用循环了；我们仅仅使用每一次迭代需要处理的任务作为参数调用迭代器即可,具体地说,迭代器接受一个函数作为参数,并且这个函数在迭代器内部被调用。\n作为一个具体的例子,我们使用上述方式重写 allwords 迭代器:\nfunction allwords (f)  -- repeat for each line in the file  for l in io.lines() do   -- repeat for each word in the line     for w in string.gfind(l, &quot;%w+&quot;) do         -- call the function         f(w)     end   end end\n\n如果我们想要打印出单词,只需要\n\n更一般的做法是我们使用匿名函数作为作为参数,下面的例子打印出单词hello’出现的次数：\nlocal count = 0 allwords(function (w)     if w == &quot;hello&quot; then count = count + 1 end en )  print(count) \n\n用 for 结构完成同样的任务:\nlocal count = 0 for w in allwords() do     if w == &quot;hello&quot; then count = count + 1 end end print(count)\n\n真正的迭代器风格的写法在Lua 老版本中很流行,那时还没有for 循环。\n两种风格的写法相差不大,但也有区别：一方面,第二种风格更容易书写和理解;另一方面,for 结构更灵活,可以使用 break和 continue 语句；在真正的迭代器风格写法中return语句只是从匿名函数中返回而不是退出循环。\n第8章编译·运行·调试虽然我们把Lua 当作解释型语言,但是Lua 会首先把代码预编译成中间码然后再执行(很多解释型语言都是这么做的)。在解释型语言中存在编译阶段听起来不合适,然而,解释型语言的特征不在于他们是否被编译,而是编译器是语言运行时的一部分,所以,执行编译产生的中间码速度会更快。我们可以说函数 dofile 的存在就是说明可以将Lua作为一种解释型语言被调用。\n前面我们介绍过 dofile,把它当作Lua 运行代码的 chunk 的一种原始的操作。dofile实际上是一个辅助的函数。真正完成功能的函数是 loadfile；与 dofile 不同的是 loadfile不会抛出错误信息而是返回错误代。.我们可以这样定义dofile:\n\n如果loadfile失败assert会抛出错误。\n完成简单的功能 dofile 比较方便,他读入文件编译并且执行。然而loadfile更加灵活。在发生错误的情况下,loadfile 返回 nil 和错误信息,这样我们就可以自定义错误处理。另外,如果我们运行一个文件多次的话,loadfile 只需要编译一次,但可多次运行。dofile却每次都要编译。\nloadstring与loadfile 相似,只不过它不是从文件里读入chunk,而是从一个串中读入。例如：\n\nf将是一个函数,调用时执行i&#x3D;i+l。\ni = 0f(); print(i)  --&gt; 1 f(); print(i)  --&gt; 2 \n\nloadstring 函数功能强大,但使用时需多加小心。确认没有其它简单的解决问题的方法再使用。\nLua 把每一个 chunk 都作为一个匿名函数处理。例如：chunk”a&#x3D;1”,loadstring 返回与其等价的 function(a&#x3D;1 end\n与其他函数一样,chunks 可以定义局部变量也可以返回值:\nf = loadstring(&quot;local a = 10; return a + 20&quot;) print(f())   --&gt; 30 \n\nloadfile 和loadstring都不会抛出错误,如果发生错误他们将返回 nil加上错误信息：\n\n另外,loadfile 和loadstring 都不会有边界效应产生,他们仅仅编译 chunk成为自己内部实现的一个匿名函数。通常对他们的误解是他们定义了函数。Lua中的函数定义是发生在运行时的赋值而不是发生在编译时。假如我们有一个文件foo.lua:\n-- file `foo.lua&#x27; function foo (x)    print(x) end\n\n当我们执行命令f &#x3D;loadfile(“foo.lua”)后,foo 被编译了但还没有被定义,如果要定义他必须运行chunk:\nf()    -- defines `foo&#x27; foo(&quot;ok&quot;)  --&gt; ok \n\n如果你想快捷的调用 dostring(比如加载并运行),可以这样\nloadstring(s)()\n\n调用 loadstring 返回的结果,然而如果加载的内容存在语法错误的话,loadstring 返\nassert(loadstring(s))()\n\n通常使用loadstring 加载一个字串没什么意义,例如:\nf = loadstring(&quot;i = i + l&quot;)\n\n大概与f&#x3D;function(i&#x3D;i+1 end 等价,但是第二段代码速度更快因为它只需要编译一次,第一段代码每次调用loadstring 都会重新编译,还有一个重要区别：loadstring 编译的时候不关心词法范围：\nlocal i = 0 f = loadstring(&quot;i = i + 1&quot;) g = function () i = i + 1 end \n\n这个例子中,和想象的一样 g使用局部变量i,然而f使用全局变量i；loadstring 总是在全局环境中编译他的串。\nloadstring通常用于运行程序外部的代码,比如运行用户自定义的代码。注意：loadstring 期望一个 chunk,即语句。如果想要加载表达式,需要在表达式前加 return,那样将返回表达式的值。看例子:\nprint &quot;enter your expression:&quot; local l = io.read() local func = assert(loadstring(&quot;return &quot; .. l)) print(&quot;the value of your expression is &quot; .. func()) \n\nloadstring返回的函数和普通函数一样,可以多次被调用:\nprint &quot;enter function to be plotted (with variable `x&#x27;):&quot; local l = io.read() local f = assert(loadstring(&quot;return &quot; .. l)) for i=1,20 do     x = i   -- global `x&#x27; (to be visible from the chunk)     print(string.rep(&quot;*&quot;, f()))end\n\n8.1reguire函数Lua 提供高级的 require 函数来加载运行库。粗略的说 require 和 dofile 完成同样的功能但有两点不同:\n\nrequire 会搜索目录加载文件\n\nrequire 会判断是否文件已经加载避免重复加载同一文件。由于上述特征,require在Lua中是加载库的更好的函数。\n\n\nrequire 使用的路径和普通我们看到的路径还有些区别,我们一般见到的路径都是-个目录列表。require 的路径是一个模式列表,每一个模式指明一种由虚文件名(require的参数)转成实文件名的方法。更明确地说,每一个模式是一个包含可选的问号的文件名。匹配的时候Lua会首先将问号用虚文件名替换,然后看是否有这样的文件存在。如果不存在继续用同样的方法用第二个模式匹配。例如,路径如下:\n?;?.lua;c:\\windows\\?;/usr/local/lua/?/?.lua\n\n调用 require”lili”时会试着打开这些文件:\nlili lili.lua c:\\windows\\lili /usr/local/lua/lili/lili.lua \n\nrequire 关注的问题只有分号(模式之间的分隔符)和问号,其他的信息(目录分隔符,文件扩展名)在路径中定义。\n为了确定路径,Lua 首先检查全局变量LUA_PATH是否为一个字符串,如果是则认为这个串就是路径;否则 require 检查环境变量 LUA_PATH 的值,如果两个都失败 require使用固定的路径(典型的”?;?.lua”)\nrequire 的另一个功能是避免重复加载同一个文件两次。Lua 保留一张所有已经加载的文件的列表(使用 table 保存)。如果一个加载的文件在表中存在 require 简单的返回；表中保留加载的文件的虚名,而不是实文件名。所以如果你使用不同的虚文件名 require同一个文件两次,将会加载两次该文件。比如 require “foo”和 require“”foo.lua”,路径为这样我们就可以判断文件是否被加载过；同样我们也可以使用一点小技巧让require 加载一个文件两次。比如,require “foo”之后_LOADED[“foo”]将不为 nil,我们可以将其赋值为nil,require”foo.lua”将会再次加载该文件。\n个路径中的模式也可以不包含问号而只是一个固定的路径,比如:\n?;?.lua;/usr/local/default.lua\n\n这种情况下，require没有匹配的时候就会使用这个固定的文件（当然这个固定的路径必须放在模式列表的最后才有意义）。在require运行一个chunk以前，它定义了一个全局变量_REQUIREDNAME 用来保存被 required 的虚文件的文件名。我们可以通过使用这个技巧扩展 require 的功能。举个极端的例子，我们可以把路径设为“&#x2F;usr&#x2F;local&#x2F;lua&#x2F;newrequire.lua”，这样以后每次调用 require 都会运行 newrequire.lua，这种情况下可以通过使用_REQUIREDNAME的值去实际加载required的文件。\n8.2 C PackagesLua 和C是很容易结合的,使用C为Lua 写包。与Lua 中写包不同,C包在使用以前必须首先加载并连接,在大多数系统中最容易的实现方式是通过动态连接库机制,然而动态连接库不是ANSIC的一部分,也就是说在标准C中实现动态连接是很困难的。\n通常Lua不包含任何不能用标准C实现的机制,动态连接库是一个特例。我们可以将动态连接库机制视为其他机制之母：一旦我们拥有了动态连接机制,我们就可以动态的加载Lua 中不存在的机制。所以,在这种特殊情况下,Lua 打破了他平台兼容的原则FreeBSD、Solaris 和其他一些Unix平台实现了这种机制,扩展其它平台支持这种机制也是不难的。在 Lua 提示符下运行 print(loadibO)看返回的结果,如果显示 bad arguments\nLua在一个叫loadlib 的函数内提供了所有的动态连接的功能。这个函数有两个参数:库的绝对路径和初始化函数。所以典型的调用的例子如下:\nlocal path = &quot;/usr/local/lua/lib/libluasocket.so&quot; local f = loadlib(path, &quot;luaopen_socket&quot;) \n\nloadlib 函数加载指定的库并且连接到Lua,然而它并不打开库(也就是说没有调用初始化函数),反之他返回初始化函数作为Lua 的一个函数,这样我们就可以直接在Lua中调用他。如果加载动态库或者查找初始化函数时出错,loadlib 将返回 nil和错误信息。我们可以修改前面一段代码,使其检测错误然后调用初始化函数：\nlocal path = &quot;/usr/local/lua/lib/libluasocket.so&quot; -- or path = &quot;C:\\\\windows\\\\luasocket.dll&quot; local f = assert(loadlib(path, &quot;luaopen_socket&quot;)) f()  -- actually open the library \n一般情况下我们期望二进制的发布库包含一个与前面代码段相似的 stub 文件,安装二进制库的时候可以随便放在某个目录,只需要修改 stub 文件对应二进制库的实际路径即可。将 stub 文件所在的目录加入到LUA_PATH,这样设定后就可以使用 require 函数加载C库了。\n8.3错误Errare humanum ést(拉丁谚语：犯错是人的本性)。所以我们要尽可能的防止错误的发生,Lua 经常作为扩展语言嵌入在别的应用中,所以不能当错误发生时简单的崩溃或者退出。相反,当错误发生时Lua 结束当前的chunk并返回到应用中。\n当Lua遇到不期望的情况时就会抛出错误,比如：两个非数字进行相加；调用一个非函数的变量；访问表中不存在的值等(可以通过 metatables 修改这种行为,后面介绍)。你也可以通过调用error 函数显示的抛出错误,error 的参数是要抛出的错误信息。\nprint &quot;enter a number:&quot; n = io.read(&quot;*number&quot;) if not n then error(&quot;invalid input&quot;) end \n\nLua提供了专门的内置函数 assert来完成上面类似的功能:\nprint &quot;enter a number:&quot; n = assert(io.read(&quot;*number&quot;), &quot;invalid input&quot;) \n\nassert 首先检查第一个参数是否返回错误,如果不返回错误 assert 简单的返回,否则assert 以第二个参数抛出错误信息。第二个参数是可选的。注意 assert是普通的函数,他会首先计算两个参数然后再调用函数,所以以下代码:\nn = io.read() assert(tonumber(n), &quot;invalid input: &quot; .. n .. &quot; is not a number&quot;)\n\n将会总是进行连接操作,使用显示的test可以避免这种情况。\n当函数遇到异常有两个基本的动作：返回错误代码或者抛出错误。这两种方式选择哪一种没有固定的规则,但有一般的原则：容易避免的异常应该抛出错误否则返回错误代码。\n例如我们考虑 sin 函数,如果以一个 table 作为参数,假定我们返回错误代码,我们需要检查错误的发生,代码可能如下：\nlocal res = math.sin(x) if not res then  -- error  ... \nlocal res &#x3D; math.sin(x)\n然而我们可以在调用函数以前很容易的判断是否有异常：\n\n然而通常情况下我们既不是检查参数也不是检查返回结果,因为参数错误可能意味着我们的程序某个地方存在问题,这种情况下,处理异常最简单最实际的方式是抛出错误并且终止代码的运行。\n再来看一个例子io.open 函数用来打开一个文件,如果文件不存在结果会怎么样呢?很多系统中,通过试着去打开文件来判断是否文件存在。所以如果io.open 不能打开文件(由于文件不存在或者没有权限),函数返回 nil和错误信息。以这种方式我们可以通过与用户交互(比如：是否要打开另一个文件)合理的处理问题:\nlocal file, msg repeat     print &quot;enter a file name:&quot;     local name = io.read()     if not name then return end  -- no input     file, msg = io.open(name, &quot;r&quot;)     if not file then print(msg) end until file\n\n如果你想偷懒不想处理这些情况,又想代码安全的运行,可以简单的使用 assert:\nfile = assert(io.open(name, &quot;r&quot;)) \n\nLua 中有一个习惯：如果io.open 失败,assert将抛出错误。\n\n注意：io.open 返回的第二个结果(错误信息)作为 assert 的第二个参数。\n8.4异常和错误处理很多应用中,不需要在Lua 进行错误处理,一般有应用来完成。通常应用要求Lua运行一段 chunk,如果发生异常,应用根据Lua 返回的错误代码进行处理。在控制台模式下的Lua解释器如果遇到异常,打印出错误然后继续显示提示符等待下一个命令。\n如果在Lua 中需要处理错误,需要使用 pcall 函数封装你的代码。\n假定你想运行一段Lua代码,这段代码运行过程中可以捕捉所有的异常和错误。\n第一步：将这段代码封装在一个函数内\nfunction foo ()  ...  if unexpected_condition then error() end  ...  print(a[i]) -- potential error: `a&#x27; may not be a table  ... end \n\n第二步：使用 pcall 调用这个函数\nif pcall(foo) then  -- no errors while running `foo&#x27;  ... else  -- `foo&#x27; raised an error: take appropriate actions  ... end\n\n当然也可以用匿名函数的方式调用 pcall:\n\npcall在保护模式下调用他的第一个参数并运行,因此可以捕获所有的异常和错误。如果没有异常和错误,pcall 返回 true 和调用返回的任何值；否则返回 nil 加错误信息。\n错误信息不一定非要是一个字符串(下面的例子是一个 table),传递给 error 的任何信息都会被 pcall 返回:\nlocal status, err = pcall(function () error(&#123;code=121&#125;) end) print(err.code)  --&gt;  121\n\n这种机制提供了我们在Lua 中处理异常和错误的所需要的全部内容。我们通过 error抛出异常,然后通过 pcall捕获他。\n8.5错误信息和回跟踪(Tracebacks)虽然你可以使用任何类型的值作为错误信息,通常情况下,我们使用字符串来描述遇到的错误信息。如果遇到内部错误(比如对一个非table 的值使用索引下表访问)Lua将自己产生错误信息,否则Lua 使用传递给error 函数的参数作为错误信息。不管在什么情况下,Lua都尽可能清楚的描述发生的错误。\nlocal status, err = pcall(function () a = &#x27;a&#x27;+1 end) print(err) --&gt; stdin:1: attempt to perform arithmetic on a string valuelocal status, err = pcall(function () error(&quot;my error&quot;) end) print(err) --&gt; stdin:1: my error \n\n例子中错误信息给出了文件名(stdin)加上行号。\n函数error还可以有第二个参数,表示错误的运行级别。有了这个参数你就无法抵赖错误是别人的了,比如,加入你写了一个函数用来检查error 是否被正确的调用：\nfunction foo (str) if type(str) ~= &quot;string&quot; then   error(&quot;string expected&quot;) end  ...end \n\n可能有人这样调用这个函数:\nfoo(&#123;x=1&#125;) \n\nLua 会指出发生错误的是foo 而不是 error,实际的错误是调用 error 时产生的,为了纠正这个问题修改前面的代码让 error报告错误发生在第二级 (你自己的函数是第一级)如下:\n\n当错误发生的时候,我们常常需要更多的错误发生相关的信息,而不单单是错误发生的位置。至少期望有一个完整的显示导致错误发生的调用栈的 tracebacks,当 pcall 返回错误信息的时候他已经释放了保存错误发生情况的栈的信息。因此,如果我们想得到tracebacks 我们必须在 pcall 返回以前获取。Lua 提供了xpcall 来实现这个功能,xpcall误处理函数,因此可以使用 debug 库收集错误相关的信息。有两个常用的 debug 处理函数：debug。debug 和 debug.traceback,前者给出Lua 的提示符,你可以自己动手察看错误发生时的情况；后者通过 traceback 创建更多的错误信息,后者是控制台解释器用来构建错误信息的函数。你可以在任何时候调用 debug.traceback获取当前运行的traceback信息:\nprint(debug.traceback())\n\n第9章 协同程序协同程序(coroutine)与多线程情况下的线程比较类似：有自己的堆栈,自己的局部变量,有自己的指令指针,但是和其他协同程序共享全局变量等很多信息。线程和协同程序的主要不同在于：在多处理器情况下,从概念上来讲多线程程序同时运行多个线程；而协同程序是通过协作来完成,在任一指定时刻只有一个协同程序在运行,并且这个正在运行的协同程序只有在明确的被要求挂起的时候才会被挂起。\n协同是非常强大的功能,但是用起来也很复杂。如果你第一次阅读本章时不理解本章中的例子请不要担心,你可以继续阅读本书的其他部分然后再回过头来阅读本章。\n9.1协同的基础Lua 通过 table 提供了所有的协同函数,create 函数创建一个新的协同程序,create只有一个参数：协同程序将要运行的代码封装而成的函数,返回值为 thread类型的值表示创建了一个新的协同程序。通常情况下,create 的参数是一个匿名函数:\n\n协同有三个状态：挂起态、运行态、停止态。当我们创建一个协同程序时他开始的状态为挂起态,也就是说我们创建协同程序的时候不会自动运行,可以使用 status 函数检查协同的状态：\n\n函数coroutine.resume 可以使程序由挂起状态变为运行态：\n\n这个例子中,协同体仅仅打印出”hi”之后便进入终止状态:\n\n当目前为止,协同看起来只是一种复杂的调用函数的方式,真正的强大之处体现在yield 函数,它可以将正在运行的代码挂起,看一个例子:\nco = coroutine.create(function ()     for i=1,10 do        print(&quot;co&quot;, i)         coroutine.yield()     end end)\n\n现在重新执行这个协同程序，程序将在第一个yield处被挂起：\n\n从协同的观点看：使用函数yield可以使程序挂起,当我们激活被挂起的程序时，yield返回并继续程序的执行直到再次遇到yield或者程序结束。 \n\n上面最后一次调用的时候,协同体已经结束,因此协同程序处于终止状态。如果我们仍然企图激活他,resume 将返回 false和错误信息。\nprint(coroutine.resume(co))   --&gt; false   cannot resume dead coroutine \n\n注意:resume 运行在保护模式下,因此如果协同内部存在错误Lua 并不会抛出错误而是将错误返回给resume函数。\nLua 中一对 resume-yield 可以相互交换数据。\n下面第一个例子resume,没有相应的 yield,resume 把额外的参数传递给协同的主程序。\nco = coroutine.create(function (a,b,c)  print(&quot;co&quot;, a,b,c) end) coroutine.resume(co, 1, 2, 3)  --&gt; co  1  2  3 \n\n第二个例子,resume 返回除了 true 以外的其他部分将作为参数传递给相应的 yield\nco = coroutine.create(function (a,b)  coroutine.yield(a + b, a - b) end) print(coroutine.resume(co, 20, 10)) --&gt; true  30  10    \n\n对称性,yield返回的额外的参数也将会传递给 resume。\nco = coroutine.create (function ()    print(&quot;co&quot;, coroutine.yield()) end) coroutine.resume(co) coroutine.resume(co, 4, 5)  --&gt; co  4  5 \n\n最后一个例子,当协同代码结束时主函数返回的值都会传给相应的resume:\n\n我们很少在同一个协同程序中使用这几种特性,但每一种都有其用处\n现在已经了解了一些协同的内容,在我们继续学习以前,先要澄清两个概念：Lua提供的这种协同我们称为不对称的协同,就是说挂起一个正在执行的协同的函数与使一个被挂起的协同再次执行的函数是不同的,有些语言提供对称的协同,这种情况下,由执行到挂起之间状态转换的函数是相同的。\n有人称不对称的协同为半协同,另一些人使用同样的术语表示真正的协同,严格意义上的协同不论在什么地方只要它不是在其他的辅助代码内部的时候都可以并且只能使执行挂起,不论什么时候在其控制栈内都不会有不可决定的调用。(However,other peopleuse the same term semi-coroutine to denote a restricted implementation of coroutines, where acoroutine can only suspend its execution when it is not inside any auxiliary function, that is,when it has no pending calls in its control stack.)。只有半协同程序的主体中才可以 yield,python 中的产生器（generator）就是这种类型的半协同的例子。\n与对称的协同和不对称协同的区别不同的是,协同与产生器的区别更大。产生器相对比较简单,他不能完成真正的协同所能完成的一些任务。我们熟练使用不对称的协同之后,可以利用不对称的协同实现比较优越的对称协同。\n9.2管道和过滤器协同最有代表性的作用是用来描述生产者-消费者问题。我们假定有一个函数在不断(中一)一中)这两个函数如下:\nfunction producer () while true do   local x = io.read()    send(x)     -- produce new value -- send to consumer  end end function consumer ()  while true do   local x = receive()  -- receive from producer   io.write(x, &quot;\\n&quot;)   -- consume new value  end end \n\n（例子中生产者和消费者都在不停的循环，修改一下使得没有数据的时候他们停下来并不困难），问题在于如何使得receive和send协同工作。只是一个典型的谁拥有住循环的情况，生产者和消费者都处在活动状态，都有自己的主循环，都认为另一方是可调用的服务。对于这种特殊的情况，可以改变一个函数的结构解除循环，使其作为被动的接受。然而这种改变在某些特定的实际情况下可能并不简单。 \n协同为解决这种问题提供了理想的方法,因为调用者与被调用者之间的resume-yield关系会不断颠倒。当一个协同调用 yield时并不会进入一个新的函数,取而代之的是返回一个未决的 resume 的调用。相似的,调用 resume 时也不会开始一个新的函数而是返回yield 的调用。这种性质正是我们所需要的,与使得 send-receive 协同工作的方式是一致的.receive 唤醒生产者生产新值,send把产生的值送给消费者消费。\n\n这种设计下,开始时调用消费者,当消费者需要值时他唤起生产者生产值,生产者生产值后停止直到消费者再次请求。我们称这种设计为消费者驱动的设计。\n我们可以使用过滤器扩展这个涉及,过滤器指在生产者与消费者之间,可以对数据进行某些转换处理。过滤器在同一时间既是生产者又是消费者,他请求生产者生产值并且转换格式后传给消费者,我们修改上面的代码加入过滤器(每一行前面加上行号)。完整的代码如下：\n\n可以调用：\np = producer()f = filter(p) consumer(f)\n\n或者：\n\n看完上面这个例子你可能很自然的想到UNIX的管道,协同是一种非抢占式的多线程。管道的方式下,每一个任务在独立的进程中运行,而协同方式下,每个任务运行在独立的协同代码中。管道在读(consumer)与写(producer)之间提供了一个缓冲,因此两者相关的的速度没有什么限制,在上下文管道中这是非常重要的,因为在进程间的切换代价是很高的。协同模式下,任务间的切换代价较小,与函数调用相当,因此读写可以很好的协同处理。\n9.3用作迭代器的协同我们可以将循环的迭代器看作生产者-消费者模式的特殊的例子。迭代函数产生值给循环体消费。所以可以使用协同来实现迭代器。协同的一个关键特征是它可以不断颠倒调用者与被调用者之间的关系,这样我们毫无顾虑的使用它实现一个迭代器,而不用保存迭代函数返回的状态。\n我们来完成一个打印一个数组元素的所有的排列来阐明这种应用。直接写这样一个迭代函数来完成这个任务并不容易,但是写一个生成所有排列的递归函数并不难。思路是这样的：将数组中的每一个元素放到最后,依次递归生成所有剩余元素的排列。代码如下:\nfunction permgen (a, n)  if n == 0 then   printResult(a)  else   for i=1,n do     -- put i-th element as the last one    a[n], a[i] = a[i], a[n]     -- generate all permutations of the other elements    permgen(a, n - 1)     -- restore i-th element    a[n], a[i] = a[i], a[n]    end end end  function printResult (a)  for i,v in ipairs(a) do   io.write(v, &quot; &quot;)  end  io.write(&quot;\\n&quot;) end  permgen (&#123;1,2,3,4&#125;, 4) \n\n有了上面的生成器后,下面我们将这个例子修改一下使其转换成一个迭代函数:\n\n第一步 printResult 改为 yield\n\n\n\n第二步,我们定义一个迭代工厂,修改生成器在生成器内创建迭代函数,并使生成器运行在一个协同程序内。迭代函数负责请求协同产生下一个可能的排列。\n\n\n这样我们就可以使用 for循环来打印出一个数组的所有排列情况了：\n\nperm 函数使用了 Lua 中常用的模式：将一个对协同的 resume 的调用封装在一个函数内部,这种方式在Lua非常常见,所以Lua专门为此专门提供了一个函数coroutine.wrap。与 create 相同的是,wrap 创建一个协同程序；不同的是 wrap 不返回协同本身,而是返回一个函数,当这个函数被调用时将 resume 协同。wrap 中 resume 协同以使用 wrap 重写 perm:\nfunction perm (a)     local n = table.getn(a)     return coroutine.wrap(function () permgen(a, n) end) end\n\n一般情况下,coroutine.wrap比 coroutine.create使用起来简单直观,前者更确切的提供了我们所需要的：一个可以 resume 协同的函数,然而缺少灵活性,没有办法知道 wrap所创建的协同的状态,也没有办法检查错误的发生。\n9.4非抢占式多线程如前面所见,Lua中的协同是一协作的多线程,每一个协同等同于一个线程,yield-resume 可以实现在线程中切换。然而与真正的多线程不同的是,协同是非抢占式的。当一个协同正在运行时,不能在外部终止他。只能通过显示的调用 yield 挂起他的执行。对于某些应用来说这个不存在问题,但有些应用对此是不能忍受的。不存在抢占式调用的程序是容易编写的。不需要考虑同步带来的bugs,因为程序中的所有线程间的同步都是显示的。你仅仅需要在协同代码超出临界区时调用 yield 即可。\n对非抢占式多线程来说,不管什么时候只要有一个线程调用一个阻塞操作(blocking)忍受的,这使得很多程序员离协同而去。下面我们将看到这个问题可以被有趣的解决。\n看一个多线程的例子：我们想通过http 协议从远程主机上下在一些文件。我们使用Diego Nehab 开发的LuaSocket 库来完成。我们先看下在一个文件的实现,大概步骤是打开一个到远程主机的连接,发送下载文件的请求,开始下载文件,下载完毕后关闭连接。\n第一,加载LuaSocket库\n\n第二,定义远程主机和需要下载的文件名\nhost = &quot;www.w3.org&quot; file = &quot;/TR/REC-html32.html&quot; \n\n第三,打开一个TCP 连接到远程主机的 80 端口(http 服务的标准端口)\nc = assert(socket.connect(host, 80)) \n\n上面这句返回一个连接对象,我们可以使用这个连接对象请求发送文件\nc:send(&quot;GET &quot; .. file .. &quot; HTTP/1.0\\r\\n\\r\\n&quot;) \n\nreceive 函数返回他送接收到的数据加上一个表示操作状态的字符串。当主机断开连接时,我们退出循环。\n第四,关闭连接\nc:close()\n\n现在我们知道了如何下载一个文件,下面我们来看看如何下载多个文件。一种方法是我们在一个时刻只下载一个文件,这种顺序下载的方式必须等前一个文件下载完成后一个文件才能开始下载。实际上是,当我们发送一个请求之后有很多时间是在等待数据的到达,也就是说大部分时间浪费在调用receive上。如果同时可以下载多个文件,效率将会有很大提高。当一个连接没有数据到达时,可以从另一个连接读取数据。很显然,协同为这种同时下载提供了很方便的支持,我们为每一个下载任务创建一个线程,当一个线程没有数据到达时,他将控制权交给一个分配器,由分配器唤起另外的线程读取数据。\n使用协同机制重写上面的代码,在一个函数内：\n\n由于我们不关心文件的内容,上面的代码只是计算文件的大小而不是将文件内容输出。(当有多个线程下载多个文件时,输出会混杂在一起),在新的函数代码中,我们使用receive从远程连接接收数据,在顺序接收数据的方式下代码如下:\nfunction receive (connection)     return connection:receive(2^10) end\n\n在同步接受数据的方式下,函数接收数据时不能被阻塞,而是在没有数据可取时yield,代码如下:\n\n调用函数 timeout(O)使得对连接的任何操作都不会阻塞。当操作返回的状态为timeout 时意味着操作未完成就返回了。在这种情况下,线程 yield。非 false 的数值作为yield的参数告诉分配器线程仍在执行它的任务。(后面我们将看到分配器需要timeout连接的情况),注意:即使在 timeout 模式下,连接依然返回他接受到直到 timeout 为止,因此receive会一直返回 s给她的调用者。\n下面的函数保证每一个下载运行在自己独立的线程内：\n\n代码中 table 中为分配器保存了所有活动的线程。\n分配器代码是很简单的,它是一个循环,逐个调用每一个线程。并且从线程列表中移除已经完成任务的线程。当没有线程可以运行时退出循环。\nfunction dispatcher ()  while true do   local n = table.getn(threads)   if n == 0 then break end  -- no more threads to run   for i=1,n do    local status, res = coroutine.resume(threads[i])    if not res then -- thread finished its task?     table.remove(threads, i)     break    end   end  end end\n\n最后,在主程序中创建需要的线程调用分配器,例如：从 W3C 站点上下载4个文件：\n\n使用协同方式下,我的机器花了6s下载完这几个文件；顺序方式下用了15s,大概2 倍的时间。\n尽管效率提高了,但距离理想的实现还相差甚远,当至少有一个线程有数据可读取的时候,这段代码可以很好的运行。否则,分配器将进入忙等待状态,从一个线程到另个线程不停的循环判断是否有数据可获取。结果协同实现的代码比顺序读取将花费30倍的CPU时间。\n为了避免这种情况出现,我们可以使用LuaSocket 库中的 select 函数。当程序在一组 socket中不断的循环等待状态改变时,它可以使程序被阻塞。我们只需要修改分配器,使用 select 函数修改后的代码如下:\nfunction dispatcher ()  while true do   local n = table.getn(threads)   if n == 0 then break end  -- no more threads to run   local connections = &#123;&#125;   for i=1,n do    local status, res = coroutine.resume(threads[i])    if not res then -- thread finished its task?     table.remove(threads, i)     break    else -- timeout     table.insert(connections, res)    end   end   if table.getn(connections) == n then    socket.select(connections)   end endend\n\n在内层的循环分配器收集连接表中timeout地连接,注意:receive将连接传递给yield,因此 resume 返回他们。当所有的连接都 timeout 分配器调用 select 等待任一连接状态的改变。最终的实现效率和上一个协同实现的方式相当,另外,他不会发生忙等待,比起顺序实现的方式消耗CPU的时间仅仅多一点点。\n第10章完整示例我们看两个完整的例子来阐明Lua 语言的使用。第一个例子来自于Lua 网站,他展示了Lua作为数据描述语言的使用。第二个例子讲解了马尔可夫链算法的实现,这个算法在Kernighan &amp; Pike 著作的 Practice of Programming 书中也有描述。这两个完整的例子之后,Lua 语言方面的介绍便到此结束。后面将继续介绍table 和面向对象的内容以及标准库、C-API等。\n10.1Lua作为数据描述语言使用Lua 网站保留一个包含世界各地使用Lua 创建的工程的例子的数据库。在数据库中我们用一个构造器以自动归档的方式表示每一个工程入口点,代码如下:\nentry&#123; title = &quot;Tecgraf&quot;, org = &quot;Computer Graphics Technology Group, PUC-Rio&quot;, url = &quot;http://www.tecgraf.puc-rio.br/&quot;, contact = &quot;Waldemar Celes&quot;, description = [[ TeCGraf is the result of a partnership between PUC-Rio, the Pontifical Catholic University of Rio de Janeiro, and &lt;A HREF=&quot;http://www.petrobras.com.br/&quot;&gt;PETROBRAS&lt;/A&gt;, the Brazilian Oil Company. TeCGraf is Lua&#x27;s birthplace, and the language has been used there since 1993. Currently, more than thirty programmers in TeCGraf use Lua regularly; they have written more than two hundred &#125; thousand lines of code, distributed among dozens of final products.]]&#125;\n\n有趣的是,工程入口的列表是存放在一个Lua 文件中的,每个工程入口以 table 的形式作为参数去调用 entry 函数。我们的目的是写一个程序将这些数据以 html 格式展示出来。由于工程太多,我们首先列出工程的标题,然后显示每个工程的明细。结果如下:\n&lt;HTML&gt; &lt;HEAD&gt;&lt;TITLE&gt;Projects using Lua&lt;/TITLE&gt;&lt;/HEAD&gt; &lt;BODY BGCOLOR=&quot;#FFFFFF&quot;&gt; Here are brief descriptions of some projects around the world that use &lt;A HREF=&quot;home.html&quot;&gt;Lua&lt;/A&gt;.   &lt;UL&gt; &lt;LI&gt;&lt;A HREF=&quot;#1&quot;&gt;TeCGraf&lt;/A&gt; &lt;LI&gt; ... &lt;/UL&gt;  &lt;H3&gt; &lt;A NAME=&quot;1&quot;  HREF=&quot;http://www.tecgraf.puc-rio.br/&quot;&gt;TeCGraf&lt;/A&gt;   &lt;SMALL&gt;&lt;EM&gt;Computer Graphics Technology Group, PUC-Rio&lt;/EM&gt;&lt;/SMALL&gt; &lt;/H3&gt;  TeCGraf is the result of a partnership between ... distributed among dozens of final products.&lt;P&gt; Contact: Waldemar Celes  &lt;A NAME=&quot;2&quot;&gt;&lt;/A&gt;&lt;HR&gt; ...  &lt;/BODY&gt;&lt;/HTML&gt;\n\n为了读取数据,我们需要做的是正确的定义函数 entry,然后使用 dofile 直接运行数据文件即可(db.lua)。注意,我们需要遍历入口列表两次,第一次为了获取标题,第二所有的入口放在一个数组内；另一种方法：使用不同的entry 函数运行数据文件两次。因为Lua 编译文件是很快的,这里我们选用第二种方法。\n首先,我们定义一个辅助函数用来格式化文本的输出(参见5.2函数部分内容)\nfunction fwrite (fmt, ...)  return io.write(string.format(fmt, unpack(arg))) end\n\n第二,我们定义一个BEGIN 函数用来写html 页面的头部\nfunction BEGIN() io.write([[ &lt;HTML&gt; &lt;HEAD&gt;&lt;TITLE&gt;Projects using Lua&lt;/TITLE&gt;&lt;/HEAD&gt; &lt;BODY BGCOLOR=&quot;#FFFFFF&quot;&gt; Here are brief descriptions of some projects around the world that use &lt;A HREF=&quot;home.html&quot;&gt;Lua&lt;/A&gt;. ]]) end\n\n第三,定义 entry 函数\na．第一个entry函数,将每个工程一列表方式写出,entry的参数o是描述工程的table。\nfunction entry0 (o)  N=N + 1  local title = o.title or &#x27;(no title)&#x27;  fwrite(&#x27;&lt;LI&gt;&lt;A HREF=&quot;#%d&quot;&gt;%s&lt;/A&gt;\\n&#x27;, N, title) end\n\n如果 o.title 为 nil 表明 table 中的域 title 没有提供,我们用固定的”no title”替换。\nb．第二个 éntry 函数,写出工程所有的相关信息,稍微有些复杂,因为所有项都是可选的。\nfunction entry1 (o)  N=N + 1  local title = o.title or o.org or &#x27;org&#x27;  fwrite(&#x27;&lt;HR&gt;\\n&lt;H3&gt;\\n&#x27;)  local href = &#x27;&#x27;   if o.url then   href = string.format(&#x27; HREF=&quot;%s&quot;&#x27;, o.url)  end  fwrite(&#x27;&lt;A NAME=&quot;%d&quot;%s&gt;%s&lt;/A&gt;\\n&#x27;, N, href, title)   if o.title and o.org then   fwrite(&#x27;\\n&lt;SMALL&gt;&lt;EM&gt;%s&lt;/EM&gt;&lt;/SMALL&gt;&#x27;, o.org)  end  fwrite(&#x27;\\n&lt;/H3&gt;\\n&#x27;)   if o.description then   fwrite(&#x27;%s&#x27;, string.gsub(o.description, &#x27;\\n\\n\\n*&#x27;, &#x27;&lt;P&gt;\\n&#x27;))   fwrite(&#x27;&lt;P&gt;\\n&#x27;)  end   if o.email then   fwrite(&#x27;Contact: &lt;A HREF=&quot;mailto:%s&quot;&gt;%s&lt;/A&gt;\\n&#x27;,     o.email, o.contact or o.email)  elseif o.contact then   fwrite(&#x27;Contact: %s\\n&#x27;, o.contact)  end end\n\n由于html中使用双引号,为了避免冲突我们这里使用单引号表示串。\n第四,定义END 函数,写 html 的尾部\nfunction END()     fwrite(&#x27;&lt;/BODY&gt;&lt;/HTML&gt;\\n&#x27;) end \n\n在主程序中,我们首先使用第一个 entry 运行数据文件输出工程名称的列表,然后再以第二个 entry 运行数据文件输出工程相关信息。\n\n10.2马尔可夫链算法我们第二个例子是马尔可夫链算法的实现,我们的程序以前 n(n&#x3D;2)个单词串为基础随机产生一个文本串。\n程序的第一部分读出原文,并且对没两个单词的前缀建立一个表,这个表给出了具有那些前缀的单词的一个顺序。建表完成后，这个程序利用这张表生成一个随机的文本。在此文本中，每个单词都跟随着它的的前两个单词，这两个单词在文本中有相同的概率。这样，我们就产生了一个非常随机，但并不完全随机的文本。例如，当应用这个程序的输出结果会出现“构造器也可以通过表构造器，那么一下几行的插入语对于整个文件来说，不是来存储每个功能的内容，而是来展示它的结构。”如果你想在队列里找到最大元素并返回最大值，接着显示提示和运行代码。下面的单词是保留单词，不能用在度和弧度之间转换。\n我们编写一个函数用来将两个单词中间加上空个连接起来:\n\n我们用 NOWORD（即\\n）表示文件的结尾并且初始化前缀单词，例如，下面的文本：\nthe more we try the more we do\n\n初始化构造的表为：\n&#123;  [&quot;\\n \\n&quot;]  = &#123;&quot;the&quot;&#125;,   [&quot;\\n the&quot;] = &#123;&quot;more&quot;&#125;,   [&quot;the more&quot;] = &#123;&quot;we&quot;, &quot;we&quot;&#125;,   [&quot;we try&quot;]  = &#123;&quot;the&quot;&#125;,  [&quot;try the&quot;] = &#123;&quot;more&quot;&#125;,   [&quot;we do&quot;] = &#123;&quot;\\n&quot;&#125;,  &#125;\n\n我们使用全局变量 statetab 来保存这个表,下面我们完成一个插入函数用来在这个statetab中插入新的单词。\nfunction insert (index, value)     if not statetab[index] then     statetab[index] = &#123;value&#125;     else     table.insert(statetab[index], value)     end end\n\n这个函数中首先检查指定的前缀是否存在,如果不存在则创建一个新的并赋上新值。如果已经存在则调用table.insert将新值插入到列表尾部。\n我们使用两个变量w1和w2 来保存最后读入的两个单词的值,对于每一个前缀,我们保存紧跟其后的单词的列表。例如上面例子中初始化构造的表。\n初始化表之后,下面来看看如何生成一个MAXGEN(&#x3D;1000)个单词的文本。首先,重新初始化 w1和 w2,然后对于每一个前缀,在其next 单词的列表中随机选择一个,打印此单词并更新w1和w2,完整的代码如下:\n-- Markov Chain Program in Lua  function allwords ()  local line = io.read() -- current line  local pos = 1 -- current position in the line  return function () -- iterator function   while line do -- repeat while there are lines    local s, e = string.find(line, &quot;%w+&quot;, pos)    if s then -- found a word?     pos = e + 1 -- update next position     return string.sub(line, s, e) -- return the word    else     line = io.read() -- word not found; try next line     pos = 1 -- restart from first position    end   end   return nil -- no more lines: end of traversal  end endfunction prefix (w1, w2)  return w1 .. &#x27; &#x27; .. w2 end  local statetab  function insert (index, value)  if not statetab[index] then   statetab[index] = &#123;n=0&#125;  end  table.insert(statetab[index], value) end  local N = 2 local MAXGEN = 10000 local NOWORD = &quot;\\n&quot;  -- build table statetab = &#123;&#125; local w1, w2 = NOWORD, NOWORD for w in allwords() do  insert(prefix(w1, w2), w)  w1 = w2; w2 = w; end insert(prefix(w1, w2), NOWORD)  -- generate text w1 = NOWORD; w2 = NOWORD -- reinitialize for i=1,MAXGEN do  local list = statetab[prefix(w1, w2)]  -- choose a random item from list  local r = math.random(table.getn(list))  local nextword = list[r]  if nextword == NOWORD then return end  io.write(nextword, &quot; &quot;)  w1 = w2; w2 = nextword end","categories":["读书笔记"],"tags":["Lua"]},{"title":"读《Effective Java》后六章","url":"/2021_12_16_effective_java/","content":"第八章 Lambda 和 Stream在Java 8中，增加了函数接口(functional interface)、Lambda 和方法引用(methodreference)，使得创建函数对象(function object)变得很容易。与此同时，还增加了StreamAPI，为处理数据元素的序列提供了类库级别的支持。在本章中，将讨论如何最佳地利用这些机制。\n第42条：Lambda优先于匿名类根据以往的经验，是用带有单个抽象方法的接口(或者，几乎都不是抽象类)作为函数类型(function type)。它们的实例称作函数对象(function object)，表示函数或者要采取的动作。自从1997年发布 JDK1.1以来，创建函数对象的主要方式是通过匿名类(anonymousclass，详见第 24条)。下面是一个按照字符串的长度对字符串列表进行排序的代码片段，它用一个匿名类创建了排序的比较函数(加强排列顺序):\n//Anonymousclassinstanceasafunctionobject-obsolete！Collections.sort(words, new Comparator&lt;String&gt;() &#123;public int compare(String sl,String s2) &#123;return Integer.compare(s1.length(), s2.length());&#125;);\n\n匿名类满足了传统的面向对象的设计模式对函数对象的需求，最著名的有策略(Strategy)模式［Gamma95］。Comparator接口代表一种排序的抽象策略(abstract strategy);上述的匿名类则是为字符串排序的一种具体策略(concrete strategy)。但是，匿名类的烦琐使得在Java中进行函数编程的前景变得十分黯淡。\n在Java8中，形成了”带有单个抽象方法的接口是特殊的，值得特殊对待”的观念。这些接口现在被称作函数接口(functional interface)，Java 允许利用Lambda 表达式(Lambdaexpression，简称Lambda)创建这些接口的实例。Lambda 类似于匿名类的函数，但是比它简洁得多。以下是上述代码用Lambda 代替匿名类之后的样子。样板代码没有了，其行为也十分明确：\n//Lambda expression asfunction object(replaces anonymous class)Collections.sort(words(s1,s2) -&gt; Integer.compare(s1.1ength()，s2.1ength()));\n\n注意，Lambda 的类型(Comparator)、其参数的类型(sl 和 s2，两个都是String)及其返回值的类型(int)，都没有出现在代码中。编译器利用一个称作类型推导(type inference)的过程，根据上下文推断出这些类型。在某些情况下，编译器无法确定类型，你就必须指定。类型推导的规则很复杂：在JLS[JLS,18]中占了整章的篇幅。几乎没有程序员能够详细了解这些规则，但是没关系。删除所有Lambda 参数的类型吧，除非它们的存在能够使程序变得更加清晰。如果编译器产生一条错误消息，告诉你无法推导出Lambda参数的类型，那么你就指定类型。有时候还需要转换返回值或者整个Lambda表达式，但是这种情况很少见。\n关于类型推导应该增加一条警告。第26条告诉你不要使用原生态类型，第29条说过要支持泛型类型，第 30条说过要支持泛型方法。在使用Lambda时，这条建议确实非常重要，因为编译器是从泛型获取到得以执行类型推导的大部分类型信息的。如果你没有提供这些信息，编译器就无法进行类型推导，你就必须在Lambda中手工指定类型，这样极大地增加了它们的烦琐程度。如果上述代码片段中的变量words 声明为原生态类型List，而不是参数化的类型List，它就不会进行编译。\n当然，如果用Lambda表达式(详见第14条和第43条)代替比较器构造方法(comparatorconstruction method)，有时这个代码片段中的比较器还会更加简练：\nCollections.sort(words,comparingInt(String::length));\n\n事实上，如果利用Java8在List接口中添加的 sort方法，这个代码片段还可以更加简短一些：\n# words.sort(comparingInt(String::1ength));\n\nJava中增加了Lambda之后，使得之前不能使用函数对象的地方现在也能使用了。例如，以第 34 条中的 Operation 枚举类型为例。由于每个枚举的 apply方法都需要不同的行为，我们用了特定于常量的类主体，并覆盖了每个枚举常量中的 apply方法。通过以下代码回顾一下：\n//Enumtypewith constant-specificclassbodies&amp;data(Item 34)public enum Operation&#123;PLUS(&quot;+&quot;) &#123;public double apply(double x, double y) &#123; return × + y;&#125;MINUS(&quot;-&quot;)&#123;public double apply(double x，double y) &#123;return x-y;&#125;TIMES(&quot;*&quot;)&#123;public double apply(double x，double y) &#123; return × * y; &#125;DIVIDE(&quot;/&quot;)&#123;public double apply(double x,double y) &#123; return x / y;&#125;private final String symbol;Operation(String symbol) &#123; this.symbol = symbol;&#125;@Override public String toStringO &#123; return symbol;&#125;public abstract double apply(double x，double y);\n由第 34 条可知，枚举实例域优先于特定于常量的类主体。Lambda 使得利用前者实现特定于常量的行为变得比用后者来得更加容易了。只要给每个枚举常量的构造器传递一个实现其行为的Lambda 即可。构造器将 Lambda 保存在一个实例域中，apply方法再将调用转给Lambda。由此得到的代码比原来的版本更简单，也更加清晰:\n//Enum withfunction object fields &amp;constant-specificbehaviorpublic enum Operation &#123;PLUS(&quot;+&quot;，(x, y)-&gt;x+ y), MINUS(&quot;-&quot;，(x，y)-&gt;×-y),TIMES(&quot;*&quot;，(x，y)-&gt;×*y),DIVIDE(&quot;/&quot;，(x，y)-&gt;×/ y);private final String symbol;private final DoubleBinaryOperator op;Operation(String Symbol,DoubleBinaryOperator op) &#123;this.symbol = symbol;this.op = op;@Override public String toStringO &#123; return symbol;&#125;public double apply(double ×，double y)&#123;return op.applyAsDouble(x，y);\n\n注意，这里给Lambda使用了 DoubleBinaryOperator接口，代表枚举常量的行为。这是在java.util.function(详见第 44条)中预定义的众多函数接口之一。它表示一个带有两个 double 参数的函数，并返回一个 double结果。\n看看基于Lambda 的Operation 枚举，你可能会想，特定于常量的方法主体已经形同虚设了，但是实际并非如此。与方法和类不同的是，Lambda 没有名称和文档;如果一个计算本身不是自描述的，或者超出了几行，那就不要把它放在一个Lambda中。对于Lambda而言，一行是最理想的，三行是合理的最大极限。如果违背了这个规则，可能对程序的可读性造成严重的危害。如果Lambda很长或者难以阅读，要么找一种方法将它简化，要么重构程序来消除它。而且，传入枚举构造器的参数是在静态的环境中计算的。因而，枚举构造器中的Lambda无法访问枚举的实例成员。如果枚举类型带有难以理解的特定于常量的行为，或者无法在几行之内实现，又或者需要访问实例域或方法，那么特定于常量的类主体仍然是首选。\n同样地，你可能会认为，在Lambda时代，匿名类已经过时了。这种想法比较接近事实，但是仍有一些工作用Lambda 无法完成，只能用匿名类才能完成。Lambda限于函数接口。如果想创建抽象类的实例，可以用匿名类来完成，而不是用Lambda。同样地，可以用匿名类为带有多个抽象方法的接口创建实例。最后一点，Lambda 无法获得对自身的引用。在Lambda 中，关键字this 是指外围实例，这个通常正是你想要的。在匿名类中，关键字this 是指匿名类实例。如果需要从函数对象的主体内部访问它，就必须使用匿名类。\nLambda 与匿名类共享你无法可靠地通过实现来序列化和反序列化的属性。因此，尽可能不要(除非迫不得已)序列化一个Lambda(或者匿名类实例)。如果想要可序列化的函数对象，如Comparator，就使用私有静态嵌套类(详见第 24条)的实例。\n总而言之，从Java 8开始，Lambda 就成了表示小函数对象的最佳方式。千万不要给函数对象使用匿名类，除非必须创建非函数接口的类型的实例。同时，还要记住，Lambda 使得表示小函数对象变得如此轻松，因此打开了之前从未实践过的在Java 中进行函数编程的大门。\n第43条：方法引l用优先于Lambda与匿名类相比，Lambda 的主要优势在于更加简洁。Java 提供了生成比Lambda 更简洁函数对象的方法：方法引用(method reference)。以下代码片段的源程序是用来保持从任意键到Integer 值的一个映射。如果这个值为该键的实例数目，那么这段程序就是一个多集合的实现。这个代码片段的作用是，当这个键不在映射中时，将数字1和键关联起来;或者当这个键已经存在，就负责递增该关联值：\n# map.merge(key，1，(count， incr) -&gt; count + incr);\n\n注意，这行代码中使用了 merge方法，这是Java 8版本在 Map 接口中添加的。如果指定的键没有映射，该方法就会插人指定值;如果有映射存在，merge方法就会将指定的函数应用到当前值和指定值上，并用结果覆盖当前值。这行代码代表了merge 方法的典型用例。\n这样的代码读起来清晰明了，但仍有些样板代码。参数count 和incr 没有添加太多价值，却占用了不少空间。实际上，Lambda要告诉你的就是，该函数返回的是它两个参数的和。从 Java 8开始，Integer(以及所有其他的数字化基本包装类型都)提供了一个名为sum的静态方法，它的作用也同样是求和。我们只要传人一个对该方法的引用，就可以更轻松地得到相同的结果：\nmap.merge(key, 1, Integer::sum) ;\n\n方法带的参数越多能用方法引用消除的样板代码就越多。但在有些Lambda 中，即便它更长，但你所选择的参数名称提供了非常有用的文档信息，也会使得Lambda 的可读性更强，并且比方法引用更易于维护。\n只要方法引l用能做的事，就没有Lambda不能完成的(只有一种情况例外，有兴趣的读者请参见 JLS,9.9-2)。也就是说，使用方法引I用通常能够得到更加简短、清晰的代码。如果Lambda太长，或者过于复杂，还有另一种选择：从Lambda 中提取代码，放到一个新的方自己满意的方式编写进人文档。\n如果是用 IDE 编程，则可以在任何可能的地方都用方法引用代替Lambda。通常(但并非总是)应该让IDE把握机会好好表现一下。有时候，Lambda 也会比方法引用更加简洁明了。这种情况大多是当方法与Lambda 处在同一个类中的时候。比如下面的代码片段，假定发生在一个名为 GoshThisClas sNameIsHumongous 的类中:\nservice.execute(GoshThisClassNameIsHumongous::action);\nLambda版本的代码如下:\nservice.execute(() -&gt; action();\n这个代码片段使用了方法引用，但是它既不比Lambda更简短，也不比它更清晰，因此应该优先考虑Lambda。类似的还有 Function 接口，它用一个静态工厂方法返回 id 函数Function.identity()。如果它不用这个方法，而是在行内编写同等的Lambda 表达式:x-&gt;×，一般会比较简洁明了。\n许多方法引用都指向静态方法，但其中有 4种没有这么做。其中两个是有限制(bound)和无限制(unbound)的实例方法引用。在有限制的引用中，接收对象是在方法引[用中指定的。有限制的引[用本质上类似于静态引用：函数对象与被引用方法带有相同的参数。在无限制的引用中，接收对象是在运用函数对象时，通过在该方法的声明函数前面额外添加一个参数来指定的。无限制的引[用经常用在流管道(Stream pipeline)(详见第45条)中作为映射和过滤函数。最后，还有两种构造器(constructor)引用，分别针对类和数组。构造器引l用是充当工厂对象。这五种方法引用概括如下：\n\n总而言之，方法引用常常比Lambda表达式更加简洁明了。只要方法引用更加简洁、清晰，就用方法引用;如果方法引用并不简洁，就坚持使用Lambda。\n第44条：坚持使用标准的函数接口在 Java 具有Lambda 表达式之后，编写 API 的最佳实践也做了相应的改变。例如在模板方法(Template Method)模式［Gamma95］中，用一个子类覆盖基本类型方法(primitivemethod)，来限定其超类的行为，这是最不讨人喜欢的。现在的替代方法是提供一个接受函数对象的静态工厂或者构造器，便可达到同样的效果。在大多数情况下，需要编写更多的构造器和方法，以函数对象作为参数。需要非常谨慎地选择正确的函数参数类型。\n以LinkedHashMap 为例。每当有新的键添加到映射中时，put 就会调用其受保护的removeEldestEntry方法。如果覆盖该方法，便可以用这个类作为缓存。当该方法返回true，映射就会删除最早传人该方法的条目。下列覆盖代码允许映射增长到100个条目，然后每添加一个新的键，就会删除最早的那个条目，始终保持最新的100个条目：\nprotected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123;return size() &gt; 100;\n\n这个方法很好用，但是用Lambda 可以完成得更漂亮。假如现在编写LinkedHash-Map，它会有一个带函数对象的静态工厂或者构造器。看一下 removeEldestEntry的声明，你可能会以为该函数对象应该带一个Map.Entry&lt;K,V&gt;，并且返回一个boolean,但实际并非如此：removeEldestEntry方法会调用 size()，获取映射中的条目数量，这是因为 removeEldestEntrY是映射中的一个实例方法。传到构造器的函数对象则不是映射中的实例方法，无法捕捉到，因为调用其工厂或者构造器时，这个映射还不存在。所以，映射必须将它自身传给函数对象，因此必须传人映射及其最早的条目作为remove 方法的参数。声明一个这样的函数接口的代码如下：\n//Unnecessary functional interface;usea standard one insteadboolean remove(Map&lt;K,V&gt; map, Map.Entry&lt;K,V&gt; eldest);\n\n这个接口可以正常工作，但是不应该使用，因为没必要为此声明一个新的接口。jaVa.util.function 包已经为此提供了大量标准的函数接口。只要标准的函数接口能够满足需求，通常应该优先考虑，而不是专门再构建一个新的函数接口。这样会使API更加容易学习，通过减少它的概念内容，显著提升互操作性优势，因为许多标准的函数接口都提供了有用的默认方法。如 Predicate 接口提供了合并断言的方法。对于上述LinkedHashMap范例，应该优先使用标准的 BiPredicate&lt;Map&lt;K,V&gt;，Map.Entry&lt;K,V&gt;&gt;接口，而不是定制 EldestEntryRemovalFunction 接口。\njava.util.Function 中共有 43 个接口。别指望能够全部记住它们，但是如果能记住其中6个基础接口，必要时就可以推断出其余接口了。基础接口作用于对象引用类型。Operator接口代表其结果与参数类型一致的函数。Predicate接口代表带有一个参数并返回一个boolean 的函数。Function 接口代表其参数与返回的类型不一致的函数。Supplier接口代表没有参数并且返回(或”提供”)一个值的函数。最后，Consumer 代表的是带有一个函数但不返回任何值的函数，相当于消费掉了其参数。这6个基础函数接口概述如下:\n\n这6个基础接口各自还有 3 种变体，分别可以作用于基本类型 int、long 和 double。它们的命名方式是在其基础接口名称前面加上基本类型而得。因此，以带有 int 的 predicate接口为例，其变体名称应该是 IntPredicate，它是一个二进制运算符带有两个 long 值参数并返回一个 long 值 LongBinaryOperator。这些变体接口的类型都不是参数化的，除 Function 变体外，后者是以返回类型作为参数。例如，LongFunction&lt;int[]&gt;表示带有一个long参数，并返回一个int[]数组。\nFunction 接口还有9种变体，用于结果类型为基本类型的情况。源类型和结果类型始终不一样，因为从类型到自身的函数就是 UnaryOperator。如果源类型和结果类型均为基本类型，就是在 Function 前面添加格式如 ScrToResult，如LongToIntFunction(有6种变体)。如果源类型为基本类型，结果类型是一个对象参数，则要在 Function 前添加ToObj，如 DoubleToObjFunction(有 3 种变体)。\n这三种基础函数接口还有带两个参数的版本，如 BiPredicate&lt;T,U&gt;、BiFunction&lt;T,U,R&gt;和 BiConsumer&lt;T,U&gt;。还有 BiFunction 变体用于返回三个相关的基本类型:ToIntBiFunction&lt;T,U&gt;、ToLongBiFunction&lt;T,U&gt; 和 ToDoubleBiFunction&lt;T,U&gt;。Consumer接口也有带两个参数的变体版本，它们带一个对象引[用和一个基本类型：Obj-DoubleConsumer、ObjIntConsumer 和 ObjLongConsumer。总之，这些基础接口有9种带两个参数的版本。\n最后，还有 BooleanSupplier 接口，它是 Supplier 接口的一种变体，返回 boolean值。这是在所有的标准函数接口名称中唯一显式提到boolean 类型的，但 boolean 返回值是通过 Predicate 及其4种变体来支持的。BooleanSupplier 接口和上述段落中提及的42个接口，总计43个标准函数接口。显然，这是个大数目，但是它们之间并非纵横交错。另一方面，你需要的函数接口都替你写好了，它们的名称都是循规蹈矩的，需要的时候并不难找到。\n现有的大多数标准函数接口都只支持基本类型。千万不要用带包装类型的基础函数接口来代替基本函数接口。虽然可行，但它破坏了第61条的规则”基本类型优于装箱基本类型”。使用装箱基本类型进行批量操作处理，最终会导致致命的性能问题。\n现在知道了，通常应该优先使用标准的函数接口，而不是用自己编写的接口。但什么时候应该自己编写接口呢？当然，是在如果没有任何标准的函数接口能够满足你的需求之时，如需要一个带有三个参数的 predicate 接口，或者需要一个抛出受检异常的接口时，当然就需要自己编写啦。但是也有这样的情况：有结构相同的标准函数接口可用，却还是应该自己编写函数接口。\n还是以咱们的老朋友Comparator为例吧。它与ToIntBiFunction&lt;T,T&gt;接口在结构上一致，虽然前者被添加到类库中时，后一个接口已经存在，但如果用后者就错了。Comparator 之所以需要有自己的接口，有三个原因。首先，每当在 API 中使用时,其名称提供了良好的文档信息，并且被大量使用。其次，Comparator接口对于如何构成一个有效的实例，有着严格的条件限制，这构成了它的总则(general contract)。实现该接口相当于承诺遵守其契约。第三，这个接口配置了大量很好用的缺省方法，可以对比较器进行转换和合并。\n如果你所需要的函数接口与Comparator一样具有一项或者多项以下特征，则必须认真考虑自己编写专用的函数接口，而不是使用标准的函数接口：\n口通用，并且将受益于描述性的名称。\n口具有与其关联的严格的契约。\n口将受益于定制的缺省方法。\n如果决定自己编写函数接口，一定要记住，它是一个接口，因而设计时应当万分谨慎(详见第21条)。\n注意，EldestEntryRemovalFunction接口(详见第199页)是用@Functional-了程序员设计意图的语句，它有三个目的：告诉这个类及其文档的读者，这个接口是针对Lambda设计的;这个接口不会进行编译，除非它只有一个抽象方法;避免后续维护人员不小心给该接口添加抽象方法。必须始终用@Functionallnterface注解对自己编写的函数接口进行标注。\n最后一点是关于函数接口在 API中的使用。不要在相同的参数位置，提供不同的函数接口来进行多次重载的方法，否则可能在客户端导致歧义。这不仅仅是理论上的问题。比如可以编写一个客户端程序，要求进行一次转换，以显示正确的重载(详见第 52条)。避免这个问题的最简单方式是，不要编写在同一个参数位置使用不同函数接口的重载。这是该建议的一个特例，详情请见第52条。\n总而言之，既然Java 有了Lambda，就必须时刻谨记用Lambda 来设计API。输人时接受函数接口类型，并在输出时返回之。一般来说，最好使用java.util.function.Function 中提供的标准接口，但是必须警惕在相对罕见的几种情况下，最好还是自己编写专用的函数接口。\n第45条：谨慎使用Stream在 Java 8 中增加了 Stream API，简化了串行或并行的大批量操作。这个 API提供了两个关键抽象：Stream(流)代表数据元素有限或无限的顺序，Stream pipeline(流管道)则代表这些元素的一个多级计算。Stream 中的元素可能来自任何位置。常见的来源包括集合、数组、文件、正则表达式模式匹配器、伪随机数生成器，以及其他 Stream。Stream 中的数据元素可以是对象引l用，或者基本类型值。它支持三种基本类型：int、long 和 double。\n一个Stream pipeline中包含一个源Stream，接着是O个或者多个中间操作(intermediateoperation)和一个终止操作(terminal operation)。每个中间操作都会通过某种方式对 Stream进行转换，例如将每个元素映射到该元素的函数，或者过滤掉不满足某些条件的所有元素。所有的中间操作都是将一个Stream 转换成另一个Stream，其元素类型可能与输入的 Stream一样，也可能不同。终止操作会在最后一个中间操作产生的Stream 上执行一个最终的计算，例如将其元素保存到一个集合中，并返回某一个元素，或者打印出所有元素等。\nStream pipeline 通常是lazy的：直到调用终止操作时才会开始计算，对于完成终止操作不需要的数据元素，将永远都不会被计算。正是这种lazy 计算，使无限 Stream 成为可能。注意，没有终止操作的Stream pipeline 将是一个静默的无操作指令，因此千万不能忘记终止操作。\nStream API 是流式(fluent)的：所有包含 pipeline 的调用可以链接成一个表达式。事实上，多个pipeline 也可以链接在一起，成为一个表达式。\n在默认情况下，Stream pipeline 是按顺序运行的。要使 pipeline 并发执行，只需在该pipeline 的任何 Stream 上调用 parallel 方法即可，但是通常不建议这么做(详见第 48 条)。\nStreamAPI包罗万象，足以用Stream执行任何计算，但是”可以”并不意味着”应该”。如果使用得当，Stream 可以使程序变得更加简洁、清晰;如果使用不当，会使程序变得混乱且难以维护。对于什么时候应该使用Stream，并没有硬性的规定，但是可以有所启发。\n以下面的程序为例，它的作用是从词典文件中读取单词，并打印出单词长度符合用户指定的最低值的所有换位词。记住，包含相同的字母，但是字母顺序不同的两个词，称作换位词(anagram)。该程序会从用户指定的词典文件中读取每一个词，并将符合条件的单词放入一个映射中。这个映射键是按字母顺序排列的单词，因此”staple”的键是”aelpst”，”petals”的键也是‘“aelpst”：这两个词就是换位词，所有换位词的字母排列形式是一样的(有时候也叫alphagram)。映射值是包含了字母排列形式一致的所有单词。词典读取完成之后，每一个列表就是一个完整的换位词组。随后，程序会遍历映射的values()，预览并打印出单词长度符合极限值的所有列表。\n//Prints all large anagram groups in a dictionary iterativelypublic class Anagrams &#123;public static void main(String[] args) throws IOException &#123;File dictionary = new File(args[0]);int minGroupSize = Integer.parseInt(args[1]);Map&lt;String, Set&lt;String&gt;&gt; groups = new HashMap&lt;&gt;();try (Scanner s = new Scanner(dictionary)) &#123;while (s.hasNext() &#123;String word = s.next();groups.computeIfAbsent(alphabetize(word)(unused) -&gt; new TreeSet&lt;&gt;().add(word);for (Set&lt;String&gt; group : groups.values())if (group.size() &gt;= minGroupSize)System.out.println(group.size() + &quot;:&quot;+ group);private static String alphabetize(String s) &#123;char[] a = s.toCharArray○);Arrays.sort(a);return new String(a);\n\n这个程序中有一个步骤值得注意。被插入到映射中的每一个单词都以粗体显示，这是使用了 Java 8 中新增的computeIfAbsent 方法。这个方法会在映射中查找一个键：如果这个键存在，该方法只会返回与之关联的值。如果键不存在，该方法就会对该键运用指定的函数对象算出一个值，将这个值与键关联起来，并返回计算得到的值。computeIfAbsent方法简化了将多个值与每个键关联起来的映射实现。\n下面举个例子，它也能解决上述问题，只不过大量使用了Stream。注意，它的所有程序都是包含在一个表达式中，除了打开词典文件的那部分代码之外。之所以要在另一个表达式中打开词典文件，只是为了使用 try-with-resources 语句，它可以确保关闭词典文件:\n// Overuse of streams-don&#x27;t do this!public class Anagrams &#123;public static void main(String[] args)throws IOException &#123;Path dictionary = Paths.get(args[0]);int minGroupSize = Integer.parseInt(args[1]);try (Stream&lt;String&gt; words = Files.lines(dictionary)) &#123;words.collect(groupingBy(word -&gt; word.chars().sorted().collect(StringBuilder::new,(sb,c) -&gt; sb.append((char) c),StringBuilder::append).toStringO))values().stream().filter(group -&gt; group.size() &gt;= minGroupSize)(dnoub +:.+Oaz1sdnou6&lt;-dnoub)dewforEach(System.out::println);\n\n如果你发现这段代码好难懂，别担心，你并不是唯一有此想法的人。它虽然简短，但是难以读懂，对于那些使用 Stream 还不熟练的程序员而言更是如此。滥用 Stream 会使程序代码更难以读懂和维护\n好在还有一种舒适的中间方案。下面的程序解决了同样的问题，它使用了Stream，但是没有过度使用。结果，与原来的程序相比，这个版本变得既简短又清晰:\n//Tastefuluse of streams enhances clarity and concisenesspublicclassAnagrams&#123;public static void main(String[] args) throws IOException &#123;Path dictionary =Paths.get(args[0]);int minGroupSize=Integer.parseInt(args[i]);try (Stream&lt;String&gt; words =Files.lines(dictionary))&#123;words.collect(groupingBy(word -&gt; alphabetize(word)))values(.stream()filter(group -&gt; group.size() &gt;= minGroupSize)forEach(g-&gt;System.out.println(g.size(+&quot;:&quot;+g));//alphabetize method is the sameas inoriginalversion\n\n即使你之前没怎么接触过Stream，这段程序也不难理解。它在 try-with-resources 块中打开词典文件，获得一个包含了文件中所有代码的Stream。Stream 变量命名为words，是建议 Stream 中的每个元素均为单词。这个 Stream 中的 pipeline 没有中间操作;它的终止操作将所有的单词集合到一个映射中，按照它们的字母排序形式对单词进行分组(详见第46条)。这个映射与前面两个版本中的是完全相同的。随后，在映射的values()视图中打开了一个新的 Stream&lt;List&gt;。当然，这个 Stream 中的元素都是换位词分组。Stream 进行了过滤，把所有单词长度小于 minGroupSize 的单词都去掉了，最后，通过终止操作的 forEach 打印出剩下的分组。\n注意，Lambda 参数的名称都是经过精心挑选的。实际上参数应当以 group 命名，只是这样得到的代码行对于书本而言太宽了。在没有显式类型的情况下，仔细命名Lambda参数，这对于Streampipeline的可读性至关重要。\n还要注意单词的字母排序是在一个单独的 alphabetize 方法中完成的。给操作命名，并且不要在主程序中保留实现细节，这些都增强了程序的可读性。在 Stream pipeline 中使用 helper 方法，对于可读性而言，比在迭代化代码中使用更为重要，因为 pipeline 缺乏显式的类型信息和具名临时变量。\n可以重新实现 alphabetize 方法来使用 Stream，只是基于 Stream 的 alphabetize方法没那么清晰，难以正确编写，速度也可能变慢。这些不足是因为Java 不支持基本类型的charStream(这并不意味着Java应该支持charStream;也不可能支持)。为了证明用Stream 处理char 值的各种危险，请看以下代码:\n&quot;Hello world!&quot;.chars().forEach(System.out::print) ;\n\n或许你以为它会输出 He11oworld！，但是运行之后发现，它输出的是7210110810的元素，并不是 char 值，而是 int 值，因此调用了 print 的 int 覆盖。名为 chars 的方法，却返回 int值的 Stream，这固然会造成困扰。修正方法是利用转换强制调用正确的覆盖：\n&quot;Hello world!&quot;.chars().forEach(x -&gt; System.out.print((char) x));\n\n但是，最好避免利用Stream来处理char值。\n刚开始使用 Stream 时，可能会冲动到恨不得将所有的循环都转换成 Stream，但是切记，千万别冲动。这可能会破坏代码的可读性和易维护性。一般来说，即使是相当复杂的任务，最好也结合 Stream 和迭代来一起完成，如上面的 Anagrams 程序范例所示。因此，重构现有代码来使用Stream，并且只在必要的时候才在新代码中使用。\n如本条目中的范例程序所示，Stream pipeline利用函数对象(一般是Lambda或者方法引用)来描述重复的计算，而迭代版代码则利用代码块来描述重复的计算。下列工作只能通过代码块，而不能通过函数对象来完成：\n口从代码块中，可以读取或者修改范围内的任意局部变量;从Lambda则只能读取final 或者有效的 final 变量［JLS 4.12.4]，并且不能修改任何 local 变量。\n从代码块中，可以从外围方法中 return、break 或 continue 外围循环，或者抛出该方法声明要抛出的任何受检异常;从Lambda中则完全无法完成这些事情。\n如果某个计算最好要利用上述这些方法来描述，它可能并不太适合Stream。反之，Stream可以使得完成这些工作变得易如反掌：\n口统一转换元素的序列过滤元素的序列口利用单个操作(如添加、连接或者计算其最小值)合并元素的顺序口将元素的序列存放到一个集合中，比如根据某些公共属性进行分组口搜索满足某些条件的元素的序列\n如果某个计算最好是利用这些方法来完成，它就非常适合使用 Stream。\n利用 Stream 很难完成的一件事情就是，同时从一个 pipeline 的多个阶段去访问相应的元素：一旦将一个值映射到某个其他值，原来的值就丢失了。一种解决办法是将每个值都映射到包含原始值和新值的一个对象对(pair object)，不过这并非万全之策，当pipeline 的多个阶段都需要这些对象对时尤其如此。这样得到的代码将是混乱、繁杂的，违背了Stream的初衷。最好的解决办法是，当需要访问较早阶段的值时，将映射颠倒过来。\n例如，编写一个打印出前 20个梅森素数(Mersenne primes)的程序。解释一下，梅森素数是一个形式为 2P-1的数字。如果p是一个素数，相应的梅森数字也是素数;那么它就是一个梅森素数。作为 pipeline 的第一个Stream，我们想要的是所有素数。下面的方法将返回(无限)Stream。假设使用的是静态导人，便于访问 BigInteger 的静态成员:\nstatic Stream&lt;BigInteger&gt;primes( &#123;return Stream.iterate(TwO, BigInteger::nextProbablePrime);\n\n方法的名称(primes)是一个复数名词，它描述了Stream 的元素。强烈建议返回Stream 的所有方法都采用这种命名惯例，因为可以增强 Stream pipeline 的可读性。该方法使用静态工厂Stream.iterate，它有两个参数：Stream 中的第一个元素，以及从前一个\npublic static void main(String[] args)&#123;.filter(mersenne -&gt;mersenne.isProbablePrime(50)).1imit(20).forEach(System.out::println);\n\n这段程序是对上述内容的简单编码示范：它从素数开始，计算出相应的梅森素数，过滤掉所有不是素数的数字(其中50是个神奇的数字，它控制着这个概率素性测试)，限制最终得到的Stream为 20个元素，并打印出来。\n现在假设想要在每个梅森素数之前加上其指数(p)。这个值只出现在第一个 Stream 中,因此在负责输出结果的终止操作中是访问不到的。所幸将发生在第一个中间操作中的映射颠倒过来，便可以很容易地计算出梅森数字的指数。该指数只不过是一个以二进制表示的位数，因此终止操作可以产生所要的结果：\n.forEach(mp -&gt; System.out.println(mp.bitLength() +&quot;:&quot;+ mp));\n\n现实中有许多任务并不明确要使用Stream，还是用迭代。例如有个任务是要将一副新纸牌初始化。假设Card 是一个不变值类，用于封装Rank 和 Suit，这两者都是枚举类型。这项任务代表了所有需要计算从两个集合中选择所有元素对的任务。数学上称之为两个集合的笛卡尔积。这是一个迭代化实现，嵌人了一个for-each 循环，大家对此应当都非常熟悉了：\n//IterativeCartesianproduct computationprivate static List&lt;Card&gt; newDeck()&#123;List&lt;Card&gt; result = new ArrayList&lt;&gt;(;for (Suit suit : Suit.valuesO)for (Rank rank : Rank.values()result.add(new Card(suit, rank));return result;\n\n这是一个基于 Stream 的实现，利用了中间操作 flatMap。这个操作是将 Stream 中的每们扁平化。注意，这个实现中包含了一个嵌人式的Lambda，如以下粗体部分所示：\n//Stream-based Cartesian product computationprivate static List&lt;Card&gt;newDeck()return Stream.of(Suit.valuesO).flatMap(suit-&gt;Stream.of(Rank.values()).map(rank -&gt; new Card(suit,rank))).collect(toListO);\n\n这两种 newDeck版本哪一种更好？这取决于个人偏好，以及编程环境。第一种版本比较简单，可能感觉比较自然，大部分Java 程序员都能够理解和维护，但是有些程序员可能会觉得第二种版本(基于Stream的)更舒服。这个版本可能更简洁一点，如果已经熟练掌握Stream和函数编程，理解起来也不难。如果不确定要用哪个版本，或许选择迭代化版本会更加安全一些。如果更喜欢Stream 版本，并相信后续使用这些代码的其他程序员也会喜欢，就应该使用 Stream 版本。\n总之，有些任务最好用 Stream 完成，有些则要用迭代。而有许多任务则最好是结合使用这两种方法来一起完成。具体选择用哪一种方法，并没有硬性、速成的规则，但是可以参考一些有意义的启发。在很多时候，会很清楚应该使用哪一种方法;有些时候，则不太明显。如果实在不确定用Stream还是用迭代比较好，那么就两种都试试，看看哪一种更好用吧\n第46条：优先选择Stream中无副作用的函数如果刚接触 Stream，可能比较难以掌握其中的窍门。就算只是用 Stream pipeline来表达计算就困难重重。当你好不容易成功了，运行程序之后，却可能感到这么做并没有享受到多大益处。Stream 并不只是一个API，它是一种基于函数编程的模型。为了获得Stream 带来的描述性和速度，有时还有并行性，必须采用范型以及API。\nStream 范型最重要的部分是把计算构造成一系列变型，每一级结果都尽可能靠近上一级结果的纯函数(pure function)。纯函数是指其结果只取决于输入的函数：它不依赖任何可变的状态，也不更新任何状态。为了做到这一点，传入Stream 操作的任何函数对象，无论是中间操作还是终止操作，都应该是无副作用的。\n有时会看到如下代码片段，它构建了一张表格，显示这些单词在一个文本文件中出现的频率：\n//Uses the streams API but not the paradigm--Don&#x27;t do this!Map&lt;String，Long&gt;freq =new HashMap&lt;&gt;O;try (Stream&lt;String&gt; words = new Scanner(file).tokens())&#123;words.forEach(word -&gt;&#123;freq.merge(word.toLowerCase)，1l,Long::sum);\n\n以上代码有什么问题吗？它毕竟使用了Stream、Lambda 和方法引用，并且得出了正确的答案。简而言之，这根本不是Stream代码;只不过是伪装成Stream 代码的迭代式代码。它并没有享受到Stream API带来的优势，代码反而更长了点，可读性也差了点，并且比相应的选代化代码更难维护。因为这段代码利用一个改变外部状态(频率表)的Lambda，完成了在终止操作的forEach 中的所有工作。forEach 操作的任务不只展示由 Stream 执行的计算结果，这在代码中并非好事，改变状态的Lambda也是如此。那么这段代码应该是什么样的呢？\n//Properuseofstreamstoinitializea frequencytableMap&lt;String，Long&gt;freq;try (Stream&lt;String&gt; words = new Scanner(file).tokensO)&#123;freq = words.collect(groupingBy(String::toLowerCase, countingO));&#125;\n\n这个代码片段的作用与前一个例子一样，只是正确使用了Stream API，变得更加简洁、清晰。那么为什么有人会以其他的方式编写呢？这是为了使用他们已经熟悉的工具。Java程序员都知道如何使用 for-each 循环，终止操作的 forEach 也与之类似。但 forEach 操作是终止操作中最没有威力的，也是对 Stream 最不友好的。它是显式迭代，因而不适合并行。forEach 操作应该只用于报告Stream 计算的结果，而不是执行计算。有时候，也可以将 forEach 用于其他目的，比如将 Stream 计算的结果添加到之前已经存在的集合中去。\n改进过的代码使用了一个收集器(collector)，为了使用Stream，这是必须了解的一个新概念。Co1lectors API很吓人：它有 39 种方法，其中有些方法还带有5个类型参数！好消息是，你不必完全搞懂这个API就能享受它带来的好处。对于初学者，可以忽略Collector接口，并把收集器当作封装缩减策略的一个黑盒子对象。在这里，缩减的意思是将Stream的元素合并到单个对象中去。收集器产生的对象一般是一个集合(即名称收集器)。\n将 Stream 的元素集中到一个真正的Collection 里去的收集器比较简单。有三个这样的收集器：toList()、toSet()和toCollection(collectionFactory)。它们分别返回一个列表、一个集合和程序员指定的集合类型。了解了这些，就可以编写Streampipeline，从频率表中提取排名前十的单词列表了:\n//Pipelinetogetatop-tenlistofwordsfromafrequencytableList&lt;String&gt; topTen = freq.keySet().streamO. sorted(comparing(freq: :get) .reversed())1imit(10)collect(toList());\n\n注意，这里没有给toList方法配上它的 Collectors 类。静态导入 collectors 的所有成员是惯例也是明智的，因为这样可以提升Streampipeline的可读性。\nreversed()。comparing 方法是一个比较器构造方法(详见第14条)，它带有一个键提取函数。函数读取一个单词，”提取”实际上是一个表查找：有限制的方法引用 freq：:get在频率表中查找单词，并返回该单词在文件中出现的次数。最后，在比较器上调用reversed，按频率高低对单词进行排序。后面的事情就简单了，只要限制 Stream 为10个单词，并将它们集中到一个列表中即可。\n上一段代码是利用 Scanner的 Stream方法来获得Stream。这个方法是在Java 9中增加的。如果使用的是更早的版本，可以把实现Iterator 的扫描器，翻译成使用了类似于第47条中适配器的Stream(streamOf(Iterable))。\nCollectors中的另外 36种方法又是什么样的呢？它们大多数是为了便于将 Stream集合到映射中，这远比集中到真实的集合中要复杂得多。每个Stream 元素都有一个关联的键和值，多个Stream元素可以关联同一个键。\n最简单的映射收集器是toMap(keyMapper，ValueMapper)，它带有两个函数，其中一个是将 Stream 元素映射到键，另一个是将它映射到值。我们采用第 34 条fromString实现中的收集器，将枚举的字符串形式映射到枚举本身：\n//UsingatoMapcollectortomakeamapfromstringto enumprivate static final Map&lt;String, Operation&gt; stringToEnum =Stream.of(values()).collect(toMap(Object::toString,e -&gt; e));\n\n如果Stream 中的每个元素都映射到一个唯一的键，那么这个形式简单的toMap是很完美的。如果多个 Stream 元素映射到同一个键，pipeline 就会抛出一个 IllegalState-Exception异常将它终止。\ntoMap 更复杂的形式，以及 groupingBy方法，提供了更多处理这类冲突的策略。其中一种方式是除了给toMap 方法提供了键和值映射器之外，还提供一个合并函数(mergefunction)。合并函数是一个 BinaryOperator，这里的V是映射的值类型。合并函数将与键关联的任何其他值与现有值合并起来，因此，假如合并函数是乘法，得到的值就是与该值映射的键关联的所有值的积。\n带有三个参数的toMap 形式，对于完成从键到与键关联的被选元素的映射也是非常有用的。假设有一个Stream，代表不同歌唱家的唱片，我们想得到一个从歌唱家到最畅销唱片之间的映射。下面这个收集器就可以完成这项任务。\n# Map&lt;Artist, Album&gt; topHits = albums.collect(toMap(Album::artist, a-&gt;a, maxBy(comparing(Album::sales))));\n\n注意，这个比较器使用了静态工厂方法 maxBy，这是从 BinaryOperator静态导入的。该方法将 Comparator转换成一个 BinaryOperator，用于计算指定比较器产生的最大值。在这个例子中，比较器是由比较器构造器方法 comparing 返回的，它有一个键提取函数Album：:SaleS。这看起来有点绕，但是代码的可读性良好。不严格地说,它的意思是”将唱片的Stream 转换成一个映射，将每个歌唱家映射到销量最佳的唱片”。这就非常接近问题陈述了。\n带有三个参数的toMap形式还有另一种用途，即生成一个收集器，当有冲突时强制”保留最后更新”(last-write-wins)。对于许多Stream 而言，结果是不确定的，但如果与映射函数的键关联的所有值都相同，或者都是可接受的，那么下面这个收集器的行为就正是你所要的：\n# // Collector to impose last-write-wins policytoMap(keyMapper，valueMapper，(oldVal， newVa1) )-&gt;new?Va1)\n\ntoMap 的第三个也是最后一种形式是，带有第四个参数，这是一个映射工厂，在使用时要指定特殊的映射实现，如 EnumMap 或者 TreeMap。\ntoMap 的前三种版本还有另外的变换形式，命名为toConcurrentMap，能有效地并行运行，并生成ConcurrentHashMap 实例。\n除了 toMap 方法，Collectors API还提供了 groupingBy方法，它返回收集器以生成映射，根据分类函数将元素分门别类。分类函数带有一个元素，并返回其所属的类别。这个类别就是元素的映射键。groupingBy方法最简单的版本是只有一个分类器，并返回一个映射，映射值为每个类别中所有元素的列表。下列代码就是在第 45条的 Anagram 程序中用于生成映射(从按字母排序的单词，映射到字母排序相同的单词列表)的收集器：\n# words.collect(groupingBy(word -&gt; alphabetize(word)))\n\n如果要让groupingBy返回一个收集器，用它生成一个值而不是列表的映射，除了分类器之外，还可以指定一个下游收集器(downstream collector)。下游收集器从包含某个类别中所有元素的Stream 中生成一个值。这个参数最简单的用法是传人toSet()，结果生成一个映射，这个映射值为元素集合而非列表。\n另一种方法是传人toCollection(collectionFactory)，允许创建存放各元素类别的集合。这样就可以自由选择自己想要的任何集合类型了。带两个参数的 groupingBy版本的另一种简单用法是，传人counting()作为下游收集器。这样会生成一个映射，它将每个类别与该类别中的元素数量关联起来，而不是包含元素的集合。这正是在本条目开头处频率表范例中见到的：\n# Map&lt;String, Long&gt; freq = words.collect(groupingBy(String::toLowerCase, counting());\n\ngroupingBy的第三个版本，除了下游收集器之外，还可以指定一个映射工厂。注意，这个方法违背了标准的可伸缩参数列表模式：参数mapFactory要在downStream 参数之前，而不是在它之后。groupingBy 的这个版本可以控制所包围的映射，以及所包围的集合，因此，比如可以定义一个收集器，让它返回值为TreeSets 的TreeMap。\ngroupingByConcurrent 方法提供了 groupingBy 所有三种重载的变体。这些变体可变体叫作 partitioningBy。除了分类方法之外，它还带一个断言(predicate)，并返回一个键为 Boolean 的映射。这个方法有两个重载，其中一个除了带有断言之外，还带有下游\n收集器。\ncounting 方法返回的收集器仅用作下游收集器。通过在 Stream 上的count方法，直接就有相同的功能，因此压根没有理由使用collect(counting())。这个属性还有 15种Collectors 方法。其中包含9种方法其名称以 summing、averaging 和 summarizing开头(相应的 Stream 基本类型上就有相同的功能)。它们还包括 reducing、filtering、mapping、flatMapping 和 collectingAndThen 方法。大多数程序员都能安全地避开这里的大多数方法。从设计的角度来看，这些收集器试图部分复制收集器中Stream 的功能，以便下游收集器可以成为”ministream”。\n目前已经提到了3个Collectors 方法。虽然它们都在Collectors 中，但是并不包含集合。前两个是 minBy和 maxBy，它们有一个比较器，并返回由比较器确定的 Stream中的最少元素或者最多元素。它们是 Stream接口中 min 和 max方法的粗略概括，也是唱片范例中用过的 BinaryOperator.maxBy方法。\n最后一个Collectors方法是joining，它只在CharSequence实例的 Stream 中操作，例如字符串。它以参数的形式返回一个简单地合并元素的收集器。其中一种参数形式在相邻元素之间插入分隔符的收集器。如果传人一个逗号作为分隔符，收集器就会返回一个用逗号隔开的值字符串(但要注意，如果Stream中的任何元素中包含逗号，这个字符串就会引起歧义)。这三种参数形式，除了分隔符之外，还有一个前缀和一个后缀。最终的收集器生成的字符串，会像在打印集合时所得到的那样，如［came，saw，conquered」。\n总而言之，编写 Stream pipeline 的本质是无副作用的函数对象。这适用于传人 Stream及相关对象的所有函数对象。终止操作中的forEach 应该只用来报告由 Stream 执行的计算结果，而不是让它执行计算。为了正确地使用Stream，必须了解收集器。最重要的收集器工厂是toList、toSet、toMap、groupingBy和joining。\n第47条：Stream要优先用Collection作为返回类型许多方法都返回元素的序列。在Java 8之前，这类方法明显的返回类型是集合接口Collection、Set 和 List;Iterable;以及数组类型。一般来说，很容易确定要返回这其中哪一种类型。标准是一个集合接口。如果某个方法只为 for-each 循环或者返回序列而存在，无法用它来实现一些 Collection 方法(一般是contains(Object))，那么就用Iterable接口吧。如果返回的元素是基本类型值，或者有严格的性能要求，就使用数组。更复杂了。\n或许你曾听说过，现在 Stream 是返回元素序列最明显的选择了，但如第 45条所述，Stream并没有淘汰迭代：要编写出优秀的代码必须巧妙地将Stream与迭代结合起来使用。如果一个API只返回一个Stream，那些想要用for-each 循环遍历返回序列的用户肯定要失望了。因为 Stream 接口只在 Iterable接口中包含了唯一一个抽象方法，Stream 对于该方法的规范也适用于 Iterable 的。唯一可以让程序员避免用 for-each 循环遍历 Stream的是 Stream 无法扩展 Iterable 接口。\n遗憾的是，这个问题还没有适当的解决办法。乍看之下，好像给 Stream 的 iterator方法传人一个方法引用可以解决。这样得到的代码可能有点杂乱、不清晰，但也不算难以理解:\n//Won&#x27;t compile,due to limitations on Java&#x27;s type inferencefor (ProcessHandle ph :ProcessHandle.allProcesses(::iterator)&#123;//Process theprocess\n\n遗憾的是，如果想要编译这段代码，就会得到一条报错的信息：\nTest.java:6: error: method reference not expected herefor (ProcessHandle ph : ProcessHandle.allProcesses()::iterator) &#123;\n\n为了使代码能够进行编译，必须将方法引用转换成适当参数化的Iterable:\n// Hideous workaround to iterate over a streamfor (ProcessHandle ph :(Iterable&lt;ProcessHandle&gt;)ProcessHandle.allProcesses()::iterator)\n\n这个客户端代码可行，但是实际使用时过于杂乱、不清晰。更好的解决办法是使用适配器方法。JDK没有提供这样的方法，但是编写起来很容易，使用在上述代码中内嵌的相同方法即可。注意，在适配器方法中没有必要进行转换，因为Java 的类型引用在这里正好派上了用场：\n//AdapterfromStream&lt;E&gt;toIterable&lt;E&gt;public static&lt;E&gt;Iterable&lt;E&gt;iterableOf(Stream&lt;E&gt; stream)&#123;return stream::iterator;有了这个适配器，就可以利用for-each 语句遍历任何 Stream:for(ProcessHandle p:iterableOf(ProcessHandle.allProcesses())&#123;//Process theprocess了\n注意，第 34条中 Anagrams 程序的 Stream版本是使用 Files.lines 方法读取词典,而迭代版本则使用了扫描器(scanner)。Files.lines 方法优于扫描器，因为后者默默地吞掉了在读取文件过程中遇到的所有异常。最理想的方式是在迭代版本中也使用 Files.lines。这是程序员在特定情况下所做的一种妥协，比如当 API 只有 Stream 能访问序列,而他们想通过 for-each语句遍历该序列的时候。\n反过来说，想要利用 Stream pipeline 处理序列的程序员，也会被只提供 Iterable 的API搞得束手无策。同样地，JDK没有提供适配器，但是编写起来也很容易：\n//AdapterfromIterable&lt;E&gt;toStream&lt;E&gt;public static &lt;E&gt;Stream&lt;E&gt; streamOf(Iterable&lt;E&gt;iterable)&#123;return StreamSupport.stream(iterable.spliteratorO, false);子\n如果在编写一个返回对象序列的方法时，就知道它只在Stream pipeline 中使用，当然就可以放心地返回Stream了。同样地，当返回序列的方法只在迭代中使用时，则应该返回Iterable。但如果是用公共的 API返回序列，则应该为那些想要编写 Stream pipeline，以及想要编写for-each语句的用户分别提供，除非有足够的理由相信大多数用户都想要使用相同的机制。\nCollection 接口是Iterable的一个子类型，它有一个 stream方法，因此提供了迭代和 stream 访问。对于公共的、返回序列的方法，Collection 或者适当的子类型通常是最佳的返回类型。数组也通过 Arrays.asList 和 Stream.of方法提供了简单的迭代和 stream 访问。如果返回的序列足够小，容易存储，或许最好返回标准的集合实现，如ArrayList 或者HashSet。但是千万别在内存中保存巨大的序列，将它作为集合返回即可。\n如果返回的序列很大，但是能被准确表述，可以考虑实现一个专用的集合。假设想要返回一个指定集合的幂集(power set)，其中包括它所有的子集。a,b,c&#125;的幂集是&#123;&#123;&#125;，&#123;a&#125;，&#123;b&#125;，&#123;c&#125;，&#123;a，b&#125;，&#123;a，c&#125;，&#123;b，c&#125;，&#123;a，b，c&#125;&#125;。如果集合中有n个元素，它的幂集就有 2n个。因此，不必考虑将幂集保存在标准的集合实现中。但是，有了AbstractList 的协助，为此实现定制集合就很容易了。\n\n技巧在于，用幂集中每个元素的索引作为位向量，在索引中排第n位，表示源集合中第 n 位元素存在或者不存在。实质上，在二进制数0至 2n-1和有 n 位元素的集合的幂集之间，有一个自然映射。代码如下:\n//Returns thepower set of aninput set as custom collectionpublic class PowerSet &#123;public static final&lt;E&gt;Collection&lt;Set&lt;E&gt;&gt;of(Set&lt;E&gt;s)&#123;List&lt;E&gt; src=new ArrayList&lt;&gt;(s);if(src.size()&gt;30)throw new IllegalArgumentException(&quot;Set too big &quot;+ s);return new AbstractList&lt;Set&lt;E&gt;&gt;()&#123;@Override public int size()&#123;return 1&lt;&lt; src.size();//2to the power srcSize@Override public boolean contains(Object o)&#123;return o instanceof Set &amp;&amp; src.containsAll((Set)o);&#123;@Override public Set&lt;E&gt; get(int index)&#123;Set&lt;E&gt; result = new HashSet&lt;&gt;();for (int i = 0;index != 0;i++，index &gt;&gt;= 1)if((index &amp; 1)==1)result.add(src.get(i));return result;;\n\n注意，如果输人值集合中超过30个元素,PowerSet.of会抛出异常。这正是用Collection而不是用 Stream 或Iterable作为返回类型的缺点：Collection 有一个返回 int类型的 size 方法，它限制返回的序列长度为 Integer.MAX_VALUE 或者 23’-1。如果集合更大，甚至无限大，Collection 规范确实允许 size 方法返回 2²-1，但这并非是最令人满意的解决方案。\n为了在 AbstractCollection上编写一个 Collection 实现，除了 Iterable必需的那一个方法之外，只需要再实现两个方法：contains 和 size。这些方法经常很容易编写出高效的实现。如果不可行，或许是因为没有在迭代发生之前先确定序列的内容，返回 Stream 或者Iterable，感觉哪一种更自然即可。如果能选择，可以尝试着分别用两个方法返回。\n有时候在选择返回类型时，只需要看是否易于实现即可。例如，要编写一个方法，用它返回一个输入列表的所有(相邻的)子列表。它只用三行代码来生成这些子列表，并将它们放在一个标准的集合中，但存放这个集合所需的内存是源列表大小的平方。这虽然没有幂集那么糟糕，但显然也是无法接受的。像给幂集实现定制的集合那样，确实很烦琐，这个可能还更甚，因为 JDK 没有提供基本的 Iterator 实现来支持。\n但是，实现输人列表的所有子列表的 Stream 是很简单的，尽管它确实需要有点洞察力。我们把包含列表第一个元素的子列表称作列表的前缀。例如，(a,b,c)的前缀就是(a)、(a,b)和(a,b，c)。同样地，把包含最后一个元素的子列表称作后缀，因此(a,b,c)的后缀就是(a,b,c)、(b,c)和(c)。考验洞察力的是，列表的子列表不过是前缀的后缀(或者说后缀的前缀)和空列表。这一发现直接带来了一个清晰且相当简洁的实现:\n//Returnsa stream ofallthesublistsofitsinputlistpublic class SubLists &#123;public static&lt;E&gt; Stream&lt;List&lt;E&gt;&gt;of(List&lt;E&gt; list)&#123;return Stream.concat(Stream.of(Collections.emptyList(),prefixes(list).flatMap(SubLists::suffixes));&#125;private static&lt;E&gt; Stream&lt;List&lt;E&gt;&gt;prefixes(List&lt;E&gt;list)&#123;return IntStream.rangeClosed(1, list.size().mapToObj(end -&gt; list.subList(0,end));private static &lt;E&gt;Stream&lt;List&lt;E&gt;&gt; suffixes(List&lt;E&gt; list)&#123;return IntStream.range(0, list.size().mapToObj(start -&gt; list.subList(start, list.size()));f\n\n注意，它用 Stream.concat 方法将空列表添加到返回的 Stream。另外还用 flatMap方法(详见第 45条)生成了一个包含了所有前缀的所有后缀的Stream。最后，通过映射IntStream.range 和 intStream.rangeClosed 返回的连续 int 值的 Stream，生成了前缀和后缀。通俗地讲，这一术语的意思就是指数为整数的标准 for 循环的 Stream 版本。因此，这个子列表实现本质上与明显的嵌套式 for 循环相类似:\nfor (int start = O; start&lt; src.size(; start++)for (int end = start + 1; end &lt;= src.size(); end++)System.out.println(src.subList(start, end));\n\n这个for循环也可以直接翻译成一个Stream。这样得到的结果比前一个实现更加简洁，但是可读性稍微差了一点。它本质上与第 45条中笛卡尔积的 Stream 代码相类似:\n//Returnsastreamofallthesublistsofitsinputlistpublic static&lt;E&gt;Stream&lt;List&lt;E&gt;&gt;of(List&lt;E&gt;list)&#123;return IntStream.range(0, 1ist.size()).mapToObj(start -&gt;IntStream.rangeClosed(start + 1, list.size()).mapToObj(end -&gt; list.subList(start，end))).flatMap(x -&gt; x);\n\n子\n像前面的for循环一样，这段代码也没有发出空列表。为了修正这个错误，也应该使用concat，如前一个版本中那样，或者用rangeClosed调用中的(int)Math.signum(start)代替1。\n子列表的这些 Stream 实现都很好，但这两者都需要用户在任何更适合迭代的地方，采用 Stream-to-Iterable适配器，或者用 Stream。Stream-to-Iterable适配器不仅打乱了客户端代码，在我的机器上循环的速度还降低了 2.3倍。专门构建的Collection 实现\n总而言之，在编写返回一系列元素的方法时，要记住有些用户可能想要当作Stream处果集合中已经有元素，或者序列中的元素数量很少，足以创建一个新的集合，那么就返回一个标准的集合，如 ArrayList。否则，就要考虑实现一个定制的集合，如幂集(power set)范例中所示。如果无法返回集合，就返回 Stream 或者Iterable，感觉哪一种更自然即可。如果在未来的 Java 发行版本中，Stream 接口声明被修改成扩展了 Iterable接口，就可以放心地返回Stream了，因为它们允许进行Stream处理和迭代。\n第48条：谨慎使用Stream并行在主流的编程语言中，Java一直走在简化并发编程任务的最前沿。1996 年 Java 发布时,就通过同步和 wait&#x2F;notify内置了对线程的支持。Java5引l人了 java.util.concurrent类库，提供了并行集合(concurrent collection)和执行者框架(executor framework)。Java 7引人了 fork-join 包，这是一个处理并行分解的高性能框架。Java 8引人了 Stream，只需要调用一次 parallel 方法就可以实现并行处理。在 Java 中编写并发程序变得越来越容易，但是要编写出正确又快速的并发程序，则一向没那么简单。安全性和活性失败是并发编程中需要面对的问题，Stream pipeline并行也不例外。\n请看摘自第45条的这段程序：\n// Stream-based program to generate the first 20 Mersenne primespublic static void main(String[] args) &#123;primes().map(p -&gt; TwO.pow(p.intValueExact()).subtract(ONE)).filter(mersenne -&gt; mersenne.isProbablePrime(50))1imit(20).forEach(System.out::println);static Stream&lt;BigInteger&gt;primes() &#123;return Stream.iterate(TwO, BigInteger::nextProbablePrime);子\n\n在我的机器上，这段程序会立即开始打印素数，完成运行花了12.5秒。假设我天真地想通过在 Stream pipeline 上添加一个 parallel()调用来提速。你认为这样会对其性能产生什么样的影响呢？运行速度会稍微快一点点吗？还是会慢一点点？遗憾的是，其结果是根本不打印任何内容了，CPU的使用率却定在90%一动不动了(活性失败)。程序最后可能会终止，但是我不想一探究竟，半个小时后就强行把它终止了。\n这是怎么回事呢？简单地说，Stream类库不知道如何并行这个pipeline，以及如何探索失败。即便在最佳环境下，如果源头是来自 Stream.iterate，或者使用了中间操作的limit，那么并行 pipeline 也不可能提升性能。这个 pipeline 必须同时满足这两个条件。更糟糕的是，默认的并行策略在处理1imit的不可预知性时，是假设额外多处理几个元素，并放弃任何不需要的结果，这些都不会影响性能。在这种情况下，它查找每个梅森素数时，所花费的时间大概是查找之前元素的两倍。因而，额外多计算一个元素的成本，大概相当于计算所有之前元素总和的时间，这个貌似无伤大雅的 pipeline，却使得自动并行算法濒临崩溃。这个故事的寓意很简单：千万不要任意地并行 Stream pipeline。它造成的性能后果有可能是灾难性的。\n总之，在 Stream 上通过并行获得的性能，最好是通过ArrayList、HashMap、HashSet和 ConcurrentHashMap 实例，数组，int 范围和long 范围等。这些数据结构的共性是，都可以被精确、轻松地分成任意大小的子范围，使并行线程中的分工变得更加轻松。Stream类库用来执行这个任务的抽象是分割迭代器(spliterator)，它是由 Stream 和Iterable 中的 spliterator 方法返回的。\n这些数据结构共有的另一项重要特性是，在进行顺序处理时，它们提供了优异的引用局部性(locality of reference)：序列化的元素引用一起保存在内存中。被那些引l用访问到的对象在内存中可能不是一个紧挨着一个，这降低了引用的局部性。事实证明，引用局部性对于并行批处理来说至关重要：没有它，线程就会出现闲置，需要等待数据从内存转移到处理器的缓存。具有最佳引用局部性的数据结构是基本类型数组，因为数据本身是相邻地保存在内存中的。\nStream pipeline 的终止操作本质上也影响了并发执行的效率。如果大量的工作在终止操作中完成，而不是全部工作在 pipeline 中完成，并且这个操作是固有的顺序，那么并行pipeline 的效率就会受到限制。并行的最佳终止操作是做减法(reduction)，用一个 Stream 的reduce方法，将所有从 pipeline 产生的元素都合并在一起，或者预先打包像 min、max、count 和 sum 这类方法。骤死式操作(short-circuiting operation)如 anyMatch、allMatch和 noneMatch 也都可以并行。由 Stream 的 collect方法执行的操作，都是可变的减法，不是并行的最好选择，因为合并集合的成本非常高。\n如果是自已编写 Stream、Iterable 或者Collection实现，并且想要得到适当的并行性能，就必须覆盖 spliterator 方法，并广泛地测试结果 Stream 的并行性能。编写高质量的分割迭代器很困难，并且超出了本书的讨论范畴。\n并行Stream不仅可能降低性能，包括活性失败，还可能导致结果出错，以及难以预计的行为(如安全性失败)。安全性失败可能是因为并行的 pipeline 使用了映射、过滤器或者程序员自己编写的其他函数对象，并且没有遵守它们的规范。Stream 规范对于这些函数对象有着严格的要求条件。例如，传到 Stream 的 reduce 操作的收集器函数和组合器函数，必须是有关联、互不干扰，并且是无状态的。如果不满足这些条件(在第 46条中提到了一些),但是按序列运行 pipeline，可能会得到正确的结果;如果并发运行，则可能会突发性失败。\n以上值得注意的是，并行的梅森素数程序虽然运行完成了，但是并没有按正确的顺序(升序)打印出素数。为了保存序列化版本程序显示的顺序，必须用forEachOrdered 代替终止操作的forEach，它可以确保按encounter 顺序遍历并行的 Stream。\n假如在使用的是一个可以有效分割的源Stream，一个可并行的或者简单的终止操作,以及互不干扰的函数对象，那么将无法获得通过并行实现的提速，除非 pipeline 完成了足够的实际工作，抵消了与并行相关的成本。据不完全估计，Stream 中的元素数量，是每个元素所执行的代码行数的很多倍，至少是十万倍［Lea 14］。\n切记：并行Stream 是一项严格的性能优化。对于任何优化都必须在改变前后对性能进行测试，以确保值得这么做(详见第67条)。最理想的是在现实的系统设置中进行测试。一般来说，程序中所有的并行 Stream pipeline 都是在一个通用的 fork-join 池中运行的。只要有一个 pipeline 运行异常，都会损害到系统中其他不相关部分的性能。\n听起来貌似在并行 Stream pipeline 时怪事连连，其实正是如此。我有个朋友，他发现在大量使用Stream 的几百万行代码中，只有少数几个并行 Stream是有效的。这并不意味着应该避免使用并行Stream。在适当的条件下，给Streampipeline添加paralle1调用，确实可以在多处理器核的情况下实现近乎线性的倍增。某些域如机器学习和数据处理，尤其适用于这样的提速。\n简单举一个并行 Stream pipeline 有效的例子。假设下面这个函数是用来计算 π(n)，素数的数量少于或者等于n:\n//Prime-counting streampipeline -benefits from parallelizationstatic long pi(long n) &#123;return LongStream.rangeClosed(2, n).mapToObj(BigInteger::valueOf).filter(i -&gt; i.isProbablePrime(50))countO;\n\n在我的机器上，这个函数花31秒完成了计算 π(10”)。只要添加一个parallel()调用，就把调用时间减少到了9.2秒：\n// Prime-counting stream pipeline - parallel versionstatic long pi(long n) &#123;return LongStream.rangeClosed(2, n).parallel().mapToObj(BigInteger::valueOf).filter(i -&gt; i.isProbablePrime(50)).count();\n\n换句话说，并行计算在我的四核机器上添加了 parallel()调用后，速度加快了3.7倍。值得注意的是，这并不是在实践中计算 n值很大时的 π(n)的方法。还有更加高效的算法，如著名的Lehmer公式。\n如果要并行一个随机数的 Stream，应该从 SplittableRandom 实例开始，而不是从ThreadLocalRandom(或实际上已经过时的 Random)开始。SplittableRandom 正是专门为此设计的，还有线性提速的可能。ThreadLocalRandom 则只用于单线程，它将自身当作一个并行的 Stream 源运用到函数中，但是没有 SplittableRandom那么快。Random 在每个操作上都进行同步，因此会导致滥用，扼杀了并行的优势。\n总而言之，尽量不要并行 Stream pipeline，除非有足够的理由相信它能保证计算的正确性，并且能加快程序的运行速度。如果对Stream 进行不恰当的并行操作，可能导致程序运行失败，或者造成性能灾难。如果确信并行是可行的，并发运行时一定要确保代码正确，并在真实环境下认真地进行性能测量。如果代码正确，这些实验也证明它有助于提升性能，只有这时候，才可以在编写代码时并行 Stream。\n\n\n本章要讨论方法设计的几个方面：如何处理参数和返回值，如何设计方法签名，如何为方法编写文档。本章大部分内容既适用于构造器，也适用于普通的方法。与第 4章一样，本章的焦点也集中在可用性、健壮性和灵活性上。\n第49条：检查参数的有效性大多数方法和构造器对于传递给它们的参数值都会有某些限制。例如，索引值必须是非负数，对象引用不能为 null，等等，这些都是很常见的。你应该在文档中清楚地指明这些限制，并且在方法体的开头处检查参数，以强制施加这些限制。它是”发生错误之后应该尽快检测出错误”这一普遍原则的一种特例。如果不能做到这一点，检测到错误的可能性就比较小，即使检测到错误了，也比较难以确定错误的根源。\n如果传递无效的参数值给方法，这个方法在执行之前先对参数进行了检查，那么它很快就会失败，并且清楚地出现适当的异常(exception)。如果这个方法没有检查它的参数，就有可能发生几种情形。该方法可能在处理过程中失败，并且产生令人费解的异常。更糟糕的是，该方法可以正常返回，但是会悄悄地计算出错误的结果。最糟糕的是，该方法可以正常返回，但是却使得某个对象处于被破坏的状态，将来在某个不确定的时候，在某个不相关的点上会引发出错误。换句话说，没有验证参数的有效性，可能导致违背失败原子性(failure atomicity)，详见第76条。\n对于公有的和受保护的方法，要用Javadoc的@throws标签(tag)在文档中说明违反参数值限制时会抛出的异常(详见第74条)。这样的异常通常为IllegalArgumentException、IndexOutOfBoundsException 或 NullPointerException(详见第 72条)。一旦在文档中记录了对于方法参数的限制，并且记录了一旦违反这些限制将要抛出的异常，强加这些限制就是非常简单的事情了。下面是一个典型的例子:\n*** Returns a BigInteger whose value is (this mod m). This method*differs from the remainder method in that it always returns a* non-negative BigInteger.*@param m the modulus，which must be positive*@return this mod m* @throws ArithmeticException if m is less than or equal to0/public BigInteger mod(BigInteger m)&#123;if(m.signum() &lt;=0)throw new ArithmeticException(&quot;Modulus&lt;=0:&quot;+m);//Dothecomputation\n\n注意，文档注释中并没有说”如果m为 null,mod 就抛出 NullPointerException”,而是作为调用m.signum()的副产物，即使方法正是这么做的。这个异常的文档是建立在数。这样可以很好地避免分别在每个方法中给每个 NullPointerException 建立文档而引起的混乱。它可以结合@Nullable 或者类似的注解一起使用，表示某个特殊的参数可以为 null，不过这个实践不是标准的，有多个注解可以完成这个作用。\n在Java7中增加的objects.requireNonNul1方法比较灵活且方便，因此不必再手工进行null检查。只要你愿意，还可以指定自已的异常详情。这个方法会返回其输人,因此可以在使用一个值的同时执行 null检查：\n# //Inline useof Java&#x27;s null-checking facilitythis.strategy = Objects.requireNonNull(strategy, &quot;strategy&quot;);\n\n也可以忽略返回值，并在必要的地方，用 Objects.requireNonNull作为独立的null 检查。\n在 Java 9中增加了检查范围的设施：java.util.Objects。这个设施包含三个方法：checkFromIndexSize、checkFromToIndex 和 checkIndex。这个设施不像检查 null的方法那么灵活。它不允许指定自己的异常详情，而是专门设计用于列表和数组索引的。它不处理关闭的范围(包含其两个端点)。但是如果它所做的正是你需要的，那么就是一个有用的工具。\n对于未被导出的方法(unexported method)，作为包的创建者，你可以控制这个方法将在哪些情况下被调用，因此你可以，也应该确保只将有效的参数值传递进来。因此，非公有的方法通常应该使用断言(assertion)来检查它们的参数，具体做法如下所示:\n# assert offset &gt;=0&amp;&amp; offset &lt;=a.length;assert length &gt;= 0 &amp;length &lt;= a.length -offset;...// Do the computation\n\n从本质上讲，这些断言是在声称被断言的条件将会为真，无论外围包的客户端如何使用它。不同于一般的有效性检查，断言如果失败，将会抛出 AssertionError。不同于一般的有效性检查，如果它们没有起到作用，本质上也不会有成本开销，除非通过将-ea(或者-enableassertions)标记(flag)传递给Java 解释器，来启用它们。关于断言的更多信息，请见 Sun 的教程［Asserts］。\n对于有些参数，方法本身没有用到，却被保存起来供以后使用，检验这类参数的有效性尤为重要。比如，以第 20条中的静态工厂方法为例，它的参数为一个 int 数组，并返回该数组的List 视图。如果这个方法的客户端要传递 null，该方法将会抛出一个 NullPointer-如果省略了这个条件检查，它就会返回一个指向新建List实例的引用，一旦客户端企图使用这个引l用，立即就会抛出 NullPointerException。到那时，要想找到List实例的来源可能就非常困难了，从而使得调试工作更加复杂。\n如前所述，有些参数被方法保存起来供以后使用，构造器正是代表了这种原则的一种特例。检查构造器参数的有效性是非常重要的，这样可以避免构造出来的对象违反了这个类的约束条件。\n在方法执行它的计算任务之前，应该先检查它的参数，这一规则也有例外。一个很重要的例外是，在某些情况下，有效性检查工作非常昂贵，或者根本是不切实际的，而且有效性检查已隐含在计算过程中完成。例如，以为对象列表排序的方法 Collections.sort(List)为例，列表中的所有对象都必须是可以相互比较的。在为列表排序的过程中，列表中的每个对象将与其他某个对象进行比较。如果这些对象不能相互比较，其中的某个比较操作就会抛出 ClassCastException，这正是sort方法应该做的事情。因此，提前检查列表中的元素是否可以相互比较，这并没有多大意义。然而，请注意，不加选择地使用这种方法将会导致失去失败原子性(failure atomicity)，详见第76条。\n有时候，某些计算会隐式地执行必要的有效性检查，但是如果检查不成功，就会抛出错误的异常。换句话说，由于无效的参数值而导致计算过程抛出的异常，与文档中标明这个方法将抛出的异常并不相符。在这种情况下，应该使用第73条中讲述的异常转换(exception translation)技术，将计算过程中抛出的异常转换为正确的异常。\n请不要由本条目的内容得出这样的结论：对参数的任何限制都是件好事。相反，在设计方法时，应该使它们尽可能通用，并符合实际的需要。假如方法对于它能接受的所有参数值都能够完成合理的工作，对参数的限制就应该是越少越好。然而，通常情况下，有些限制对于被实现的抽象来说是固有的。\n简而言之，每当编写方法或者构造器的时候，应该考虑它的参数有哪些限制。应该把这些限制写到文档中，并且在这个方法体的开头处，通过显式的检查来实施这些限制。养成这样的习惯是非常重要的。只要有效性检查有一次失败，你为必要的有效性检查所付出的努力便都可以连本带利地得到偿还了。\n第50条：必要时进行保护性拷贝Java 用起来如此舒适的一个因素在于，它是一门安全的语言(safe language)。这意味着，它对于缓冲区溢出、数组越界、非法指针以及其他的内存破坏错误都自动免疫，而这些错误却困扰着诸如C和C++这样的不安全语言。在一门安全语言中，在设计类的时候，可以确切地知道，无论系统的其他部分发生什么问题，这些类的约束都可以保持为真。对于那些”把所有内存当作一个巨大的数组来对待”的语言来说，这是不可能的。\n即使在安全的语言中，如果不采取一点措施，还是无法与其他的类隔离开来。假设类的客户端会尽其所能来破坏这个类的约束条件，因此你必须保护性地设计程序。实际上，只有当有人试图破坏系统的安全性时，才可能发生这种情形;更有可能的是，对你的API产生误解的程序员，所导致的各种不可预期的行为，只好由类来处理。无论是哪种情况，编写一些面对客户的不良行为时仍能保持健壮性的类，这是非常值得投人时间去做的事情。\n如果没有对象的帮助，另一个类不可能修改对象的内部状态，但是对象很容易在无意识的情况下提供这种帮助。例如，以下面的类为例，它声称可以表示一段不可变的时间周期:\n//Broken &quot;immutable&quot;time period classpublic final class Period &#123;private final Date start;private final Date end;*** @paramstart the beginning of the period* @param end the end of the period; must not precede start* @throws IllegalArgumentException if start is after end* @throws NullPointerException if start or end is null*public Period(Date start，Date end)&#123;if (start.compareTo(end) &gt; 0)throw new IllegalArgumentException(start + &quot; after &quot; + end);this.start = start;this.end = end;public Date start() &#123;return start;public Date end()&#123;return end;//Remainder omitted\n\n乍看之下，这个类似乎是不可变的，并且强加了约束条件：周期的起始时间(start)不能在结束时间(end)之后。然而，因为Date类本身是可变的，因此很容易违反这个约束条件：\n//AttacktheinternalsofaPeriodinstanceDate start = new Date();Date end = new Date();Period p = new Period(start，end);end.setYear(78);// Modifies internals of p!\n\n从Java 8开始，修正这个问题最明显的方式是使用Instant(或LocalDateTime，或者ZonedDateTime)代替 Date，因为Instant(以及另一个java.time 类)是不可变的(详见第 17条)。Date 已经过时了，不应该在新代码中使用。也就是说，问题依然存在：有时候，还是需要在API和内部表达式中使用可变的值类型，本条目中讨论的方法正适用于这些情况。\n为了保护 Period 实例的内部信息避免受到这种攻击，对于构造器的每个可变参数进行保护性拷贝(defensive copy)是必要的，并且使用备份对象作为Period实例的组件，而不使用原始的对象：\n// Repaired constructor-makes defensive copies of parameterspublic Period(Date start，Date end) &#123;this.start = new Date(start.getTime());this.end  = new Date(end.getTime());if (this.start.compareTo(this.end) &gt; 0)throw new IllegalArgumentException(this.start +&quot; after &quot; + this.end);&#125;\n\n用了新的构造器之后，上述的攻击对于 Period 实例不再有效。注意，保护性拷贝是在检查参数的有效性(详见第49条)之前进行的，并且有效性检查是针对拷贝之后的对象，而不是针对原始的对象。虽然这样做看起来有点不太自然，却是必要的。这样做可以避免是指从检查参数开始，直到拷贝参数之间的时间段。在计算机安全社区中，这被称作Time-Of-Check&#x2F;Time-Of-Use或者TOCTOU攻击［ViegaO1]。\n同时也请注意，我们没有用 Date 的 clone 方法来进行保护性拷贝。因为 Date 是非final的，不能保证clone 方法一定返回类为java.util.Date 的对象：它有可能返回专门出于恶意的目的而设计的不可信子类的实例。例如，这样的子类可以在每个实例被创建的时候，把指向该实例的引用记录到一个私有的静态列表中，并且允许攻击者访问这个列表。这将使得攻击者可以自由地控制所有的实例。为了阻止这种攻击，对于参数类型可以被不可信任方子类化的参数，请不要使用clone方法进行保护性拷贝。\n虽然替换构造器就可以成功地避免上述的攻击，但是改变 Period 实例仍然是有可能的，因为它的访问方法提供了对其可变内部成员的访问能力：\n// Second attack on the internals of a Period instanceDate start = new Date();Date end = new Date();Period p = new Period(start， end);p.end().setYear(78); // Modifies internals of p!\n\n为了防御这第二种攻击，只需修改这两个访问方法，使它返回可变内部域的保护性拷贝:\n// Repaired accessors - make defensive copies of internal fieldspublic Date start() &#123;return new Date(start.getTime();public Date endO)&#123;return new Date(end.getTime();\n\n采用了新的构造器和新的访问方法之后，Period真正是不可变的了。不管程序员是多么恶意，或者多么不合格，都绝对不会违反”周期的起始时间不能晚于结束时间”这个约束条件。确实如此，因为除了 Period 类自身之外，其他任何类都无法访问 Period 实例中的任何一个可变域。这些域被真正封装在对象的内部。\n访问方法与构造器不同，它们在进行保护性拷贝的时候允许使用clone 方法。之所以如此，是因为我们知道，Period 内部的 Date 对象的类型是java.util.Date，而不可能是其他某个潜在的不可信子类。也就是说，基于第13条中所阐述的原因，一般情况下，最好使用构造器或者静态工厂。\n参数的保护性拷贝并不仅仅针对不可变类。每当编写方法或者构造器时，如果它允许客户提供的对象进人到内部数据结构中，则有必要考虑一下，客户提供的对象是否有可能是可变的。如果是，就要考虑你的类是否能够容忍对象进人数据结构之后发生变化。如果答案是否定的，就必须对该对象进行保护性拷贝，并且让拷贝之后的对象而不是原始对象进人到数据结构中。例如，如果你正在考虑使用由客户提供的对象引l用作为内部 Set实例的元素，或者作为内部Map实例的键(key)，就应该意识到，如果这个对象在插入之后再被修改，Set 或者 Map 的约束条件就会遭到破坏。\n在内部组件被返回给客户端之前，对它们进行保护性拷贝也是同样的道理。不管类是否为不可变的，在把一个指向内部可变组件的引用返回给客户端之前，也应该加倍认真地考虑。解决方案是，应该返回保护性拷贝。记住长度非零的数组总是可变的。因此，在把内部数组返回给客户端之前，总要进行保护性拷贝。另一种解决方案是，给客户端返回该数组的不可变视图(immutableview)。这两种方法在第15条中都已经演示过了。\n可以肯定地说，上述的真正启示在于，只要有可能都应该使用不可变的对象作为对象内部的组件，这样就不必再为保护性拷贝(详见第17条)操心。在前面的 Period 例子中，使用了Instant(或LocalDateTime，或者ZonedDateTime)，除非使用Java 8之前类型，而不是使用 Date 对象引用。\n保护性拷贝可能会带来相关的性能损失，这种说法并不总是正确的。如果类信任它的调用者不会修改内部的组件，可能因为类及其客户端都是同一个包的双方，那么不进行保护必拷贝也是可以的。在这种情况下，类的文档中就必须清楚地说明，调用者绝不能修改受到影响的参数或者返回值。\n即使跨越包的作用范围，也并不总是适合在将可变参数整合到对象中之前，对它进行保护性拷贝。有一些方法和构造器的调用，要求参数所引用的对象必须有个显式的交接(handoff)过程。当客户端调用这样的方法时，它承诺以后不再直接修改该对象。如果方法或者构造器期望接管一个由客户端提供的可变对象，它就必须在文档中明确地指明这一点。\n如果类所包含的方法或者构造器的调用需要移交对象的控制权，这个类就无法让自身抵御恶意的客户端。只有当类和它的客户端之间有着互相的信任，或者破坏类的约束条件不会伤害到除了客户端之外的其他对象时，这种类才是可以接受的。后一种情形的例子是包装类模式(详见第18条)。根据包装类的本质特征，客户端只需在对象被包装之后直接访问它，就可以破坏包装类的约束条件，但是，这么做往往只会伤害到客户端自己。\n简而言之，如果一个类包含有从客户端得到或者返回到客户端的可变组件，这个类就必须保护性地拷贝这些组件。如果拷贝的成本受到限制，并且类信任它的客户端不会不恰当地修改组件，就可以在文档中指明客户端的职责是不得修改受到影响的组件，以此来代替保护性拷贝。\n第51条：谨慎设计方法签名本条目是若干API设计技巧的总结，它们都还不足以单独开设一个条目。综合来说，这些设计技巧将有助于使你的API更易于学习和使用，并且比较不容易出错。\n谨慎地选择方法的名称。方法的名称应该始终遵循标准的命名习惯(详见第 68条)。首要目标应该是选择易于理解的，并且与同一个包中的其他名称风格一致的名称。第二个目标应该是选择与大众认可的名称(如果存在的话)相一致的名称。如果还有疑问，请参考Java类库的 API。尽管 Java类库的 API 中也有大量不一致的地方，考虑到这些 Java 类库的规模和范围，这是不可避免的，但它们还是得到了相当程度的认可。\n不要过于追求提供便利的方法。每个方法都应该尽其所能。方法太多会使类难以学习、使用、文档化、测试和维护。对于接口而言，这无疑是正确的，方法太多会使接口实现者和接口用户的工作变得复杂起来。对于类和接口所支持的每个动作，都提供一个功能齐全的方法。只有当一项操作被经常用到的时候，才考虑为它提供快捷方式(shorthand)。如果不能确定，最好不要提供快捷方式。\n避免过长的参数列表。目标是四个参数或者更少。大多数程序员都无法记住更长的参数列表。如果你编写的许多方法都超过了这个限制，你的 API就不太便于使用，除非用户不停地参考它的文档。现代的IDE通过智能提示会有所帮助，但最好还是使用简短的参数列表。相同类型的长参数序列格外有害。API的用户不仅无法记住参数的顺序，而且，当他们不小心弄错了参数顺序时，程序仍然可以编译和运行，只不过这些程序不会按照作者的意图进行工作。\n有三种技巧可以缩短过长的参数列表。第一种是把一个方法分解成多个方法，每个方法只需要这些参数的一个子集。如果不小心，这样做会导致方法过多。但是通过提升它们的正交性(orthogonality)，还可以减少(reduce)方法的数目。例如，考虑java.util.List接口。它并没有提供在子列表(sublist)中查找元素的第一个索引和最后一个索引的方法，这两个方法都需要三个参数。相反，它提供了 subList方法，这个方法带有两个参数，并起来，获得期望的功能，而这两个方法都分别只有一个参数。而且，subList方法也可以与其他任何”针对List实例进行操作”的方法结合起来，在子列表上执行任意的计算。这样得到的API就有很高的功能－权重(power-to-weight)比。\n缩短长参数列表的第二种技巧是创建辅助类(helper class)，用来保存参数的分组。这些辅助类一般为静态成员类(详见第 24条)。如果一个频繁出现的参数序列可以被看作是代表了某个独特的实体，则建议使用这种方法。例如，假设你正在编写一个表示纸牌游戏的类，你会发现经常要传递一个双参数的序列来表示纸牌的点数和花色。如果增加辅助类来表示一张纸牌，并且把每个参数序列都换成这个辅助类的单个参数，那么这个纸牌游戏类的API以及它的内部表示都可能会得到改进。\n结合了前两种技巧特征的第三种技巧是，从对象构建到方法调用都采用Builder模式(详见第2条)。如果方法带有多个参数，尤其是当它们中有些是可选的时候，最好定义一个对象来表示所有参数，并允许客户端在这个对象上进行多次”setter”(设置)调用，每次调用都设置一个参数，或者设置一个较小的相关的集合。一旦设置了需要的参数，客户端就调用对象的”执行”(execute)方法，它对参数进行最终的有效性检查，并执行实际的计算。\n对于参数类型，要优先使用接口而不是类(详见第64条)。只要有适当的接口可用来定义参数，就优先使用这个接口，而不是使用实现该接口的类。例如，没有理由在编写方法时使用 HashMap 类来作为输人，相反应当使用 Map 接口作为参数。这使你可以传人一个Hashtable、HashMap、TreeMap、TreeMap 的子映射表(submap)，或者任何有待于将来编写的Map实现。如果使用的是类而不是接口，则限制了客户端只能传人特定的实现，如果碰巧输入的数据是以其他的形式存在，就会导致不必要的、可能非常昂贵的拷贝操作。\n对于boolean参数，要优先使用两个元素的枚举类型。它使代码更易于阅读和编写，尤其是当你在使用支持自动完成功能的IDE时。它也使以后更易于添加其他的选项。例如，你可能会有一个 Thermometer 类型，它带有一个静态工厂方法，而这个静态工厂方法的签名需要带有这个枚举的值：\n# public enum TemperatureScale &#123; FAHRENHEIT,CELSIUS &#125;\n\nThermometer.newInstance (TemperatureScale.CELSIUS) 不仅比 Thermometer.newInstance(true)更有用，而且你还可以在未来的发行版本中将 KELVIN 添加到 Tem-依赖重构到枚举常量的方法中(详见第 34条)。例如，每个范围常量都可以有一个方法，它带有一个 double值，并将它规格化成摄氏度。\n第52条：慎用重载下面这个程序的意图是好的，它试图根据一个集合是 Set、List，还是其他的集合类型，来对它进行分类：\n// Broken! - What does this program print?public class CollectionClassifier&#123;public static String classify(Set&lt;?&gt; s)&#123;return &quot;Set&quot;;&#125;public static String classify(List&lt;?&gt; lst) &#123;return &quot;List&quot;;&#125;public static String classify(Collection&lt;?&gt; c)&#123;return &quot;Unknown Collection&quot;;子public static void main(String[] args) &#123;Collection&lt;?&gt;[] collections =&#123;new HashSet&lt;String&gt;(),new ArrayList&lt;BigInteger&gt;(),new HashMap&lt;String, String&gt;().values()for (Collection&lt;?&gt; c:collections)System.out.println(classify(c));\n\n你可能期望这个程序会打印出 Set，紧接着是List，以及 Unknown Collection，但实际上不是这样。它打印了三次 Unknown Collection。为什么会这样呢？因为classify方法被重载(overloaded)了，而要调用哪个重载方法是在编译时做出决定的。对于for循环中的全部三次迭代，参数的编译时类型都是相同的：Collection。每次迭代的运行时类型都是不同的，但这并不影响对重载方法的选择。因为该参数的编译时类型为Collection，所以，唯一合适的重载方法是classify(Collection&lt;?&gt;)，在循环的每次迭代中，都会调用这个重载方法。\n这个程序的行为有悖常理，因为对于重载方法的选择是静态的，而对于被覆盖的方法的选择则是动态的。选择被覆盖的方法的正确版本是在运行时进行的，选择的依据是被调用方法所在对象的运行时类型。这里重新说明一下，当一个子类包含的方法声明与其祖先类中的方法声明具有同样的签名时，方法就被覆盖了。如果实例方法在子类中被覆盖了，并且这个方法是在该子类的实例上被调用的，那么子类中的覆盖方法(overriding method)将会执行，而不管该子类实例的编译时类型到底是什么。为了进行更具体的说明，以下面的程序为例：\nclass Wine &#123;String name() &#123; return &quot;wine&quot;;&#125;class Sparklingwine extends Wine&#123;@Override String name( &#123; return &quot;sparkling wine&quot;;&#125;子class Champagne extends SparklingWine &#123;@Override String name( &#123; return &quot;champagne&quot;;&#125;public class Overriding &#123;public static void main(String[] args)&#123;List&lt;Wine&gt; wineList = List.of(new Wine(， new SparklingWine()， new Champagne();for (Wine wine :wineList)System.out.println(wine.nameO);\n\nname 方法是在类 Wine 中被声明的，但是在类 SparklingWine 和 Champagne 中被覆盖。正如你所预期的那样，这个程序打印出 wine、sparkling wine 和 champagne,尽管在循环的每次迭代中，实例的编译时类型都为Wine。当调用被覆盖的方法时，对象的编译时类型不会影响到哪个方法将被执行;”最为具体的”(most specific)那个覆盖版本总是会得到执行。这与重载的情形相比，对象的运行时类型并不影响”哪个重载版本将被执行”;选择工作是在编译时进行的，完全基于参数的编译时类型。\n在 CollectionClassifier 示例中，该程序的意图是：期望编译器根据参数的运行时类型自动将调用分发给适当的重载方法，以此来识别出参数的类型，就好像 Wine 的例子中的 name 方法所做的那样。方法重载机制完全没有提供这样的功能。假设需要有个静态方法，这个程序的最佳修正方案是，用单个方法来替换这三个重载的 classify方法，并在这个方法中做一个显式的instanceof测试：\npublic static String classify(Collection&lt;?&gt;c)&#123;return c instanceof Set?&quot;Set&quot;:Cinstanceof List ? &quot;List&quot;:&quot;Unknown Collection&quot;;\n\n因为覆盖机制是标准规范，而重载机制是例外，所以，覆盖机制满足了人们对于方法调用行为的期望。正如 CollectionClassifier 例子所示，重载机制很容易使这些期望落空。如果编写出来的代码的行为可能使程序员感到困惑，那么它就是很糟糕的实践。对于API来说尤其如此。如果API的普通用户根本不知道”对于一组给定的参数，其中的哪个重载方法将会被调用”，那么使用这样的API就很可能导致错误。这些错误要等到运行时发生了怪异的行为之后才会显现出来，导致许多程序员无法诊断出这样的错误。因此，应该避免\n胡乱地使用重载机制。到底是什么造成胡乱使用重载机制呢？这个问题仍有争议。安全而保守的策略是，永远不要导出两个具有相同参数数目的重载方法。如果方法使用可变参数，除第53条中所述的情形之外，保守的策略是根本不要重载它。如果你遵守这些限制，程序员永远也不会陷人”对于任何一组实际的参数，哪个重载方法才是适用的”这样的疑问中。这项限制并不麻烦，因为你始终可以给方法起不同的名称，而不使用重载机制。\n例如，以 ObjectOutputStream 类为例。对于每个基本类型，以及几种弓[用类型，它的 write 方法都有一种变形。这些变形方法并不是重载 write 方法，而是具有诸如 write-Boolean(boolean)、writeInt(int)和 writeLong(long)这样的签名。与重载方案相比较，这种命名模式带来的好处是，可以提供相应名称的读方法，比如 readBoolean()、\n对于构造器，你没有选择使用不同名称的机会;一个类的多个构造器总是重载的。在许多情况下，可以选择导出静态工厂，而不是构造器(详见第1条)。对于构造器，还不用担心重载和覆盖的相互影响，因为构造器不可能被覆盖。或许你有可能导出多个具有相同参数数目的构造器，所以有必要了解一下如何安全地做到这一点。\n如果对于”任何一组给定的实际参数将应用于哪个重载方法上”始终非常清楚，那么导出多个具有相同参数数目的重载方法就不可能使程序员感到混淆。对于每一对重载方型，就属于这种不会感到混淆的情形了。如果显然不可能把一种类型的实例转换为另一种类型，这两种类型就是根本不同的。在这种情况下，一组给定的实际参数应用于哪个重载方法上就完全由参数的运行时类型来决定，不可能受到其编译时类型的影响，所以主要的混淆根源就消除了。例如，ArrayList有一个构造器带一个 int参数，另一个构造器带一个Collection 参数。难以想象在任何情况下，这两个构造器被调用时哪一个会产生混淆。\n在Java5发行版本之前，所有的基本类型都根本不同于所有的引用类型，但是当自动装箱出现之后，就不再如此了，它会导致真正的麻烦。以下面这个程序为例：\npublic class SetList &#123;public static void main(String[]  args) &#123;Set&lt;Integer&gt; set = new TreeSet&lt;&gt;();List&lt;Integer&gt; list = new ArrayList&lt;&gt;();for (int i=-3;i&lt; 3;i++)&#123;set.add(i);list.add(i);for(int i= 0;i&lt; 3;i++)&#123;set.remove(i) ;list.remove(i) ;System.out.println(set + &quot; &quot; + list);\n\n首先，程序将-3至2之间的整数添加到了排好序的集合和列表中，然后在集合和列表中都进行3次相同的 remove 调用。如果像大多数人一样，希望程序从集合和列表中去除非整数值(0、1 和2)，并打印出［-3，-2，-1］［-3，-2，-1］。事实上，程序从集合中去除了非整数，还从列表中去除了奇数值，打印出［-3，-2，－1］［-2，0，2］。我们将这种行为称之为混乱，已是保守的说法。\n实际发生的情况是：set.remove(i)调用选择重载方法 remove(E)，这里的E是集合(Integer)的元素类型，将i从 int 自动装箱到Integer 中。这是你所期待的行为，因此程序不会从集合中去除正值。另一方面，list.remove(i)调用选择重载方法remove(int i)，它从列表的指定位置上去除元素。如果从列表［-3，-2，-1，0，1，2］开始，去除第零个元素，接着去除第一个、第二个，得到的是［-2，〇，2］，这个秘密被揭开了。为了解决这个问题，要将 1ist.remove 的参数转换成Integer，迫使选择正确的重载方法。另一种方法是调用 Integer.valueOf(i)，并将结果传给list.remove。这两种方法都如我们所料，打印出［-3，-2，－1］［-3，-2，－1］：\nfor(int i= 0;i&lt; 3;i++)&#123;set.remove(i);list.remove((Integer) i); // or remove(Integer.value0f(i))remove 方法：remove(E)和remove(int)。当它在Java 5发行版本中被泛型化之前,List接口有一个remove(Object)而不是remove(E)，相应的参数类型：Object和int，则根本不同。但是自从有了泛型和自动装箱之后，这两种参数类型就不再根本不同了。换句话说，Java 语言中添加了泛型和自动装箱之后，破坏了List接口。幸运的是，Java类库中几乎再没有 API受到同样的破坏，但是这种情形清楚地说明了，自动装箱和泛型成了Java语言的组成部分之后，谨慎重载显得更加重要了。\n\n在Java 8中增加了lambda 和方法引用之后，进一步增加了重载造成混淆的可能。比如，以下面这两个代码片段为例：\nnew Thread(System.out::println).start();# ExecutorService exec = Executors.newCachedThreadPool();exec.submit(System.out::println) ;\n\nThread 构造器调用和 submit 方法调用看起来很相似，但前者会进行编译，而后者不会。参数都是一样的(System.out：:println)，构造器和方法都有一个带有 Runnable的重载。这里发生了什么呢？令人感到意外的是：submit 方法有一个带有 Callable的重载，而 Thread构造器则没有。也许你会认为这应该没什么区别，因为所有的完美的，但重载方案的算法却不是这么做的。也许同样令人感到惊奇的是，如果 println方法也没有被重载，submit方法调用则是合法的。这是被引l用的方法(println)的重载，与被调用方法(submit)的结合，阻止了重载方案算法按你预期的方式完成。\n从技术的角度来看，问题在于，System.out：:println是一个不精确的方法引用(inexact method reference)［JLS,15.13.1]，而且”某些包含隐式类型 lambda 表达式或者不精确方法引用的参数表达式会被可用性测试忽略，因为它们的含义要到选择好目标类型之后才能确定［JLS,15.12.2』”。如果你不理解这段话的意思也没关系，这是针对编译器作者而言的。重点是在同一个参数位置，重载带有不同函数接口的方法或者构造器会造成混淆。因此，不要在相同的参数位置调用带有不同函数接口的方法。按照本条目的说法，不同的函数接口并非根本不同。如果传人命令行参数：-Xlint：overloads，Java 编译器会对这种有问题的重载发出警告。\n数组类型和 Object 之外的类截然不同。数组类型和 Serializable 与 Cloneable之外的接口也截然不同。如果两个类都不是对方的后代，这两个独特的类就是不相关的(unrelated)［JLS，5.5］。例如，String 和 Throwable 就是不相关的。任何对象都不可能是两个不相关的类的实例，因此不相关的类也是根本不同的。\n还有其他一些”类型对”的例子也是不能相互转换的［JLS,5.1.12］，但是，一旦超出了上述这些简单的情形，大多数程序员要想搞清楚”一组实际的参数应用于哪个重载方法上”就会非常困难。确定选择哪个重载方法的规则是非常复杂的，这些规则在每个发行版本中都变得越来越复杂。很少有程序员能够理解其中的所有微妙之处。\n有时候，尤其在更新现有类的时候，可能会被迫违反本条目的指导原则。例如，自从Java4 发行版本以来，String类就已经有一个contentEquals(StringBuffer)方法。在 Java 5 发行版本中，新增了一个称作 CharSequence 的接口，用来为 StringBuffer、StringBuilder、String、CharBuffer以及其他类似的类型提供公共接口。在Java平台中增加 CharSequence 的同时，String 也配备了重载的contentEquals 方法，即contentEquals (CharSequence) 方法。\n尽管这样的重载显然违反了本条目的指导原则，但是只要当这两个重载方法在同样的参数上被调用时，它们执行的是相同的功能，重载就不会带来危害。程序员可能并不知道哪个重载函数会被调用，但只要这两个方法返回相同的结果就行。确保这种行为的标准做法是，让更具体化的重载方法把调用转发给更一般化的重载方法：\n//Ensuringthat2methodshaveidenticalbehaviorbyforwardingpublic boolean contentEquals(StringBuffer sb)&#123;return contentEquals((CharSequence) sb);子\n\n虽然Java平台类库很大程度上遵循了本条目中的建议，但是也有诸多的类违背了。例如，String 类导出两个重载的静态工厂方法：valueOf(char[］)和valueOf(Object)，当这两个方法被传递了同样的对象引用时，它们所做的事情完全不同。没有正当的理由可以解释这一点，它应该被看作是一种反常行为，有可能会造成真正的混淆。\n简而言之，”能够重载方法”并不意味着就”应该重载方法”。一般情况下，对于多个具有相同参数数目的方法来说，应该尽量避免重载方法。在某些情况下，特别是涉及构造器的时候，要遵循这条建议也许是不可能的。在这种情况下，至少应该避免这样的情形：同一组参数只需经过类型转换就可以被传递给不同的重载方法。如果不能避免这种情形，例如，因为正在改造一个现有的类以实现新的接口，就应该保证：当传递同样的参数时，所有重载方法的行为必须一致。如果不能做到这一点，程序员就很难有效地使用被重载的方法或者构造器，同时也不能理解它为什么不能正常地工作。\n第53条：慎用可变参数可变参数方法一般称作variable aritymethod(可匹配不同长度的变量的方法)［JLS，8.4.1］，它接受0个或者多个指定类型的参数。可变参数机制首先会创建一个数组，数组的大小为在调用位置所传递的参数数量，然后将参数值传到数组中，最后将数组传递给方法。\n例如，下面就是一个可变参数方法，带有int参数的一个序列，并返回它们的总和。正如你所期望的，sum(1，2，3)的值为6，Sum()的值为0:\n//Simpleuseofvarargsstatic int sum(int... args) &#123;int sum = 0;for (int arg : args)sum += arg;return sum;\n\n有时候，必须编写需要一个或者多个某种类型参数的方法，而不是需要0个或者多个。个函数的定义就不太好了。你可以在运行时检查数组长度：\n// The WRoNG way to use varargs to pass one or more arguments!static int min(int... args) &#123;if (args.length == 0)int min = args[0];for(int i= l;i&lt; args.length;i++)if (args[i]&lt;min)min = args[i];return min;了\n\n这种解决方案有几个问题。其中最严重的问题是，如果客户端调用这个方法时，并没有传递参数进去，它就会在运行时而不是编译时发生失败。另一个问题是，这段代码很不美观。你必须在 args 中包含显式的有效性检查，除非将 min 初始化为 Integer.MAX_VALUE,否则将无法使用 for-each 循环，这样的代码也不美观。\n幸运的是，有一种更好的方法可以实现想要的效果。声明该方法带有两个参数，一个是指定类型的正常参数，另一个是这种类型的可变参数。这种解决方案解决了前一个示例中的所有不足：\n//Therightwayto usevarargsto pass one or more argumentsstatic int min(int firstArg, int... remainingArgs) &#123;int min = firstArg;for (int arg : remainingArgs)if (arg &lt; min)min = arg;return min;子\n\n如你所见，当你真正需要让一个方法带有不定数量的参数时，可变参数就非常有效。可变参数是为printf而设计的，该方法是与可变参数同时添加到Java平台中的，为了核心的反射机制(详见第 65条)，被改造成利用可变参数。Printf 和反射机制都从可变参数中获得了极大的益处。\n在重视性能的情况下，使用可变参数机制要特别小心。每次调用可变参数方法都会导致一次数组分配和初始化。如果凭经验确定无法承受这一成本，但又需要可变参数的灵活性，还有一种模式可以让你如愿以偿。假设确定对某个方法95%的调用会有3个或者更少的参数，就声明该方法的5个重载，每个重载方法带有0至3个普通参数，当参数的数目超过3个时，就使用一个可变参数方法：\npublic void foo() &#123;&#125;public void foo(int al) &#123;&#125;public void foo(int al，int a2)&#123;&#125;public void foo(int al，int a2，int a3) &#123; &#125;public void foo(int al，int a2，int a3，int... rest) &#123;&#125;\n\n现在你知道了，当参数的数目超过3个时，所有调用中只有5%需要创建数组。就像大多数的性能优化一样，这种方法通常不太恰当，但是一旦真正需要它时，它可就帮上大忙了。\nEnumSet类对它的静态工厂使用了这种方法，最大限度地减少创建枚举集合的成本。当时这么做是有必要的，因为枚举集合为位域提供了在性能方面有竞争力的替代方法，这是很重要的(详见第36条)。\n简而言之，在定义参数数目不定的方法时，可变参数方法是一种很方便的方式。在使用可变参数之前，要先包含所有必要的参数，并且要关注使用可变参数所带来的性能影响。\n第54条：返回零长度的数组或者集合，而不是null像下面这样的方法并不少见:\n// Returns null to indicate an empty collection. Don&#x27;t do this!private final List&lt;Cheese&gt; cheesesInStock = ...;/*** @return a list containing all of the cheeses in the shop,or null if no cheeses are available for purchase.*public List&lt;Cheese&gt; getCheeses()&#123;return cheesesInStock.isEmpty() ? null : new ArrayList&lt;&gt;(cheesesInStock);\n\n把没有奶酪(cheese)可买的情况当作是一种特例，这是不合常理的。这样做会要求客户端中必须有额外的代码来处理 null返回值，例如:\nList&lt;Cheese&gt; cheeses = shop.getCheeses();if (cheeses !=null &amp;&amp; cheeses.contains(Cheese.STILTON))System.out.println(&quot;Jolly good, just the thing.&quot;);\n\n对于一个返回 null 而不是零长度数组或者集合的方法，几乎每次用到该方法时都需要这种曲折的处理方式。这样做很容易出错，因为编写客户端程序的程序员可能会忘记写这种专门的代码来处理 null返回值。这样的错误也许几年都不会被注意到，因为这样的方法通常返回一个或者多个对象。返回null而不是零长度的容器，也会使返回该容器的方法实现代码变得更加复杂。\n有时候会有人认为：null返回值比零长度集合或者数组更好，因为它避免了分配零长度的容器所需要的开销。这种观点是站不住脚的，原因有两点。第一，在这个级别上担心性能问题是不明智的，除非分析表明这个方法正是造成性能问题的真正源头(详见第 67条)。第二，不需要分配零长度的集合或者数组，也可以返回它们。下面是返回可能的零长度集合的一段典型代码。一般情况下，这些都是必须的：\n//The right way to return a possibly empty collectionpublic List&lt;Cheese&gt; getCheeses()&#123;return new ArrayList&lt;&gt;(cheesesInStock);了\n\n万一有证据表示分配零长度的集合损害了程序的性能，可以通过重复返回同一个不可变的零长度集合，避免了分配的执行，因为不可变对象可以被自由共享(详见第17条)。下面的代码正是这么做的，它使用了Collections.emptyList方法。如果返回的是集合，最好使用Collections.emptySet;如果返回的是映射，最好使用Collections。emptyMap。但是要记住，这是一个优化，并且几乎用不上。如果你认为确实需要，必须在行动前后分别测试测量性能，确保这么做确实是有帮助的：\n// Optimization -avoids allocating empty collectionspublic List&lt;Cheese&gt; getCheeses() &#123;return cheesesInStock.isEmpty() ? Collections.emptyList():new ArrayList&lt;&gt;(cheesesInStock);&#125;\n\n说，应该只返回一个正确长度的数组，这个长度可以为零。注意，我们将一个零长度的数组传递给了toArray 方法，以指明所期望的返回类型，即 Cheese[］:\n//The right way to return a possibly empty arraypublic Cheese[] getCheeses() &#123;return cheesesInStock.toArray(new Cheese[o]);子\n\n如果确信分配零长度的数组会伤害性能，可以重复返回同一个零长度的数组，因为所有零长度的数组都是不可变的：\n// Optimization - avoids allocating empty arraysprivate static final Cheese[] EMPTY_CHEESE_ARRAY= new Cheese[O];public Cheese[] getCheeses()&#123;return cheesesInStock.toArray(EMPTY_CHEESE_ARRAY);&#125;\n\n在优化性能的版本中，我们将同一个零长度的数组传进了每一次的toArraY调用，每当 cheesesInStock 为空时，就会从 getCheese 返回这个数组。千万不要指望通过预先分配传人toArray 的数组来提升性能。研究表明，这样只会适得其反［Shipilevl6］:\n// Don&#x27;t do this - preallocating the array harms performance!return cheesesInStock.toArray(new Cheese[cheesesInStock.size(]);\n\n简而言之，永远不要返回 null，而不返回一个零长度的数组或者集合。如果返回 null,那样会使API更难以使用，也更容易出错，而且没有任何性能优势。\n第55条：谨慎返回optinal在Java 8之前，要编写一个在特定环境下无法返回任何值的方法时，有两种方法：要么抛出异常，要么返回nul1(假设返回类型是一个对象引用类型)。但这两种方法都不够完美。异常应该根据异常条件保留起来(详见第69条)。由于创建异常时会捕捉整个堆栈轨迹，因此抛出异常的开销很高。返回 nul1没有这些缺点，但它有自身的不足。如果方法返回 null，客户端就必须包含特殊的代码来处理返回 null的可能性，除非程序员能证明不可能返回 null。如果客户端疏忽了，没有检查 null返回值，并将 null返回值保存在某个数据结构中，那么未来在与这个问题毫不相关的某处代码中，随时有可能发生NullPointerException 异常。\n在Java 8中，还有第三种方法可以编写不能返回值的方法。Optinal类代表的是一个不可变的容器，它可以存放单个非null的T引用，或者什么内容都没有。不包含任何内容的 optional 称为空(empty)。非空的optional 中的值称作存在(present)。optional本质上是一个不可变的集合，最多只能存放一个元素。Optional没有实现Collection接口，但原则上是可以的。\n理论上能返回T的方法，实践中也可能无法返回，因此在某些特定的条件下，可以改为声明返回 Optional。它允许方法返回空的结果，表明无法返回有效的结果。返回Optional 的方法比抛出异常的方法使用起来更灵活，也更容易，并且比返回 null 的方法更不容易出错。\n在第30条展示过下面这个方法，用来根据元素的自然顺序，计算集合中的最大值。\n//Returnsmaximumvalueincollection-throwsexceptionifemptypublic static &lt;E extends Comparable&lt;E&gt;&gt; E max(Collection&lt;E&gt; c)&#123;if (c.isEmptyO)throw new IllegalArgumentException(&quot;Empty collection&quot;);Eresult=null;for(Ee:c)if(result = null 1l e.compareTo(result)&gt;0)result =Objects.requireNonNull(e);return result;\n\n如果指定的集合为空，这个方法就会抛出 IllegalArgumentException。在第 30条中说过，更好的替代方法是返回Optional。下面就是修改之后的代码:\n//Returnsmaximum valueincollectionas an Optional&lt;E&gt;public static&lt;E extends Comparable&lt;E&gt;&gt;Optional&lt;E&gt;max(Collection&lt;E&gt;c)&#123;if (c.isEmptyO)return Optional.emptyO);Eresult=null;for(Ee:c)if(result ==null 1l e.compareTo(result)&gt;0)result = Objects.requireNonNull(e);return Optional.of(result);\n\n如上所示，返回 optional是很简单的事。只要用适当的静态工厂创建optional 即可。在这个程序中，我们使用了两个optional：Optional.empty()返回一个空的 optional,Optional.of(value)返回一个包含了指定非 null值的optional。将 null 传人Optional.of(value)是一个编程错误。如果这么做，该方法将会抛出 NullPointerException。Optional.ofNullable(value)方法接受可能为 null的值，当传人null值时就返回一个空的optional。永远不要通过返回 Optional 的方法返回 null：因为它彻底违背了 optional 的本意。\nStream 的许多终止操作都返回 optional。如果重新用stream 编写 max方法，让 stream的 max 操作替我们完成产生 optional的工作(虽然还是需要传人一个显式的比较器):\n// Returns max val in collection as Optional&lt;E&gt;-uses streampublic static &lt;E extends Comparable&lt;E&gt;&gt;Optional&lt;E&gt; max(Collection&lt;E&gt;c)&#123;return c.stream(.max(Comparator.natural0rderO);\n\n那么，如何选择是返回 optional，还是返回 null，或是抛出异常呢？Optional 本质上与受检异常(详见第71条)相类似，因为它们强迫 API用户面对没有返回值的现实。抛出未受检的异常，或者返回null，都允许用户忽略这种可能性，从而可能带来灾难性的后果。但是，抛出受检异常需要在客户端添加额外的样板代码。\n如果方法返回 optional，客户端必须做出选择：如果该方法不能返回值时应该采取什么动作。你可以指定一个缺省值：\n或者抛出任何适当的异常。注意此处传入的是一个异常工厂，而不是真正的异常。这避免了创建异常的开销，除非它真正抛出异常：\n//Using anoptionalto throwachosenexceptionToy myToy = max(toys).orElseThrow(TemperTantrumException::new);如果你能够证明optional为非空，就不必指定如果optional为空要采取什么动作，直接从optional获得值即可;但是如果你的判断错了，代码就会抛出一个NoSuchElement-Exception:\n\n&#x2F;&#x2F;Usingoptional whenyouknow there’sareturnvalueElement lastNobleGas &#x3D; max(Elements.NOBLE_GASES).getO);\n有时候，获取缺省值的开销可能很高，除非十分必要，否则还是希望能够避免这一开销。对于这类情况，Optional 提供了一个带有 Supplier的方法，只在必要的时候才调用它。这个方法叫orElseGet，但或许应该叫orElseCompute，因为它与三个名称以 compute 开头的 Map 方法密切相关。有几个Optional方法可以用来处理更加特殊用例的情况：filter、map、flatMap 和 ifPresent。Java 9 又在其中新增了两个方法 or 和ifPresentOrElse。如果上述基本方法不适用，可以查看文档寻找更高级的方法，看看它们是否能够完成你所需的任务。\n万一这些方法都无法满足需求，Optional还提供了isPresent()方法，它可以被当作是一个安全阀。当 optional 中包含一个值时，它返回true;当 optional 为空时，返回false。该方法可用于对optional 结果执行任意的处理，但要确保正确使用。isPresent的许多用法都可以用上述任意一种方法取代。这样得到的代码一般会更加简短、清晰，也更符合习惯用法。\n例如，以下代码片段用于打印出一个进程的父进程ID，当该进程没有父进程时打印 N&#x2F;A。这里使用了在Java9中引l人的ProcessHand类：\nOptional&lt;ProcessHandle&gt; parentProcess = ph.parent(;System.out.println(&quot;Parent PID: &quot;+ (parentProcess.isPresentO) ?String.valueOf(parentProcess.get(.pid()) : &quot;N/A&quot;));\n上述代码片段可以用以下的代码代替，这里使用了Optional 的 map 函数:\nSystem.out.println(&quot;Parent PID:&quot;+ph.parent() .map(h -&gt; String.value0f(h.pid())).orElse(&quot;N/A&quot;));\n\n当用 Stream 编程时，经常会遇到 Stream&lt;Optional&gt;，为了推动进程还需要一个包含了非空optional中所有元素的 Stream。如果使用的是Java 8版本，可以像这样弥补差距：\nstreamOfOptionals.filter(Optional::isPresent).map(Optional: :get)\n\n在Java 9中，Optional 还配有一个 stream()方法。这个方法是一个适配器，如果optional 中有一个值，它就将 Optional变成包含一个元素的 Stream;如果 optional为空,地取代上述代码片段，如下：\nstreamOfOptionalsflatMap(Optional::stream)\n\n但是并非所有的返回类型都受益于optional的处理方法。容器类型包括集合、映射、Stream、数组和 optional，都不应该被包装在optional 中。不要返回空的 Optional免于处理一个 optional。ProcessHandle 类确实有 arguments 方法，它返回 Optional&lt;String[]&gt;，但是应该把这个方法看作是一个不该被模仿的异常。\n那么何时应该声明一个方法来返回 Optional而不是返回 T呢？规则是：如果无法返回结果并且当没有返回结果时客户端必须执行特殊的处理，那么就应该声明该方法返回Optional。也就是说，返回Optional并非不需要任何成本。\nOptional是一个必须进行分配和初始化的对象，从 optional读取值时需要额外的开销。这使得optional不适用于一些注重性能的情况。一个特殊的方法是否属于此类，只能通过仔细的测量来确定才行(详见第 67条)。\n返回一个包含了基本包装类型的optional，比返回一个基本类型的开销更高，因为optional有两级包装，不是0 级。因此，类库设计师认为必须为基本类型 int、long 和 double 提供类似 Optional的方法。这些 optional 类型为：OptionalInt、OptionalLong 和OptionalDouble。这些包含了Optional中大部分但并非全部的方法。因此，永远不应该返回基本包装类型的 optional，”小型的基本类型”(Boolean、Byte、Character、Short 和Float)除外。\n到目前为止，我们已经讨论了返回optional，以及返回之后对它们的处理方法。之所以还没有讨论到其他可能的用途，是因为 optional 的大部分其他用途都还受到质疑。例如，永远不应该用optional作为映射值。如果这么做，有两种方式来表达一个键的逻辑缺失：要么这个键可以不出现在映射中，要么它可以存在，并映射到一个空的 optional。这些既增加了无谓的复杂度，并极有可能造成混淆和出错。更通俗地说，几乎永远都不适合用 optional作为键、值，或者集合或数组中的元素。\n这里留下了一个尚未解答的问题：适合将optional保存在实例域中吗？这个答案散发着”恶臭的气息”：它建议使用包含optional域的子类。不过有时候它又是有道理的。以第2条中的 NutritionFacts 类为例，NutritionFacts 实例中包含了许多不必要的域。你不可能给这些域中每一个可能的合并都提供一个子类。而且，这些域有基本类型，导致不方便直接描述这种缺失。NutritionFacts 最好的 API会从 get 方法处为每个 optional 域获得一个 optional，因此将那些 optional 作为域保存在对象中的做法会变得很有意义。\n总而言之，如果发现自己在编写的方法始终无法返回值，并且相信该方法的用户每次在调用它时都要考虑到这种可能性，那么或许就应该返回一个optional。但是，应当注意到与返回optional 相关的真实的性能影响;对于注重性能的方法，最好是返回一个 null，或者抛出异常。最后，尽量不要将optional用作返回值以外的任何其他用途。\n第56条：为所有导出的API元素编写文档注释如果要想使一个API真正可用，就必须为其编写文档。传统意义上的API文档是手工生成的，所以保持文档与代码同步是一件很烦琐的事情。Java 编程环境提供了一种被称为 Javadoc 的实用工具，从而使这项任务变得很容易。Javadoc 利用特殊格式的文档注释(documentationcomment，通常被写作doc comment)，根据源代码自动产生API文档。\n虽然文档注释还没有正式成为Java编程语言的一部分，但它们已经构成了每个程序员都应该知道的事实 API。这些规范的内容在如何编写文档注释(How to Write Doc Comments)的网页上进行了说明［Javadoc-guide］。虽然这个网页在 Java 4 发行版本之后还没有进行更新，但它仍然是个很有价值的资源。在Java 9 中新增了一个重要的文档标签：{@index};在Java 8中增加了一个文档标签：{@implSpec};在Java 5中新增了两个文档标签：{@literal}和{@code}。这些标签在之前提到过的网页上已经没有了，但会在本条目中讨论到。\n为了正确地编写API文档，必须在每个被导出的类、接口、构造器、方法和域声明之前增加一个文档注释。如果类是可序列化的，也应该对它的序列化形式编写文档(详见第87条)。如果没有文档注释，Javadoc 所能够做的也就是重新生成该声明，作为受影响的API元素的唯一文档。使用没有文档注释的API是非常痛苦的，也很容易出错。公有的类不能使用缺省构造器，因为无法为它们提供文档注释。为了编写出可维护的代码，还应该为那些没有被导出的类、接口、构造器、方法和域编写文档注释。\n方法的文档注释应该简洁地描述出它和客户端之间的约定。除了专门为继承而设计的类中的方法(详见第19条)之外，这个约定应该说明这个方法做了什么，而不是说明它是如何完成这项工作的。文档注释应该列举出这个方法的所有前提条件(precondition)和后置条件(postcondition)，所谓前提条件是指为了使客户能够调用这个方法，而必须要满足的条件;所谓后置条件是指在调用成功完成之后，哪些条件必须要满足。一般情况下，前提条件是由@throws 标签针对未受检的异常所隐含描述的;每个未受检的异常都对应一个前提违例(precondition violation)。同样地，也可以在一些受影响的参数的@param 标记中指定前提条件。\n除了前提条件和后置条件之外，每个方法还应该在文档中描述它的副作用(sideeffect)。所谓副作用是指系统状态中可以观察到的变化，它不是为了获得后置条件而明确要求的变化。例如，如果方法启动了后台线程，文档中就应该说明这一点。\n为了完整地描述方法的约定，方法的文档注释应该让每个参数都有一个@param 标签，以及一个 @return 标签(除非这个方法的返回类型为 void)，以及对于该方法抛出的每个异常，无论是受检的还是未受检的都应有一个@throws 标签(详见第 74 条)。如果@return标签中的文本与方法的描述一致，就允许省略，具体取决于你所遵循的编码标准。\n按照惯例，跟在@param 标签或者@return 标签后面的文字应该是一个名词短语，描述了这个参数或者返回值所表示的值。在极少数情况下，也会用算术表达式来代替名词短语，详情请参考BigInteger 的例子。跟在@throws 标签之后的文字应该包含单词”if”(如果)，紧接着是一个名词短语，它描述了这个异常将在什么样的条件下抛出。按照惯例，@param、@return 或者@throws 标签后面的短语或者子句都不用句点来结束。下面这个简短的文档注释演示了所有这些习惯做法：\n***Returns the element at the specified position in this list.*&lt;p&gt;This method is &lt;i&gt;not&lt;/i&gt;guaranteed to run in constant* time. In some implementations it may run in time proportional* to the element position.* @param index index of element to return;must benon-negative and less thanthe size of this list* @throws IndexOutOfBoundsException if the index is out of range(&#123;@code index&lt;0 1l index &gt;=this.size(&#125;)*/E get(int index);\n\n翻译成HTML，文档注释中包含的任意HTML元素都会出现在结果HTML文档中。有时程序员还会把HTML表格嵌人到它们的文档注释中，但是这种做法并不多见。\n还要注意，@throws子句的代码片段中到处使用了Javadoc 的{@code}标签。它有两个作用：造成该代码片段以codefont(代码字体)呈现，并限制HTML标记和嵌套的Javadoc标签在代码片段中进行处理。后一种属性正是允许我们在代码片段中使用小于号(&lt;)，虽然它是一个HTML元字符。为了将一个多行的代码示例包含在文档注释中，要使用包在HTML 的标签里面的 Javadoc 标签{@code}。换句话说，是先在多行的代码示例前使用字符{@code，然后在代码后面加上}。这样就可以在代码中保留换行，不需要对HTML元字符进行转义，但@ 符号并非如此，如果代码使用了注释就必须进行转义。\n最后，要注意这个文档注释中用到了词语”this list”。按惯例，当”this”一词被用在实例方法的文档注释中时，它应该始终是指方法调用所在的对象。\n如第 15 条所述，在专门为了继承设计类时，必须在文档中注释它的自用模式(self-use patterm),便于程序员了解覆盖其方法的语义。这些自用模式应该利用Java 8 中增加的@implSpec标签进行文档注释。回顾一下，普通的文档注释是描述方法及其客户端之间的约定;相反,@implSpec 注释则是描述方法及其子类之间的约定，如果子类继承了该方法，或者通过super 调用了方法，则允许子类依赖实现行为。下面是具体的用法范例:\n* Returns true if this collection is empty.*@imp1Spec*Thisimplementation returns &#123;@code this.size() ==0&#125;* @return true if this collection is emptypublicboolean isEmpty() &#123;...&#125;\n从 Java 9 开始，Javadoc 工具仍然忽略 @implSpec 标签，除非传入命令行参数：-tag中得到改进。\n不要忘记，为了产生包含HTML元字符的文档，比如小于号(&lt;)、大于号(&gt;)以及”与”号(&amp;)，必须采取特殊的动作。让这些字符出现在文档中的最佳办法是用{@literal}标签将它们包围起来，这样就限制了HTML标记和嵌套的Javadoc 标签的处理。除了它不以代码字体渲染文本之外，其他方面都和{@code}标签一样。例如，这个Javadoc 片段:\n*A geometric seriesconvergesif&#123;@literal|r|&lt;1&#125;.\n\n它产生了文档：”A geometric series converges if|rl&lt;1.”{@literal}标签也可以只是括住小于号，而不是整个不等式，所产生的文档是一样的，但是在源代码中见到的文档注释的可读性就会更差。这说明了一条通则：文档注释在源代码和产生的文档中都应该是易于阅读的。如果无法让两者都易读，产生的文档的可读性要优先于源代码的可读性。\n每个文档注释的第一句话(如下所示)成了该注释所在元素的概要描述(summarydescription)。例如，本条目之前的文档注释中的概要描述为”返回这个列表中指定位置上的元素”。概要描述必须独立地描述目标元素的功能。为了避免混淆，同一个类或者接口中的两个成员或者构造器，不应该具有同样的概要描述。特别要注意重载的情形，在这种情况下，往往很自然地在描述中使用同样的第一句话(但在文档注释中这是不可接受的)。\n注意所期待的概要描述中是否包括句点，因为句点会过早地终止这个描述。例如，一个以”A college degree,such as B.S.,M.S.or Ph.D.”开头的文档注释，会产生这样的概要描述:”A college degree,such as B.S，M.S.”问题在于，概要描述会在后面紧接着的空格、跳格或者行终结符的第一个句点处(或者在第一个块标签处)结束［Javadoc-ref」。此处，缩写”M.S.”中的第二个句点后面紧接着用了一个空格。最好的解决方法是，用{@literal}标签将讨厌的句点以及所有关联的文本都包起来，使得源代码中的句点后面不再是空格：\n***A college degree, such as B.S.，&#123;@literal M.S.&#125; or Ph.D.*/public class Degree &#123; ...&#125;\n\n说概要描述是文档注释中的第一个句子(sentence)，这似乎有点误导人。规范指出，概要描述很少是个完整的句子。对于方法和构造器而言，概要描述应该是个完整的动词短语(包含任何对象)，它描述了该方法所执行的动作。例如：\nArrayList(intinitialCapacity)：用指定的初始容量构造一个空的列表。Collection.size()：返回该集合中元素的数目。\n\n如这些示例所示，使用第三人称时态(returns the number)比使用第二人称(return thenumber)更加确切。\n对于类、接口和域，概要描述应该是一个名词短语，它描述了该类或者接口的实例，或者域本身所代表的事物。例如：\n口Instant：时间轴上的一个瞬时点。\nMath.PI：非常接近于 PI(圆周长度与直径的比值)的 double 值。\nJava 9在 Javadoc 生成的 HTML中添加了客户端索引l。这个索引I简化了在大型API文档集中进行搜索的任务，它采用了页面右上角的搜索框的形式。当你在搜索框中输入时，会出现一个下拉菜单，上面显示出相匹配的页面。像类、方法和域这类 API元素，会被自动索引。有时候，会想要索引一些对于 API 比较重要的其他条件。为此，增加了{@index}标签。如果要索引文档注释中出现的某一个条件，只需将它包在这个标签中即可，如下面这个代码片段所示:\n*Thismethod complies withthe&#123;@index IEEE 754&#125; standard.\n\n需要特别小心文档注释中的泛型、枚举和注解。当为泛型或者方法编写文档时，确保要在文档中说明所有的类型参数。\n*An object that maps keys to values.A map cannot contain* duplicatekeys;each keycan map to at most one value.*(Remainder omitted)*@param &lt;K&gt;the typeof keys maintained by this map*@param &lt;V&gt; the type of mapped values*/public interface Map&lt;k,V&gt; &#123;...&#125;\n\n当为枚举类型编写文档时，要确保在文档中说明常量，以及类型，还有任何公有的方法。注意，如果文档注释很简短，可以将整个注释放在一行上:\n*** An instrument section of a symphony orchestra.*public enum OrchestraSection &#123;/** Woodwinds,such as flute,clarinet，and oboe.*/WOODWIND,/** Brass instruments,such as french horn and trumpet.*/BRASS,/*Percussion instruments,such as timpani and cymbals.*/PERCUSSION,/** Stringed instruments,such as violin and cello.*/STRING;\n\n为注解类型编写文档时，要确保在文档中说明所有成员，以及类型本身。带有名词短语的文档成员，就当成域一样对待。对于该类型的概要描述，要使用一个动词短语，说明当程序元素具有这种类型的注解时它表示什么意思：\n***Indicates that the annotated method is a test method that* must throw the designated exception to pass.*@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface ExceptionTest &#123;/***Theexception thatthe annotatedtest methodmust throw* in order to pass. (The test is permitted to throw any*subtype ofthe type described bythisclass object.)*Class&lt;? extends Throwable&gt; value();\n\n包级私有的文档注释应该放在一个称作 package-info.java 的文件中。除了这些注释之外，package-info.java 中还必须包含包声明，还可以包含这个声明中的注解。同样地，如果选择使用模块系统(详见第 15条)，应该将模块级的注释放在 module-info。java 文件中。\nAPI有两个特征在文档中经常被忽视，即线程安全性和可序列化性。类或者静态方法是否线程安全，应该在文档中对它的线程安全级别进行说明，如第82条所述。如果类是可序列化的，就应该在文档中说明它的序列化形式，如第87条所述。\nJavadoc 具有”继承”方法注释的能力。如果一个API元素没有文档注释，Javadoc将会搜索最为适用的文档注释，接口的文档注释将优先于超类的文档注释。搜索算法的细节可以在《TheJavadoc Reference Guide》［ Javadoc-ref ]中找到。也可以利用{@inheritDoc}标签从超类型中继承文档注释的部分内容。这意味着类还可以重用它所实现的接口的文档注释，而不需要拷贝这些注释。这项机制有可能减轻维护多个几乎相同的文档注释的负担，但使用它需要一些小技巧，并具有一些局限性。关于这一点的详情超出了本书的范围，在此不做讨论。\n关于文档注释有一点需要特别注意。虽然为所有导出的API元素提供文档注释是必要的，但是这样做并非一劳永逸。对于由多个相互关联的类组成的复杂API，通常有必要用一个外部文档来描述该API的总体结构，对文档注释进行补充。如果有这样的文档，相关的类或者包文档注释就应该包含一个对这个外部文档的链接。\nJavadoc 遵循本条目提出的许多建议进行自动检测。在Java 7中，需要用命令行参这样的IDE插件，会进一步根据这些建议完成检测［ Burn01］。通过运行一个 HTML 有效性检查器(HTML validity checker)来检测由 Javadoc 产生的 HTML 文件，也可以降低文档注释中出错的可能性。这样可以检测出 HTML标签的许多不正确用法，以及应该被转义的HTML元字符。Internet上有几个这类检查器可供下载，并且也可以利用W3C MarkupValidationService[W3C-validator]来进行在线检验HTML。在验证产生的HTML时，要记住，从Java 9开始，Javadoc 都可以生成HTML5，以及HTML 4.01，虽然它默认是生成HTML4.01。如果要用Javadoc生成HTML5，可以使用命令行参数-htm15。\n本条目中所述的内容涵盖了基本的惯例。虽然到目前为止，已经过去了15年，编写文档注解最权威的指导仍然是《How toWriteDocComments》Javadoc-guide」。\n如果遵循本条目中的指导，生成的文档应该能够清晰地描述你的API。但唯一确定了解的方式，就是去阅读由 Javadoc 工具生成的网页。每一个将被其他人使用的 API都值得你这么做。正如测试程序几乎无疑会导致对代码做出修改一样，阅读文档一般至少也会导致对文档注释进行些许的修改。\n简而言之，要为API编写文档，文档注释是最好、最有效的途径。对于所有可导出的API元素来说，使用文档注释应该被看作是强制性的要求。要采用一致的风格来遵循标准的约定。记住，在文档注释内部出现任何 HTML标签都是允许的，但是HTML 元字符必须要经过转义。\n第九章 通用编程本章主要讨论Java 语言的细枝末节，包含局部变量的处理、控制结构、类库的用法、各种数据类型的用法，以及两种不是由语言本身提供的机制(反射机制和本地方法)的用法。最后讨论了优化和命名惯例。\n第57条：将局部变量的作用域最小化本条目与第15 条本质上是类似的。将局部变量的作用域最小化，可以增强代码的可读性和可维护性，并降低出错的可能性。\n较早的编程语言(如C语言)要求局部变量必须在代码块的开头进行声明，出于习惯，有些程序员目前还是继续这样做。这个习惯应该改正。在此提醒，Java 允许你在任何可以出现语句的地方声明变量。\n要使局部变量的作用域最小化，最有力的方法就是在第一次要使用它的地方进行声明。如果变量在使用之前进行声明，这只会造成混乱一对于试图理解程序功能的读者来说，这又多了一种只会分散他们注意力的因素。等要用到该变量时，读者可能已经记不起该变量的类型或者初始值了。\n过早地声明局部变量不仅会使它的作用域过早地扩展，而且结束得过晚。局部变量的作用域从它被声明的点开始扩展，一直到外围块的结束处。如果变量是在”使用它的块”之外被声明的，当程序退出该块之后，该变量仍是可见的。如果变量在它的目标使用区域之前或者之后被意外地使用，后果将可能是灾难性的。\n几乎每一个局部变量的声明都应该包含一个初始化表达式。如果你还没有足够的信息来对一个变量进行有意义的初始化，就应该推迟这个声明，直到可以初始化为止。这条规则有个例外的情况与trY-Catch 语句有关。如果一个变量被一个方法初始化，而这个方法可能会抛出一个受检异常，该变量就必须在trY块的内部被初始化。如果变量的值必须在try块的外部用到，它就必须在try块之前被声明，但是在try块之前，它还不能被”有意义地初始化”。请参照第65条中的例子。\n循环中提供了特殊的机会来将变量的作用域最小化。无论是传统的for循环，还是for-each 形式的 for 循环，都允许声明循环变量(loop variable)，它们的作用域被限定在正好需要的范围之内。(这个范围包括循环体，以及循环体之前的初始化、测试、更新部分。)因此，如果在循环终止之后不再需要循环变量的内容，for循环就优先于while 循环。\n例如，下面是一种遍历集合的首选做法(详见第58条)：\n//Preferred idiomforiteratingovera collectionor arrayfor(Element e:c)&#123;...//DoSomething withe子\n\n如果需要访问迭代器，可能要调用它的 remove 方法，首选做法是利用传统的 for 循环代替 for-each循环：\n//Idiom for iterating whenyou need the iteratorfor(Iterator&lt;Element&gt; i= c.iteratorO;i.hasNextO;)&#123;Element e = i.next();.:// Do something with e and i了\n\n为了弄清楚为什么这些for 循环比 while 循环更好，请参考下面的代码片段，它包含两个 while 循环，以及一个Bug:\nIterator&lt;Element&gt;i=c.iterator(;while (i.hasNextO)&#123;doSomething(i.next();了Iterator&lt;Element&gt; i2 = c2.iterator(;while (i.hasNextO) &#123; //BUG!doSomethingElse(i2.next());了\n\n第二个循环中包含一个”剪切－粘贴”错误：本来是要初始化一个新的循环变量i2,却使用了旧的循环变量i，遗憾的是，这时 i仍然还在有效范围之内。结果代码仍然可以通过编译，运行的时候也不会抛出异常，但是它所做的事情却是错误的。第二个循环并没有在c2 上迭代，而是立即终止，造成c2 为空的假象。因为这个程序的错误是悄然发生的，所以可能在很长时间内都不会被发现。\n如果类似的”剪切－粘贴”错误发生在前面任何一种for循环中，结果代码根本就不能通过编译。在第二个循环开始之前，第一个循环的元素(或者迭代器)变量已经不在它的作用域范围之内了。下面就是一个传统for 循环的例子:\nfor (Iterator&lt;Element&gt; i = c.iteratorO; i.hasNext();)&#123;Element e = i.nextO;..// Do something with e and i// Compile-time error - cannot find symbol ifor (Iterator&lt;Element&gt; i2 = c2.iterator(O;i.hasNext();)&#123;Element e2 = i2.next();...// Do something with e2 and i2\n\n如果使用for循环，犯这种”剪切－粘贴”错误的可能性就会大大降低，因为通常没有必要在两个循环中使用不同的变量名。循环是完全独立的，所以重用元素(或者迭代器)变量的名称不会有任何危害。实际上，这也是很流行的做法。\n使用 for循环与使用 while循环相比还有另外一个优势：更简短，从而增强了可读性。下面是另外一种对局部变量的作用域进行最小化的循环做法：\nfor (int i = 0，n = expensiveComputation();i&lt; n;i++)&#123;..// Do something with i;子\n\n关于这种做法要关注的重点是，它具有两个循环变量i和n，二者具有完全相同的作用域。第二个变量n被用来保存第一个变量的极限值，从而避免在每次迭代中执行冗余计算。通常，如果循环测试中涉及方法调用，并且可以保证在每次迭代中都会返回同样的结果，就应该使用这种做法。\n最后一种”将局部变量的作用域最小化”的方法是使方法小而集中。如果把两个操作(activity)合并到同一个方法中，与其中一个操作相关的局部变量就有可能会出现在执行另一个操作的代码范围之内。为了防止这种情况发生，只需将这个方法分成两个：每个操作用一个方法来完成。\n第58条：for-each循环优先于传统的for循环如第 45条所述，有些任务最好结合Stream 来完成，有些最好结合迭代完成。下面是用一个传统的 for 循环遍历集合的例子:\n// Not the best way to iterate over a collection!for (Iterator&lt;Element&gt; i = c.iterator(; i.hasNext(; )&#123;Element e = i.next();...//Dosomethingwithe了\n\n用传统的for 循环遍历数组的做法如下:\n//Notthebestwaytoiterateoveranarray!for (int i = 0;i &lt; a.length;i++)&#123;..// Do something with a[i]\n\n这些做法都比 while 循环(详见第 57条)更好，但是它们并不完美。迭代器和索引l变量都会造成一些混乱一而你需要的只是元素而已。而且，它们也代表着出错的可能。迭代器在每个循环中出现三次，索引变量在每个循环中出现四次，其中有两次让你很容易出错。一旦出错，就无法保证编译器能够发现错误。最后一点是，这两个循环是截然不同的，容器的类型转移了不必要的注意力，并且为修改该类型增加了一些困难。\nfor-each循环(官方称之为”增强的for语句”)解决了所有问题。通过完全隐藏迭代器或者索引变量，避免了混乱和出错的可能。这种模式同样适用于集合和数组，同时简化了将容器的实现类型从一种转换到另一种的过程：\n//The preferredidiomfor iterating over collections and arraysfor (Element e:elements)&#123;...//Dosomething withe了\n\n当见到冒号(：)时，可以把它读作”在·里面”。因此上面的循环可以读作”对于元素elements 中的每一个元素é”。注意，利用for-each循环不会有性能损失，甚至用于数组也一样：它们产生的代码本质上与手工编写的一样。\n对于嵌套式迭代，for-each 循环相对于传统 for 循环的优势还会更加明显。下面就是人们在试图对两个集合进行嵌套迭代时经常会犯的错误：\n//Can you spot thebug?enum Suit &#123; CLUB，DIAMOND，HEART，SPADE &#125;enum Rank &#123; ACE，DEUCE，THREE，FOUR，FIVE，SIX，SEVEN，EIGHT,NINE， TEN, JACK, QUEEN, KING &#125;static Collection&lt;Suit&gt; suits = Arrays.asList(Suit.values());static Collection&lt;Rank&gt; ranks = Arrays.asList(Rank.values();List&lt;Card&gt; deck = new ArrayList&lt;&gt;();for (Iterator&lt;Suit&gt; i = suits.iteratorO; i.hasNextO;)for (Iterator&lt;Rank&gt; j = ranks.iterator(); j.hasNext(); )deck.add(new Card(i.next(), j.next()));\n\n如果之前没有发现这个Bug也不必难过。许多专家级的程序员偶尔也会犯这样的错误。问题在于，在迭代器上对外部的集合(suits)调用了太多次 next方法。它应该从外部的循环进行调用，以便每种花色调用一次，但它却是从内部循环调用，因此每张牌调用一次。在用完所有花色之后，循环就会抛出 NoSuchElementException异常。\n如果真的那么不幸，并且外部集合的大小是内部集合大小的几倍(可能因为它们是相同的集合)，循环就会正常终止，但是不会完成你想要的工作。例如，下面就是一个考虑不周的尝试，想要打印一对骰子的所有可能的滚法：\n// Same bug, different symptom!enum FaCe &#123; ONE，TWO，THREE，FOUR，FIVE，SIX &#125;Collection&lt;Face&gt; faces = EnumSet.allof(Face.class);for (Iterator&lt;Face&gt; i = faces.iterator(); i.hasNext(;)# for (Iterator&lt;Face&gt; j = faces.iterator();j.hasNext();)(S XS，，NN，)重9‘而不是预计的那 36 种组合。\n\n为了修正这些示例中的Bug，必须在外部循环的作用域中添加一个变量来保存外部元素：\n// Fixed, but ugly - you can do better!for (Iterator&lt;Suit&gt; i= suits.iterator(; i.hasNextO;) &#123;Suit suit = i.next();for (Iterator&lt;Rank&gt; j = ranks.iterator(; j.hasNext();)deck.add(new Card(suit, j.next());\n\n如果使用的是嵌套式for-each 循环，这个问题就会完全消失。产生的代码将如你所希望的那样简洁:\n//Preferred idiom for nested iteration on collections and arraysfor (Suit suit : suits)for (Rank rank :ranks)deck.add(new Card(suit, rank));\n\n遗憾的是，有三种常见的情况无法使用for-each 循环：\n口解构过滤一如果需要遍历集合，并删除选定的元素，就需要使用显式的迭代器，以便可以调用它的 remove 方法。使用Java 8中增加的Collection 的 removeIf方法，常常可以避免显式的遍历。\n口转换—如果需要遍历列表或者数组，并取代它的部分或者全部元素值，就需要列表迭代器或者数组索引，以便设定元素的值。\n口平行迭代一如果需要并行地遍历多个集合，就需要显式地控制迭代器或者索引变量，以便所有迭代器或者索引变量都可以同步前进(就如上述有问题的牌和骰子的示例中无意间所示范的那样)。\n如果你发现自己处于以上任何一种情况之下，就要使用普通的for循环，并且要警惕本条目中提到的陷阱。\nfor-each 循环不仅能遍历集合和数组，还能遍历实现 Iterable接口的任何对象，该接口中只包含单个方法，具体如下：\npublic interface Iterable&lt;E&gt;&#123;//Returnsan iterator over the elements in this iterableIterator&lt;E&gt; iterator();\n\n如果不得不从头开始编写自己的工terator 实现，其中还是有些技巧的，但是如果编写的是表示一组元素的类型，则应该坚决考虑让它实现 Iterable 接口，甚至可以选择让它不要实现Collection 接口。这样，你的用户就可以利用 for-each 循环遍历类型，他们会永远心怀感激的。\n总而言之，与传统的 for 循环相比，for-each 循环在简洁性、灵活性以及出错预防性方面都占有绝对优势，并且没有性能惩罚的问题。因此，当可以选择的时候，for-each循环应该优先于 for 循环。\n第59条：了解和使用类库假设你希望产生位于0和某个上界之间的随机整数。面对这个常见的任务，许多程序员会编写出如下所示的方法：\n//Commonbutdeeplyflawed!static Random rnd = new RandomO;static int random(int n) &#123;return Math.abs(rnd.nextInt()) % n;&#125;\n\n这个方法看起来可能不错，但是却有三个缺点。第一个缺点是，如果n 是一个比较小的2的乘方，经过一段相当短的周期之后，它产生的随机数序列将会重复。第二个缺点是，如果 n 不是2的乘方，那么平均起来，有些数会比其他的数出现得更为频繁。如果 n 比较大，这个缺点就会非常明显。这可以通过下面的程序直观地体现出来，它会产生100万个经过精心指定的范围内的随机数，并打印出有多少个数字落在随机数取值范围的前半部分:\npublic static void main(String[] args) &#123;int n=2*(Integer.MAX_VALUE/ 3);int 1ow=0;for(int i=0;i&lt;1000000;i++)if (random(n) &lt;n/2)low++;System.out.println(low);\n\n如果 random方法工作正常，这个程序打印出来的数将接近于100万的一半，但是如果真正运行这个程序，就会发现它打印出来的数接近于 666666。由 random 方法产生的数字有三分之二落在随机数取值范围的前半部分。\nrandom 方法的第三个缺点是，在极少数情况下，它的失败是灾难性的，因为会返回一个落在指定范围之外的数。之所以如此，是因为这个方法试图通过调用Math.abs，将rnd.nextInt()返回的值映射为一个非负整数int。如果 nextInt()返回Integer.MIN_VALUE，那么Math.abs也会返回Integer.MIN_VALUE，假设n不是2的乘方，那么取模操作符(%)将返回一个负数。这几乎肯定会使程序失败，而且这种失败很难重现。\n为了编写能修正这三个缺点的 random方法，有必要了解关于同余伪随机数生成器、数论和2的求补算法的相关知识。幸运的是，你并不需要自己来做这些工作一已经有现成的成果可以为你所用。这一成果被称作Random.nextInt(int)。你无须关心nextInt(int)的实现细节(如果你有强烈的好奇心，可以研究它的文档或者源代码)。具有算法背景的高级工程师已经花了大量的时间来设计、实现和测试这个方法，然后经过这个领域中的专家的审查，以确保它的正确性。之后，标准类库经过了Beta测试并正式发行，几年之间已经有成千上万的程序员在使用它。在这个方法中还没有发现过缺陷，但是，如果将来发现有缺陷，在下一个发行版本中就会修正这些缺陷。通过使用标准类库，可以充分利用这些编写标准类库的专家的知识，以及在你之前的其他人的使用经验。\n从Java 7开始，就不应该再使用Random了。现在选择随机数生成器时，大多使用ThreadLocalRandom。它会产生更高质量的随机数，并且速度非常快。在我的机器上，比 Random 快了 3.6 倍。对于 Fork Join Pool 和并行 Stream，则使用 SplittableRandom。\n使用标准类库的第二个好处是，不必浪费时间为那些与工作不太相关的问题提供特别的解决方案。就像大多数程序员一样，应该把时间花在应用程序上，而不是底层的细节上。\n使用标准类库的第三个好处是，它们的性能往往会随着时间的推移而不断提高，无须你做任何努力。因为许多人在使用它们，并且是当作工业标准在使用，所以提供这些标准类库的组织有强烈的动机要使它们运行得更快。这些年来，许多Java平台类库已经被重新编写了，有时候是重复编写，从而在性能上有了显著的提高。\n使用标准类库的第四个好处是，它们会随着时间的推移而增加新的功能。如果类库中漏掉了某些功能，开发者社区就会把这些缺点公示出来，漏掉的功能就会添加到后续的发行版本中。\n使用标准类库的最后一个好处是，可以使自己的代码融人主流。这样的代码更易读、更易维护、更易被大多数的开发人员重用。\n既然有那么多的优点，使用标准类库机制而不选择专门的实现，这显然是符合逻辑的，然而还是有相当一部分的程序员没有这样做。为什么呢？可能他们并不知道有这些类库机制的存在。在每个重要的发行版本中，都会有许多新的特性被加入到类库中，所以与这些新特性保持同步是值得的。每当Java平台有重要的发行时，都会发布一个网页来说明新的特性。这些网页值得好好读一读「Java8-feat,Java9-feat]。举个例子，假设想要编写一个程序，用它打印出命令行中指定的一条URL 的内容(Linux 中 curl 命令的作用大体如此)。在 Java 9之前，这些代码有点烦琐，但是Java 9在 InputStream 中增加了transferTo方法。下面就是利用这个新方法完成这项任务的完整程序：\n//Printingthecontentsofa URLwith transferTo,addedinJava9public static void main(String[] args) throws IOException &#123;try (InputStream in = new URL(args[0]).openStream()) &#123;in.transferTo(System.out);\n\n这些标准类库太庞大了，以至于不可能学完所有的文档[Java9-api]，但是每个程序员都应该熟悉 java.lang、java.util、java.io 及其子包中的内容。关于其他类库的知识可以根据需要随时学习。总结类库中的机制超出了本条目的范围，几年来它们已经发展得十分庞大了。\n其中有几个类库值得一提。CollectionsFramework(集合框架)和Stream类库(详见第45条至第 48 条)应该成为每一位程序员基本工具箱中的一部分，同样也应该成为java.util.concurrent 中并发机制的组成部分。这个包既包含高级的并发工具来简化多线程的编程任务，还包含低级别的并发基本类型，允许专家们自己编写更高级的并发抽象。关于java.util.concurrent 的高级部分，请参阅第 80条和第 81 条。\n在某些情况下，一个类库工具并不能满足你的需要。你的需求越是特殊，这种情形就越有可能发生。虽然你的第一个念头应该是使用标准类库，但是，如果你在观察了它们在某些领域所提供的功能之后，确定它不能满足需要，你就得使用其他的实现。任何一组类库所提供的功能总是难免会有遗漏。如果你在Java类库中找不到所需要的功能，下一个选择应该是在高级的第三方类库中去寻找，比如Google 优秀的开源Guava 类库［Guava］。如果在所有相应的类库中都无法找到你所需的功能，就只能自己实现这些功能了。\n总而言之，不要重复发明轮子。如果你要做的事情看起来是十分常见的，有可能类库中已经有某个类完成了这样的工作。如果确实是这样，就使用现成的;如果还不清楚是否存在这样的类，就去查一查。一般而言，类库的代码可能比你自己编写的代码更好一些，并且会随着时间的推移而不断改进。这并不是在质疑你作为一个程序员的能力。从经济角度的分析表明：类库代码受到的关注远远超过大多数普通程序员在同样的功能上所能给予的投人。\n第60条：如果需要精确的答案，请避免使用float和double运算(binary floating-point arithmetic)，这是为了在广泛的数值范围上提供较为精确的快速近似计算而精心设计的。然而，它们并没有提供完全精确的结果，所以不应该被用于需要精确结果的场合。float 和 double 类型尤其不适合用于货币计算，因为要让一个float 或\n例如，假设你的口袋中有 $1.03，花掉了42之后还剩下多少钱呢？下面这个很简单的程序片段试图回答这个问题：\nSystem.out.print1n(1.03 - 0.42);\n遗憾的是，它输出的结果是0.6100000000000001。这并不是个别的例子。假设你的口袋里有$1，你买了9个垫圈，每个为10。那么应该找回多少零头呢？\nSystem.out.println(1.00 - 9 * 0.10);\n根据上述程序片段，你得到的是$0.09999999999999998。\n你可能会认为，只要在打印之前将结果做一下舍人就可以解决这个问题，但遗憾的是，这种做法并不总是可行的。例如，假设你的口袋里有$1，你看到货架上有一排美味的糖果，标价分别为 10、20、30，等等，一直到$1。你打算从标价为10c的糖果开始，每种买1颗，一直到不能支付货架上下一种价格的糖果为止，那么你可以买多少颗糖果？还会找回多少零头？下面是一个简单的程序，用来解决这个问题：\n//Broken-usesfloatingpointformonetarycalculation！public static void main(String[] args) &#123;double funds = 1.00;int itemsBought = 0;for(double price=0.10;funds &gt;=price;price +=0.10)&#123;funds -= price;itemsBought++;System.out.println(itemsBought + &quot;items bought.&quot;);System.out.println(&quot;Change: $&quot; + funds);\n\n如果真正运行这个程序，你会发现可以支付3颗糖果，并且还剩下$0.3999999999999999。这个答案是不正确的！解决这个问题的正确方法是使用 BigDecimal、int 或者 1ong 进行货币计算。\n下面的程序是上一个程序的简单翻版，它使用BigDecimal类型代替double。注意，它使用了 BigDecimal 的 String 构造器，而不是用 double 构造器。为了避免将不正确的值引人到计算中，这是必需的[Bloch05,Puzzle 2]:\npublic static void main(String[] args)&#123;final BigDecimal TEN_CENTS = new BigDecimal(&quot;.10&quot;);int itemsBought = 0;BigDecimal funds = new BigDecimal(&quot;1.00&quot;);for (BigDecimal price = TEN_CENTS;funds.compareTo(price) &gt;= 0;price = price.add(TEN_CENTS)) &#123;funds = funds.subtract(price);itemsBought++;System.out.println(itemsBought + &quot; items bought.&quot;);System.out.println(&quot;Money left over: $&quot; + funds);\n\n如果运行这个修改过的程序，会发现可以支付4颗糖果，还剩下 $0.00。这才是正确的答案。\n然而，使用BigDecimal有两个缺点：与使用基本运算类型相比，这样做很不方便,而且速度很慢。对于解决这样一个简单的问题，后一种缺点并不要紧，但是前一种缺点可能会让你很不舒服。\n除了使用 BigDecimal 之外，还有一种办法是使用 int 或者long，到底选用 int 还是long 要取决于所涉及数值的大小，同时要自己处理十进制小数点。在这个示例中，最明显的做法是以分为单位进行计算，而不是以元为单位。下面是这个例子的简单翻版，展示了这种做法：\npublic static void main(String[] args)&#123;int itemsBought = 0;int funds=100;for (int price = 10;funds &gt;= price;price += 10)&#123;funds-=price;itemsBought++;System.out.println(itemsBought + &quot; items bought.&quot;);System.out.println(&quot;Cash left over:&quot;+ funds + &quot;cents&quot;);\n总而言之，对于任何需要精确答案的计算任务，请不要使用 float 或者 double。如果你想让系统来处理十进制小数点，并且不介意因为不使用基本类型而带来的不便，就请使用BigDecimal。使用BigDecimal 还有一些额外的好处，它允许你完全控制舍人，每当一个操作涉及舍人的时候，你都可以从8种舍人模式中选择其一。如果你正通过合法强制的舍入行为进行商务计算，使用 BigDecimal 是非常方便的。如果性能非常关键，并且你又不介意自己处理十进制小数点，而且所涉及的数值又不太大，就可以使用 int 或者 1ong。如果数值范围没有超过9位十进制数字，就可以使用 int;如果不超过18 位数字，就可以使用 long。如果数值可能超过18位数字，就必须使用 BigDecimal。\n第61条：基本类型优先于装箱基本类型Java 有一个类型系统由两部分组成，它包含基本类型(primitive)，如 int、double 和boolean，以及引用类型(reference type)，如 String 和List。每个基本类型都有一个对应的引l用类型，称作装箱基本类型(boxed primitive)。装箱基本类型中对应于int、double和boolean 的分别是 Integer、Double 和 Boolean。\n如第6条中提到的，自动装箱(autoboxing)和自动拆箱(auto-unboxing)模糊了但并没有完全抹去基本类型和装箱基本类型之间的区别。这两种类型之间真正是有差别的，要很清楚在使用的是哪种类型，并且要对这两种类型进行谨慎的选择，这些都非常重要。\n在基本类型和装箱基本类型之间有三个主要区别。第一，基本类型只有值，而装箱基了它对应基本类型的所有函数值之外，还有个 null。最后一点区别是，基本类型通常比装箱基本类型更节省时间和空间。如果不小心，这三点区别都会让你陷人麻烦之中。\n以下面这个比较器为例，它被设计用来表示 Integer 值的递增数字顺序。(回想一下，比较器的compare 方法返回的数值到底为负数、零还是正数，要取决于它的第一个参数是小于、等于还是大于它的第二个参数。)在实践中并不需要你编写这个在 Integer 中实现自然顺序的比较器，因为这是不需要比较器就可以得到的，但它展示了一个有趣的例子:\n这个比较器表面看起来似乎不错，它可以通过许多测试。例如，它可以通过Collections.sort正确地给一个有100万个元素的列表进行排序，无论这个列表中是否包含重复的元素。但是这个比较器有着严重的缺陷。如果你要让自己信服，只要打印 naturalOrder.Compare(newInteger(42)，newInteger(42))的值便可以分晓。这两个Integer实例都表示相同的值(42)，因此这个表达式的值应该为0，但它输出的却是1，这表明第一个Integer 值大于第二个。\n问题出在哪呢？naturalOrder 中的第一个测试工作得很好。对表达式i&lt;j执行计算会导致被i和j引l用的Integer 实例被自动拆箱(auto-unboxed);也就是说，它提取了它们的基本类型值。计算动作要检查产生的第一个int值是否小于第二个。但是假设答案是否定的。下一个测试就是执行计算表达式i==j，它在两个对象引用上执行同一性比较(identitycomparison)。如果i和j引用表示同一个int值的不同的Integer实例，这个比较操作就会返回 false，比较器会错误地返回 1，表示第一个Integer 值大于第二个。对装箱基本类型运用==操作符几乎总是错误的。\n\n事实上，如果需要用比较器描述一个类型的自然顺序，只要调用Comparator.natural-Order()即可，如果自已编写比较器，则应该使用比较器构造方法，或者在基本类型上使用静态比较方法(详见第14条)。也就是说，修正这个问题的做法是添加两个局部变量，来保存对应于装箱 Integer 参数的基本类型 int 值，并在这些变量上执行所有的比较操作。这样可以避免大量的同一性比较：\nComparator&lt;Integer&gt; natural0rder = (iBoxed, jBoxed) )-&gt;int i = iBoxed, j = jBoxed; // Auto-unboxingreturn i&lt; j?-1:(i == j? 0:1);接下来，看看下面这个小程序:public class Unbelievable &#123;static Integer i;public static void main(String[] args) &#123;if (i == 42)System.out.println(&quot;Unbelievable&quot;) ;\n\n它不会打印出 Unbelievable—但是它的行为也是很奇怪的。它在计算表达式(i &#x3D;&#x3D; 42)的时候抛出 NullPointerException 异常。问题在于，i是个Integer，而不是 int,就像所有的对象引l用域一样，它的初始值为 null。当程序计算表达式(i&#x3D;&#x3D; 42)时，它会将 Integer 与 int 进行比较。几乎在任何一种情况下，当在一项操作中混合使用基本类型和装箱基本类型时，装箱基本类型就会自动拆箱，这种情况无一例外。如果null对象引用被自动拆箱，就会抛出一个NullPointerException 异常。就如这个程序所示，它几乎可以在任何位置发生。修正这个问题很简单，声明i是个 int 而不是Integer 即可。\n最后，以第6条中的这个程序为例：\n//Hideously slowprogram！Canyou spot the object creation?public staticvoid main(String[] args)&#123;Long sum = OL;for(long i= O;i&lt;Integer.MAX_VALUE;i++)&#123;:=+unsSystem.out.println(sum) ;了\n\n这个程序运行起来比预计的要慢一些，因为它不小心将一个局部变量(sum)声明为是装箱基本类型Long，而不是基本类型 1ong。程序编译起来没有错误或者警告，变量被反复地装箱和拆箱，导致明显的性能下降。\n在本条目中所讨论的这三个程序中，问题是一样的：程序员忽略了基本类型和装箱基本类型之间的区别，并尝到了苦头。在前两个程序中，其结果是彻底的失败;在第三个程序中，则有严重的性能问题。\n那么什么时候应该使用装箱基本类型呢？它们有几个合理的用处。第一个是作为集合中的元素、键和值。你不能将基本类型放在集合中，因此必须使用装箱基本类型。这是一种更通用的特例。在参数化类型和方法(详见第5章)中，必须使用装箱基本类型作为类型参数，因为 Java 不允许使用基本类型。例如，你不能将变量声明为 ThreadLocal类型，因此必须使用 ThreadLocal代替。最后，在进行反射的方法调用(详见第65条)时，必须使用装箱基本类型。\n总而言之，当可以选择的时候，基本类型要优先于装箱基本类型。基本类型更加简单，也更加快速。如果必须使用装箱基本类型，要特别小心！自动装箱减少了使用装箱基本类型的烦琐性，但是并没有减少它的风险。当程序用&#x3D;&#x3D;操作符比较两个装箱基本类型时，它做了个同一性比较，这几乎肯定不是你所希望的。当程序进行涉及装箱和拆箱基本类型的混合类型计算时，它会进行拆箱，当程序进行拆箱时，会抛出 NullPointerException 异常。最后，当程序装箱了基本类型值时，会导致较高的资源消耗和不必要的对象创建。\n第62条：如果其他类型更适合，则尽量避免使用字符串字符串被用来表示文本，它在这方面也确实做得很好。因为字符串很通用，并且Java语言也支持得很好，所以自然就会有这样一种倾向：即使在不适合使用字符串的场合，人们往往也会使用字符串。本条目就是讨论一些不应该使用字符串的情形。\n字符串不适合代替其他的值类型。当一段数据从文件、网络，或者键盘设备，进人程序之后，它通常以字符串的形式存在。有一种自然的倾向是让它继续保留这种形式，但是，只有当这段数据本质上确实是文本信息时，这种想法才是合理的。如果它是数值，就应该被转换为适当的数值类型，比如 int、float 或者 BigInteger 类型。如果它是个”是－或-否”这种问题的答案，就应该被转换为 boolean 类型。如果存在适当的值类型，不管是基本类型，还是对象引用，大多应该使用这种类型;如果不存在这样的类型，就应该编写一个类型。虽然这条建议是显而易见的，但通常未能得到遵守。\n字符串不适合代替枚举类型。正如第34条中所讨论的，枚举类型比字符串更加适合用来表示枚举类型的常量。\n字符串不适合代替聚合类型。如果一个实体有多个组件，用一个字符串来表示这个实体通常是很不恰当的。例如，下面这行代码来自于真实的系统一标识符的名称已经被修改了，以免发生纠纷:\n# //Inappropriate use of string as aggregate typeString compoundKey = className + &quot;#&quot; + i.next(;\n\n这种方法有许多缺点。如果用来分隔域的字符也出现在某个域中，结果就会出现混乱。为了访问单独的域，必须解析该字符串，这个过程非常慢，也很烦琐，还容易出错。你无法提供equals、toString 或者compareTo 方法，只好被迫接受 String 提供的行为。更好的做法是，简单地编写一个类来描述这个数据集，通常是一个私有的静态成员类(详见第24条)。\n字符串也不适合代替能力表(capabilities)。有时候，字符串被用于对某种功能进行授权访问。例如，考虑设计一个提供线程局部变量(thread-local variable)的机制。这个机制提供的变量在每个线程中都有自己的值。自Java 1.2 发行版本以来，Java类库就有提供线程局部变量的机制，但在那之前，程序员必须自己完成。几年前，面对这样的设计任务时，有些人提出了同样的设计方案：利用客户提供的字符串键对每个线程局部变量的内容进行访问授权：\n// Broken -inappropriate use of string as capability！public class ThreadLocal &#123;private ThreadLocal( &#123; &#125; // Noninstantiable// Sets the current thread&#x27;s value forthenamed variable.public static void set(String key, Object value);// Returns the current thread&#x27;svaluefor the named variable.public static Object get(String key);\n\n这种方法的问题在于，这些字符串键代表了一个共享的全局命名空间。要使这种方法可行，客户端提供的字符串键必须是唯一的：如果两个客户端各自决定为它们的线程局部变量使用同样的名称，它们实际上就无意中共享了这个变量，这样往往会导致两个客户端都失败，而且安全性也很差。恶意的客户端可能有意地使用与另一个客户端相同的键，以便非法地访问其他客户端的数据。\n要修正这个API并不难，只要用一个不可伪造的键(有时被称为能力)来代替字符串即可：\npublic class ThreadLocal&#123;private ThreadLocal() &#123;&#125; // Noninstantiablepublic static class Key &#123;// (Capability)Key)&#123;&#125;// Generates a unique，unforgeablekeypublic static Key getKeyO) &#123;return new KeyO;子public static void set(Key key，Object value);public static Object get(Key key);\n\n这样虽然解决了基于字符串的API的两个问题，但是你还可以做得更好。你实际上不再需要静态方法，它们可以被代之以键(Key)中的实例方法，这样这个键就不再是键，而是线程局部变量了。此时，这个不可被实例化的顶层类也不再做任何实质性的工作，因此可以删除这个顶层类，并将嵌套类命名为 ThreadLocal:\npublic finalclass ThreadLocal &#123;public ThreadLocal(;public void set(Object value);public Object get();\n\n这个API不是类型安全的，因为当你从线程局部变量得到它时，必须将值从Object转换成它实际的值。不可能使原始的基于 String 的 API 为类型安全的，要使基于 Key 的API为类型安全的也很困难，但是通过将 ThreadLoca1 类泛型化(详见第 29 条)，使这个API变成类型安全的就是很简单的事情了：\npublic finalclass ThreadLocal&lt;T&gt; &#123;public ThreadLocalO;public void set(T value);public T getO;\n\n粗略地讲，这正是java.lang.ThreadLocal提供的 API。除了解决了基于字符串的API的问题之外，与前面的两个基于键的 API相比，它还更快速、更美观。\n总而言之，如果可以使用更加合适的数据类型，或者可以编写更加适当的数据类型，就应该避免用字符串来表示对象。若使用不当，字符串会比其他的类型更加笨拙、更不灵活、速度更慢，也更容易出错。经常被错误地用字符串来代替的类型包括基本类型、枚举类型和聚合类型。\n第63条：了解字符串连接的性能字符串连接操作符(+)是把多个字符串合并为一个字符串的便利途径。要想产生单独一行的输出，或者构造一个字符串来表示一个较小的、大小固定的对象，使用连接操作符是非常合适的，但是它不适合运用在大规模的场景中。为连接n个字符串而重复地使用字符串连接操作符，需要n的平方级的时间。这是由于字符串不可变(详见第17条)而导致的不幸结果。当两个字符串被连接在一起时，它们的内容都要被拷贝。\n例如，下面的方法通过重复地为每个项目连接一行，构造出一个代表该账单声明的字符串：\n// Inappropriate use of string concatenation -Performs poorly!public String statementO&#123;String result =&quot;&quot;;for(inti=O;i&lt;numItems(O;i++)result += lineForItem(i);// String concatenationreturn result;\n如果项目的数量巨大，这个方法的执行时间就难以估算。为了获得可以接受的性能，请用StringBuilder代替String，来存储构造过程中的账单声明：\npublic String statementO &#123;StringBuilder b = new StringBuilder(numItems( * LINE_WIDTH);for(int i=0;i&lt; numItemsO;i++)b.append(lineForItem(i));return b.toStringO;\n从Java 6以来，已经做了大量的工作使字符串连接变得更加快速，但是上述两种做法的性能差别还是很大：如果 numItems 返回 100，并且 1ineForItem 返回一个固定长度为80个字符的字符串，在我的机器上，第二种做法比第一种做法要快6.5倍。因为第一种做法的开销随项目数量而呈平方级增加，项目的数量越大，性能的差别就会越明显。注意，第二种做法预先分配了一个 StringBuilder，使它大到足以容纳整个结果字符串，因此不需要自动扩展。即使使用了默认大小的 StringBuilder，它也仍然比第一种做法快5.5倍。\n原则很简单：不要使用字符串连接操作符来合并多个字符串，除非性能无关紧要。否则，应该使用 StringBuilder 的 append 方法。另一种做法是使用字符数组，或者每次只处理一个字符串，而不是将它们组合起来。\n第64条：通过接口引1用对象第 51条建议：应该使用接口而不是类作为参数类型。更通俗来讲，应该优先使用接口而不是类来引用对象。如果有合适的接口类型存在，那么对于参数、返回值、变量和域来说，就都应该使用接口类型进行声明。只有当你利用构造器创建某个对象的时候，才真正需要引l用这个对象的类。为了更具体地说明这一点，以LinkedHashSet的情形为例，它是Set接口的一个实现。在声明变量的时候应该养成这样的习惯：\n而不是像这样的声明：\n//Bad-usesclassastype！LinkedHashSet&lt;Son&gt; SonSet = new LinkedHashSet&lt;&gt;();\n\n如果养成了用接口作为类型的习惯，程序将会更加灵活。当你决定更换实现时，所要做的就只是改变构造器中类的名称(或者使用一个不同的静态工厂)。例如，第一个声明可以被改变为：\nSetsonSet &#x3D;new HashSet&lt;&gt;()\n周围的所有代码都可以继续工作。周围的代码并不知道原来的实现类型，所以它们对于这种变化并不在意。\n有一点值得注意：如果原来的实现提供了某种特殊的功能，而这种功能并不是这个接口的通用约定所要求的，并且周围的代码又依赖于这种功能，那么很关键的一点是，新的实现也要提供同样的功能。例如，如果第一个声明周围的代码依赖于LinkedHashSet的同步策略，那么在声明中用 HashSet 代替LinkedHashSet 就是不正确的，因为 HashSet 不能保证相关的选代顺序。\n为什么要改变实现类型呢？因为第二个实现提供了比第一个更好的性能，或者因为它提供了你所期待的而原来的实现缺乏的功能。比如，假设有一个域中包含了一个HashMap 实例。如果将它改成EnumMap，则可以提供更好的性能，并且迭代顺序与键的自然顺序一致,但是如果键的类型为枚举类型，你就只能使用EnumMap。如果将HashMap 改成Linkded-HashMap，则能提供可以预估的迭代顺序，以及可以与 HashMap 比拟的性能，对于键类型没有任何特殊的要求。\n你可能会觉得，用变量的实现类型来声明变量，也是可以接受，因为可以同时改变声明类型和实现类型，但是不能确保修改后的程序可以编译。如果客户端代码使用了没有出现在新实现中的原始实现类型中的方法，或者客户端代码将该实例传到了需要原始实现类型的方法中，那么代码在完成这样的修改之后将不再进行编译。用接口类型声明变量要”保持诚实”。\n如果没有合适的接口存在，完全可以用类而不是接口来引用对象。以值类(valueclass)为例，比如 String 和 BigInteger。记住，值类很少会用多个实现编写。它们经常是final的，并且很少有对应的接口。使用这种值类作为参数、变量、域或者返回类型是再合适不过的了。\n不存在适当接口类型的第二种情形是，对象属于一个框架，而框架的基本类型是类，不是接口。如果对象属于这种基于类的框架(class-based framework)，就应该用相关的基类(base class)(往往是抽象类)来引l用这个对象，而不是用它的实现类。许多java.io类，比如 OutputStream 就属于这种情形。\n不存在适当接口类型的最后一种情形是，类实现了接口但它也提供了接口中不存在的法。如果程序依赖于这些额外的方法，这种类就应该只被用来引用它的实例，永远也不应该被用作参数类型。\n上，给定的对象是否具有适当的接口应该是很显然的。如果是，用接口引用对象就会使程序更加灵活。如果没有适合的接口，就用类层次结构中提供了必要功能的最小的具体类来引用对象吧。\n第65条：接口优先于反射机制核心反射机制(core reflection facility)，java.lang.reflect包，提供了”通过程序来访问任意类”的能力。给定一个Class对象，可以获得Constructor、Method 和Field 实例，它们分别代表了该 Class 实例所表示的类的构造器、方法和域。这些对象提供了”通过程序来访问类的成员名称、域类型、方法签名等信息”的能力。\n此外，Constructor、Method 和 Field实例使你能够通过反射机制操作它们的底层对等体：通过调用 Constructor、Method 和 Field 实例上的方法，可以构造底层类的实例、调用底层类的方法，并访问底层类中的域。例如，Method.invoke 使你可以调用任何类的任何对象上的任何方法(遵从常规的安全限制)。反射机制允许一个类使用另一个类，即使当前者被编译的时候后者还根本不存在。然而，这种能力也要付出代价：\n口损失了编译时类型检查的优势，包括异常检查。如果程序企图用反射方式调用不存在的或者不可访问的方法，在运行时它将会失败，除非采取了特别的预防措施。\n口执行反射访问所需要的代码非常笨拙和长。编写这样的代码非常乏味，阅读起来也很困难。\n口性能损失。反射方法调用比普通方法调用慢了许多。具体慢了多少，这很难说，因为受到了多个因素的影响。在我的机器上，调用一个没有输入参数和int返回值的方法，用普通方法调用比用反射机制调用快了11倍。\n有一些复杂的应用程序需要使用反射机制。这些示例包括代码分析工具和依赖注人框架。不过最近以来，这类工具已经不再使用反射机制，因为它的缺点越来越明显。如果你怀疑自己的应用程序是否也需要反射机制，它很有可能是不需要的。\n如果只是以非常有限的形式使用反射机制，虽然也要付出少许代价，但是可以获得许多好处。许多程序必须用到的类在编译时是不可用的，但是在编译时存在适当的接口或者超类，通过它们可以引用这个类(详见第64条)。如果是这种情况，就可以用反射方式创建实例，然后通过它们的接口或者超类，以正常的方式访问这些实例。\n例如，下面的程序创建了一个 Set实例，它的类是由第一个命令行参数指定的。该程序把其余的命令行参数插人到这个集合中，然后打印该集合。不管第一个参数是什么，程序都会打印出余下的命令行参数，其中重复的参数会被消除掉。这些参数的打印顺序取决于第一个参数中指定的类。如果指定java.util.HashSet，显然这些参数就会以随机的顺序打印出来;如果指定java.util.TreeSet，则会按照字母顺序打印，因为TreeSet中的元素是排好序的。相应的代码如下:\n//Reflectiveinstantiationwithinterface accesspublic static void main(String[] args)&#123;//Translatetheclassnameintoa Class objectClass&lt;? extends Set&lt;String&gt;&gt; cl = null;try&#123;c1 =(Class&lt;? extends Set&lt;String&gt;&gt;) // Unchecked cast!Class.forName(args[0]);&#125; catch (ClassNotFoundException e)&#123;fatalError(&quot;Class not found.&quot;);//Get the constructorConstructor&lt;? extends Set&lt;String&gt;&gt; cons = null;try&#123;cons = cl.getDeclaredConstructor();&#125; catch (NoSuchMethodException e) &#123;fatalError(&quot;No parameterless constructor&quot;);//Instantiate the setSet&lt;String&gt; S = null;try &#123;s = cons.newInstance(;&#125;catch (IllegalAccessException e)&#123;fatalError(&quot;Constructor not accessible&quot;);&#125;catch (InstantiationException e) &#123;fatalError(&quot;Class not instantiable.&quot;);&#125; catch (InvocationTargetException e) &#123;fatalError(&quot;Constructor threw &#x27;+ e.getCause());&#125;catch (ClassCastException e)&#123;fatalError(&quot;Class doesn&#x27;t implement Set&quot;);//Exercisethe sets.addAll(Arrays.asList(args).subList(1, args.length));System.out.println(s) ;private static void fatalError(String msg) &#123;System.err.println(msg) ;System.exit(1);\n\n尽管这只是一个试验程序，但是它所演示的方法是非常强大的。这个试验程序可以很容易地变成一个通用的集合测试器，通过侵人式地操作一个或者多个集合实例，并检查是否遵守 Set接口的约定，以此来验证指定的 Set实现。同样地，它也可以变成一个通用的集合性能分析工具。实际上，它所演示的这种方法足以实现一个成熟的服务提供者框架(service provider framework)，详见第1条。绝大多数情况下，使用反射机制时需要的也正是这种方法。\n这个示例演示了反射机制的两个缺点。第一，这个例子会产生6个运行时异常，如果不使用反射方式的实例化，这6个错误都会成为编译时错误。(为了好玩，你也可以通过传人适当的命令行参数，让程序逐个生成这6个异常。)第二，根据类名生成其实例需要 25行冗长的代码，而调用一个构造器则可以非常简洁地只用一行代码。程序的长度可以通过捕捉ReflectiveOperationException 异常来减少，这是在Java 7中引l人的各种反射异常的一个超类。这两个缺点都局限于实例化对象的那部分代码。一旦对象被实例化，它与其他的Set实例就难以区分了。在实际的程序中，通过这种限定使用反射的方法，绝大部分代码可以不受影响。\n如果试着编译这个程序，会得到一条未受检的转换警告。这条警告是合法的，因此转情况下，程序在实例化这个类时就会抛出一个ClassCastException 异常。要了解禁止这种警告的最佳方法，请参见第27条。\n类对于在运行时可能不存在的其他类、方法或者域的依赖性，用反射法进行管理是合理的，但是很少使用。如果要编写一个包，并且它运行的时候就必须依赖其他某个包的多个版本，这种做法可能就非常有用。具体做法就是，在支持包所需要的最小环境下对它进行编译，通常是最老的版本，然后以反射方式访问任何更加新的类或者方法。如果企图访问的新类或者新方法在运行时不存在，为了使这种方法有效你还必须采取适当的动作。所谓适当的动作，可能包括使用某种其他可替换的办法来达到同样的目的，或者使用简化的功能进行处理。\n总而言之，反射机制是一种功能强大的机制，对于特定的复杂系统编程任务，它是非常必要的，但它也有一些缺点。如果你编写的程序必须要与编译时未知的类一起工作，如有可能，就应该仅仅使用反射机制来实例化对象，而访问对象时则使用编译时已知的某个接口或者超类。\n第66条：谨慎地使用本地方法Java NativeInterface(JNI)允许Java 应用程序调用本地方法(native method)，所谓本地方法是指用本地编程语言(比如C或者C++)来编写的方法。它们提供了”访问特定于平台的机制”的能力，比如访问注册表(registry)。它们还提供了访问本地遗留代码库的能力，从而可以访问遗留数据(legacy data)。最后，本地方法可以通过本地语言，编写应用程序中注重性能的部分，以提高系统的性能。\n使用本地方法来访问特定于平台的机制是合法的，但是几乎没有必要：因为随着Java平台的不断成熟，它提供了越来越多以前只有在宿主平台上才拥有的特性。例如，Java 9增加的进程API，提供了访问操作系统进程的能力。当Java 中没有相当的类库可用时，使用本地方法来使用遗留代码库也是合法的。\n使用本地方法来提高性能的做法不值得提倡。在早期的发行版本中(Java 3 发行版本之前)，这样做往往是很有必要的，但是从那以后，JVM实现变得越来越快了。对于大多数任务，现在用Java 就可以获得与之相当的性能。举例来说，当Java 1.1 发行版本中增加了java.math 时，BigInteger 是在一个用C编写的快速多精度运算库的基础上实现的。在 Java 3 发行版本中，BigInteger 则完全用Java 重新实现了，并且进行了精心的性能调优，运行得比原来的本地实现更快。\n这个故事有一个悲伤的尾声：从那时起,BigInteger几乎没怎么改变，但在Java8中，大整数却以更快的乘积速度在发展。当时，遗留代码库的工作还在持续快速地发展中，著名的有 GNU 高精度算术运算库(GNU Multiple Precision，GMP)。对于需要真正高性能的高精度算术运算的 Java 程序员，现在通过本地方法来使用 GMP 也是无可厚非的[Blum14]。\n使用本地方法有一些严重的缺陷。因为本地语言不是安全的(详见第50条)，所以使用本地方法的应用程序也不再能免受内存毁坏错误的影响。因为本地语言是与平台相关的，使用本地方法的应用程序也不再是可自由移植的。使用本地方法的应用程序也更难调试。如果不小心，本地方法还可能降低性能，因为回收垃圾器不是自动的，甚至无法追踪本机内存(native memory)使用情况(详见第8条)，而且在进人和退出本地代码时，还需要相关的开销。最后一点，需要”胶合代码”的本地方法编写起来单调乏味，并且难以阅读。\n总而言之，在使用本地方法之前务必三思。只有在极少数情况下需要使用本地方法来提高性能。如果你必须要使用本地方法来访问底层的资源，或者遗留代码库，也要尽可能少用本地代码，并且要全面进行测试。本地代码中只要有一个Bug都可能破坏整个应用程序。\n第67条：谨慎地进行优化有三条与优化有关的格言是每个人都应该知道的：\n很多计算上的过失都被归咎于效率(没有达到必要的效率)，而不是任何其他的原因—甚至包括盲目地做傻事。\nWilliam A. Wulf [Wulf72]\n不要去计较效率上的一些小小的得失，在97%的情况下，不成熟的优化才是一切问题的根源。\nDonald E. Knuth [Knuth74]\n在优化方面，我们应该遵守两条规则：\n规则 1：不要进行优化。\n规则2(仅针对专家)：还是不要进行优化一也就是说，在你还没有绝对清晰的未优化方案之前，请不要进行优化。\nM.A. Jackson [Jackson75]\n所有这些格言都比 Java 程序设计语言的出现早了 20 年。它们讲述了一个关于优化的深刻真理：优化的弊大于利，特别是不成熟的优化。在优化过程中，产生的软件可能既不快速，也不正确，而且还不容易修正。\n不要为了性能而牺牲合理的结构。要努力编写好的程序而不是快的程序。如果好的程序不够快，它的结构将使它可以得到优化。好的程序体现了信息隐藏(information hiding)的原则：只要有可能，它们就会把设计决策集中在单个模块中，因此可以改变单个决策，而不会影响到系统的其他部分(详见第15条)。\n这并不意味着，在完成程序之前就可以忽略性能问题。实现上的问题可以通过后期的优化而得到修正，但是，遍布全局并且限制性能的结构缺陷几乎是不可能被改正的，除非重新编写系统。在系统完成之后再改变设计的某个基本方面，会破坏系统的结构，从而难以维护和改进。因此，必须在设计过程中考虑到性能问题。\n要努力避免那些限制性能的设计决策。当一个系统设计完成之后，其中最难以更改的组件是那些指定了模块之间交互关系以及模块与外界交互关系的组件。在这些设计组件之中，最主要的是API、交互层(wire-level)协议以及永久数据格式。这些设计组件不仅在事后难以甚至不可能改变，而且它们都有可能对系统本该达到的性能产生严重的限制。\n要考虑API设计决策的性能后果。使公有的类型成为可变的，这可能会导致大量不必要的保护性拷贝(详见第 50条)。同样地，在适合使用复合模式的公有类中使用继承，会把这个类与它的超类永远地束缚在一起，从而人为地限制了子类的性能(详见第18条)。最后一个例子，在API中使用实现类型而不是接口，会把你束缚在一个具体的实现上，即使将来出现更快的实现你也无法使用(详见第64条)。\nAPI设计对于性能的影响是非常实际的。以 Java.awt.Component类中的getSize方法为例。决定就是，这个注重性能的方法将返回 Dimension 实例，与此密切相关的决定是，Dimension 实例是可变的，迫使这个方法的任何实现都必须为每个调用分配一个新的Dimension 实例。尽管在现代 VM上分配小对象的开销并不大，但是分配数百万个不必要的对象仍然会严重地损害性能。\n在这种情况下，有几种可供选择的替换方案。理想情况下，Dimension 应该是不可变的(详见第 17条);另一种方案是，用两个方法来替换 getSize 方法，它们分别返回 Dimension的方法被加人到Component API中。然而，原先的客户端代码仍然可以使用 getSize方法，并且仍然要承受原始API设计决策所带来的性能影响。\n幸运的是，一般而言，好的API设计也会带来好的性能。为获得好的性能而对API进行包装，这是一种非常不好的想法。导致你对API进行包装的性能因素可能会在平台未来的发行版本中，或者在将来的底层软件中不复存在，但是被包装的API以及由它引起的问题将永远困扰着你。\n一旦精心地设计了程序，并且产生了一个清晰、简明、结构良好的实现，那么就到了该考虑优化的时候了，假定此时你对于程序的性能还不满意。\n回想一下Jackson 提出的两条优化原则：”不要优化”以及”(仅针对专家)还是不要优化”。他可以再增加一条：在每次试图做优化之前和之后，要对性能进行测量。你可能会惊讶于自己的发现。试图做的优化通常对于性能并没有明显的影响，有时候甚至会使性能变得更差。主要原因在于，要猜出程序把时间花在哪些地方并不容易。你认为程序慢的地方可能并没有问题，这种情况下实际上是在浪费时间去尝试优化。大多数人认为：程序把90%的时间花在10%的代码上了。\n的信息，比如每个方法大致上花费了多少时间、它被调用多少次。除了确定优化的重点之，外，它还可以警告你是否需要改变算法。如果一个平方级(或更差)的算法潜藏在程序中，无论怎么调整和优化都很难解决问题。你必须用更有效的算法来替换原来的算法。系统中的代码越多，使用性能剖析器就显得越发重要。这就好像要在一堆干草中寻找一根针：这堆干草越大，使用金属探测器就越有用。值得特别提及的另一种工具是jmh，它不是一个性能部析器，而是微基准测试框架(microbenchmarking framework)，它提供了非并行地可见 Java代码性能详情的能力[JMH]。\n在Java平台上对优化的结果进行测量，比在其他的传统平台(如C和C++)上更有必要，因为Java程序设计语言没有很强的性能模型(performance model)：各种基本操作的相对开销也没有明确定义。程序员所编写的代码与CPU执行的代码之间存在”语义沟”(semantic gap)，而且这条语义沟比传统编译语言中的更大，这使得要想可靠地预测出任何优化的性能结果都非常困难。大量流传的关于性能的说法最终都被证明为半真半假，或者根，本就不正确。\n不仅Java 的性能模型未得到很好的定义，而且在不同的JVM实现，不同的发行版本,以及不同的处理器中，也都各不相同。如果将要在多个JVM实现和多种硬件平台上运行程序，很重要的一点是，需要在每个Java 实现上测量优化效果。有时候，还必须在从不同JVM实现或者硬件平台上得到的性能结果之中进行权衡。\n自从本条目开始编写以来的近二十年，Java软件堆栈的每一个组件都变得更加复杂，从管理器到虚拟机，再到类库，运行Java 的各种硬件也得到了迅猛的发展。这些因素结合起来导致现在 Java 程序的性能比 2001 年时更难以预测了，因此对测量性能的需求也相应地增加了。\n总而言之，不要费力去编写快速的程序一一应该努力编写好的程序，速度自然会随之而来。但在设计系统的时候，特别是在设计API、交互层协议和永久数据格式的时候，一定要考虑性能的因素。当构建完系统之后，要测量它的性能。如果它足够快，你的任务就完成了。如果不够快，则可以在性能剖析器的帮助下，找到问题的根源，然后设法优化系统中相关的部分。第一个步骤是检查所选择的算法：再多的低层优化也无法弥补算法的选择不当。必要时重复这个过程，在每一次修改之后都要测量性能，直到满意为止。\n第68条：遵守普遍接受的命名惯例Java平台建立了一整套很好的命名惯例(naming convention)，其中有许多命名惯例包含在了《The Java Language Specification》[JLS,6.1]中。不严格地讲，这些命名惯例分为两大类：字面的(typographical)和语法的(grammatical)。\n字面的命名惯例比较少，但也涉及包、类、接口、方法、域和类型变量。应该尽量不违反这些惯例，不到万不得已，千万不要违反。如果API违反了这些惯例，使用起来可能会很困难。如果实现违反了它们，可能会难以维护。在这两种情况下，违反惯例都会潜在地给使用这些代码的其他程序员带来困惑和苦恼，并且使他们做出错误的假设，造成程序出错。本条目将对这些惯例做简要的介绍。\n包和模块的名称应该是层次状的，用句号分隔每个部分。每个部分都包括小写字母，极少数情况下还有数字。任何将在你的组织之外使用的包，其名称都应该以你的组织的Internet 域名开头，并且顶级域名要放在前面，例如edu.cmu、com.google、Org.eff。标准类库和一些可选的包，其名称以java 和javax 开头，它们属于这一规则的例外。用户创建的包的名称绝不能以java 和javax开头。关于将Internet域名转换为包名称前缀的详细规则，请参见《The Java Language Specification》[JLS,6.1]。\n包名称的其余部分应该包括一个或者多个描述该包的组成部分。这些组成部分应该比较简短，通常不超过8个字符。鼓励使用有意义的缩写形式，例如，使用util而不是utilities。只取首字母的缩写形式也是可以接受的，例如 awt。每个组成部分通常都应该由一个单词或者一个缩写词组成。\n许多包的名称中都只有一个组成部分再加上Internet域名。比较大的名称使用附加部分是正确的，它们的规模要求它们要被分割成一个非正式的层次结构。例如，javax.util包有着非常丰富的包层次，如javax.util.concurrent.atomic。这样的包通常被称为子包(subpackage)，尽管Java 语言并没有提供对包层次的支持。\n类和接口的名称，包括枚举和注解类型的名称，都应该包括一个或者多个单词，每个单词的首字母大写，例如List 和 FutureTask。应该尽量避免用缩写，除非是一些首字母缩写和一些通用的缩写，比如 max 和min。对于首字母缩写，到底应该全部大写还是只有首字母大写，没有统一的说法。虽然有些程序员仍然采用全部大写的形式，但还是有人强烈支持只首字母大写：即使连续出现多个首字母缩写的形式，你仍然可以区分出一个单词的起始处和结束处。比如类名 HTTPURL 和 HttpUrl 你更愿意看到哪一个?\n方法和域的名称与类和接口的名称一样，都遵守相同的字面惯例，只不过方法或者域的名称的第一个字母应该小写，例如 remove、ensureCapacitY。如果由首字母缩写组成的单词是一个方法或者域名称的第一个单词，它就应该是小写形式。\n上述规则的唯一例外是”常量域”，它的名称应该包含一个或者多个大写的单词，中间用下划线符号隔开，例如VALUES 或NEGATIVE_INFINITY。常量域是个静态final域,它的值是不可变的。如果静态 final域有基本类型，或者有不可变的引用类型(详见第17条)，它就是个常量域。例如，枚举常量是常量域。如果静态 final域有个可变的引用类型，若被引用的对象是不可变的，它也仍然可以是个常量域。注意，常量域是唯一推荐使用下划线的情形。\n局部变量名称的字面命名惯例与成员名称类似，只不过它也允许缩写，单个字符和短字符序列的意义取决于局部变量所在的上下文环境，例如i、denom 和houseNum。输人参数是一种特殊的局部变量。它们的命名应该比普通的局部变量更加小心，因为它们的名称是其方法文档的一个组成部分。\n类型参数名称通常由单个字母组成。这个字母通常是以下五种类型之一：T表示任意的类型，E 表示集合的元素类型，K和V 表示映射的键和值类型，X表示异常。函数的返回类型通常是R。任何类型的序列可以是T、U、V 或者 T1、T2、T3。\n为了快速查阅，下表列出了字面惯例的例子。\n\n语法命名惯例比字面惯例更加灵活，也更有争议。对于包而言，没有语法命名惯例。可被实例化的类(包括枚举类型)通常用一个名词或者名词短语命名，例如 Thread、命名，如 Collectors 或者Collections。接口的命名与类相似，例如Collection 或Comparator，或者用一个以 able 或 ible 结尾的形容词来命名，例如 Runnable、Iterable或者Accessible。由于注解类型有这么多用处，因此没有单独安排词类。名词、动词、介词和形容词都很常用，例如 BindingAnnotation、Inject、ImplementedBy 或者Singleton.\n执行某个动作的方法通常用动词或者动词短语(包括对象)来命名，例如append或drawImage。对于返回boolean 值的方法，其名称往往以单词is开头，很少用has，后面跟名词或名词短语，或者任何具有形容词功能的单词或短语，例如 isDigit、isProbablePrime、isEmpty、isEnabled 或者 hasSiblingS。\n如果方法返回被调用对象的一个非boolean 的函数或者属性，它通常用名词、名词短语，或者以动词 get 开头的动词短语来命名，例如 size、hashCode 或者 getTime。有一个组织声称只有第三种形式(以 get开头)才可以接受，但是这种声明没有得到支持。前两种形式往往会产生可读性更好的代码，例如:\n以 get 开头的形式主要出现在被废弃的 Java Beans 规范中，它形成了早期的可重用组件架构的基础。有些现代工具继续依赖 Beans 命名惯例，你大可放心地在那些需要结合这些工具一起使用的代码中使用。如果类中包含了用于相同属性的 setter 方法和 getter 方法，也强烈建议采用这种命名形式。在这种情况下，这两种方法应该分别被命名为 getAttribute 和setAttribute.\n有些方法的名称值得专门提及。转换对象类型的实例方法，它们返回不同类型的独立对象的方法，经常被称为toType，例如 toString 或者toArraY。返回视图(view，详见第6条，视图的类型不同于接收对象的类型)的方法经常被称为 asType，例如 asList。返回一个与被调用对象同值的基本类型的方法，经常被称为 typeValue，例如 intValue。静态工厂的常用名称包括 from、of、valueOf、instance、getInstance、newInstance、getType和newType(详见第1条)。\n域名称的语法惯例没有很好地建立起来，它们也没有类、接口和方法名称那么重要，因为设计良好的 API很少会包含暴露出来的域。boolean 类型的域命名与boolean 类型的访问方法(accessor method)很类似，但是省去了初始的 is，例如 initialized 和 composite。其他类型的域通常用名词或者名词短语来命名，比如 height、digits 或bodyStyle。局部变量的语法惯例类似于域的语法惯例，但是更弱一些。\n总而言之，把标准的命名惯例当作一种内在的机制来看待，并且学着用它们作为第二特性。字面惯例是非常直接和明确的;语法惯例则更复杂，也更松散。下面这句话引[自盲目遵从这些命名惯例。”请使用大家公认的做法。\n第10章充分发挥异常的优点，可以提高程序的可读性、可靠性和可维护性。如果使用不当,它们也会带来负面的影响。本章提供了一些关于有效使用异常的指导原则。\n第69条：只针对异常的情况才使用异常某一天，如果你不走运的话，可能会碰到下面这样的代码：\n//Horrible abuseof exceptions.Don&#x27;tever do this！try&#123;int i=0;while(true)range[i++].climb();&#125;catch (ArrayIndexOutOfBoundsException e)&#123;\n\n这段代码有什么作用？看起来根本不明显，这正是它没有真正被使用的原因(详见第67条)。事实证明，作为一个要对数组元素进行遍历的实现方式，它的构想是非常拙劣的。当这个循环企图访问数组边界之外的第一个数组元素时，用抛出(throw)、捕获(catch)、忽略ArrayIndexOutOfBoundsException 的手段来达到终止无限循环的目的。假定它与数组循环的标准模式是等价的，对于任何一个Java 程序员来说，下面的标准模式一看就会明白：\n# for (Mountain m : range)m.climb();\n\n那么，为什么有人会优先使用基于异常的循环，而不是用行之有效的模式呢？这是被误导了，他们企图利用 Java 的错误判断机制来提高性能，因为 VM 对每次数组访问都要检查越界情况，所以他们认为正常的循环终止测试被编译器隐藏了，但在 for-each 循环中仍然可见，这无疑是多余的，应该避免。这种想法有三个错误：\n因为异常机制的设计初衷是用于不正常的情形，所以几乎没有JVM实现试图对它们进行优化，使它们与显式的测试一样快速。把代码放在 trY-catch 块中反而阻止了现代 JVM 实现本来可能要执行的某些特定优化。口对数组进行遍历的标准模式并不会导致冗余的检查。有些现代的JVM实现会将它们优化掉。\n实际上，基于异常的模式比标准模式要慢得多。在我的机器上，对于一个有100个元素的数组，基于标准模式比异常的模式快了2倍。\n基于异常的循环模式不仅模糊了代码的意图，降低了它的性能，而且它还不能保证正常工作！如果出现了不相关的Bug，这个模式会悄悄地失效，从而掩盖了这个Bug，极大地增加了调试过程的复杂性。假设循环体中的计算过程调用了一个方法，这个方法执行了对某个不相关数组的越界访问。如果使用合理的循环模式，这个Bug会产生未被捕捉的异常，从而导致线程立即结束，产生完整的堆栈轨迹。如果使用这个被误导的基于异常的循环模式，与这个 Bug 相关的异常将会被捕捉到，并且被错误地解释为正常的循环终止条件。\n这个例子的教训很简单：顾名思义，异常应该只用于异常的情况下;它们永远不应该用于正常的控制流。一般地，应该优先使用标准的、容易理解的模式，而不是那些声称可以提供更好性能的、弄巧成拙的方法。即使真的能够改进性能，面对平台实现的不断改进，这种模式的性能优势也不可能一直保持。然而，由这种过度聪明的模式带来的微妙的Bug，以及维护的痛苦却依然存在。\n这条原则对于 API设计也有启发。设计良好的 API 不应该强迫它的客户端为了正常的控制流而使用异常。如果类具有”状态相关”(state-dependent)的方法，即只有在特定的不testing)方法，即指示是否可以调用这个状态相关的方法。例如,Iterator接口有一个”状态相关”的 next方法，及相应的状态测试方法 hasNext。这使得利用传统的 for 循环(以及 for-each 循环，在内部使用了 hasNext方法)对集合进行迭代的标准模式成为可能:\nfor (Iterator&lt;Foo&gt; i = collection.iterator();i.hasNext();) &#123;Foo foo = i.next();·&#125;如果 Iterator 缺少hasNext 方法，客户端将被迫改用下面的做法://Donotusethishideouscodeforiterationoveracollection！try&#123;Iterator&lt;Foo&gt; i = collection.iterator();while(true)&#123;Foo foo = i.next();子&#125; catch (NoSuchElementException e) &#123;\n\n这应该非常类似于本条目刚开始时对数组进行迭代的例子。除了代码烦琐且令人误解之外，这个基于异常的模式可能执行起来也比标准模式更差，并且还可能掩盖系统中其他不相关部分中的 Bug。\n另一种提供单独的状态测试方法的做法是，如果”状态相关的”方法无法执行想要的计算，就让它返回一个零长度的optional值(详见第55条)，或者返回一个可识别的值，比如null。\n对于”状态测试方法”和”optional返回值或可识别的返回值”这两种做法，有些指导原则可以帮助你在两者之中做出选择。如果对象将在缺少外部同步的情况下被并发访问，或者可被外界改变状态，就必须使用optional返回值或者可识别的返回值，因为在调用”状态测试”方法和调用对应的”状态相关”方法的时间间隔之中，对象的状态有可能会发生变化。如果单独的”状态测试”方法必须重复”状态相关”方法的工作，从性能的角度考虑，就应该使用可被识别的返回值。如果所有其他方面都是等同的，那么”状态测试”方法则略优于可被识别的返回值。它提供了稍微更好的可读性，对于使用不当的情形可能更加易于检测和改正：如果忘了去调用状态测试方法，状态相关的方法就会抛出异常，使这个Bug变得很明显;如果忘了去检查可识别的返回值，这个Bug 就很难被发现。optional返回值不会有这方面的问题。\n总而言之，异常是为了在异常情况下使用而设计的。不要将它们用于普通的控制流，也不要编写迫使它们这么做的API。\n第70条：对可恢复的情况使用受检异常，对编程错误使用运行时异常Java 程序设计语言提供了三种可抛出结构(throwable)：受检异常(checked exception)运行时异常(run-time exception)和错误(error)。关于什么时候适合使用哪种可抛出结构，程序员中间存在一些困惑。虽然这项决定并不总是那么清晰，但还是有些一般性的原则提出了强有力的指导。\n在决定使用受检异常或是未受检异常时，主要的原则是：如果期望调用者能够适当地恢复，对于这种情况就应该使用受检异常。通过抛出受检的异常，强迫调用者在一个catch子句中处理该异常，或者将它传播出去。因此，方法中声明要抛出的每个受检异常，都是对API用户的一种潜在指示：与异常相关联的条件是调用这个方法的一种可能的结果。\nAPI的设计者让API用户面对受检异常，以此强制用户从这个异常条件中恢复。用户可以忽视这样的强制要求，只需捕获异常并忽略即可，但这往往不是个好办法(详见第 77条)。\n有两种未受检的可抛出结构：运行时异常和错误。在行为上两者是等同的：它们都是不需要也不应该被捕获的可抛出结构。如果程序抛出未受检的异常或者错误，往往就属于不可恢复的情形，继续执行下去有害无益。如果程序没有捕捉到这样的可抛出结构，将会导致当前线程中断(halt)，并出现适当的错误消息。\n用运行时异常来表明编程错误。大多数的运行时异常都表示前提违例(preconditionviolation)。所谓前提违例是指 API 的客户没有遵守 API规范建立的约定。例如，数组访问的约定指明了数组的下标值必须在零和数组长度减1之间。ArrayIndexOutOfBoundsException表明违反了这个前提。\n这条建议有一个问题：对于要处理可恢复的条件，还是处理编程错误，情况并非总是那么黑白分明。例如，考虑资源枯竭的情形，这可能是由于程序错误而引起的，比如分配了一块不合理的过大的数组，也可能确实是由于资源不足而引起的。如果资源枯竭是由于临时的短缺，或是临时需求太大所造成的，这种情况可能就是可恢复的。API设计者需要判断这样的资源枯竭是否允许恢复。如果你相信一种情况可能允许恢复，就使用受检的异常;如果不是，则使用运行时异常。如果不清楚是否有可能恢复，最好使用未受检的异常，原因请参见第71条的讨论。\n虽然JLS(Java 语言规范)并没有要求，但是按照惯例，错误往往被JVM 保留下来使用，以表明资源不足、约束失败，或者其他使程序无法继续执行的条件。由于这已经是个几乎被普遍接受的惯例，因此最好不要再实现任何新的 Error 子类。因此，你实现的所有未受检的抛出结构都应该是RuntimeException 的子类(直接的或者间接的)。不仅不应该定义Error子类，甚至也不应该抛出 AssertionError异常。\n类，这也是可能的。JLS并没有直接规定这样的抛出结构，而是隐式地指定了：从行为意义上讲，它们等同于普通的受检异常(即 Exception 的子类，但不是 RuntimeException的子类)。那么，什么时候应该使用这样的抛出结构呢？一句话：永远也不会用到。它与普通的受检异常相比没有任何益处，只会困扰API的用户。\nAPI的设计者往往会忘记，异常也是个完全意义上的对象，可以在它上面定义任意的方法。这些方法的主要用途是为捕获异常的代码而提供额外的信息，特别是关于引[发这个异常条件的信息。如果没有这样的方法，程序员必须要懂得如何解析”该异常的字符串表示法”，以便获得这些额外信息。这是极为不好的做法(详见第12条)。类很少会指定它们的字符串表示法中的细节，因此，对于不同的实现及不同的版本，字符串表示法会大相径庭。由此可见，”解析异常的字符串表示法”的代码可能是不可移植的，也是非常脆弱的。\n因为受检异常往往指明了可恢复的条件，所以，对于这样的异常，提供一些辅助方法尤其重要，通过这些方法，调用者可以获得一些有助于恢复的信息。例如，假设因为用户资金不足，当他企图购买一张礼品卡时导致失败，于是抛出一个受检的异常。这个异常应该提供一个访问方法，以便允许客户查询所缺的费用金额，使得调用者可以将这个数值传递给用户。关于这个主题的更多详情，请参阅第75条。\n总而言之，对于可恢复的情况，要抛出受检异常;对于程序错误，要抛出运行时异常。不确定是否可恢复，则抛出未受检异常。不要定义任何既不是受检异常也不是运行时异常的抛出类型。要在受检异常上提供方法，以便协助恢复。\n第71条：避免不必要地使用受检异常许多Java 程序员不喜欢受检异常，但是如果使用得当，它们可以改善API和程序。不同于返回码和未受检异常的是，它们强迫程序员处理异常的条件，大大增强了可靠性。也就是说，过分使用受检异常会使API使用起来非常不方便。如果方法抛出受检异常，调用该方法的代码就必须在一个或者多个catch 块中处理这些异常，或者它必须声明抛出这些异常，并让它们传播出去。无论使用哪一种方法，都给程序员增添了不可忽视的负担。这种负担在Java8 中更重了，因为抛出受检异常的方法不能直接在Stream 中使用(详见第 45条至第48 条)。\n如果正确地使用API并不能阻止这种异常条件的产生，并且一旦产生异常，使用API的程序员可以立即采取有用的动作，这种负担就被认为是正当的。除非这两个条件都成立，否则更适合于使用未受检异常。作为一个石蕊测试(石蕊测试是指简单而具有决定性的测试)，你可以试着问自己：程序员将如何处理该异常。下面的做法是最好的吗?\n&#125; catch (TheCheckedException e) &#123;throw newAssertionErrorO;// Can&#x27;t happen!&#125;下面这种做法又如何?&#125; catch (TheCheckedException e) &#123;e.printStackTrace(); // Oh well, we loseSystem.exit(1) ;\n\n如果使用API的程序员无法做得比这更好，那么未受检的异常可能更为合适。\n如果方法抛出的受检异常是唯一的，它给程序员带来的额外负担就会非常高。如果这个方法还有其他的受检异常，该方法被调用的时候，必须已经出现在一个七rY块中，所以这个异常只需要另外一个catch 块。如果方法只抛出一个受检异常，单独这一个异常就表示：该方法必须放置于一个try块中，并且不能在 Stream 中直接使用。在这种情况下，应该问问自己，是否还有别的途径可以避免使用受检异常。\n消除受检异常最容易的方法是，返回所要的结果类型的一个optional(详见第55条)。这个方法不抛出受检异常，而只是返回一个零长度的optional。这种方法的缺点是，方法无法返回任何额外的信息，来详细说明它无法执行你想要的计算。相反，异常则具有描述性的类型，并且能够导出方法，以提供额外的信息(详见第70条)。\n“把受检异常变成未受检异常”的一种方法是，把这个抛出异常的方法分成两个方法，其中第一个方法返回一个boolean 值，表明是否应该抛出异常。这种 API重构，把下面的调用序列：\n// Invocation with checked exceptiontry &#123;obj.action(args) ;&#125;catch(TheCheckedException e)&#123;...// Handle exceptional condition\n\n重构为：\n//Invocation with state-testing method and unchecked exceptionif (obj.actionPermitted(args)) &#123;obj.action(args) ;&#125;else&#123;..// Handle exceptional condition\n\n这种重构并非总是恰当的，但是，凡是在恰当的地方，它都会使API用起来更加舒服。虽然后者的调用序列没有前者漂亮，但是这样得到的API更加灵活。如果程序员知道调用将会成功，或者不介意由于调用失败而导致的线程终止，这种重构还允许以下这个更为简单的调用形式：\nobj.action(args) ;\n如果你怀疑这个简单的调用序列是否符合要求，这个API重构可能就是恰当的。这样重构之后的API在本质上等同于第 69条中的”状态测试方法”，并且同样的告诫依然适用：如果对象将在缺少外部同步的情况下被并发访问，或者可被外界改变状态，这种重构就是不恰当的，因为在 actionPermitted 和 action 这两个调用的时间间隔之中，对象的状态有可能会发生变化。如果单独的 actionPermitted 方法必须重复 action 方法的工作，出于性能的考虑，这种API重构就不值得去做。\n总而言之，在谨慎使用的前提之下，受检异常可以提升程序的可读性;如果过度使用，将会使API使用起来非常痛苦。如果调用者无法恢复失败，就应该抛出未受检异常。如果可以恢复，并且想要迫使调用者处理异常的条件，首选应该返回一个optional值。当且仅当万一失败时，这些无法提供足够的信息，才应该抛出受检异常。\n第72条：优先使用标准的异常专家级程序员与缺乏经验的程序员一个最主要的区别在于，专家追求并且通常也能够实现高度的代码重用。代码重用是值得提倡的，这是一条通用的规则，异常也不例外。Java平台类库提供了一组基本的未受检异常，它们满足了绝大多数API的异常抛出需求。\n重用标准的异常有多个好处。其中最主要的好处是，它使API更易于学习和使用，因为它与程序员已经熟悉的习惯用法一致。第二个好处是，对于用到这些API的程序而言，它们的可读性会更好，因为它们不会出现很多程序员不熟悉的异常。最后(也是最不重要的)一点是，异常类越少，意味着内存占用(footprint)就越小，装载这些类的时间开销也越少。\n最经常被重用的异常类型是IllegalArgumentException(详见第 49条)。当调用者传递的参数值不合适的时候，往往就会抛出这个异常。比如，假设某一个参数代表了”某个动作的重复次数”，如果程序员给这个参数传递了一个负数，就会抛出这个异常。\n另一个经常被重用的异常是IllegalStateException。如果因为接收对象的状态而使调用非法，通常就会抛出这个异常。例如，如果在某个对象被正确地初始化之前，调用者就企图使用这个对象，就会抛出这个异常。\n可以这么说，所有错误的方法调用都可以被归结为非法参数或者非法状态，但是，还有一些其他的标准异常也被用于某些特定情况下的非法参数和非法状态。如果调用者在某个不允许null值的参数中传递了 null，习惯的做法就是抛出 NullPointerException 异常，而不是 IllegalArgumentException。同样地，如果调用者在表示序列下标的参数中传递了越界的值，应该抛出的就是IndexOutOfBoundsException 异常，而不是Illegal-ArgumentException.\n另一个值得了解的通用异常是ConcurrentModificationException。如果检测到一个专门设计用于单线程的对象，或者与外部同步机制配合使用的对象正在(或已经)被并发地修改，就应该抛出这个异常。这个异常顶多就是一个提示，因为不可能可靠地侦测到并发的修改。\n最后一个值得注意的标准异常是 UnsupportedOperationException。如果对象不支持所请求的操作，就会抛出这个异常。很少用到它，因为绝大多数对象都会支持它们实现的所有方法。如果类没有实现由它们实现的接口所定义的一个或者多个可选操作(optionaloperation)，它就可以使用这个异常。例如，对于只支持追加操作的List 实现，如果有人试图从列表中删除元素，它就会抛出这个异常。\n不要直接重用Exception、RuntimeException、Throwable 或者Error。对待这些类要像对待抽象类一样。你无法可靠地测试这些异常，因为它们是一个方法可能抛出的其他异常的超类。\n下表概括了最常见的可重用异常：\n\n虽然这些都是Java平台类库中迄今为止最常被重用的异常，但是，在条件许可的情况下，其他的异常也可以被重用。例如，如果要实现诸如复数或者有理数之类的算术对象，也可以重用 ArithmeticException 和 NumberFormatException。如果某个异常能够满足你的需要，就不要犹豫，使用就是，不过一定要确保抛出异常的条件与该异常的文档中描述的条件一致。这种重用必须建立在语义的基础上，而不是建立在名称的基础之上。而且，如果希望稍微增加更多的失败－捕获(failure-capture)信息(详见第75条)，可以放心地子类化标准异常，但要记住异常是可序列化的(详见第12章)。这也正是”如果没有非常正当的理由，千万不要自己编写异常类”的原因。\n选择重用哪一种异常并非总是那么精确，因为上表中的”使用场合”并不是相互排斥的。比如，以表示一副纸牌的对象为例。假设有一个处理发牌操作的方法，它的参数是发一手牌的纸牌张数。假设调用者在这个参数中传递的值大于整副纸牌的剩余张数。这种情形既可以被解释为 IllegalArgumentException(handSize 参数的值太大)，也可以被解释为IllegalStateException(纸牌对象包含的纸牌太少)。在这种情况下，如果没有可用的参数值，就抛出IllegalStateException，否则就抛出IllegalArgumentExceptione\n第73条：抛出与抽象对应的异常如果方法抛出的异常与它所执行的任务没有明显的联系，这种情形将会使人不知所措。当方法传递由低层抽象抛出的异常时，往往会发生这种情况。除了使人感到困惑之外，这也”污染”了具有实现细节的更高层的API。如果高层的实现在后续的发行版本中发生了变化，它所抛出的异常也可能会跟着发生变化，从而潜在地破坏现有的客户端程序。\n为了避免这个问题，更高层的实现应该捕获低层的异常，同时抛出可以按照高层抽象进行解释的异常。这种做法称为异常转译(exception translation)，如下代码所示:\n//ExceptionTranslationtry &#123;..//Use lower-levelabstraction to do our bidding&#125;catch(LowerLevelException e)&#123;throw new HigherLevelException(...);子\n\n下面的异常转译例子取自于 AbstractSequentialList类，该类是List接口的一个骨架实现(skeletal implementation)，详见第 20条。在这个例子中，按照List接口中get方法的规范要求，异常转译是必需的：\n*** Returns the element at the specified position in this list.* @throws IndexOutOfBoundsException if the index is out of range(&#123;@code index &lt; 0 Il index &gt;= size()&#125;).*/public E get(int index)&#123;ListIterator&lt;E&gt; i = listIterator(index);try&#123;return i.next();&#125; catch (NoSuchElementException e) &#123;\n\n一种特殊的异常转译形式称为异常链(exception chaining)，如果低层的异常对于调试导致高层异常的问题非常有帮助，使用异常链就很合适。低层的异常(原因)被传到高层的异常，高层的异常提供访问方法(Throwable 的 getCause 方法)来获得低层的异常:\n// Exception Chainingtry&#123;...// Use lower-level abstraction to do our bidding&#125; catch (LowerLevelException cause)&#123;throw new HigherLevelException(cause);\n\n高层异常的构造器将原因传到支持链(chaining-aware)的超级构造器，因此它最终将被传给 Throwable的其中一个运行异常链的构造器，例如 Throwable(Throwable):\n//Exception with chaining-awareconstructorclass HigherLevelException extends Exception &#123;HigherLevelException(Throwable cause) &#123;super(cause) ;子\n\n大多数标准的异常都有支持链的构造器。对于没有支持链的异常，可以利用 Throwable的 initCause方法设置原因。异常链不仅让你可以通过程序(用 getCause)访问原因,还可以将原因的堆栈轨迹集成到更高层的异常中。\n尽管异常转译与不加选择地从低层传递异常的做法相比有所改进，但是也不能滥用它。如有可能，处理来自低层异常的最好做法是，在调用低层方法之前确保它们会成功执行，从而避免它们抛出异常。有时候，可以在给低层传递参数之前，检查更高层方法的参数的有效性，从而避免低层方法抛出异常。\n如果无法阻止来自低层的异常，其次的做法是，让更高层来悄悄地处理这些异常，从而将高层方法的调用者与低层的问题隔离开来。在这种情况下，可以用某种适当的记录机制(如java.util.logging)将异常记录下来。这样有助于管理员调查问题，同时又将客户端代码和最终用户与问题隔离开来。\n总而言之，如果不能阻止或者处理来自更低层的异常，一般的做法是使用异常转译，只有在低层方法的规范碰巧可以保证”它所抛出的所有异常对于更高层也是合适的”情况下，才可以将异常从低层传播到高层。异常链对高层和低层异常都提供了最佳的功能：它允许抛出适当的高层异常，同时又能捕获低层的原因进行失败分析(详见第75条)。\n第74条：每个方法抛出的所有异常都要建立文档描述一个方法所抛出的异常，是正确使用这个方法时所需文档的重要组成部分。因此,花点时间仔细地为每个方法抛出的异常建立文档是特别重要的。\n始终要单独地声明受检异常，并且利用Javadoc的@throws 标签，准确地记录下抛出每个异常的条件。如果一个公有方法可能抛出多个异常类，则不要使用”快捷方式”声明它会抛出这些异常类的某个超类。永远不要声明一个公有方法直接”throws Exception”，或者更糟糕的是声明它直接”throwsThrowable”，这是非常极端的例子。这样的声明不仅没有为程序员提供关于”这个方法能够抛出哪些异常”的任何指导信息，而且大大地妨碍了该方法的使用，因为它实际上掩盖了该方法在同样的执行环境下可能抛出的任何其他异常。这条建议有一个例外，就是 main 方法，它可以被安全地声明抛出 Exception，因为它只通过虚拟机调用。\n虽然Java语言本身并没有要求程序员为一个方法声明它可能会抛出的未受检异常，但是，如同受检异常一样，仔细地为它们建立文档是非常明智的。未受检异常通常代表编程上的错误(详见第70条)，让程序员了解所有这些错误都有助于帮助他们避免犯同样的错误。对于方法可能抛出的未受检异常，如果将这些异常信息很好地组织成列表文档，就可以有效地描述出这个方法被成功执行的前提条件。每个方法的文档应该描述它的前提条件(详见第56条)，这是很重要的，在文档中记录下未受检异常是满足前提条件的最佳做法。\n对于接口中的方法，在文档中记录下它可能抛出的未受检异常显得尤为重要。这份文档构成了该接口的通用约定(general contract)的一部分，它指定了该接口的多个实现必须遵循的公共行为。\n使用Javadoc的@throws 标签记录下一个方法可能抛出的每个未受检异常，但是不要使用throws 关键字将未受检的异常包含在方法的声明中。使用 API 的程序员必须知道哪些异常是需要受检的，哪些是不需要受检的，因为他们有责任区分这两种情形。当缺少由throws 声明产生的方法标头时，由 Javadoc 的@throws 标签所产生的文档就会提供明显的提示信息，以帮助程序员区分受检异常和未受检异常。\n应该注意的是，为每个方法可能抛出的所有未受检异常建立文档是很理想的，但是在实践中并非总能做到这一点。当类被修订之后，如果有个导出方法被修改了，它将会抛出额外的未受检异常，这不算违反源代码或者二进制兼容性。假设一个类调用了另一个独立编写的类中的方法。第一个类的编写者可能会为每个方法抛出的未受检异常仔细地建立文档，但是，如果第二个类被修订了，抛出了额外的未受检异常，很有可能第一个类(它并没有被修订)就会把新的未受检异常传播出去，尽管它并没有声明这些异常。\n如果一个类中的许多方法出于同样的原因而抛出同一个异常，在该类的文档注释中对这个异常建立文档，这是可以接受的，而不是为每个方法单独建立文档。一个常见的例子是NullPointerException。若类的文档注释中有这样的描述：”All methods in this class throw aNullPointerException if a null object reference is passed in any parameter”(如果 null 对象引|用被传递到任何一个参数中，这个类中的所有方法都会抛出 NullPointerException)，或者有其他类似的语句，这是可以的。\n总而言之，要为你编写的每个方法所能抛出的每个异常建立文档。对于未受检异常和受检异常，以及抽象的方法和具体的方法一概如此。这个文档在文档注释中应当采用@throws 标签的形式。要在方法的throws 子句中为每个受检异常提供单独的声明，但是不要声明未受检的异常。如果没有为可以抛出的异常建立文档，其他人就很难或者根本不可能有效地使用你的类和接口。\n第75条：在细节消息中包含失败－捕获信息当程序由于未被捕获的异常而失败的时候，系统会自动地打印出该异常的堆栈轨迹。在堆栈轨迹中包含该异常的字符串表示法(string representation)，即它的toString 方法的调用结果。它通常包含该异常的类名，紧随其后的是细节消息(detail message)。通常,这只是程序员或者网站可靠性工程师在调查软件失败原因时必须检查的信息。如果失败的情形不容易重现，要想获得更多的信息会非常困难，甚至是不可能的。因此，异常类型的toString方法应该尽可能多地返回有关失败原因的信息，这一点特别重要。换句话说，异常的字符串表示法应该捕获失败，以便于后续进行分析。\n为了捕获失败，异常的细节信息应该包含”对该异常有贡献”的所有参数和域的值。例如，IndexOutOfBoundsException 异常的细节消息应该包含下界、上界以及没有落在界内的下标值。该细节消息提供了许多关于失败的信息。这三个值中任何一个或者全部都有可能是错的。实际的下标值可能小于下界或等于上界(“越界错误”)，或者它可能是个无效值，太小或太大。下界也有可能大于上界(严重违反内部约束条件的一种情况)。每一种情形都代表了不同的问题，如果程序员知道应该去查找哪种错误，就可以极大地加速诊断过程。\n对安全敏感的信息有一条忠告。由于在诊断和修正软件问题的过程中，许多人都可以看见堆栈轨迹，因此千万不要在细节消息中包含密码、密钥以及类似的信息！\n虽然在异常的细节消息中包含所有相关的数据是非常重要的，但是包含大量的描述信息往往没有什么意义。堆栈轨迹的用途是与源文件结合起来进行分析，它通常包含抛出该异常的确切文件和行数，以及堆栈中所有其他方法调用所在的文件和行数。关于失败的冗长描述信息通常是不必要的，这些信息可以通过阅读源代码而获得。\n异常的细节消息不应该与”用户层次的错误消息”混为一谈，后者对于最终用户而言必须是可理解的。与用户层次的错误消息不同，异常的字符串表示法主要是让程序员或者网站可靠性工程师用来分析失败的原因。因此，信息的内容比可读性要重要得多。用户层次的错误消息经常被本地化，而异常的细节消息则几乎没有被本地化。\n为了确保在异常的细节消息中包含足够的失败－捕捉信息，一种办法是在异常的构造器而不是字符串细节消息中引入这些信息。然后，有了这些信息，只要把它们放到消息描述中，就可以自动产生细节消息。例如，IndexOutOfBoundsException 使用如下构造器代替 String 构造器:\n* Constructs an IndexOutOfBoundsException.* @param lowerBound the lowest legal index value*@param index the actualindexvaluepublic IndexOutOfBoundsException(int lowerBound, int upperBound,int index)&#123;// Generate a detail message that captures the failuresuper(String.format(&quot;Lower bound: %d, Upper bound: %d， Index: %d&quot;,lowerBound, upperBound, index));// Save failure information for programmatic accessthis.lowerBound = lowerBound;this.upperBound = upperBound;this.index = index;\n\n从 Java 9开始，IndexOutOfBoundsException 终于获得了一个构造器，它可以带一个类型为 int 的 index 参数值，但遗憾的是，它删去了 lowerBound 和 upperBound参数。更通俗地说，Java平台类库并没有广泛地使用这种做法，但是，这种做法仍然值得大力推荐。它使程序员更加易于抛出异常以捕获失败。实际上，这种做法使程序员不想捕获失败都难！这种做法可以有效地把代码集中起来放在异常类中，由这些代码对异常类自身中的异常产生高质量的细节消息，而不是要求类的每个用户都多余地产生细节消息。\n正如第 70条中所建议的，为异常的失败－捕获信息(在上述例子中为 lowerBound、upperBound 和 index)提供一些访问方法是合适的。提供这样的访问方法对受检的异常，比对未受检异常更为重要，因为失败－捕获信息对于从失败中恢复是非常有用的。程序员希望通过程序的手段来访问未受检异常的细节，这很少见(尽管也是可以想象的)。然而，即使对于未受检异常，作为一般原则提供这些访问方法也是明智的(详见第 12 条)。\n第76条：努力使失败保持原子性当对象抛出异常之后，通常我们期望这个对象仍然保持在一种定义良好的可用状态之中，即使失败是发生在执行某个操作的过程中间。对于受检异常而言，这尤为重要，因为调用者期望能从这种异常中进行恢复。一般而言，失败的方法调用应该使对象保持在被调用之前的状态。具有这种属性的方法被称为具有失败原子性(failure atomic)。\n有几种途径可以实现这种效果。最简单的办法莫过于设计一个不可变的对象(详见第17条)。如果对象是不可变的，失败原子性就是显然的。如果一个操作失败了，它可能会阻止创建新的对象，但是永远也不会使已有的对象保持在不一致的状态之中，因为当每个对象被创建之后它就处于一致的状态之中，以后也不会再发生变化。\n对于在可变对象上执行操作的方法，获得失败原子性最常见的办法是，在执行操作之前检查参数的有效性(详见第 49条)。这可以使得在对象的状态被修改之前，先抛出适当的异常。比如，以第7条中的 Stack.pop 方法为例:\npublic Object pop()&#123;if (size == 0)throw new EmptyStackException();Object result = elements[--size];elements[size]=null;// Eliminate obsolete referencereturn result;\n\n如果取消对初始大小(size)的检查，当这个方法企图从一个空栈中弹出元素时，它仍然会抛出异常。然而，这将会导致size 域保持在不一致的状态(负数)之中，从而导致将来对该对象的任何方法调用都会失败。此外，那时，pop 方法抛出的 ArrayIndexOutOfBounds-Exception异常对于该抽象来说也是不恰当的(详见第73条)。\n一种类似的获得失败原子性的办法是，调整计算处理过程的顺序，使得任何可能会失败的计算部分都在对象状态被修改之前发生。如果对参数的检查只有在执行了部分计算之后才能进行，这种办法实际上就是上一种办法的自然扩展。比如，以TreeMap 的情形为例，它的元素被按照某种特定的顺序做了排序。为了向TreeMap 中添加元素，该元素的类型就必须是可以利用 TreeMap 的排序准则与其他元素进行比较的。如果企图增加类型不正确的元素，在 tree以任何方式被修改之前，自然会导致ClassCastException异常。\n第三种获得失败原子性的办法是，在对象的一份临时拷贝上执行操作，当操作完成之后再用临时拷贝中的结果代替对象的内容。如果数据保存在临时的数据结构中，计算过程会更加迅速，使用这种办法就是件很自然的事。例如，有些排序函数会在执行排序之前，先把它的输入列表备份到一个数组中，以便降低在排序的内循环中访问元素所需要的开销。这是出于性能考虑的做法，但是，它增加了一项优势：即使排序失败，它也能保证输入列表保持原样。\n最后一种获得失败原子性的办法远远没有那么常用，做法是编写一段恢复代码(recoverycode)，由它来拦截操作过程中发生的失败，以及使对象回滚到操作开始之前的状态上。这种办法主要用于永久性的(基于磁盘的)数据结构。\n虽然一般情况下都希望实现失败原子性，但并非总是可以做到。举个例子，如果两个留在不一致的状态之中。因此，在捕获了ConcurrentModificationException 异常之后再假设对象仍然是可用的，这就是不正确的。错误通常是不可恢复的，因此，当方法抛出AssertionError时，不需要努力去保持失败原子性。\n即使在可以实现失败原子性的场合，它也并不总是人们所期望的。对于某些操作，它会显著地增加开销或者复杂性。也就是说，一旦了解了这个问题，获得失败原子性往往既简单又容易。\n总而言之，作为方法规范的一部分，它产生的任何异常都应该让对象保持在调用该方法之前的状态。如果违反这条规则，API文档就应该清楚地指明对象将会处于什么样的状态。遗憾的是，大量现有的 API 文档都未能做到这一点。\n第77条：不要忽略异常尽管这条建议看上去是显而易见的，但是它却常常被违反，因而值得再次提出来。当API的设计者声明一个方法将抛出某个异常的时候，他们等于正在试图说明某些事情。所以，请不要忽略它！要忽略一个异常非常容易，只需将方法调用通过try语句包围起来，并包含一个空的catch块：\n// Empty catch block ignores exception - Highly suspect!try&#123;&#125;catch(SomeException e)&#123;\n\n空的catch块会使异常达不到应有的目的，即强迫你处理异常的情况。忽略异常就如同忽略火警信号一样一—如果把火警信号器关掉了，当真正有火灾发生时，就没有人能看到火警信号了。或许你会侥幸逃过劫难，或许结果将是灾难性的。每当见到空的catch 块时，应该让警钟长鸣。\n有些情形可以忽略异常。比如，关闭 FileInputStream 的时候。因为你还没有改变文件的状态，因此不必执行任何恢复动作，并且已经从文件中读取到所需要的信息，因此不必终止正在进行的操作。即使在这种情况下，把异常记录下来还是明智的做法，因为如果这些异常经常发生，你就可以调查异常的原因。如果选择忽略异常，catch 块中应该包含一条注释，说明为什么可以这么做，并且变量应该命名为ignored:\nFuture&lt;Integer&gt; f = exec.submit(planarMap::chromaticNumber) ;int numColors = 4; // Default; guaranteed sufficient for any maptry &#123;numColors = f.get(1L, TimeUnit.SECONDS);// Use default: minimal coloring is desirable, not required&#125;\n\n本条目中的建议同样适用于受检异常和未受检异常。不管异常代表了可预见的异常条件，还是编程错误，用空的catch 块忽略它，都将导致程序在遇到错误的情况下悄然地执行下去。然后，有可能在将来的某个点上，当程序不能再容忍与错误源明显相关的问题时,它就会失败。正确地处理异常能够彻底避免失败。只要将异常传播给外界，至少会导致程序迅速失败，从而保留了有助于调试该失败条件的信息。\n第十一章 并发线程机制允许同时进行多个活动。并发程序设计比单线程程序设计要困难得多，因为有更多的东西可能出错，也很难重现失败。但是你无法避免并发，因为我们所做的大部分事情都需要并发，而且并发也是能否从多核的处理器中获得好的性能的一个条件，这些现在都是很平常的事了。本章阐述的建议可以帮助你编写出清晰、正确、文档组织良好的并发程序。\n第78条：同步访问共享的可变数据关键字 synchronized 可以保证在同一时刻，只有一个线程可以执行某一个方法，或者某一个代码块。许多程序员把同步的概念仅仅理解为一种互斥(mutualexclusion)的方式，即，当一个对象被一个线程修改的时候，可以阻止另一个线程观察到对象内部不一致的状态。按照这种观点，对象被创建的时候处于一致的状态(详见第17条)，当有方法访问它的时候，它就被锁定了。这些方法观察到对象的状态，并且可能会引起状态转变(statetransition)，即把对象从一种一致的状态转换到另一种一致的状态。正确地使用同步可以保证没有任何方法会看到对象处于不一致的状态中。\n这种观点是正确的，但是它并没有说明同步的全部意义。如果没有同步，一个线程的它还可以保证进人同步方法或者同步代码块的每个线程，都能看到由同一个锁保护的之前所有的修改效果。\nJava 语言规范保证读或者写一个变量是原子的(atomic)，除非这个变量的类型为 long或者 double[JLS，17.4，17.7]。换句话说，读取一个非 long 或 double 类型的变量，可以保证返回值是某个线程保存在该变量中的，即使多个线程在没有同步的情况下并发地修改这个变量也是如此。\n你可能听说过，为了提高性能，在读或写原子数据的时候，应该避免使用同步。这个建议是非常危险而错误的。虽然语言规范保证了线程在读取原子数据的时候，不会看到任意的数值，但是它并不保证一个线程写入的值对于另一个线程将是可见的。为了在线程之间进行可靠的通信，也为了互斥访问，同步是必要的。这归因于Java语言规范中的内存模型(memory model)，它规定了一个线程所做的变化何时以及如何变成对其他线程可见[JLS,17.4; Goetz06, 16]。\n如果对共享的可变数据的访问不能同步，其后果将非常可怕，即使这个变量是原子可读写的。以下面这个阻止一个线程妨碍另一个线程的任务为例。Java 的类库中提供了Thread.stop方法，但是在很久以前就不提倡使用该方法了，因为它本质上是不安全的—使用它会导致数据遭到破坏。千万不要使用 Thread.stop 方法。要阻止一个线程妨碍另一个线程，建议的做法是让第一个线程轮询(poll)一个boolean 域，这个域一开始为false，但是可以通过第二个线程设置为true，以表示第一个线程将终止自己。由于boolean 域的读和写操作都是原子的，程序员在访问这个域的时候不再需要使用同步：\n// Broken!-How long would you expect thisprogram to run?public class StopThread &#123;private static boolean stopRequested;public static void main(String[] args)throws InterruptedException &#123;Thread backgroundThread = new Thread(O) -&gt;&#123;int i = 0;while (!stopRequested)i++;&#125;);backgroundThread. start() ;TimeUnit.SECONDS.sleep(1);stopRequested = true;\n\n你可能期待这个程序运行大约一秒钟左右，之后主线程将 stopRequested设置为true，致使后台线程的循环终止。但是在我的机器上，这个程序永远不会终止：因为后台线程永远在循环！\n问题在于，由于没有同步，就不能保证后台线程何时‘看到”主线程对 stopRequested的值所做的改变。没有同步，虚拟机将以下代码：\nwhile (!stopRequested)i++;\n转变成这样:\n# if (!stopRequested)while (true)i++;\n\n这种优化称作提升(hoisting)，正是OpenJDK Server VM 的工作。结果是一个活性失败(liveness failure)：这个程序并没有得到提升。修正这个问题的一种方式是同步访问 stop-Requested域。这个程序会如预期般在大约一秒之内终止:\n//Properly synchronized cooperative thread terminationpublic class StopThread &#123;private static boolean stopRequested;private static synchronized void requestStop() &#123;stopRequested = true;private static synchronized boolean stopRequested() &#123;return stopRequested;子public static void main(String[] args)throws InterruptedException &#123;Thread backgroundThread = new Thread(() -&gt; &#123;inti=0;while (!stopRequested())i++;);backgroundThread.start();TimeUnit.SECONDS.sleep(1);requestStop();\n\n注意写方法(requestStop)和读方法(stopRequested)都被同步了。只同步写方法还不够！除非读和写操作都被同步，否则无法保证同步能起作用。有时候，会在某些机器上看到只同步了写(或读)操作的程序看起来也能正常工作，但是在这种情况下，表象具有很大的欺骗性。\nStopThread 中被同步方法的动作即使没有同步也是原子的。换句话说，这些方法的同步只是为了它的通信效果，而不是为了互斥访问。虽然循环的每个迭代中的同步开销很小，还是有其他更正确的替代方法，它更加简洁，性能也可能更好。如果 stopRequested被声明为 volatile，第二种版本的 StopThread 中的锁就可以省略。虽然volatile 修饰符不执行互斥访问，但它可以保证任何一个线程在读取该域的时候都将看到最近刚刚被写入的值：\n//Cooperative threadterminationwithavolatilefieldpublic class StopThread &#123;private static volatile boolean stopRequested;public static void main(String[] args)throws InterruptedException &#123;Thread backgroundThread = new Thread(() -&gt; &#123;int i= 0;while (!stopRequested)i++;H);backgroundThread.start();TimeUnit.SECONDS.sleep(1) ;stopRequested = true;\n\n在使用volatile 的时候务必要小心。以下面的方法为例，假设它要产生序列号：:\n// Broken - requires synchronization!private static volatile int nextSerialNumber = 0;public static int generateSerialNumber() &#123;return nextSerialNumber++;\n\n这个方法的目的是要确保每个调用都返回不同的值(只要不超过2”个调用)。这个方法的状态只包含一个可原子访问的域：nextSerialNumber，这个域的所有可能的值都是合法的。因此，不需要任何同步来保护它的约束条件。然而，如果没有同步，这个方法仍然无法正确地工作。\n问题在于，增量操作符(++)不是原子的。它在 nextSerialNumber域中执行两项操作：首先它读取值，然后写回一个新值，相当于原来的值再加上1。如果第二个线程在第一个线程读取旧值和写回新值期间读取这个域，第二个线程就会与第一个线程一起看到同一个值，并返回相同的序列号。这就是安全性失败(safety failure)：这个程序会计算出错误的结果。\n修正 generateSerialNumber方法的一种方法是在它的声明中增加 synchronized修饰符。这样可以确保多个调用不会交叉存取，确保每个调用都会看到之前所有调用的效果。一旦这么做，就可以且应该从 nextSerialNumber中删除volatile 修饰符。为了保护这个方法，要用long 代替int，或者在nextSerialNumber要进行包装时抛出异常。\n最好还是遵循第59 条中的建议，使用AtomicLong 类，它是java.util.concurrent.atomic的组成部分。这个包为在单个变量上进行免锁定、线程安全的编程提供了基本类型。虽然volatile 只提供了同步的通信效果，但这个包还提供了原子性。这正是你想让generateSerialNumber 完成的工作，并且它可能比同步版本完成得更好:\n//Lock-free synchronizationwith java.util.concurrent.atomicprivate static final AtomicLong nextSerialNum = new AtomicLongO;public static long generateSerialNumber(&#123;return nextSerialNum.getAndIncrementO;\n了避免本条目中所讨论到的问题的最佳办法是不共享可变的数据。要么共享不可变的数据(详见第17条)，要么压根不共享。换句话说，将可变数据限制在单个线程中。如果采用这一策略，对它建立文档就很重要，以便它可以随着程序的发展而得到维护。深刻地理解正在使用的框架和类库也很重要，因为它们引入了你不知道的线程。\n让一个线程在短时间内修改一个数据对象，然后与其他线程共享，这是可以接受的,它只同步共享对象引用的动作。然后其他线程没有进一步的同步也可以读取对象，只要它没有再被修改。这种对象被称作高效不可变(effectivelyimmutable)[Goetz06，3.5.4]。将这种对象引用从一个线程传递到其他的线程被称作安全发布(safe publication)[Goetz06,3.5.3]。安全发布对象引用有许多种方法：可以将它保存在静态域中，作为类初始化的一部分;可以将它保存在volatile域、final域或者通过正常锁定访问的域中;或者可以将它放到并发的集合中(详见第81条)。\n总而言之，当多个线程共享可变数据的时候，每个读或者写数据的线程都必须执行同可变数据会造成程序的活性失败(liveness failure)和安全性失败(safetyfailure)。这样的失败是最难调试的。它们可能是间歇性的，且与时间相关，程序的行为在不同的虚拟机上可能根本不同。如果只需要线程之间的交互通信，而不需要互斥，volatile 修饰符就是一种可以接受的同步形式，但要正确地使用它可能需要一些技巧。\n第79条：避免过度同步第78条告诫过我们缺少同步的危险性。本条目则关注相反的问题。依据情况的不同，过度同步则可能导致性能降低、死锁，甚至不确定的行为。\n为了避免活性失败和安全性失败，在一个被同步的方法或者代码块中，永远不要放弃对客户端的控制。换句话说，在一个被同步的区域内部，不要调用设计成要被覆盖的方法，或者是由客户端以函数对象的形式提供的方法(详见第24条)。从包含该同步区域的类的角度来看，这样的方法是外来的(alien)。这个类不知道该方法会做什么事情，也无法控制它。根据外来方法的作用，从同步区域中调用它会导致异常、死锁或者数据损坏。\n为了对这个过程进行更具体的说明，以下面的类为例，它实现了一个可以观察到的集合包装(set wrapper)。该类允许客户端在将元素添加到集合中时预订通知。这就是观察者(Observer)模式[Gamma95]。为了简洁起见，类在从集合中删除元素时没有提供通知，但要提供通知也是一件很容易的事情。这个类是在第 18条中可重用的 ForwardingSet上实现的：\n// Broken - invokes alien method from synchronized block!public class ObservableSet&lt;E&gt; extends ForwardingSet&lt;E&gt;&#123;public ObservableSet(Set&lt;E&gt; set) &#123; super(set);&#125;private finalList&lt;Setobserver&lt;E&gt;&gt; observers= new ArrayList&lt;&gt;();public void addobserver(Setobserver&lt;E&gt; observer)&#123;synchronized(observers) &#123;observers.add(observer) ;public boolean remove0bserver(SetObserver&lt;E&gt; observer) &#123;synchronized(observers) &#123;return observers.remove(observer);private void notifyElementAdded(E element) &#123;synchronized(observers) &#123;for (SetObserver&lt;E&gt; observer : observers)observer.added(this, element);@Override public boolean add(E element)boolean added = super.add(element);if (added)notifyElementAdded(element);return added;@Override public boolean addAll(Collection&lt;? extends E&gt; c)&#123;boolean result = false;for (E element : c)result |= add(element); // Calls notifyElementAddedreturn result;\n\n观察者通过调用 addObserver 方法预订通知，通过调用 removeObserver 方法取消预订。在这两种情况下，这个回调(callback)接口的实例都会被传递给方法:\n@FunctionalInterface public interface SetObserver&lt;E&gt;&#123;// Invoked when an element is addedto theobservable setvoid added(ObservableSet&lt;E&gt; set, E element);\n这个接口的结构与BiConsumer&lt;ObservableSet,E&gt;一样。我们选择定义一个定制的函数接口，因为该接口和方法名称可以提升代码的可读性，且该接口可以发展整合多个回调。也就是说，还可以设置合理的参数来使用 BiConsumer(详见第 44 条)。\n如果只是粗略地检验一下，ObservableSet会显得很正常。例如，下面的程序打印出0～99的数字：\npublic static void main(String[] args) &#123;ObservableSet&lt;Integer&gt; set =new ObservableSet&lt;&gt;(new HashSet&lt;&gt;());set.addobserver((s, e) -&gt; System.out.println(e));for(int i=0;i&lt; 100;i++)set.add(i);\n现在我们来尝试一些更复杂点的例子。假设我们用一个 addObserver 调用来代替这个调用，用来替换的那个 addobserver 调用传递了一个打印 Integer 值的观察者，这个值被添加到该集合中，如果值为23，这个观察者要将自身删除：\nset.addobserver(new Setobserver&lt;&gt;() &#123;public void added(ObservableSet&lt;Integer&gt; s, Integer e) &#123;System.out.println(e);if(e==23)s.removeObserver(this););\n\n注意，这个调用以一个匿名类 SetObserver 实例代替了前一个调用中使用的lambda。这是因为函数对象需要将自身传给s.removeObserver，而 lambda则无法访问它们自己(详见第42条)。\n你可能以为这个程序会打印数字0～23，之后观察者会取消预订，程序会悄悄地完成它问题在于，当 notifyElementAdded 调用观察者的 added 方法时，它正处于遍历 obser-vers列表的过程中。added方法调用可观察集合的 removeObserver方法，从而调用observers.remove。现在我们有麻烦了。我们正企图在遍历列表的过程中，将一个元素从列表中删除，这是非法的。notifyElementAdded方法中的迭代是在一个同步的块中，可以防止并发的修改，但是无法防止迭代线程本身回调到可观察的集合中，也无法防止修改它的observers列表。\n现在我们要尝试一些比较奇特的例子：我们来编写一个试图取消预订的观察者，但是不直接调用removeObserver，它用另一个线程的服务来完成。这个观察者使用了一个executor service(详见第 80条):\n//Observerthatusesabackgroundthreadneedlesslyset.addobserver(new Setobserver&lt;&gt;() &#123;public void added(ObservableSet&lt;Integer&gt; S, Integer e) &#123;System.out.println(e);if(e == 23) &#123;ExecutorService exec =Executors.newSingleThreadExecutor(;try&#123;exec.submit(() -&gt; s.removeObserver(this)).get();&#125; catch (ExecutionException | InterruptedException ex)&#123;throw new AssertionError(ex);&#125;finally&#123;exec.shutdown() ;&#125;);\n\n顺便提一句，注意看这个程序在一个catch 子句中捕获了两个不同的异常类型。这个机制是在 Java 7中增加的，不太正式地称之为多重捕获(multi-catch)。它可以极大地提升代码的清晰度，行为与多异常类型相同的程序，其篇幅可以大幅减少。\n运行这个程序时，没有遇到异常，而是遭遇了死锁。后台线程调用s.removeObserver，它企图锁定 observers，但它无法获得该锁，因为主线程已经有锁了。在这期间，主线程一直在等待后台线程来完成对观察者的删除，这正是造成死锁的原因。\n这个例子是刻意编写用来示范的，因为观察者实际上没理由使用后台线程，但这个问题却是真实的。从同步区域中调用外来方法，在真实的系统中已经造成了许多死锁，例如GUI工具箱。\n在前面这两个例子中(异常和死锁)，我们都还算幸运。调用外来方法(added)时，同步区域(observers)所保护的资源处于一致的状态。假设当同步区域所保护的约束条件暂时无效时，你要从同步区域中调用一个外来方法。由于Java程序设计语言中的锁是可重入的(reentrant)，这种调用不会死锁。就像在第一个例子中一样，它会产生一个异常，因为调用线程已经有这个锁了，因此当该线程试图再次获得该锁时会成功，尽管概念上不相关的另一项操作正在该锁所保护的数据上进行着。这种失败的后果可能是灾难性的。从本质上来说，这个锁没有尽到它的职责。可重入的锁简化了多线程的面向对象程序的构造，但是它们可能会将活性失败变成安全性失败。\n幸运的是，通过将外来方法的调用移出同步的代码块来解决这个问题通常并不太困难。对于 notifyElementAdded 方法，这还涉及给 observers 列表拍张”快照”，然后没有锁也可以安全地遍历这个列表了。经过这一修改，前两个例子运行起来便再也不会出现异常或者死锁了：\n//Alien method moved outside of synchronized block-open callsprivate void notifyElementAdded(E element)&#123;List&lt;Setobserver&lt;E&gt;&gt; snapshot = null;synchronized(observers) &#123;snapshot = new ArrayList&lt;&gt;(observers);8for(Setobserver&lt;E&gt; observer : snapshot)observer.added(this, element);子\n\n事实上，要将外来方法的调用移出同步的代码块，还有一种更好的方法。Java类库提供了一个并发集合(concurrent collection)，详见第8l条，称作CopyOnWriteArrayList,这是专门为此定制的。这个CopyOnWriteArrayList 是ArrayList 的一种变体，它通过重新拷贝整个底层数组，在这里实现所有的写操作。由于内部数组永远不改动，因此迭代不需要锁定，速度也非常快。如果大量使用，CopyOnWriteArrayList的性能将大受影响，但是对于观察者列表来说却是很好的，因为它们几乎不改动，并且经常被遍历。\n如果将这个列表改成使用CopyOnWriteArrayList，就不必改动ObservableSet的 add 和 addAll 方法。下面是这个类的其余代码。注意其中并没有任何显式的同步:\nnew CopyOnWriteArrayList&lt;&gt;(;public void addObserver(SetObserver&lt;E&gt; observer)&#123;observers.add(observer) ;public boolean removeObserver(Setobserver&lt;E&gt; observer)&#123;return observers.remove(observer);子private void notifyElementAdded(E element)&#123;for (Setobserver&lt;E&gt; observer: observers)observer.added(this, element) ;子\n\n在同步区域之外被调用的外来方法被称作”开放调用”(open call)[Goetz06,10.1.4]。除了可以避免失败之外，开放调用还可以极大地增加并发性。外来方法的运行时间可能为任意时长。如果在同步区域内调用外来方法，其他线程对受保护资源的访问就会遭到不必要的拒绝。\n通常来说，应该在同步区域内做尽可能少的工作。获得锁，检查共享数据，根据需要转换数据，然后释放锁。如果你必须要执行某个很耗时的动作，则应该设法把这个动作移到同步区域的外面，而不违背第78条中的指导方针。\n本条目的第一部分是关于正确性的。接下来，我们要简单地讨论一下性能。虽然自Java平台早期以来，同步的成本已经下降了，但更重要的是，永远不要过度同步。在这个多核的时代，过度同步的实际成本并不是指获取锁所花费的CPU时间;而是指失去了并行的机会，以及因为需要确保每个核都有一个一致的内存视图而导致的延迟。过度同步的另一项潜在开销在于，它会限制虚拟机优化代码执行的能力。\n如果正在编写一个可变的类，有两种选择：省略所有的同步，如果想要并发使用，就允许客户端在必要的时候从外部同步，或者通过内部同步，使这个类变成是线程安全的(详见第82条)，你还可以因此获得明显比从外部锁定整个对象更高的并发性。jaVa.util中的集合(除了已经废弃的Vector 和Hashtable之外)采用了前一种方法，而java.util.concurrent中的集合则采用了后一种方法(详见第81条)。\n在 Java 平台出现的早期，许多类都违背了这些指导方针。例如，StringBuffer 实例几乎总是被用于单个线程之中，而它们执行的却是内部同步。为此,StringBuffer 基本上都由StringBuilder 代替，它是一个非同步的 StringBuffer。同样地，java.util.Random中线程安全的伪随机数生成器，被java.util.concurrent.ThreadLocalRandom 中非同步的实现取代，主要也是出于上述原因。当你不确定的时候，就不要同步类，而应该建立文档，注明它不是线程安全的。\n如果你在内部同步了类，就可以使用不同的方法来实现高并发性，例如分拆锁、分离锁和非阻塞并发控制。这些方法都超出了本书的讨论范围，但有其他著作对此进行了阐述[Goetz06, Herlihy12 ］。\n步对这个域的访问(除非这个类能够容忍不确定的行为)。多线程的客户端要在这种方法上执行外部同步是不可能的，因为其他不相关的客户端不需要同步也能调用该方法。域本质上就是一个全局变量，即使是私有的也一样，因为它可以被不相关的客户端读取和修改。第78条中的 generateSerialNumber方法使用的 nextSerialNumber 域就是这样的一个例子。\n总而言之，为了避免死锁和数据破坏，千万不要从同步区域内部调用外来方法。更通俗地讲，要尽量将同步区域内部的工作量限制到最少。当你在设计一个可变类的时候，要考虑一下它们是否应该自己完成同步操作。在如今这个多核的时代，这比永远不要过度同步来得更重要。只有当你有足够的理由一定要在内部同步类的时候，才应该这么做，同时还应该将这个决定清楚地写到文档中(详见第82条)。\n第80条：executor、task和stream优先于线程本书第1版中阐述了简单的工作队列(work queue)[Bloch01，详见第 49 条］的代码。这个类允许客户端按队列等待由后台线程异步处理的工作项目。当不再需要这个工作队列时，客户端可以调用一个方法，让后台线程在完成了已经在队列中的所有工作之后，优雅地终止自己。这个实现几乎就像一件玩具，但即使如此，它还是需要一整页精细的代码，一不小心，就容易出现安全问题或者导致活性失败。幸运的是，你再也不需要编写这样的代码了。\n到本书第二版出版的时候，Java平台中已经增加了java。util.concurrent。这个包中包含了一个Executor Framework，它是一个很灵活的基于接口的任务执行工具。它创建了一个在各方面都比本书第一版更好的工作队列，却只需要这一行代码：\nExecutorService exec &#x3D; Executors.newSingleThreadExecutor();\n下面是为执行而提交一个runnable的方法:\nexec.execute(runnable);\n下面是告诉executor 如何优雅地终止(如果你没有这么做，虚拟机可能不会退出):\nexec.shutdown() ;\n你可以利用executor service 完成更多的工作。例如，可以等待完成一项特殊的任务(就如第79条中的get方法一样)，你可以等待一个任务集合中的任何任务或者所有任务完成(利用 invokeAny或者 invokeAll方法)，可以等待 executor service 优雅地完成终止(利用 awaitTermination 方法)，可以在任务完成时逐个地获取这些任务的结果(利用ExecutorCompletionService)，可以调度在某个特殊的时间段定时运行或者阶段性地运行的任务(利用 ScheduledThreadPoolExecutor)，等等。\n如果想让不止一个线程来处理来自这个队列的请求，只要调用一个不同的静态工厂，这个工厂创建了一种不同的 executor service，称作线程池(thread pool)。你可以用固定或者可变数目的线程创建一个线程池。java.util.concurrent.Executors类包含了静态工厂，能为你提供所需的大多数executor。然而，如果你想来点特别的，可以直接使用ThreadPoolExecutor类。这个类允许你控制线程池操作的几乎每个方面。\n为特殊的应用程序选择executor service是很有技巧的。如果编写的是小程序，或者是轻量负载的服务器，使用Executors.newCachedThreadPool通常是个不错的选择，因为它不需要配置，并且一般情况下能够正确地完成工作。但是对于大负载的服务器来说，缓存的线程池就不是很好的选择了！在缓存的线程池中，被提交的任务没有排成队列，而是直接交给线程执行。如果没有线程可用，就创建一个新的线程。如果服务器负载得太重，以致它所有的CPU都完全被占用了，当有更多的任务时，就会创建更多的线程，这样只会使情况变得更糟。因此，在大负载的产品服务器中，最好使用Executors。newFixedThreadPool，它为你提供了一个包含固定线程数目的线程池，或者为了最大限度地控制它，就直接使用 ThreadPoolExecutor类。\n不仅应该尽量不要编写自己的工作队列，而且还应该尽量不直接使用线程。当直接使用线程时，Thread 是既充当工作单元，又是执行机制。在Executor Framework 中，工作单元和执行机制是分开的。现在关键的抽象是工作单元，称作任务(task)。任务有两种：Runnable及其近亲Callable(它与Runnable类似，但它会返回值，并且能够抛出任意的异常)。执行任务的通用机制是executor service。如果你从任务的角度来看问题，并让一个executor service 替你执行任务，在选择适当的执行策略方面就获得了极大的灵活性。从本质上讲，Executor Framework所做的工作是执行，Collections Framework所做的工作是聚合(aggregation)。\n在 Java 7中，Executor Framework 得到了扩展，它可以支持 fork-join 任务了，这些任务是通过一种称作 fork-join 池的特殊 executor 服务运行的。fork-join 任务用 ForkJoinTask实例表示，可以被分成更小的子任务，包含 ForkJoinPool 的线程不仅要处理这些任务，高吞吐量，并降低延迟。fork-join 任务的编写和调优是很有技巧的。并发的 stream(详见第48条)是在forkjoin池上编写的，我们不费什么力气就能享受到它们的性能优势，前提是假设它们正好适用于我们手边的任务。\nExecutor Framework的完整处理方法超出了本书的讨论范围，但是有兴趣的读者可以参阅《 Java Concurrency in Practice》一书 [Goetz06]。\n第81条：并发工具优先于wait和notify本书第1版中专门用了一个条目来说明如何正确地使用wait和 notify(Bloch01，详见第 50条)。它提出的建议仍然有效，并且在本条目的最后也对此做了概述，但是这条建议现在远远没有之前那么重要了。这是因为几乎没有理由再使用 wait 和 notify了。自从Java 5发行版本开始，Java平台就提供了更高级的并发工具，它们可以完成以前必须在wait 和 notify上手写代码来完成的各项工作。既然正确地使用wait和 notify比较困难，就应该用更高级的并发工具来代替。\njava.util.concurrent中更高级的工具分成三类：Executor Framework、并发集合(ConcurrentCollection)以及同步器(Synchronizer)，ExecutorFramework只在第80条中简单地提到过，并发集合和同步器将在本条目中进行简单的阐述。\n并发集合为标准的集合接口(如List、Queue 和 Map)提供了高性能的并发实现。为了提供高并发性，这些实现在内部自己管理同步(详见第79条)。因此，并发集合中不可能排除并发活动;将它锁定没有什么作用，只会使程序的速度变慢。\n因为无法排除并发集合中的并发活动，这意味着也无法自动地在并发集合中组成方法调用。因此，有些并发集合接口已经通过依赖状态的修改操作(state-dependent modify operation)进行了扩展，它将几个基本操作合并到了单个原子操作中。事实证明，这些操作在并发集合中已经够用，它们通过缺省方法(详见第21条)被加到了Java 8对应的集合接口中。\n例如，Map 的 putIfAbsent(key，Value)方法，当键没有映射时会替它插人一个映射，并返回与键关联的前一个值，如果没有这样的值，则返回 null。这样就能很容易地实现线程安全的标准 Map 了。例如，下面这个方法模拟了 String.intern 的行为:\n// Concurrent canonicalizing map atop ConcurrentMap-not optimalprivate static final ConcurrentMap&lt;String, String&gt; map =new ConcurrentHashMap&lt;&gt;();public static String intern(String s) &#123;String previousValue = map.putIfAbsent(s, s);return previousValue == null ? s : previousValue;了\n事实上，你还可以做得更好。ConcurrentHashMap 对获取操作(如 get)进行了优化。因此，只有当 get 表明有必要的时候，才值得先调用 get，再调用 putIfAbsent:\n// Concurrent canonicalizing map atop ConcurrentMap - faster!public static String intern(String s) &#123;String result = map.get(s);if(result == null)&#123;result = map.putIfAbsent(s, s);if (result == null)result = s;了return result;\n\nConcurrentHashMap除了提供卓越的并发性之外，速度也非常快。在我的机器上,上面这个优化过的 intern方法比 String.intern 快了不止6倍(但是记住，String.intern 必须使用某种弱引l用，避免随着时间的推移而发生内存泄漏)。并发集合导致同步的集合大多被废弃了。比如，应该优先使用concurrentHashMap，而不是使用collections。synchronizedMap。只要用并发 Map 替换同步 Map，就可以极大地提升并发应用程序的性能。\n待(或者阻塞)到可以成功执行为止。例如，BlockingQueue扩展了Queue接口，并添加了包括take在内的几个方法，它从队列中删除并返回了头元素，如果队列为空，就等待。这样就允许将阻塞队列用于工作队列(work queue)，也称作生产者－消费者队列(producer-consumerqueue)，一个或者多个生产者线程(producer thread)在工作队列中添加工作项目，并且当工作项目可用时，一个或者多个消费者线程(consumer thread)则从工作队列中取出队列并处理工作项目。不出所料，大多数ExecutorService 实现(包括ThreadPoolExecutor)都使用了一个BlockingQueue(详见第80条)。\n同步器(Synchronizer)是使线程能够等待另一个线程的对象，允许它们协调动作。最常用的同步器是CountDownLatch 和 Semaphore。较不常用的是CyclicBarrier和Exchanger。功能最强大的同步器是 Phaser。\n倒计数锁存器(CountdownLatch)是一次性的障碍，允许一个或者多个线程等待一型的参数，这个int参数是指允许所有在等待的线程被处理之前，必须在锁存器上调用countDown方法的次数。\n要在这个简单的基本类型之上构建一些有用的东西，做起来是相当容易。例如，假设想要构建一个简单的框架，用来给一个动作的并发执行定时。这个框架中只包含单个方法，该方法带有一个执行该动作的executor，一个并发级别(表示要并发执行该动作的次数)，以及表示该动作的runnable。所有的工作线程(worker thread)自身都准备好，要在timer线程启动时钟之前运行该动作。当最后一个工作线程准备好运行该动作时，timer线程就”发起头炮”，同时允许工作线程执行该动作。一旦最后一个工作线程执行完该动作，timer 线程就立即停止计时。直接在 wait 和 notify之上实现这个逻辑会很混乱，而在CountDownLatch 之上实现则相当简单:\n//Simple framework for timing concurrent executionpublic static long time(Executor executor, int concurrency,Runnable action) throws InterruptedException &#123;CountDownLatch ready = new CountDownLatch(concurrency);CountDownLatch start = new CountDownLatch(1);CountDownLatch done = new CountDownLatch(concurrency) ;for (int i= O;i&lt; concurrency;i++)&#123;executor.execute(() -&gt;&#123;ready.countDown(); // Tell timer we&#x27;re readytry &#123;start.await(); // wait till peers are readyaction.run(;&#125;catch (InterruptedException e) &#123;Thread.currentThread() .interrupt() ;&#125;finally &#123;done.countDownO); // Tell timer we&#x27;re done&#125;);ready.await(); //Waitforallworkerstobereadylong startNanos = System.nanoTime();start.countDownO); // And they&#x27;re off!done.await(); // Wait for all workers to finishreturn System.nanoTime() - startNanos;子\n\n注意这个方法使用了三个倒计数锁存器。第一个是 ready，工作线程用它来告诉timer线程它们已经准备好了。然后工作线程在第二个锁存器 start上等待。当最后一个工作线程调用ready.countDown 时，timer线程记录下起始时间，并调用 start.countDown,允许所有的工作线程继续进行。然后 timer 线程在第三个锁存器done 上等待，直到最后一个工作线程运行完该动作，并调用 done.countDown。一旦调用这个，timer 线程就会苏醒过来，并记录下结束的时间。\n还有一些细节值得注意。传递给time 方法的 executor 必须允许创建至少与指定并发级别一样多的线程，否则这个测试就永远不会结束。这就是线程饥饿死锁(thread starvationdeadlock)[Goetz06 8.1.1]。如果工作线程捕捉到InterruptedException，就会利用习惯用法 Thread.currentThread().interrupt()重新断言中断，并从它的 run 方法中返回。这样就允许 executor 在必要的时候处理中断，事实上也理应如此。注意，我们利用了 System.nanoTime 来给活动定时。对于间歇式的定时，始终应该优先使用 System.nanoTime，而不是使用 System.currentTimeMillis。因为 System.nanoTime 更准确，也更精确，它不受系统的实时时钟的调整所影响。最后，注意本例中的代码并不能进行准确的定时，除非 action 能完成一定量的工作，比如一秒或者一秒以上。众所周知，准确的微基准测试十分困难，最好在专门的框架如 jmh 的协助下进行[JMH]。\n本条目仅仅触及了并发工具的一些皮毛。例如，前一个例子中的那三个倒计数锁存器其实可以用一个 CyclicBarrier 或者 Phaser 实例代替。这样得到的代码更加简洁，但是理解起来比较困难。\n虽然你始终应该优先使用并发工具，而不是使用 wait方法和 notify方法，但可能必须维护使用了 wait 方法和 notify方法的遗留代码。wait 方法被用来使线程等待某个条件。它必须在同步区域内部被调用，这个同步区域将对象锁定在了调用 wait方法的对象上。下面是使用 wait 方法的标准模式:\n// The standard idiom for using the wait methodsynchronized (obj) &#123;while (&lt;condition does not hold&gt;)obj.waitO; // (Releases lock, and reacquires on wakeup)... // Perform action appropriate to condition\n\n始终应该使用wait循环模式来调用wait方法;永远不要在循环之外调用wait方法。循环会在等待之前和之后对条件进行测试。\n在等待之前测试条件，当条件已经成立时就跳过等待，这对于确保活性是必要的。如果条件已经成立，并且在线程等待之前，notify(或者 notifyAll)方法已经被调用，则无法保证该线程总会从等待中苏醒过来。\n在等待之后测试条件，如果条件不成立的话继续等待，这对于确保安全性是必要的。当条件不成立的时候，如果线程继续执行，则可能会破坏被锁保护的约束关系。当条件不成立时，有下面一些理由可使一个线程苏醒过来：\n口另一个线程可能已经得到了锁，并且从一个线程调用 notify方法那一刻起，到等待线程苏醒过来的这段时间中，得到锁的线程已经改变了受保护的状态。\n口条件并不成立，但是另一个线程可能意外地或恶意地调用了 notify方法。在公有可访问的对象上等待，这些类实际上把自己暴露在了这种危险的境地中。公有可访问对象的同步方法中包含的wait方法都会出现这样的问题。\n( )有某些等待线程的条件已经被满足，但是通知线程可能仍然调用 notifyAll方法。\n口在没有通知的情况下，等待线程也可能(但很少)会苏醒过来。这被称为”伪唤醒”\n(spurious wakeup) [POSIX, 11.4.3.6.1; Java9-api]。\n一个相关的话题是，为了唤醒正在等待的线程，你应该使用 notify方法还是 notify-All方法(回忆一下，notify方法唤醒的是单个正在等待的线程，假设有这样的线程存在，而 notifyAll方法唤醒的则是所有正在等待的线程)。一种常见的说法是，应该始终使用notifyAll方法。这是合理而保守的建议。它总会产生正确的结果，因为它可以保证你将会唤醒所有需要被唤醒的线程。你可能也会唤醒其他一些线程，但是这不会影响程序的正确性。这些线程醒来之后，会检查它们正在等待的条件，如果发现条件并不满足，就会继续等待。\n从优化的角度来看，如果处于等待状态的所有线程都在等待同一个条件，而每次只有一个线程可以从这个条件中被唤醒，那么你就应该选择调用 notify方法，而不是notifyAll 方法。\n即使这些前提条件都满足，也许还是有理由使用 notifyAll 方法而不是 notify 方法。就好像把wait方法调用放在一个循环中，以避免在公有可访问对象上的意外或恶意的通知一样，与此类似，使用 notifyAll 方法代替 notify 方法可以避免来自不相关线程的意外或恶意的等待。否则，这样的等待会”吞掉”一个关键的通知，使真正的接收线程无限地等待下去。\n简而言之，直接使用 wait 方法和 notify方法就像用”并发汇编语言”进行编程一样，而java.util.concurrent则提供了更高级的语言。没有理由在新代码中使用 wait方法和 notify方法，即使有，也是极少的。如果你在维护使用 wait方法和notify方法的代码，务必确保始终是利用标准的模式从 while 循环内部调用 wait方法。一般情况下，应该优先使用 notifyAll方法，而不是使用 notify方法。如果使用 notify方法，请一定要小心，以确保程序的活性。\n第82条：线程安全性的文档化当一个类的方法被并发使用的时候，这个类的行为如何，是该类与其客户端程序建立的约定的重要组成部分。如果你没有在一个类的文档中描述其行为的并发性情况，使用这个类的程序员将不得不做出某些假设。如果这些假设是错误的，所得到的程序就可能缺少足够的同步(详见第78条)，或者过度同步(详见第79条)。无论属于这其中的哪一种情况，都可能会发生严重的错误。\n你可能听到过这样的说法：通过查看文档中是否出现 synchronized 修饰符，可以确定一个方法是否是线程安全的。这种说法从几个方面来说都是错误的。在正常的操作中，Javadoc 并没有在它的输出中包含 synchronized 修饰符，这是有理由的。因为在－个方法声明中出现synchronized修饰符，这是个实现细节，并不是导出的APl的一部分。它并不一定表明这个方法是线程安全的。\n而且”出现了synchronized关键字就足以用文档说明线程安全性”的这种说法隐含了一个错误的观念，即认为线程安全性是一种”要么全有要么全无”的属性。实际上，线程安全性有多种级别。一个类为了可被多个线程安全地使用，必须在文档中清楚地说明它所支持的线程安全性级别。下述分项概括了线程安全性的几种级别。这些分项并没有涵盖所有的可能，只是列出了常见的情形：\n口不可变的(immutable)一这个类的实例是不变的。所以，不需要外部的同步。这样的例子包括 String、Long 和 BigInteger(详见第 17条)。\n口无条件的线程安全(unconditionally thread-safe)——这个类的实例是可变的，但是这个类有着足够的内部同步，所以它的实例可以被并发使用，无须任何外部同步。其例子包括 AtomicLong 和 ConcurrentHashMap。\n口有条件的线程安全(conditionally thread-safe)——除了有些方法为进行安全的并发使用而需要外部同步之外，这种线程安全级别与无条件的线程安全相同。这样的例子包括Collections.synchronized 包装返回的集合，它们的迭代器要求外部同步。\n口非线程安全(not thread-safe)一这个类的实例是可变的。为了并发地使用它们，客户端必须利用自己选择的外部同步包围每个方法调用(或者调用序列)。这样的例子包括通用的集合实现，例如 ArrayList 和 HashMap。\n口线程对立的(thread-hostile)一这种类不能安全地被多个线程并发使用，即使所有的方法调用都被外部同步包围。线程对立的根源通常在于，没有同步地修改静态数据。没有人会有意编写一个线程对立的类;这种类是因为没有考虑到并发性而产生的后果。当一个类或者方法被发现是线程对立的，一般会得到修正，或者被标注为”不再建议使用”。第78条中的generateSerialNumber方法就是线程对立的，因为没有从内部进行同步，详情请参阅第79条。\n这些分类(除了线程对立的之外)粗略对应于《JavaConcurrency inPractice》一书中的线程安全注解(thread safety annotation)，分别为 Immutable、ThreadSafe 和 NotThread-Safe [Goetz06，Appendix A]。上述分类中无条件和有条件的线程安全类别都涵盖在 Thread-Safe注解中了。\n在文档中描述一个有条件的线程安全类要特别小心。你必须指明哪个调用序列需要外部同步，还要指明为了执行这些序列，必须获得哪一把锁(极少的情况下是指哪几把锁)。通常情况下，这是指作用在实例自身上的那把锁，但也有例外。例如，Collections.synchronizedMap 的文档中有这样的说明:\nIt isimperative that the user manually synchronize on the returned map wheniterating over any of its collection views:\n(当遍历任何被返回 Map 的集合视图时，用户必须手工对它们进行同步：)\nMap&lt;K, V&gt; m = Co1lections.synchronizedMap(new HashMap&lt;&gt;();Set&lt;K&gt; s = m.keySet;// Needn&#x27;t be in synchronized blocksynchronized(m) &#123; // Synchronizing on m, not s!for (K key : s)key.fO ;&#125;\n\n如果没有遵循这样的建议，就可能造成不确定的行为。\n类的线程安全说明通常放在它的文档注释中，但是带有特殊线程安全属性的方法则应该在它们自己的文档注释中说明它们的属性。没有必要说明枚举类型的不可变性。除非从返回类型来看已经很明显，否则静态工厂必须在文档中说明被返回对象的线程安全性，如Collections.synchronizedMap(上述) 所示。\n当一个类承诺”使用一个公有可访问的锁对象”时，就意味着允许客户端以原子的方式执行一个方法调用序列，但是，这种灵活性是要付出代价的。并发集合(如Concurrent-起拒绝服务(denial-of service)攻击，他只需超时地保持公有可访问锁即可。这有可能是无意的，也可能是有意的。\n为了避免这种拒绝服务攻击，应该使用一个私有锁对象(private lock object)来代替同步的方法 (隐含着一个公有可访问锁)：\n//Privatelockobjectidiom-thwartsdenial-of-serviceattackprivate final Object lock = new Object();public void foo()&#123;synchronized(lock) &#123;\n\n因为这个私有锁对象不能在这个类之外被访问，也不能被这个类的客户端程序所访问，所以客户端不可能妨碍对象的同步。实际上，我们正是在应用第15条的建议，把锁对象封装在它所同步的对象中。\n注意 1ock域被声明为 final 的。这样可以防止不小心改变它的内容，而导致不同步访问包含对象的悲惨后果(详见第78条)。我们这是在应用第 17条的建议，将 1ock域的可变性减到最小。lock 域应该始终声明为 final。这是真的，无论是使用普通的监控锁(如上所述)，还是使用来自java.util.concurrent.locks 包中的锁。\n私有锁对象模式只能用在无条件的线程安全类上。有条件的线程安全类不能使用这种模式，因为它们必须在文档中说明：在执行某些方法调用序列时，它们的客户端程序必须获得哪把锁。\n私有锁对象模式特别适用于那些专门为继承而设计的类(详见第19条)。如果这种类使用它的实例作为锁对象，子类可能很容易在无意中妨碍基类的操作，反之亦然。出于不同的目的而使用相同的锁，子类和基类可能会”相互绊住对方的脚”。这不只是一个理论意义上的问题。例如，这种现象在 Thread 类上就出现过[Bloch05，Puzzle 77]。\n简而言之，每个类都应该利用字斟句酌的说明或者线程安全注解，清楚地在文档中说明它的线程安全属性。Synchronized 修饰符与这个文档毫无关系。有条件的线程安全类必须在文档中指明”哪个方法调用序列需要外部同步，以及在执行这些序列的时候要获得哪把锁”。如果你编写的是无条件的线程安全类，就应该考虑使用私有锁对象来代替同步的方法。这样可以防止客户端程序和子类的不同步干扰，让你能够在后续的版本中灵活地对并发控制采用更加复杂的方法。\n第83条：慎用延迟初始化延迟初始化(lazy initialization)是指延迟到需要域的值时才将它初始化的行为。如果永远不需要这个值，这个域就永远不会被初始化。这种方法既适用于静态域，也适用于实例域。虽然延迟初始化主要是一种优化，但它也可以用来破坏类中的有害循环和实例初始化[Bloch05, Puzzle 51 ]。\n就像大多数的优化一样，对于延迟初始化，最好建议”除非绝对必要，否则就不要这么做”(详见第67条)。延迟初始化就像一把双刃剑。它降低了初始化类或者创建实例的开销，却增加了访问被延迟初始化的域的开销。根据延迟初始化的域的哪个部分最终需要初始化、一样)实际上降低了性能。\n也就是说，延迟初始化有它的好处。如果域只在类的实例部分被访问，并且初始化这个域的开销很高，可能就值得进行延迟初始化。要确定这一点，唯一的办法就是测量类在用和不用延迟初始化时的性能差别。\n始化的域，采用某种形式的同步是很重要的，否则就可能造成严重的Bug(详见第78条)。本条目中讨论的所有初始化方法都是线程安全的。\n在大多数情况下，正常的初始化要优先于延迟初始化。下面是正常初始化的实例域的一个典型声明。注意其中使用了final 修饰符(详见第 17 条):\n&#x2F;&#x2F;Normal initialization of an instance fieldprivate final FieldType field &#x3D; computeFieldValueO;\n如果利用延迟优化来破坏初始化的循环，就要使用同步访问方法，因为它是最简单、最清楚的替代方法：\n&#x2F;&#x2F;Lazyinitializationofinstance field-synchronizedaccessorprivate FieldType field;\nprivate synchronized FieldType getFieldO{if (field &#x3D;&#x3D; nul1)field &#x3D; computeFieldValue;return field;\n这两种习惯模式(正常的初始化和使用了同步访问方法的延迟初始化)应用到静态域上时保持不变，除了给域和访问方法声明添加了 static 修饰符之外。\n如果出于性能的考虑而需要对静态域使用延迟初始化，就使用lazyinitializationholderclass 模式。这种模式(也称作initialize-on-demandholder class idiom)保证了类要到被用到的时候才会被初始化[JLS，12.4.1]。如下所示：\n//Lazyinitializationholderclass idiom forstaticfieldsprivate static class FieldHolder&#123;private staticFieldType getField()&#123;return FieldHolder.field;&#125;\n\n当 getField方法第一次被调用时，它第一次读取FieldHolder.field，导致FieldHolder 类得到初始化。这种模式的魅力在于，getField 方法没有被同步，并且只执行一个域访问，因此延迟初始化实际上并没有增加任何访问成本。现代的VM将在初始化该类的时候，同步域的访问。一旦这个类被初始化，虚拟机将修补代码，以便后续对该域的访问不会导致任何测试或者同步。\n如果出于性能的考虑而需要对实例域使用延迟初始化，就使用双重检查模式(double-check idiom)。这种模式避免了在域被初始化之后访问这个域时的锁定开销(详见第 79条)。这种模式背后的思想是：两次检查域的值，因此名字叫双重检查(double-check)，第一次检查时没有锁定，看看这个域是否被初始化了;第二次检查时有锁定。只有当第二次检查时表明这个域没有被初始化，才会对这个域进行初始化。因为如果域已经被初始化就不会有锁定，这个域被声明为 volatile 就很重要了(详见第 78 条)。下面就是这种习惯模式：\nprivate FieldType getFieldO)&#123;FieldType result = field;if(result ==null)&#123;// First check(nolocking)synchronized(this) &#123;if (field == null) // Second check (with locking)field = result = computeFieldValue();子return result;\n\n这段代码可能看起来似乎有些费解。尤其对于需要用到局部变量result可能有点不解。这个变量的作用是确保 fielα 只在已经被初始化的情况下读取一次。虽然这不是严格需要，但是可以提升性能，并且因为给低级的并发编程应用了一些标准，因此更加优雅。在我的机器上，上述的方法比没用局部变量的方法快了大约1.4倍。\n虽然也可以对静态域应用双重检查模式，但是没有理由这么做，因为lazy initializationholder class idiom是更好的选择。\n双重检查模式的两个变量值得一提。有时可能需要延迟初始化一个可以接受重复初始化的实例域。如果处于这种情况，就可以使用双重检查模式的一个变量，它负责分配第二次检查。没错，它就是单重检查模式(single-check idiom)。下面就是这样的一个例子。注意field 仍然被声明为 volatile:\n//Single-checkidiom-cancauserepeatedinitialization！private volatile FieldType field;private FieldType getFieldO)&#123;FieldType result = field;if (result == nul1)field = result = computeFieldValue();return result;了\n\n查模式(double-check idiom)或者单重检查模式(single-check idiom)应用到数值型的基本类型域时，就会用0来检查这个域(这是数值型基本变量的默认值)，而不是用 null。\n如果你不在意是否每个线程都重新计算域的值，并且域的类型为基本类型，而不是long 或者 double 类型，就可以选择从单重检查模式的域声明中删除 volatile 修饰符。这种变体称之为 racy single-check idiom。它加快了某些架构上的域访问，代价是增加了额外的初始化(直到访问该域的每个线程都进行一次初始化)。这显然是一种特殊的方法，不适合于日常的使用。\n总而言之，大多数的域应该正常地进行初始化，而不是延迟初始化。如果为了达到性迟初始化方法。对于实例域，就使用双重检查模式(double-check idiom);对于静态域，则使用lazy initialization holder class idiom。对于可以接受重复初始化的实例域，也可以考虑使用单重检查模式(single-check idiom)。\n第84条：不要依赖于线程调度器当有多个线程可以运行时，由线程调度器(thread scheduler)决定哪些线程将会运行，以及运行多长时间。任何一个合理的操作系统在做出这样的决定时，都会努力做到公正，但是所采用的策略却大相径庭。因此，编写良好的程序不应该依赖于这种策略的细节。任何依赖于线程调度器来达到正确性或者性能要求的程序，很有可能都是不可移植的。\n要编写出健壮、响应良好、可移植的多线程应用程序，最好的办法是确保可运行线程的平均数量不明显多于处理器的数量。这使得线程调度器没有更多的选择：它只需要运行这些可运行的线程，直到它们不再可运行为止。即使在根本不同的线程调度算法下，这些程序的行为也不会有很大的变化。注意可运行线程的数量并不等于线程的总数量，前者可能更多。在等待的线程并不是可运行的。\n保持可运行线程数量尽可能少的主要方法是，让每个线程做些有意义的工作，然后等待更多有意义的工作。如果线程没有在做有意义的工作，就不应该运行。根据Executor务保持适当得小，彼此独立。任务不应该太小，否则分配的开销也会影响到性能。\n线程不应该一直处于忙－等(busy-wait)的状态，即反复地检查一个共享对象，以等待某些事情发生。除了使程序易受到调度器的变化影响之外，忙－等这种做法也会极大地增加处理器的负担，降低了同一机器上其他进程可以完成的有用工作量。作为不该做的一个极端的反面例子，考虑下面这个CountDownLatch的不正当的重新实现:\n//AwfulCountDownLatch implementation-busy-waitsincessantly！public class SlowCountDownLatch&#123;private int count;public SlowCountDownLatch(int count)&#123;if(count &lt;0)throw new IllegalArgumentException(count +&quot;&lt;O&quot;);this.count = count;publicvoidawaitO&#123;while(true)&#123;synchronized(this) &#123;if(count ==0)return;public synchronized void countDownO &#123;if (count != 0)count--;\n\n在我的机器上，当1000个线程在锁存器(latch)中等待的时候，SlowCountDownLatchJava 自带的 CountDownLatch 比人快了大约10倍。虽然这个例子可能显得有点牵强，但是系统中有一个或者多个线程处于不必要的可运行状态，这种现象并不少见。其性能和可移植性都可能受到损害。\n如果某一个程序不能工作，是因为某些线程无法像其他线程那样获得足够的CPU时间，那么，不要企图通过调用Thread.yield来”修正”该程序。你可能好不容易成功地让程序能够工作，但这样得到的程序仍然是不可移植的。同一个 yield 调用在一个 JVM实现上能提高性能，而在另一个JVM实现上却有可能会更差，在第三个JVM实现上则可能没有影响。Thread.yield 没有可测试的语义(testable semantic)。更好的解决办法是重新构造应用程序，以减少可并发运行的线程数量。\n有一种相关的方法是调整线程优先级(thread priority)，也可以算是一条建议。线程优先级是Java平台上最不可移植的特征了。通过调整某些线程的优先级来改善应用程序的响应能力，这样做并非不合理，却是不必要的，也是不可移植的。通过调整线程的优先级来解决严重的活性问题是不合理的。在你找到并修正底层的真正原因之前，这个问题可能会再次出现。\n总而言之，不要让应用程序的正确性依赖于线程调度器。否则，得到的应用程序将既不健壮，也不具有可移植性。同样，不要依赖 Thread．yield 或者线程优先级。这些机制都只是影响到调度器。线程优先级可以用来提高一个已经能够正常工作的程序的服务质量，但永远不应该用来”修正”一个原本并不能工作的程序。\n第十二章 序列化本章讨论对象序列化(object serialization)，它是Java 的一个框架，用来将对象编码成字节流(序列化)，并从字节流编码中重新构建对象(反序列化)。一旦对象被序列化后，它的编码就可以从一台正在运行的虚拟机被传递到另一台虚拟机上，或者被存储到磁盘上，供后续反序列化时使用。本章主要关注序列化的风险，以及如何将风险降到最低。\n第85条：其他方法优先于Java序列化1997年，Java 新增了序列化时，就被认为是有风险的。这种方法已经作为研究语言(Modula-3)做过尝试，但在生产语言中还从未试过。虽然分布式对象使程序员这部分的工作简化了，为之付出的代价却是不可见的构造器，还有API和实现之间模糊的界限，而且在代码的正确性、性能、安全性、维护性方面都有潜在的问题。拥护者们相信利大于弊，但是历史证明事实正好相反。\n在本书第2版中谈到的安全性问题，事实证明每一点滴都可能酿成大祸。2000 年之前广泛讨论的安全漏洞，十年之后酿成了严重的攻击事件(exploit)，其中著名的有 2016 年11月发生在旧金山市政交通局(SFMTAMuni)的黑客勒索软件攻击事件，导致整个收费系统整整瘫痪了两天[Gallagher16]。\n序列化的根本问题在于，其攻击面(attack surface)过于庞大，无法进行防护，并且它还在不断地扩大：对象图是通过在 ObjectInputStream 上调用 readobject 方法进行反序列化的。这个方法其实是个神奇的构造器，它可以将类路径上几乎任何类型的对象都实例化，只要该类型实现了 Serializablé 接口。在反序列化字节流的过程中，该方法可以执行以上任意类型的代码，因此所有这些类型的代码都是攻击面的一部分。\n攻击面包括Java平台类库中的类、第三方类库如ApacheCommons Collections中的类，以及应用本身的类。即便遵守所有相关的最佳实践，成功地编写了无可击的可序列化类，这个应用也依然是有漏洞的。引用CERT(计算机安全应急响应组)协调中心技术经理RobertSeacord的话说：\nJava反序列化是一个明显存在的风险，它不仅被应用直接广泛使用，也被Java子系统如RMI(远程方法调用)、JMX(Java管理扩展)和JMS(Java消息系统)等大量地间接使用。将不被信任的流进行反序列化，可能导致远程代码执行(Remote Code Execution，RCE)、拒 绝服务(Denial-of-Service，DoS)，以及一系列其他的攻击。即使应用本身没有做错任何事情，也可能受到这些攻击[Seacord17].\n攻击者和安全研究员都在研究Java类库和常用的第三方类库中可序列化的类型，寻找在进行潜在危险活动的反序列化期间被调用的方法。这些方法被称作指令片段(gadget)。多现指令片段链的功能十分强大，允许攻击者在底层硬件中执行任意的本机代码，唯一的机会就是为反序列化提交精心编写的字节流。这正是发生在 SFMTA Muni 的攻击。这个攻击不是孤立的，还会有其他的攻击，并且会越来越多。\n如果不使用任何指令片段，对于需要长时间进行反序列化的简短字节流，只要引发反序列化，就可以轻松地展开一次拒绝服务攻击。这样的字节流被称作反序列化炸弹(deserializationbomb)[Svoboda16]。下面举一个来自WouterCoekaerts 的范例，它只用了散列集和一个字符串\n［Coekaerts 15]://Deserializationbomb o-deserializing thisstreamtakesforeverstatic byte[] bombO &#123;Set&lt;Object&gt;root =new HashSet&lt;&gt;(;Set&lt;0bject&gt; s1=root;Set&lt;Object&gt; s2 = new HashSet&lt;&gt;();for(int i=0;i&lt;100;i++)&#123;Set&lt;Object&gt; t1 = new HashSet&lt;&gt;(;Set&lt;0bject&gt; t2 = new HashSet&lt;&gt;(;tl.add(&quot;foo&quot;);// Make tlunequaltot2s1.add(t1);s1.add(t2);s2.add(t1); s2.add(t2);sl = tl;s2= t2;return serialize(root);// Method omitted for brevity了\n\n用。整个字节流的长度为5744个字节，但在反序列化之前，总长度会呈爆炸式增长。问题在于，反序列化 HashSet 实例需要计算其元素的散列码。根散列集合中的这 2个元素，就级之深。因此，反序列化集合会导致hashCode 方法被调用超过 210次。反序列化花费的时间是无限的，而且它从不提示是什么东西出了错。它几乎不产生任何对象，堆栈深度也是有限的。\n我们怎么做才能预防这些问题呢？每当反序列化一个不信任的字节流时，自己就要试着去攻击它。避免序列化攻击的最佳方式是永远不要反序列化任何东西。引用1983年电影《WarGames》中Joshua的话：”获胜的唯一方法就是压根儿不参与比赛。”在新编写的任何新系统中都没有理由再使用Java 序列化。为了避免Java序列化的诸多风险，还有许多其他机制可以完成对象和字节序列之间的转化，它们同时还能带来很多便利，诸如跨平台支持、高性能、一个大型的工具生态系统，以及一个广阔的专家社区。本书把这些机制作称跨平台会把它们称作序列化系统，但本书不那样用，避免与Java 序列化造成混淆。\n这些表示法的共同点是，它们都远比Java 序列化要简单得多。它们不支持任意对象图的自动序列化和反序列化。而是支持包含属性／值对的简单的结构化数据对象。它们只支持的分布式系统，同时又简单得足以避免自Java序列化出现以来就一直造成困扰的那些重大问题。\n最前沿的跨平台结构化数据表示法是JSON[JSON]和ProtocolBuffers，也称作protobuf[Protobuf]。JSON 是 Douglas Crockford为浏览器－服务器之间的通信设计的,Protocol Buffers是Google为了在服务器之间保存和交换结构化数据设计的。尽管有时候这些表示法也被称作中性语言(language-neutral)，JSON起初却是为 JavaScript 开发的，protobuf是为 C++开发的，这两者都保持着设计初衷的痕迹。\nJSON和 protobuf之间最明显的区别在于，JSON是基于文本的，人类可以阅读，而protobuf是二进制的，从根本上来说更有效;JSON 纯粹就是一个数据表示法，而 protobuf则提供模式(类型)，建立文档，强制正确的用法。虽然 protobuf比JSON更加有效，但JSON对于基于文本的表示法却非常高效。protobuf虽然是一个二进制表示法，但它提供了可以替代的另一种文本表示法(pbtxt)，当人类需要读懂它的时候可以使用。\n如果无法完全避免Java 序列化，或许是因为需要在Java 序列化的遗留系统环境中工作，下一步最好永远不要反序列化不被信任的数据。尤其是永远不应该接受来自不信任资源的RMI通信。Java 官方安全编码指导方针中提出：”对不信任数据的反序列化，从本质上来说是危险的，应该予以避免。”这个句子在文中用红色的字体突出显示，在介绍这一点的整个文档中，只有这一句话[Java-secure]。\n如果无法避免序列化，又不能绝对确保被反序列化的数据的安全性，就应利用Java9中新增的对象反序列化过滤(object deserialization filtering)，这一功能也已经移植到了 Java 较早的版本(java.io.ObjectInputFilter)。它可以在数据流被反序列化之\n前，为它们定义一个过滤器。它可以操作类的粒度，允许接受或者拒绝某些类。默认接受类，同时拒绝可能存在危险的黑名单(blacklisting);默认拒绝类，同时接受假定安全的白名单(whitelisting)。白名单优于黑名单，因为黑名单只能抵御已知的攻击。有一个[Schneiderl6]。过滤设施也能帮助你避免过度使用内存，并广泛深人对象图，但无法防御上面提到过的序列化炸弹。\n遗憾的是，序列化在 Java 生态系统中仍然十分普遍。如果在维护的系统是基于Java 序列化的，一定要认真考虑将它迁移到跨平台的结构化数据表示法，尽管这项工作费时费力。现实中，可能会发现仍然需要编写或者维护可序列化的类。要编写出正确、安全和高效的序列化类，需要加倍小心。本章剩下的内容将针对何时以及如何做到上述要求提出专业的建议。\n总而言之，序列化是很危险的，应该予以避免。如果是重新设计一个系统，一定要用如果必须这么做，就要使用对象的反序列化过滤，但要注意的是，它并不能确保阻止所有的攻击。不要编写可序列化的类。如果必须这么做，一定要倍加小心地进行试验。\n第86条：谨慎地实现Serializable接口要想使一个类的实例可被序列化，非常简单，只要在它的声明中加人implementsSerializable字样即可。正因为太容易了，所以普遍存在这样一种误解，认为程序员毫不费力就可以实现序列化。而实际的情形要复杂得多。虽然使一个类可被序列化的直接开销非常低，甚至可以忽略不计，但是为了序列化而付出的长期开销往往是相当高的。\n实现Serializable接口而付出的最大代价是，一旦一个类被发布，就大大降低了”改变这个类的实现”的灵活性。如果一个类实现了Serializable 接口，它的字节流编码(或者说序列化形式)就变成了它的导出的API的一部分。一旦这个类被广泛使用，往往必须永远支持这种序列化形式，就好像你必须要支持导出的API的所有其他部分一样。如果不努力设计一种自定义的序列化形式(custom serialized form)，而仅仅接受了默认的序列化形式，这种序列化形式将被永远地束缚在该类最初的内部表示法上。换句话说，如果接受了默认的序列化形式，这个类中私有的和包级私有的实例域将都变成导出的API的一部分，这不符合”最低限度地访问域”的实践准则(详见第15条)，从而它就失去了作为信息隐藏工具的有效性。\n如果接受了默认的序列化形式，并且以后又要改变这个类的内部表示法，则结果可能导致序列化形式的不兼容。客户端程序企图用这个类的旧版本来序列化一个类，然后用新版本进行反序列化，结果将导致程序失败。反之亦然。在改变内部表示法的同时仍然维持原来的序列化形式(使用 objectOutputStream.putFields 和 ObjectInputStream.readFields)，这也是可能的，但是做起来比较困难，并且会在源代码中留下一些明显的隐患。因此，应该仔细地设计一种高质量的序列化形式，并且在很长时间内都愿意使用这种形式(详见第87条和第90条)。这样做将会增加开发的初始成本，但这是值得的。设计良好的序列化形式也许会给类的演变带来限制;但是设计不好的序列化形式则可能会使类根本无法演变。\n序列化会使类的演变受到限制，这种限制的一个例子与流的唯一标识符(stream uniqueidentifier)有关，通常称它为序列版本UID(serialversionUID)。每个可序列化的类都有一个唯一标识号与它相关联。如果你没有在一个名为 serialVersionUID 的私有静态 final的long 域中显式地指定该标识号，系统就会对这个类的结构运用一个加密的散列函数(SHA-1)，从而在运行时自动产生该标识号。这个自动产生的值会受到类名称、它所实现的接口的名称，以及所有公有的和受保护的成员的名称所影响。如果你通过任何方式改变了这些信息，比如，增加了一个不是很重要的工具方法，自动产生的序列版本UID也会发生变化。因此，如果你没有声明一个显式的序列版本UID，兼容性将会遭到破坏，在运行时导致 InvalidClassException 异常。\n实现Serializable的第二个代价是，它增加了出现Bug和安全漏洞的可能性(详见第85条)。通常情况下，对象是利用构造器来创建的;序列化机制是一种语言之外的对象创建机制(extralinguistic mechanism)。无论你是接受了默认的行为，还是覆盖了默认的行为，反序列化机制(deserialization)都是一个”隐藏的构造器”，具备与其他构造器相同的特点。因为反序列化机制中没有显式的构造器，所以你很容易忘记要保证：反序列化过程必须也要保证所有”由真正的构造器建立起来的约束关系”，并且不允许攻击者访问正在构造过程中的对象的内部信息。依靠默认的反序列化机制，很容易使对象的约束关系遭到破坏，以及遭受到非法访问(见第88条)。\n实现Serializable的第三个代价是，随着类发行新的版本，相关的测试负担也会增加。当一个可序列化的类被修订的时候，很重要的一点是，要检查是否可以”在新版本中序列化一个实例，然后在旧版本中反序列化”，反之亦然。因此，测试所需要的工作量与”可序列化的类的数量和发行版本号”的乘积成正比，这个乘积可能会非常大。你必须既要确保”序列化－反序列化”过程成功，也要确保结果产生的对象真正是原始对象的复制品。如果在最初编写一个类的时候，就精心设计了自定义的序列化形式，测试的要求就可以有所降低。\n实现Serializable接口并不是一个很轻松就可以做出的决定。如果一个类将要加人到某个框架中，并且该框架依赖于序列化来实现对象传输或者持久化，对于这个类来说，一个组件，并且后者必须实现 Serializable接口，若前者也实现了 Serializable接口，它就会更易于被后者使用。然而，有许多实际的开销都与实现 Serializable接口有关。每当你实现一个类的时候，都需要权衡一下所付出的代价和带来的好处。根据经验，如BigInteger 和Instant 等值类应该实现 Serializable接口，大多数的集合类也应该如此。代表活动实体的类，比如线程池(thread pool)，一般不应该实现 Serializable接口。\n为了继承而设计的类(详见第19条)应该尽可能少地去实现Serializable接口，用户的接口也应该尽可能少继承Serializable接口。如果违反了这条规则，扩展这个类或者实现这个接口的程序员就会背上沉重的负担。然而在某些情况下违反这条规则却是合适的。例如，如果一个类或者接口存在的目的主要是为了参与到某个框架中，该框架要求所有的参与者都必须实现 Serializable 接口，那么，对于这个类或者接口来说，实现或者扩展 Serializable接口就是非常有意义的。\n在为了继承而设计的类中，真正实现了 Serializable接口的有 Throwable类和Component 类。因为 Throwable 类实现了 Serializable 接口，所以 RMI 的异常可以从服务器端传到客户端。Component 类实现了 Serializable 接口，因此 GUI可以被发送、保存和恢复，但是即使在 Swing 和 AWT的鼎盛时间，这个机制在实践中也鲜被使用。\n如果实现了一个带有实例域的类，它是可序列化和可扩展的，就应该担心以下几个风险。如果类的实例域值有一些约束条件，重要的是防止子类覆盖 finalize 方法，类只要通过覆盖finalize 并把它声明为 final 便可以完成这个任务。否则，类就很容易受到终结器攻击(finalizer attack)，详见第 8条。最后，如果类有限制条件，当类的实例域被初始化成它们的默认值(整数类型为O，boolean 为 false，对象引l用类型为 null)时，就会违背这些约束条件，这时候就必须给这个类添加 readObjectNoData 方法:\n//readobjectNoDataforstatefulextendableserializableclassesprivate void readObjectNoDataO) throws InvalidObjectException &#123;throw new InvalidobjectException(&quot;Stream data required&quot;);&#125;\n\n括给现有的可序列化类添加可序列化的超类[Serialization，3.5]。\n有一条告诫与”不要实现Serializable接口”有关。如果一个专门为了继承而设计的类不是可序列化的，那么想要编写出可序列化的子类就特别费力。这种类正常的反序列化就要求超类得有一个可访问的无参构造器[Serialization，1.10]。如果没有提供这样的无参构造器，子类就会被迫使用序列化代理模式(serialization proxy patten)，详见第 90 条。\n内部类(详见第 24条)不应该实现Serializable 接口。它们使用编译器产生的合成域(synthetic field)来保存指向外围实例(enclosing instance)的引用，以及保存来自外围作用域的局部变量的值。”这些域如何对应到类定义中”并没有明确的规定，就好像没有指定匿名类和局部类的名称一样。因此，内部类的默认序列化形式是定义不清楚的。然而，静态成员类(static member class)却可以实现Serializable接口。\n简而言之，千万不要认为实现 Serializable 接口会很容易。除非一个类只在受保护的环境下使用，在这里版本之间永远不会交互，服务器永远不会暴露给不可信任的数据，否则,实现 Serializable 接口就是个很严肃的承诺，必须认真对待。如果一个类允许继承，则更要加倍小心。\n第87条：考虑使用自定义的序列化形式当你在时间紧迫的情况下设计一个类时，一般合理的做法是把工作重心集中在设计最佳的API上。有时候，这意味着要发行一个”用完后即丢弃”的实现，因为你知道以后会在新版本中将它替换掉。正常情况下，这不成问题，但是如果这个类实现了 Serializable接口，并且使用了默认的序列化形式，你就永远无法彻底摆脱那个应该丢弃的实现了。它将永远牵制住这个类的序列化形式。这不只是一个纯理论的问题，在Java平台类库中已经有几个类出现了这样的问题，包括BigInteger类。\n如果事先没有认真考虑默认的序列化形式是否合适，则不要贸然接受。接受默认的序列化形式是一个非常重要的决定，需要从灵活性、性能和正确性等多个角度对这种编码形式进行考察。一般来讲，只有当自行设计的自定义序列化形式与默认的序列化形式基本相同时，才能接受默认的序列化形式。\n考虑以一个对象为根的对象图，相对于它的物理表示法而言，该对象的默认序列化形式是一种相当有效的编码形式。换句话说，默认的序列化形式描述了该对象内部所包含的数据，以及每一个可以从这个对象到达的其他对象的内部数据。它也描述了所有这些对象被链接起来后的拓扑结构。对于一个对象来说，理想的序列化形式应该只包含该对象所表示的逻辑数据，而逻辑数据与物理表示法应该是各自独立的。\n如果一个对象的物理表示法等同于它的逻辑内容，可能就适合于使用默认的序列化形式。例如，对于下面这些仅仅表示人名的类，默认的序列化形式就是合理的：\n//Good candidate for default serialized formpublic classNameimplements Serializable&#123;***Last name.Must be non-null.*@serial*private final String lastName***First name. Must be non-null.* @serial*/private final String firstName;*** Middle name,or null if there is none*@serialprivate final String middleName;..// Remainder omitted\n\n从逻辑的角度而言，一个名字通常包含三个字符串，分别代表姓、名和中间名。Name中的实例域精确地反映了它的逻辑内容。\n即使你确定了默认的序列化形式是合适的，通常还必须提供一个readobject方法以保证约束关系和安全性。对于这个Name类而言，readObject方法必须确保lastName和firstName是非null的。第88条和第90条将详细讨论这个问题。\n注意，虽然 lastName、firstName 和 middleName 域是私有的，但是它们仍然有相应的注释文档。这是因为，这些私有域定义了一个公有的API，即这个类的序列化形式，并且该公有的 API 必须建立文档。@serial 标签告诉 Javadoc 工具，把这些文档信息放在有关序列化形式的特殊文档页中。\n下面的类与Name 类不同，它是另一个极端，该类表示了一个字符串列表(此刻我们暂时忽略关于”最好使用标准List实现”的建议):\n//Awfulcandidatefordefaultserializedformpublic final class StringList implements Serializable &#123;private int size = 0;private Entry head = null;private static class Entry implements Serializable &#123;String data;Entry next;Entry previous;...// Remainder omitted\n从逻辑意义上讲，这个类表示了一个字符串序列。但是从物理意义上讲，它把该序列表示成一个双向链表。如果你接受了默认的序列化形式，该序列化形式将不遗余力地镜像出(mirror)链表中的所有项，以及这些项之间的所有双向链接。\n当一个对象的物理表示法与它的逻辑数据内容有实质性的区别时，使用默认序列化形式会有以下4个缺点：\n口它使这个类的导出API永远地束缚在该类的内部表示法上。在上面的例子中，私有的 StringList.Entry类变成了公有 API的一部分。如果在将来的版本中，内部表示法发生了变化，StringList 类仍需要接受链表形式的输人，并产生链表形式的输出。这个类永远也摆脱不掉维护链表项所需要的所有代码，即使它不再使用链表作为内部数据结构了，也仍然需要这些代码。\n口它会消耗过多的空间。在上面的例子中，序列化形式既表示了链表中的每个项，也表示了所有的链接关系，这是不必要的。这些链表项以及链接只不过是实现细节，不值得记录在序列化形式中。因为这样的序列化形式过于庞大，所以，把它写到磁盘中，或者在网络上传输都将非常慢。\n口它会消耗过多的时间。序列化逻辑并不了解对象图的拓扑关系，所以它必须要经过一个昂贵的图遍历(traversal)过程。在上面的例子中，沿着 next引l用进行遍历是非常简单的。\n口它会引起栈溢出。默认的序列化过程要对对象图执行一次递归遍历，即使对于中等规模的对象图，这样的操作也可能会引起栈溢出。在我的机器上，如果 String-List实例包含1000～1800个元素，对它进行序列化就会产生 StackOverflow-Error栈溢出错误。奇怪的是，到底最低多少个元素会引发栈溢出呢？(在我的机器上)每次运行的结果都不一样。引发问题的最少列表元素数量取决于平台实现以及命令行参数，有些实现可能根本不存在这样的问题。\n对于 StringList类，合理的序列化形式可以非常简单，只需先包含链表中字符串的数目，然后紧跟着这些字符串即可。这样就构成了 StringList 所表示的逻辑数据，与它的物理表示细节脱离。下面是 StringList的一个修订版本，它包含 writeObject 和readObject 方法，用来实现这样的序列化形式。顺便提醒一下，transient 修饰符表明这个实例域将从一个类的默认序列化形式中省略掉：\n//StringListwithareasonablecustomserializedformpublic final class StringList implements Serializable &#123;private transient int size = 0;private transient Entry head = null;// NolongerSerializable!private static class Entry&#123;String data;Entry next;Entry previous;// Appends the specified string to the listpublic final void add(String s)&#123;...&#125;*** Serialize this &#123;@code StringList&#125; instance.* @serialData The size of the list (the number of strings*it contains) is emitted (&#123;@code int&#125;)，followed by all of* its elements (each a &#123;@code String&#125;)，in the proper*sequence.private void writeObject(ObjectOutputStream s)throws IoException&#123;s.defaultWriteObjectO;S.writeInt(size);// Write out all elements in the proper order.for (Entry e = head; e != null; e = e.next)s.writeObject(e.data);private void readobject(ObjectInputStream s)throws IOException, ClassNotFoundException &#123;s.defaultReadObject();int numElements = s.readInt();//Read in allelementsand insert them in listfor(inti=0;i&lt;numElements;i++)add((String) s.readObject()) ;...// Remainder omitted\n\n尽管 StringList 的所有域都是瞬时的(transient)，但 writeObject 方法的首要任务仍是调用defaultWriteObject,readobject方法的首要任务则是调用defaultRead-Object。如果类的所有实例域都是瞬时的，从技术角度而言，不调用 defaultWrite-Object和 defaultReadObject也是允许的，但是序列化规范依然要求你不管怎样都要调用它们。这样得到的序列化形式允许在以后的发行版本中增加非瞬时的实例域，并且还能保持向前或者向后兼容性。如果某一个实例将在未来的版本中被序列化，然后在前一个版本中被反序列化，那么，后增加的域将被忽略掉。如果旧版本的readobject方法没有调用defaultReadObject，反序列化过程将失败，并引发 StreamCorruptedException 异常。\n注意，尽管writeObject方法是私有的，它也有文档注释。这与Name 类中私有域的文档注释是同样的道理。该私有方法定义了一个公有的 API，即序列化形式，并且这个公有的 API应该建立文档。如同域的 @serial 标签一样，方法的 @serialData 标签也告知 Javadoc 工具，要把该文档信息放在有关序列化形式的文档页上。\n套用以前对性能的讨论形式，如果平均字符串长度为 10个字符，StringList 修订版本的序列化形式就只占用原序列化形式一半的空间。在我的机器上，同样是10个字符长度的情况下，StringList修订版的序列化速度比原版本的快2倍。最终，修订版中不存在栈溢出的问题，因此，对于可被序列化的 StringList 的大小也没有实际的上限。\n虽然默认的序列化形式对于 StringList类来说只是不适合而已，对于有些类，情况却变得更加糟糕。对于StringList，默认的序列化形式不够灵活，并且执行效果不佳，但是序列化和反序列化 StringList 实例会产生对原始对象的忠实拷贝，它的约束关系没有被破坏，从这个意义上讲，这个序列化形式是正确的。但是，如果对象的约束关系要依赖于实现的具体细节，对于它们来说，情况就不是这样了。\n例如，考虑散列表的情形。它的物理表示法是一系列包含”键－值”(key-value)项的散列桶。到底一个项将被放在哪个桶中，这是该键的散列码的一个函数，一般情况下，不同的 JVM实现不保证会有同样的结果。实际上，即使在同一个JVM 实现中，也无法保证每次运行都会一样。因此，对于散列表而言，接受默认的序列化形式将会构成一个严重的Bug。对散列表对象进行序列化和反序列化操作所产生的对象，其约束关系会遭到严重的破坏。\n无论你是否使用默认的序列化形式，当defaultWriteObject方法被调用的时候，每一个未被标记为transient 的实例域都会被序列化。因此，每一个可以被标记为transient的实例域都应该做上这样的标记。这包括那些冗余的域，即它们的值可以根据其他”基本数据域”计算而得到的域，比如缓存起来的散列值。它也包括那些”其值依赖于 JVM 的某一次运行”的域，比如一个1ong 域代表了一个指向本地数据结构的指针。在决定将一个域做成非瞬时的之前，请一定要确信它的值将是该对象逻辑状态的一部分。如果你正在使用一种自定义的序列化形式，大多数实例域，或者所有的实例域都应该被标记为transient，就像上述例子中的 StringList那样。\n如果你正在使用默认的序列化形式，并且把一个或者多个域标记为transient，则要记住，当一个实例被反序列化的时候，这些域将被初始化为它们的默认值(defaultvalue)：对于对象引用域，默认值为 null;对于数值基本域，默认值为0;对于boolean 域，默认值为 false[JLS,4.12.5]。如果这些值不能被任何 transient 域所接受，你就必须提供一个readObject 方法，它首先调用 defaultReadobject，然后把这些 transient 域恢复为可被初始化(详见第83条)。\n无论你是否使用默认的序列化形式，如果在读取整个对象状态的任何其他方法上强制任何同步，则也必须在对象序列化上强制这种同步。因此，如果你有一个线程安全的对象(详见第82条)，它通过同步每个方法实现了它的线程安全，并且你选择使用默认的序列化形式，就要使用下列的 writeObject 方法:\n//writeObjectforsynchronizedclasswithdefaultserialized formprivate synchronized void writeObject(ObjectOutputStream s)throws IoException&#123;s.defaultWriteObjectO;子\n\n如果把同步放在 writeObject方法中，就必须确保它遵守与其他动作相同的锁排[Goetz06, 10.1.5]。\n不管你选择了哪种序列化形式，都要为自己编写的每个可序列化的类声明一个显式的这样做也会带来小小的性能好处。如果没有提供显式的序列版本UID，就需要在运行时通过一个高开销的计算过程来产生一个序列版本UID。\n要声明一个序列版本UID非常简单，只要在你的类中增加下面这行代码：\nprivate static final long serialVersionUID &#x3D; randomLongValue;\n在编写新的类时，为randomLongValue选择什么值并不重要。通过在该类上运行serialver工具，你就可以得到一个这样的值，你也可以凭空编造一个数值。如果你想修改一个没有序列版本UID的现有的类，并希望新的版本能够接受现有的序列化实例，就必须使用那个自动为旧版本生成的值。通过在旧版的类上运行 serialver 工具，可以得到这个数值(被序列化的实例为之存在的那个数值)。\n如果你想为一个类生成一个新的版本，这个类与现有的类不兼容，那么你只需修改序列版本UID声明中的值即可。前一版本的实例经序列化之后，再做反序列化时会引发InvalidClassException 异常而失败。不要修改序列版本 UiD，否则将会破坏类现有的已被序列化实例的兼容性。\n总而言之，当你决定要将一个类做成可序列化的时候(详见第 86 条)，请仔细考虑应该采用什么样的序列化形式。只有当默认的序列化形式能够合理地描述对象的逻辑状态时，才能使用默认的序列化形式;否则就要设计一个自定义的序列化形式，通过它合理地描述对象的状态。你应该分配足够多的时间来设计类的序列化形式，就好像分配足够多的时间来设计它的导出方法一样(详见第51条)。正如你无法在将来的版本中去掉导出方法一样，你也不能去掉序列化形式中的域;它们必须被永久地保留下去，以确保序列化兼容性。选择错误的序列化形式对于一个类的复杂性和性能都会有永久的负面影响。\n第88条：保护性地编写readObject方法第 50 条介绍了一个不可变的日期范围类，它包含可变的私有 Date 域。该类通过在其构造器和访问方法(accessor)中保护性地拷贝 Date对象，极力地维护其约束条件和不可变性。该类如下代码所示:\n// Immutable class that uses defensive copyingpublic final class Period &#123;private final Date start;private final Date end;*** @param start the beginning of the period* @param end the end of the period; must not precede start* @throws IllegalArgumentException if start is after end* @throws NullPointerException if start or end is null*/public Period(Date start，Date end) &#123;this.start = new Date(start.getTime());this.end  = new Date(end.getTime());if (this.start.compareTo(this.end) &gt; 0)throw new IllegalArgumentException(start + &quot; after &quot; + end);public Date start () &#123; return new Date(start.getTime();&#125;public Date end () &#123; return new Date(end.getTime();&#125;public String toString() &#123; return start + &quot;-&quot;+ end; &#125;..// Remainder omitted\n\n假设决定要把这个类做成可序列化的。因为 Period 对象的物理表示法正好反映了它的逻辑数据内容，所以，使用默认的序列化形式并没有什么不合理的(详见第87条)。因此,为了使这个类成为可序列化的，似乎你所需要做的也就是在类的声明中增加 implementsSerializable 字样。然而，如果你真的这样做，那么这个类将不再保证它的关键约束了。\n问题在于，readobject方法实际上相当于另一个公有的构造器，如同其他的构造器一样，它也要求警惕同样的所有注意事项。构造器必须检查其参数的有效性(详见第49条)，并且在必要的时候对参数进行保护性拷贝(详见第 50 条)，同样地，readObject 方法也需要这样做。如果 readobject 方法无法做到这两者之一，对于攻击者来说，要违反这个类的约束条件相对就比较简单了。\n不严格地说，readobject方法是一个”用字节流作为唯一参数”的构造器。在正常使用的情况下，对一个正常构造的实例进行序列化可以产生字节流。但是，当面对一个人工仿造的字节流时，readobject 产生的对象会违反它所属的类的约束条件，这时问题就产生了。这种字节流可以用来创建一个不可能的对象(impossible object)，这是利用普通的构造器无法创建的。\n假设我们仅仅在 Period类的声明中加上了 implements Serializable字样。那么这个不完整的程序将产生一个 Period 实例，它的结束时间比起始时间还要早。对于高阶位 byte 值设置的转换，是因为 Java 缺乏 byte 字面量，并且不幸地决定给 byte 类型做标签，这两个因素联合产生的后果：\n//Bytestreamcouldn&#x27;thavecomefromarealPeriodinstance！private static final byte[] serializedForm=&#123;(byte)0xac，(byte)0xed，0x00，0x05，0x73，0x72，0x00，0x06,0x50，0x65，0x72，0x69，0x6f，0x64，0x40，0x7e，(byte)0xf8,0x2b，0x4f，0x46，(byte)0xc0，(byte)0xf4，0x02，0x00，0x02,0x4c， 0x00， 0x03， 0x65，0x6e， 0x64，0x74，0x00, 0x10，0x4c,0x6a，0x61，@ 0x76，0x61，0x2f， 0x75，0×74，0x69， 0x6c， 0x2f,0x44， 0x61， 0×74， 0x65，0x3b， 0x4c，0x00, 0x05， 0×73， 0x74,0x61,0x72，@ 0×74， 0x71，0x00， 0x7e，0x00， 0x01, ，0x78，0x70，0x73， 0x72， 0x00, 0x0e， 0x6a， 0x61, 0x76， 0x61, 0x2e，0x75,0x74，0x69, 0x6c, 0x2e，0x44， 0x61， 0×74， 0x65， ，0x68，0x6a,(byte)0x81, 0x01, 0x4b，0x59， 0x74，0x19, ，0x03，0x00，0x00,0x78，0x70, 0×77， 0x08， 0x00， 0x00，0x00，0x66，( (byte)oxdf,0x6e， 0xle, 0x00, 0×78， 0×73， 0x71，0x00，0x7e，0x00，0x03，0x77，0x08，0x00，0x00，0x00，(byte)0xd5，0x17，0x69，0x22,0x00，0x78;public static void main(String[] args)&#123;Period p=(Period) deserialize(serializedForm);System.out.println(p);//Returns the object with the specified serialized formstatic Object deserialize(byte[]sf)&#123;try&#123;return new ObjectInputStream(new ByteArrayInputStream(sf)).readObject(;&#125;catch (IOException | ClassNotFoundException e)&#123;throw new IllegalArgumentException(e);\n\n被用来初始化 serializedForm 的byte 数组常量是这样产生的：首先对一个正常的Period 实例进行序列化，然后对得到的字节流进行手工编辑。对于这个例子而言，字节流的细节并不重要，但是如果你很好奇，可以在《JavaObjectSerializationSpecification》[Serialization,6]中查到有关序列化字节流格式的描述信息。如果运行这个程序，它会打印出”Fri Jan 01 12:00:00 PST 1999 - Sun Jan 01 12:00:00 PST 1984”。只要把 Period声明成可序列化的，就会使我们创建出违反其类约束条件的对象。\n为了修正这个问题，可以为 Period提供一个readobject方法，该方法首先调用defaultReadObject，然后检查被反序列化之后的对象的有效性。如果有效性检查失败，readobject方法就抛出一个InvalidobjectException异常，使反序列化过程不能成功地完成：\n//readobjectmethod withvalidity checking-insufficient！private void readObject(ObjectInputStream s)throws IoException,ClassNotFoundException &#123;s.defaultReadObject();// Check that our invariants are satisfiedif (start.compareTo(end) &gt;0)throw new InvalidobjectException(start +&quot;after &quot;+ end);\n\n尽管这样的修正避免了攻击者创建无效的Period实例，但是，这里仍然隐藏着一个更为微妙的问题。通过伪造字节流，要想创建可变的 Period 实例仍是有可能的，做法是:的两个私有的 Date 域。攻击者从 ObjectInputStream 中读取 Period 实例，然后读取附加在其后面的”恶意编制的对象引用”。这些对象引l用使得攻击者能够访问到Period对象内部的私有 Date 域所引l用的对象。通过改变这些 Date 实例，攻击者可以改变 Period实例。下面的类演示了这种攻击：\npublic class MutablePeriod &#123;//A period instancepublic final Period period;// period&#x27;s start field, to which we shouldn&#x27;t have accesspublic final Date start;//period&#x27;s end field,to whichwe shouldn&#x27;t have accesspublic final Date end;public MutablePeriod()&#123;try&#123;ByteArrayOutputStream bos =new ByteArrayOutputStream();ObjectOutputStream out=new ObjectOutputStream(bos);//Serializeavalid Period instanceout.writeObject(new Period(new Date(), new Date());**Append rogue&quot;previous object refs&quot;for internal*Date fields in Period.For details，see &quot;Java*Object Serialization Specification,&quot;S Section 6.4.byte[] ref =&#123;0x71，0，0x7e，0，5&#125;;// Ref #5bos.write(ref);// The start fieldref[4]=4; Ref #4bos.write(ref); // The end field// Deserialize Period and &quot;stolen&quot;Date referencesObjectInputStream in = new ObjectInputStream(new ByteArrayInputStream(bos.toByteArrayO));period =(Period) in.readobject(;start = (Date) in.readObject(;end = (Date) in.readObject();catch (IOException I ClassNotFoundException e)&#123;throw new AssertionError(e);\n\n要查看正在进行的攻击，请运行以下程序：\npublic static void main(String[]args)&#123;MutablePeriod mp = new MutablePeriod(;Period p = mp.period;Date pEnd = mp.end;//Let&#x27;s turn back the clockpEnd.setYear(78);System.out.println(p);// Bring backthe 60s!pEnd.setYear(69);System.out.println(p) ;\n在我这里的机器上，运行这个程序，产生的输出结果如下：\nWed Nov 2200:21:29PST2017-WedNov 22 00:21:29PST 1978Wed Nov 22 00:21:29 PST 2017 - Sat Nov 22 00:21:29 PST 1969\n\n虽然 Period实例被创建之后，它的约束条件没有被破坏，但是要随意地修改它的内部组件仍然是有可能的。一旦攻击者获得了一个可变的 Period实例，就可以将这个实例传递给一个”安全性依赖于 Period 的不可变性”的类，从而造成更大的危害。这种推断并不牵强：实际上，有许多类的安全性就是依赖于 String 的不可变性。\n问题的根源在于，Period 的 readObject 方法并没有完成足够的保护性拷贝。当一个对象被反序列化的时候，对于客户端不应该拥有的对象引用，如果哪个域包含了这样的对象引用，就必须要做保护性拷贝，这是非常重要的。因此，对于每个可序列化的不可变类，如果它包含了私有的可变组件，那么在它的 readobject 方法中，必须要对这些组件进行保护性拷贝。下面的 readobject 方法可以确保 Period 类的约束条件不会遭到破坏，以保持它的不可变性：\n//readobject methodwithdefensivecopyingandvaliditycheckingprivate void readobject(ObjectInputStream s)throws IoException,ClassNotFoundException &#123;s.defaultReadObject();// Defensively copy ourmutablecomponentsstart = new Date(start.getTimeO);end = new Date(end.getTime());//Check that our invariants aresatisfiedif (start.compareTo(end) &gt;0)throw new InvalidobjectException(start +&quot; after &quot;+ end);\n注意，保护性拷贝是在有效性检查之前进行的，而且我们没有使用 Date 的clone 方法来执行保护性拷贝。这两个细节对于保护Period类免受攻击是必要的(详见第50条)。同时也要注意到，对于 final域，保护性拷贝是不可能的。为了使用 readObject 方法，我们必须要将 start 和 énd 域做成非 final 的。这是很遗憾的，但是这还算是相对比较好的做法。有了这个新的 readobject方法，并去掉了 start 和 end 域的 final 修饰符之后，MutablePeriod 类将不再有效。此时，上面的攻击程序会产生如下输出:\nWed Nov2200:23:41PST2017-WedNov2200:23:41PST2017WedNov2200:23:41PST2017-WedNov2200:23:41PST2017\n有一个简单的”石蕊”测试，可以用来确定默认的readobject方法是否可以被接受。测试方法：增加一个公有的构造器，其参数对应于该对象中每个非瞬时的域，并且无论参数的值是什么，都是不进行检查就可以保存到相应的域中的。对于这样的做法，你是否会感到很舒适？如果你对这个问题的回答是否定的，就必须提供一个显式的 readobject方法，并且它必须执行构造器所要求的所有有效性检查和保护性拷贝。另一种方法是，可以使用序列化代理模式(serialization proxy pattern)，详见第 90条。强烈建议使用这个模式，因为它分担了安全反序列化的部分工作。\n对于非 final的可序列化的类，在 readobject方法和构造器之间还有其他类似的地方。与构造器一样，readobject方法不可以调用可被覆盖的方法，无论是直接调用还是间接调用都不可以(详见第19条)。如果违反了这条规则，并且覆盖了该方法，被覆盖的方法将在子类的状态被反序列化之前先运行。程序很可能会失败[Bloch05，Puzzle 91]。\n总而言之，在编写 readObject 方法的时候，都要这样想：你正在编写一个公有的构造器，无论给它传递什么样的字节流，它都必须产生一个有效的实例。不要假设这个字节流一定代表着一个真正被序列化过的实例。虽然在本条目的例子中，类使用了默认的序列化形式，但是，所有讨论到的有可能发生的问题也同样适用于使用自定义序列化形式的类。下面以摘要的形式给出一些指导方针，有助于编写出更加健壮的 readobject方法：\n口对于对象引用域必须保持为私有的类，要保护性地拷贝这些域中的每个对象。不可变类的可变组件就属于这一类别。对于任何约束条件，如果检查失败，则抛出一个 InvalidObjectException 异常。这些检查动作应该跟在所有的保护性拷贝之后。口如果整个对象图在被反序列化之后必须进行验证，就应该使用 ObjectInputVali-dation 接口(本书没有讨论)。口无论是直接方式还是间接方式，都不要调用类中任何可被覆盖的方法。\n第89条：对于实例控制，枚举类型优先于readResolve第3 条讲述了Singleton(单例)模式，并且给出了以下这个 Singleton 类的示例。这个类限制了对其构造器的访问，以确保永远只创建一个实例：\npublic class Elvis&#123;public static final Elvis INSTANCE = new ElvisO);private ElvisO&#123;...&#125;public void leaveTheBuildingO &#123; ... &#125;子\n\n正如在第3条中提到的，如果这个类的声明中加上了 implements Serializable的字样，它就不再是一个单例。无论该类使用了默认的序列化形式，还是自定义的序列化形式(详见第 87条)，都没有关系;也跟它是否提供了显式的 readObject方法(见详第 88条)无关。任何一个 readObject 方法，不管是显式的还是默认的，都会返回一个新建的实例，这个新建的实例不同于该类初始化时创建的实例。\nreadResolve 特性允许你用 readObject 创建的实例代替另一个实例[Serialization,3.7]。对于一个正在被反序列化的对象，如果它的类定义了一个readResolve 方法，并且具备正确的声明，那么在反序列化之后，新建对象上的 readResolve 方法就会被调用。然后，该方法返回的对象引用将被返回，取代新建的对象。在这个特性的绝大多数用法中，指向新建对象的引用不需要再被保留，因此立即成为垃圾回收的对象。\n如果 Elvis 类要实现 Serializable 接口，下面的 readResolve 方法就足以保证它的单例属性：\n//readResolveforinstancecontrol-youcandobetter！private Object readResolve() &#123;//Returntheonetrue Elvis andlet the garbagecollector// take care of the Elvis impersonator.return INSTANCE;子\n\n该方法忽略了被反序列化的对象，只返回该类初始化时创建的那个特殊的Elvis 实例。因此，Elvis 实例的序列化形式并不需要包含任何实际的数据;所有的实例域都应该被声明为瞬时的。事实上，如果依赖readResolve 进行实例控制，带有对象引用类型的所有实例域则都必须声明为transient。否则，那种破釜沉舟式的攻击者，就有可能在readResolve 方法被运行之前，保护指向反序列化对象的引用，采用的方法类似于在第88条中提到过的 MutablePeriod 攻击。\n这种攻击有点复杂，但是背后的思想却很简单。如果单例包含一个非瞬时的对象引用域，这个域的内容就可以在单例的 readResolve 方法运行之前被反序列化。当对象引用域的内容被反序列化时，它就允许一个精心制作的流”盗用”指向最初被反序列化的单例的引用。\n以下是它更详细的工作原理。首先，编写一个”盗用者”类，它既有readResolver含”盗用者”类，”盗用者”类则引用这个单例。\n由于单例包含”盗用者”类，当这个单例被反序列化时，”盗用者”类的readResolve方法先运行。因此，当”盗用者”的 readResolve 方法运行时，它的实例域仍然引用被部分反序列化(并且也还没有被解析)的 Singleton。\n“盗用者”的readResolve 方法从它的实例域中将引l用复制到静态域中，以便该引l用可以在 readResolve 方法运行之后被访问到。然后这个方法为它所藏身的那个域返回一个正确的类型值。如果没有这么做，当序列化系统试着将”盗用者”引用保存到这个域中时，虚拟机就会抛出 ClassCastException。\n为了更具体地说明这一点，我们以下面这个有问题的单例为例：\n// Broken singleton - has nontransient object reference field!public class Elvis implements Serializable &#123;public static final Elvis INSTANCE = new ElvisO);private Elvis() &#123;&#125;private String[] favoriteSongs =&#123;&quot;Hound Dog&quot;，&quot;Heartbreak Hotel&quot;&#125;;public void printFavorites( &#123;System.out.println(Arrays.toString(favoriteSongs));private Object readResolve() &#123;return INSTANCE;\n\n如下”盗用者”类，是根据上述的描述构造的:\npublic class ElvisStealer implements Serializable&#123;static Elvis impersonator;private Elvis payload;private Object readResolve() &#123;//Saveareference tothe&quot;unresolved&quot;Elvis instanceimpersonator = payload;//Return object of correct type for favoriteSongs fieldreturn new String[] &#123;&quot;A Fool Such as I&quot;&#125;;private static final long serialVersionUID=0;\n下面是一个不完整的程序，它反序列化一个手工制作的流，为那个有缺陷的单例产生两个截然不同的实例。这个程序中省略了反序列化方法，因为它与第88条中的一样：\npublic class ElvisImpersonator &#123;//Bytestreamcouldn&#x27;t havecome from arealElvisinstance！private static final byte[] serializedForm = &#123;(byte)oxac, (byte)0xed，0x00，0x05，0x73，0x72，0x00，0x05,0x45，0x6c， 0x76，0x69， 0×73， (byte)0x84, (byte)0xe6,(byte)0x93, 0x33， (byte)0xc3, (byte)0xf4, (byte)0x8b,0x32， 0x02， 0x00, 0x01, 0x4c, 0x00， Ox0d, 0x66， 0x61， 0x76，0x6f, 0x72， 0x69, 0×74， 0x65， 0x53, 0x6f， 0x6e, 0x67， 0x73,0x74，0x00, 0x12， 0x4c, 0x6a, 0x61, 0x76， 0x61, 0x2f， 0x6c,0x61, 0x6e， 0x67, 0x2f, 0x4f, 0x62， 0x6a, 0x65， 0x63， 0x74，0x3b, 0x78， 0×70， 0×73， 0×72， 0x00, OxOc, 0x45, 0x6c, 0x76,0x69, 0×73， 0x53， 0x74， 0x65， 0x61， 0x6c, 0x65， 0×72， 0x00,0x00, 0x00， 0x00， 0x00， 0x00， 0x00, 0x00, 0x02, 0×00， 0x01,0x4c，0x00, 0x07， 0x70， 0x61， 0x79， 0x6c， 0x6f, 0x61， 0x64,0x74; 0x00， 0×07，0x4c, 0x45，0x6c，0x76， 0x69，0x73，0x3b，0x78，0x70，0x71，0x00，0x7e，0x00，0x02public static void main(String[] args)&#123;// Initializes ElvisStealer.impersonator and returns//the real Elvis (which is Elvis.INSTANCE)Elvis elvis =(Elvis) deserialize(serializedForm);Elvis impersonator = ElvisStealer.impersonator;elvis.printFavorites(;impersonator.printFavorites(;了\n运行这个程序会产生如下输出，最终证明可以创建两个截然不同的Elvis 实例(包含两种不同的音乐品位):\n# [Hound Dog, Heartbreak Hotel][A Fool Such as I]\n\n通过将favoriteSongs 域声明为transient，可以修正这个问题，但是最好把Elvis 做成是一个单元素的枚举类型(详见第3条)。就如 ElvisStealer攻击所示范的，用readResolve方法防止”临时”被反序列化的实例受到攻击者的访问，这种方法很脆弱，需要万分谨慎。\n如果将一个可序列化的实例受控的类编写成枚举，Java 就可以绝对保证除了所声明的常量之外，不会有其他实例，除非攻击者恶意地使用了享受特权的方法，如Accessible-Object.setAccessible。能够做到这一点的任何一位攻击者，已经具备了足够的特权来执行任意的本地代码，后果不堪设想。将 Elvis 写成枚举的例子如下所示:\n&#x2F;&#x2F; Enum singleton - the preferred approachpublic enum Elvis {INSTANCE;private String[] favoriteSongs &#x3D;{“Hound Dog”，”Heartbreak Hotel”};public void printFavoritesO {System.out.println(Arrays.toString(favoriteSongs));\n用readResolve 进行实例控制并不过时。如果必须编写可序列化的实例受控的类，在编译时还不知道它的实例，你就无法将类表示成一个枚举类型。\nreadResolve 的可访问性(accessibility)很重要。如果把readResolve方法放在一个final类上，它就应该是私有的。如果把 readResolver方法放在一个非 final类上，就必须认真考虑它的可访问性。如果它是私有的，就不适用于任何子类。如果它是包级私有的，就只适用于同一个包中的子类。如果它是受保护的或者公有的，就适用于所有没有覆盖它的子类。如果 readResolve 方法是受保护的或者是公有的，并且子类没有覆盖它，对序列化过的子类实例进行反序列化，就会产生一个超类实例，这样有可能导致ClassCastException 异常。\n总而言之，应该尽可能地使用枚举类型来实施实例控制的约束条件。如果做不到，同时又需要一个既可序列化又是实例受控的类，就必须提供一个 readResolver 方法，并确保该类的所有实例域都为基本类型，或者是瞬时的。\n第90条：考虑用序列化代理代替序列化实例正如第 85 条和第 86 条中提到的，以及本章一直在讨论的，决定实现 Serializable接口，会增加出错和出现安全问题的可能性，因为它允许利用语言之外的机制来创建实例，而不是用普通的构造器。然而，有一种方法可以极大地减少这些风险。这种方法就是序列化代理模式(serialization proxy pattern)。\n序列化代理模式相当简单。首先，为可序列化的类设计一个私有的静态嵌套类，精确地表示外围类的实例的逻辑状态。这个嵌套类被称作序列化代理(serialization proxy)，它应该有一个单独的构造器，其参数类型就是那个外围类。这个构造器只从它的参数中复制数据：它不需要进行任何一致性检查或者保护性拷贝。从设计的角度来看，序列化代理的默认序列化形式是外围类最好的序列化形式。外围类及其序列代理都必须声明实现Serializable接口。\n例如，以第50条中编写的不可变的Period类为例，它在第88条中被做成可序列化的。以下是这个类的一个序列化代理。Period 类是如此简单，以致它的序列化代理有着与类完全相同的域：\n//SerializationproxyforPeriodclassprivate staticclass SerializationProxy implements Serializable&#123;private final Date start;private final Date end;SerializationProxy(Period p)&#123;this.start = p.start;this.end = p.end;子private static final long serialVersionUID =234098243823485285L; // Any number wi11 do (Item 87)\n\n接下来，将下面的 writeReplace 方法添加到外围类中。通过序列化代理，这个方法可以被逐字地复制到任何类中:\n//writeReplace method for the serialization proxy patternprivate Object writeReplace() &#123;return new SerializationProxy(this);&#125;\n的实例。换句话说，writeReplace 方法在序列化之前，将外围类的实例转变成了它的序列化代理。\n有了 writeReplace 方法之后，序列化系统永远不会产生外围类的序列化实例，但是攻击者有可能伪造，企图违反该类的约束条件。为了防御此类攻击，只要在外围类中添加如下 readobject 方法即可:\n//readobject method for the serialization proxy patternprivate void readobject(ObjectInputStream stream)throws InvalidobjectException &#123;throw new InvalidobjectException(&quot;Proxy required&quot;);\n\n最后，在 SerializationProxy类中提供一个 readResolve 方法，它返回一个逻辑上相当的外围类的实例。这个方法的出现，导致序列化系统在反序列化时将序列化代理转变回外围类的实例。\n这个 readResolve 方法仅仅利用它的公有 API 创建外围类的一个实例，这正是该模式的魅力所在。它极大地消除了序列化机制中语言本身之外的特征，因为反序列化实例是利用与任何其他实例相同的构造器、静态工厂和方法而创建的。这样你就不必单独确保被反序列化的实例一定要遵守类的约束条件。如果该类的静态工厂或者构造器建立了这些约束条件，并且它的实例方法在维持着这些约束条件，你就可以确信序列化也会维持这些约束条件。\n以下是上述 Period.SerializationProxy 的 readResolve 方法:\n//readResolve method for Period.SerializationProxyprivate Object readResolve() &#123;return new Period(start，end);// Uses public constructon了\n正如保护性拷贝方法一样(详见第88条)，序列化代理方法可以阻止伪字节流的攻击(详见第88条)以及内部域的盗用攻击(详见第88条)。与前两种方法不同，这种方法允许 Period 类的域为 final 的，为了确保 Period类真正是不可变的(详见第17条)，这一点很有必要。与前两种方法不同的还有，这种方法不需要太费心思。你不必知道哪些域可能受到狡猾的序列化攻击的威胁，你也不必显式地执行有效性检查，作为反序列化的一部分。\n还有另外一种方法，使用这种方法时，序列化代理模式的功能比保护性拷贝的更加强大。序列化代理模式允许反序列化实例有着与原始序列化实例不同的类。你可能认为这在实际应用中没有什么作用，其实不然。\n以EnumSet的情况为例(详见第36条)。这个类没有公有的构造器，只有静态工厂。从客户端的角度来看，它们返回 EnumSet 实例，但是在目前的OpenJDK实现中，它们是返回两种子类之一，具体取决于底层枚举类型的大小。如果底层的枚举类型有64个一一JumboEnumSet.\n现在考虑这种情况：如果序列化一个枚举集合，它的枚举类型有60个元素，然后给这个枚举类型再增加5个元素，之后反序列化这个枚举集合。当它被序列化的时候，是一个RegularEnumSet实例，但是一旦它被反序列化，它最好是一个JumboEnumSet实例。实际发生的情况正是如此，因为 EnumSet使用序列化代理模式。如果你有兴趣，可以看看如下的EnumSet序列化代理，它实际上就这么简单:\n//EnumSet&#x27;s serializationproxyprivate static class SerializationProxy &lt;E extends Enum&lt;E&gt;&gt;implements Serializable &#123;// The element type ofthis enum set.private final Class&lt;E&gt; elementType;// The elements contained in this enum set.private final Enum&lt;?&gt;[] elements;SerializationProxy(EnumSet&lt;E&gt; set) &#123;elementType = set.elementType;elements = set.toArray(new Enum&lt;?&gt;[0]);private Object readResolve()&#123;EnumSet&lt;E&gt; result = EnumSet.noneOf(elementType);for (Enum&lt;?&gt; e : elements)result.add((E)e);return result;\n序列化代理模式有两个局限性。它不能与可以被客户端扩展的类相兼容(详见第19条)。它也不能与对象图中包含循环的某些类相兼容：如果你企图从一个对象的序列化代理的readResolve方法内部调用这个对象中的方法，就会得到一个ClassCast-Exception异常，因为你还没有这个对象，只有它的序列化代理。\n最后一点，序列化代理模式所增强的功能和安全性并不是没有代价的。在我的机器上，加了14%\n总而言之，当你发现自己必须在一个不能被客户端扩展的类上编写readobject或者writeObject方法时，就应该考虑使用序列化代理模式。要想稳健地将带有重要约束条件的对象序列化时，这种模式可能是最容易的方法。\n与第2版中条目的对应关系\n\n\n参考文献[Asserts] Programming with Assertions. 2002. Sun Microsystems.http://docs.oracle.com/javase/8/docs/technotes/guides/language &#x2F;assert.html\n[Beck04]  Beck, Kent. 2004. JUnit Pocket Guide. Sebastopol, CA: O’ReillyMedia, Inc. ISBN: 0596007434.\n[Bloch01] Bloch, Joshua. 2001. Effective Java Programming LanguageGuide. Boston: Addison-Wesley. ISBN: 0201310058.\n[Bloch05] Bloch, Joshua, and Neal Gafter. 2005. Java Puzzlers: Traps,Pitfalls, and Corner Cases. Boston: Addison-Wesley.ISBN: 032133678X.\n[Blum14] Blum, Scott. 2014. “Faster RSA in Java with GMP? The SquareCorner (blog). Feb. 14, 2014. https://medium.com/square-corner-blog/faster-rsa-in-java-with-gmp-8b13c51c6ec4\n[Bracha04]  Bracha, Gilad. 2004.”Lesson: Generics”” online supplement to TheJava Tutorial: A Short Course on the Basics, 6th ed. Upper SaddleRiver, NJ: Addison-Wesley, 2014. https://docs.oracle.com/javase/tutorial/extra/generics/\n[Burn01] Burn, Oliver. 2001-2017. Checkstyle.http:&#x2F;checkstyle.sourceforge.net\n[Coekaerts 15]  Coekaerts, Wouter (@WouterCoekaerts). 2015. “Billion-laughs-style DoS for Java serialization https://gist.github.com/coekie/a27cc406fc9f3dc7a70d … WONTFIX, Twitter, November 9,2015, 9:46 a.m. https://twitter.com/woutercoekaerts/status/663774695381078016\n[CompSci17]   Brief of Computer Scientists as Amici Curiae for the United StatesCourt of Appeals for the Federal Circuit, Case No. 17-1118, OracleAmerica, Inc. v. Google, Inc. in Support of Defendant-Appellee.(2017)\n[Dagger] Dagger. 2013. Square, Inc. http://square.github.io/dagger/[Guava] Guava. 2017. Google Inc. https://github.com/google/guava[Guice] Guice. 2006. Google Inc. https://github.com/google/guice[Javadoc-ref]  Javadoc Reference Guide. 2014-2017. Oracle.\n[Gallagher16]  Gallagher, Sean. 2016. “Muni system hacker hit others by scanningfor year-old Java vulnerability. Ars Technica, November 29, 2016.https://arstechnica.com/information-technology/2016/11/san-francisco-transit-ransomware-attacker-likely-used-year-old-java-exploit/\n[Gamma95] Gamma, Erich, Richard Helm, Ralph Johnson, and John Vlissides.1995. Design Patterns: Elements of Reusable Object-OrientedSoftware. Reading, MA: Addison-Wesley. ISBN: 0201633612.\n[Goetz06] Goetz, Brian. 2006. Java Concurrency in Practice. With TimPeierls, Joshua Bloch, Joseph Bowbeer, David Holmes, and DougLea. Boston: Addison-Wesley. ISBN: 0321349601.\n[Gosling97] Gosling, James. 1997. “The Feel of Java.’ Computer 30 no. 6 (June1997): 53-57. http://dx.doi.org/10.1109/2.587548\n[Herlihy12] Herlihy, Maurice, and Nir Shavit. 2012. The Art of MultiprocessorProgramming, Revised Reprint. Waltham, MA: Morgan KaufmannPublishers. ISBN: 0123973376.\n[Jackson75]  Jackson, M. A. 1975. Principles of Program Design. London:Academic Press. ISBN: 0123790506.\n[Java-secure] Secure Coding Guidelines for Java SE. 2017. Oracle. http://www.oracle.com/technetwork/java/seccodeguide-139067.html[Java8-feat] What’s New in JDK 8. 2014. Oracle. http://www.oracle.com &#x2F;technetwork&#x2F;java&#x2F;javase&#x2F;8-whats-new-2157071.html\n[Java9-feat] Java Platform, Standard Edition What’s New in Oracle JDK 9.2017. Oracle. https://docs.oracle.com/javase/9/whatsnew/toc.htm[Java9-api] Java Platform, Standard Edition &amp; Java Development Kit Version9 API Specification. 2017. Oracle. https://docs.oracle.com &#x2F;javase&#x2F;9&#x2F;docs&#x2F;api&#x2F;overview-summary.html\n[Javadoc-guide] How to Write Doc Comments for the Javadoc Tool. 2000-2004Sun Microsystems. http://www.oracle.com/technetwork/java/javase/documentation/index-137868.html\n\nhttps://docs.oracle.com/javase/9/javadoc/javadoc.htm[JLS] Gosling, James, Bill Joy, Guy Steele, and Gilad Bracha. 2014. TheJava Language Specification, Java SE 8 Edition. Boston: Addison-Wesley. ISBN: 013390069X.[JMH] Code Tools: jmh. 2014. Oracle.http://openjdk.java.net/projects/code-tools/jmh/[JSON]  Introducing JSON. 2013. Ecma International. https://www.json.org[Kahan91]  Kahan, William, and J. W. Thomas. 1991. Augmenting aProgramming Language with Complex Arithmetic.UCB&#x2F;CSD-91-667, University of California, Berkeley.[Knuth74] Knuth, Donald. 1974. Structured Programming with go toStatements. In Computing Surveys 6: 261-301.[Lea14] Lea, Doug. 2014. When to use parallel streams.http://gee.cs.oswego.edu/dl/html/StreamParallelGuidance.html[Lieberman86]  Lieberman, Henry. 1986. Using Prototypical Objects to ImplementShared Behavior in Object-Oriented Systems. In Proceedings ofthe First ACM Conference on Object-Oriented ProgrammingSystems, Languages, and Applications, pages 214223, Portland,September 1986. ACM Press.[Liskov87] Liskov, B. 1988. Data Abstraction and Hierarchy. In Addendum tothe Proceedings of OOPSLA ‘87 and SIGPLAN Notices, Vol. 23,No. 5: 17-34, May 1988.[Naftalin07] Naftalin, Maurice, and Philip Wadler. 2007. Java Generics andCollections. Sebastopol, CA: O’Reilly Media, Inc.ISBN: 0596527756.[Parnas72] Parnas, D. L. 1972. On the Criteria to Be Used in DecomposingSystems into Modules. In Communications of the ACM 15: 1053-1058.[POSIX] 9945-1:1996 (ISO&#x2F;IEC) [IEEE&#x2F;ANSI Std. 1003.1 1995 Edition]Information Technology—-Portable Operating System Interface(POSIX)—Part 1: System Application: Program Interface (API) CLanguage] (ANSI), IEEE Standards Press, ISBN: 1559375736.[Protobuf] Protocol Buffers. 2017. Google Inc.https://developers.google.com/protocol-buffers[Schneider16] Schneider, Christian. 2016. SWAT (Serial Whitelist Application\n[Seacord17] Seacord, Robert. 2017. Combating Java DeserializationVulnerabilities with Look-Ahead Object Input Streams (LAOIS).San Francisco: NCC Group Whitepaper.https://www.nccgroup.trust/globalassets/our-research/us/whitepapers/2017/june/ncc_group_combating_java_deserialization.vulnerabilities_with_look-ahead_object_input_streams1.pdf\n[Serialization]   Java Object Serialization Specification. March 2005. SunMicrosystems. http://docs.oracle.com/javase/9/docs/specs &#x2F;serialization&#x2F;index.html\n[Sestoft16] Sestoft, Peter. 2016. Java Precisely, 3rd ed. Cambridge, MA: TheMIT Press. ISBN: 0262529076.\n[Shipilev16] Aleksey Shipilev. 2016. Arrays of Wisdom of the Ancients.https://shipilev.net/blog/2016/arrays-wisdom-ancients/\n[Smith62] Smith, Robert. 1962. Algorithm 116 Complex Division.In Communications of the ACM 5, no. 8 (August 1962): 435.[Snyder86]  Snyder, Alan. 1986. “Encapsulation and Inheritance in Object-Oriented Programming Languages.” In Object-OrientedProgramming Systems, Languages, and Applications ConferenceProceedings, 38-45. New York, NY: ACM Press.\n[Spring] Spring Framework. Pivotal Software, Inc. 2017.https://projects.spring.io/spring-framework/\n[Stroustrup] Stroustrup, Bjarne. [ca. 2000]. “Is Java the language you wouldhave designed if you didn’t have to be compatible with C? BjarneStroustrup’s FAQ. Updated Ocober 1, 2017.http://www.stroustrup.com/bs_faq.html#Java\n[Stroustrup95]  Stroustrup, Bjarne. 1995. “”Why C++ is not just an object-orientedprogramming language.” In Addendum to the proceedings of the10th annual conference on Object-oriented programming systems,languages, and applications, edited by Steven Craig Bilow andPatricia S. Bilow New York, NY: ACM.http://dx.doi.org/10.1145/260094.260207\n[Svoboda16] Svoboda, David. 2016. Exploiting Java Serialization for Fun andProfit. Software Engineering Institute, Carnegie Mellon University.https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=484347[Thomas94] Thomas, Jim, and Jerome T. Coonen. 1994. “Issues RegardingImaginary Types for C and C++.” In The Journal of C Language\nTranslation 5, no. 3 (March 1994): 134-138.\n[ThreadStop] Why Are Thread.stop, Thread.suspend, Thread. resume andRuntime.runFinalizers0nExit Deprecated? 1999. SunMicrosystems. https://docs.oracle.com/javase/8/docs/technotes/guides/concurrency/threadPrimitiveDeprecation.html\n[Viega01] Viega, John, and Gary McGraw. 2001. Building Secure Software:How to Avoid Security Problems the Right Way. Boston: Addison-Wesley. ISBN: 020172152X.\n[W3C-validator] W3C MarkupValidation Service. 2007. World Wide WebConsortium. http://validator.w3.org/\n[Wulf72] Wulf, W. A Case Against the GOTO. 1972. In Proceedings of the25th ACM National Conference 2: 791-797. New York, NY: ACMPress.\n推荐阅读Effective系列\n\n\n\n\n\n\n作者简介JoshuaBloch美国卡内基-梅隆大学教授，曾是Google公司首席Java架构师、Sun公司杰出工程师和Transarc公司高级系统设计师。他带领团队设计和实现过无数的Java平台特性，包括JDK5.0语言增强版和获奖的JavaCollectionsFramework。他拥有哥伦比亚大学的计算机科学学士学位和卡内基-梅隆大学的计算机科学博士学位。他的著作还包括《JavaPuzzlers》和《Java并发编程实战》(曾获Jolt大奖提名)等。\n译者简介俞黎敏(YuLimin，网名：阿敏总司令)2008年7月加入IBM广州分公司，担任高级技术顾问，主要负责WebSphere系列产品以及云计算、物联网相关的技术支持工作，专注于产品新特性、系统性能调优、疑难问题诊断与解决。开源爱好者，曾参与Spring中文论坛组织的《Spring 2.0Reference》中文翻译的一审和二审，满江红开放技术研究组织启动的《Seam1.2.1Reference》的中文翻译，组织完成了《Seam 2.0Reference》的中文翻译工作。CSDN、CJSDN、Dev2Dev、Matrix、JavaWorldTW、Spring中文等Java论坛的版主，在各大技术社区为推动开源和敏捷开发做出了积极的贡献。翻译、审校过多本图书。\n个人网站:http://www.Java2Class.net博客 : http://blog.csdn.net/YuLimin/\nEffective Java本书第2版是在Java6发行之后不久出版的，此后Java又发生了巨大的变化。这本Jolt获奖作品现在已经针对Java7、8、9进行了全面的更新，充分展示了新的Java编程语言及其类库特性。当前的Java编程语言支持多种泛型，这使得Java程序员迫切需要具体的实践建议一—本书正是为此而生的。\n提出了具体的建议，揭示了Java平台的精妙之处，并更新了之前的代码范例。每个条目的综合描述和解释都阐明了应该怎么做，不应该怎么做，以及为什么。\n本书的内容涵盖了Java7、8和9中新增的语言及类库特性，包括在其面向对象根部添加的函数编程构造。书中\n本书新增内容包括：函数接口、Lambda表达式、方法引用，以及StreamAPI?接口中的缺省方法和静态方法①类型推导，包括泛型的Diamond操作符@SafeVarargs注解try-with-resources语句新增的类库特性，如Optional接口、java.time包，以及集合的便利工厂方法\n\n\nPearsonwww.pearson.com\n投稿热线：(010) 88379604客服热线：(010)88379426 88361066购书热线：(010) 68326294 88379649 68995259华章网站：www.hzbook.com网上购书：www.china-pub.com|数字阅读：www.hzmedia.com.cn\n","categories":["读书笔记"],"tags":["Java","Effective Java"]},{"title":"读《Effective Java》前六章","url":"/2021_12_01_effective_java/","content":"本书作者Joshua Bloch曾是Sun Microsystems的Java架构师,现在是Google的工程师。\n这是一本任何想要提高技能和编写更好代码的Java开发人员的必读之书。里面全是干货。\n“我很希望我10年前就能拥有这本书。有人可能认为我不需要任何Java方面的书籍,但是我需要这本书。”——Java之父James Gosling\n\n\n\n目录\n引言本书的目标是帮助读者更加有效地使用 Java 编程语言及其基本类库 java.lang、java.util和java.io,以及子包java.util.concurrent 和java.util.function 等。本书也会时不时地讨论到其他的类库。\n本书一共包含90个条目,每个条目讨论一条规则。这些规则反映了最有经验的优秀程序员在实践中常用的一些有益的做法。全书以一种比较松散的方式将这些条目组织成12章,每一章都涉及软件设计的一个主要方面。因此,并不一定需要按部就班地从头到尾阅读本书,因为每个条目都有一定程度的独立性。这些条目相互之间经常交叉引用,因此可以很容易地在书中找到自己需要的内容。\n自从本书上一个版本出版之后,Java平台中又增加了许多新特性。本书中大多数条目都以一定的方式用到了这些特性。下表列出了主要特性所在的主要章节或条目。\n\n大多数条目都通过程序示例进行了说明。本书一个突出的特点是,包含了许多用来说明设计模式(Design Pattern)和习惯用法(Idiom)的代码示例。当需要参考设计模式领域的标准参考书[Gamma 95]时,还为这些设计模式和习惯用法提供了交叉引用。\n许多条目都包含有一个或多个应该在实践中避免的程序示例。像这样的例子,有时候也叫作”反模式”(Antipattern),在注释中清楚地标注为”&#x2F;&#x2F;Never do this!”。对于每一种情况,条目中都解释了为什么此例不好,并提出了另外的解决方法。\n本书不是针对初学者的,而是假设读者已经熟悉Java 编程语言。如果你还不熟悉,请考虑先参阅一本好的 Java人门书籍,比如 Peter Sestoft 的《Java Precisely》[Sestoftl6]。本书适用于任何具有实际Java 工作经验的程序员,对于高级程序员,也应该能够提供一些发人深思的东西。\n本书中大多数规则都源于少数几条基本的原则。清晰性和简洁性最为重要：组件的用户永远也不应该被其行为所迷惑。组件要尽可能小,但又不能太小[本书中使用的术语”组件”(Component),是指任何可重用的软件元素,从单个方法,到包含多个包的复杂框架,都可以是一个组件]。代码应该被重用,而不是被拷贝。组件之间的依赖性应该尽可能地降到最小。错误应该尽早被检测出来,最好是在编译时就发现并解决。\n虽然本书中的规则不会百分之百地适用于任何时刻和任何场合,但是,它们确实体现了绝大多数情况下的最佳编程实践。你不应该盲目地遵循这些规则,但偶尔有了充分理由之后,可以去打破这些规则。同大多数学科一样,学习编程艺术首先要学会基本的规则,然后才能知道什么时候可以打破这些规则。\n本书大部分内容都不是讨论性能的,而是关心如何编写出清晰、正确、可用、健壮、灵活和可维护的程序来。如果你能够做到这一点,那么要想获得所需要的性能往往也就水到渠成了(详见第67条)。有些条目确实谈到了性能问题,甚至有的还提供了性能指标。但在提及这些指标的时候,会出现”在我的机器上”这样的话,所以应该把这些指标视同近似值。\n有必要提及的是,我的机器是一台过时的家用电脑,CPU是四核Intel Core i7-4770K,主频 3.5 GHz,内存 DDR3-1866 CL9 16G,在 Microsoft Windows 7 Professional SP1(64 位)操作系统平台上运行Azul公司发行的OpenJDK：Zulu9.0.0.15版本。\n讨论Java 编程语言及其类库特性的时候,有时候必须要指明具体的发行版本。为了简单起见,本书使用了平时大家惯用的昵称,而不是正式的发行名称。下表列出了发行名称与昵称之间的对应关系：\n\n尽管这些示例都很完整,但是它们注重可读性更甚于注重完整性。它们直接使用了java.util 和java.io包中的类。为了编译这些示例程序,可能需要在程序中加上一行这些示例。\n本书采用的大部分技术术语都与《The JavaLanguage Specification,Java SE8Edition》[JLS]相同。有一些术语则值得特别提及一下。Java 语言支持四种类型：接口(包括注释)类(包括 enum)、数组和基本类型。前三种类型通常被称为引l用类型(reference type),类实例和数组是对象(object),而基本类型的值则不是对象。类的成员(member)由它的域(field)、方法(method)、成员类(member class)和成员接口(member interface)组成。方法的签名(signature)由它的名称和所有参数类型组成；签名不包括方法的返回类型。\n本书也使用了一些与 《 Th巳 Java Language Specification 》 不同的术语。 例如,本书用术语”继承”(inheritance)作为”子类化”( subclassing)的同义词。 本书不再使用”接口继承” 这种说法,而是简单地说, 一个类实现(implement)了一个接口,或者一个接口扩展( extend )了另一个接口。 为了描述”在没有指定访问级别的情况下所使用的访问级别”,本书使用了传统的描述性术语”包级私有”(package-private),而不是技术性术语”包级访问”(package access)级别 [ JLS. 6.6. 1 ] 。\n本书也使用了一些在《The Java Language Specification》中没有定义的术语。术语”导出的API”(exported API),或者简单地说API,是指类、接口、构造器(constructor)、成员和序列化形式(serialized form),程序员通过它们可以访问类、接口或者包。(术语API是 Application Programming Interface 的简写,这里之所以使用API 而不用接口,是为了不与Java语言中的interface类型相混淆。)使用API编写程序的程序员被称为该API的用户(user),在类的实现中使用了 API 的类被称为该 API 的客户端(client)。\n类、接口、构造器、成员以及序列化形式被统称为 API 元素(API element)。API由所有可在定义该API的包之外访问的API元素组成。任何客户端都可以使用这些API元素,而 API 的创建者则负责支持这些 API元素。Javadoc 工具类在它的默认操作模式下也正是为这些元素生成文档,这绝非偶然。不严格地讲,一个包的导出API是由该包中的每个公有(public)类或者接口中所有公有的或者受保护的(protected)成员和构造器组成。\n在Java 9 中新增了模块系统(module system)。如果类库使用了模块系统,其 API 就是类库的模块声明导出的所有包的导出API组合。\n第二章 创建和销毁对象本章的主题是创建和销毁对象：何时以及如何创建对象,何时以及如何避免创建对象,如何确保它们能够适时地销毁,以及如何管理对象销毁之前必须进行的各种清理动作。\n第1条：用静态工厂方法代替构造器对于类而言,为了让客户端获取它自身的一个实例,最传统的方法就是提供一个公有的构造器。还有一种方法,也应该在每个程序员的工具箱中占有一席之地。类可以提供一个公有的静态工厂方法(static factory method),它只是一个返回类的实例的静态方法。下面是类型值转换成了一个Boolean对象引用：\npublic static Boolean valueOf(boolean b) &#123;    return b ? Boolean.TRUE : Boolean.FALSE;&#125;\n\n注意,静态工厂方法与设计模式[Gamma95]中的工厂方法(FactoryMethod)模式不同。本条目中所指的静态工厂方法并不直接对应于设计模式(Design Pattern)中的工厂方法。\n如果不通过公有的构造器,或者说除了公有的构造器之外,类还可以给它的客户端提供静态工厂方法。提供静态工厂方法而不是公有的构造器,这样做既有优势,也有劣势。\n静态工厂方法与构造器不同的第一大优势在于,它们有名称。如果构造器的参数本身没有确切地描述正被返回的对象,那么具有适当名称的静态工厂会更容易使用,产生的客户端代码也更易于阅读。例如,构造器BigInteger(int,int,Random)返回的BigInteger可能为素数,如果用名为 BigInteger.probablePrime 的静态工厂方法来表示,显然更为清楚。(Java 4版本中增加了这个方法。)\n一个类只能有一个带有指定签名的构造器。编程人员通常知道如何避开这一限制：通过提供两个构造器,它们的参数列表只在参数类型的顺序上有所不同。实际上这并不是个好主意。面对这样的API,用户永远也记不住该用哪个构造器,结果常常会调用错误的构造器。并且在读到使用了这些构造器的代码时,如果没有参考类的文档,往往不知所云。\n由于静态工厂方法有名称,所以它们不受上述限制。当一个类需要多个带有相同签名的构造器时,就用静态工厂方法代替构造器,并且仔细地选择名称以便突出静态工厂方法之间的区别。\n静态工厂方法与构造器不同的第二大优势在于,不必在每次调用它们的时候都创建一个新对象。这使得不可变类(详见第17条)可以使用预先构建好的实例,或者将构建好的实例缓存起来,进行重复利用,从而避免创建不必要的重复对象。Boolean.valueOf(boolean)方法说明了这项技术：它从来不创建对象。这种方法类似于享元(Flyweight)模式[Gamma95]。如果程序经常请求创建相同的对象,并且创建对象的代价很高,则这项技术可以极大地提升性能。\n静态工厂方法能够为重复的调用返回相同对象,这样有助于类总能严格控制在某个时刻哪些实例应该存在。这种类被称作实例受控的类(instance-controlled)。编写实例受控的类有几个原因。实例受控使得类可以确保它是一个Singleton(详见第3条)或者是不可实例实例,即当且仅当a&#x3D;&#x3D;b时,a.equals(b)才为true。这是享元模式[Gamma95]的基础。枚举(enum)类型(详见第 34条)保证了这一点。\n静态工厂方法与构造器不同的第三大优势在于,它们可以返回原返回类型的任何子类型的对象。这样我们在选择返回对象的类时就有了更大的灵活性。\n这种灵活性的一种应用是,API可以返回对象,同时又不会使对象的类变成公有的。以这种方式隐藏实现类会使 API变得非常简洁。这项技术适用于基于接口的框架(interface-based framework)(详见第 20条),因为在这种框架中,接口为静态工厂方法提供了自然返回类型。\n在 Java 8 之前,接口不能有静态方法,因此按照惯例,接口 Type 的静态工厂方法被放在一个名为 Types 的不可实例化的伴生类(详见第 4条)中。例如,Java Collections Framework的集合接口有 45个工具实现,分别提供了不可修改的集合、同步集合,等等。几乎所有这些实现都通过静态工厂方法在一个不可实例化的类(java.util.Collections)中导出。所有返回对象的类都是非公有的。\n现在的Collections Framework API 比导出 45 个独立公有类的那种实现方式要小得多,每种便利实现都对应一个类。这不仅仅是指 API数量上的减少,也是概念意义上的减少:为了使用这个API,用户必须掌握的概念在数量和难度上都减少了。程序员知道,被返回的对象是由相关的接口精确指定的,所以他们不需要阅读有关的类文档。此外,使用这种静态工厂方法时,甚至要求客户端通过接口来引用被返回的对象,而不是通过它的实现类来引用被返回的对象,这是一种良好的习惯(详见第64条)。\n从Java 8版本开始,接口中不能包含静态方法的这一限制成为历史,因此一般没有任何理由给接口提供一个不可实例化的伴生类。已经被放在这种类中的许多公有的静态成员,应该被放到接口中去。但是要注意,仍然有必要将这些静态方法背后的大部分实现代码,单独放进一个包级私有的类中。这是因为在Java 8中仍要求接口的所有静态成员都必须是公有的。在Java 9中允许接口有私有的静态方法,但是静态域和静态成员类仍然需要是公有的。\n静态工厂的第四大优势在于,所返回的对象的类可以随着每次调用而发生变化,这取决于静态工厂方法的参数值。只要是已声明的返回类型的子类型,都是允许的。返回对象的类也可能随着发行版本的不同而不同。\nEnumSet(详见第 36 条)没有公有的构造器,只有静态工厂方法。在OpenJDK实现中,它们返回两种子类之一的一个实例,具体则取决于底层枚举类型的大小：如果它的元素有64个或者更少,就像大多数枚举类型一样,静态工厂方法就会返回一个RegalarEumSet实例,实例,用一个1ong 数组进行支持。\n这两个实现类的存在对于客户端来说是不可见的。如果RegularEnumSet不能再给小的枚举类型提供性能优势,就可能从未来的发行版本中将它删除,不会造成任何负面的影响。同样地,如果事实证明对性能有好处,也可能在未来的发行版本中添加第三甚至第四个心它是EnumSet的某个子类。\n静态工厂的第五大优势在于,方法返回的对象所属的类,在编写包含该静态工厂方法的类时可以不存在。这种灵活的静态工厂方法构成了服务提供者框架(Service ProviderFramework)的基础,例如 JDBC(Java 数据库连接)API。服务提供者框架是指这样一个系统：多个服务提供者实现一个服务,系统为服务提供者的客户端提供多个实现,并把它们从多个实现中解耦出来。\n服务提供者框架中有三个重要的组件：服务接口(ServiceInterface),这是提供者实现的；提供者注册API(Provider Registraticn API),这是提供者用来注册实现的；服务访问API(ServiceAccessAPI),这是客户端用来获取服务的实例。服务访问API是客户端用来指定某种选择实现的条件。如果没有这样的规定,API就会返回默认实现的一个实例,或者允许客户端遍历所有可用的实现。服务访问API是”灵活的静态工厂”,它构成了服务提供者框架的基础。\n服务提供者框架的第四个组件服务提供者接口(ServiceProviderInterface)是可选的,它表示产生服务接口之实例的工厂对象。如果没有服务提供者接口,实现就通过反射方式进行实例化(详见第 65条)。对于 JDBC来说,Connection 就是其服务接口的一部分,DriverManager.registerDriver 是提供者注册 API, DriverManager.getConnection是服务访问 API,DriVer 是服务提供者接口。\n服务提供者框架模式有着无数种变体。例如,服务访问API可以返回比提供者需要的更丰富的服务接口。这就是桥接(Bridge)模式[Gamma95]。依赖注人框架(详见第5条)可以被看作是一个强大的服务提供者。从Java 6版本开始,Java平台就提供了一个通用的服务提供者框架java.util.ServiceLoader,因此你不需要(一般来说也不应该)再自己编写了(详见第 59条)。JDBC不用 ServiceLoader,因为前者出现得比后者早。\n静态工厂方法的主要缺点在于,类如果不含公有的或者受保护的构造器,就不能被子类化。例如,要想将Collections Framework中的任何便利的实现类子类化,这是不可能的。但是这样也许会因祸得福,因为它鼓励程序员使用复合(composition),而不是继承(详见第18条),这正是不可变类型所需要的(详见第17条)。\n静态工厂方法的第二个缺点在于,程序员很难发现它们。在API文档中,它们没有像构造器那样在API文档中明确标识出来,因此,对于提供了静态工厂方法而不是构造器的类来说,要想查明如何实例化一个类是非常困难的。Javadoc工具总有一天会注意到静态工厂方法。同时,通过在类或者接口注释中关注静态工厂,并遵守标准的命名习惯,也可以弥补这一劣势。下面是静态工厂方法的一些惯用名称。这里只列出了其中的一小部分：\nfrom一—类型转换方法,它只有单个参数,返回该类型的一个相对应的实例,例如:\nDate d = Date.from(instant);\n口of一一聚合方法,带有多个参数,返回该类型的一个实例,把它们合并起来,例如：\nSet&lt;Rank&gt; faceCards = EnumSet.of(JACK, QUEEN, KING) ;\nvalueOf一—比from 和of更烦琐的一种替代方法,例如:\nBigInteger prime = BigInteger.valueOf(Integer.MAX_VALUE);\ninstance 或者 getInstance—返回的实例是通过方法的(如有)参数来描述的,但是不能说与参数具有同样的值,例如：\nStackWalker luke = StackWalker.getInstance(options);\ncreate 或者 newInstance—像 instance 或者 getInstance一样,但 create或者 newInstance 能够确保每次调用都返回一个新的实例,例如:\nObject newArray = Array.newInstance(classObject, arrayLen) ;\n用。Type 表示工厂方法所返回的对象类型,例如:\nFileStore fs = Files.getFileStore(path);\nType 表示工厂方法所返回的对象类型,例如:\nBufferedReader br = Files.newBufferedReader(path);\ntype- getType 和 newType 的简版,例如:\nList&lt;Complaint&gt; litany = Collections.list(legacyLitany);\n简而言之,静态工厂方法和公有构造器都各有用处,我们需要理解它们各自的长处。静态工厂经常更加合适,因此切忌第一反应就是提供公有的构造器,而不先考虑静态工厂。\n第2条：遇到多个构造器参数时要考虑使用构建器静态工厂和构造器有个共同的局限性：它们都不能很好地扩展到大量的可选参数。比如用一个类表示包装食品外面显示的营养成分标签。这些标签中有几个域是必需的：每份的含量、每罐的含量以及每份的卡路里。还有超过 20个的可选域：总脂肪量、饱和脂肪量、转化脂肪、胆固醇、钠,等等。大多数产品在某几个可选域中都会有非零的值。\n对于这样的类,应该用哪种构造器或者静态工厂来编写呢？程序员一向习惯采用重叠构造器(telescoping constructor)模式,在这种模式下,提供的第一个构造器只有必要的参数,第二个构造器有一个可选参数,第三个构造器有两个可选参数,依此类推,最后一个构造器包含所有可选的参数。下面有个示例,为了简单起见,它只显示四个可选域：\n//Telescoping constructor pattern - does not scale well!public class NutritionFacts &#123;    private final int servingSize; //(mL) required    private final int servings; //(per container) required    private final int calories; //(per serving) optional    private final int fat; // (g/serving) optional    private final int sodium; // (mg/serving) optional    private final int carbohydrate;// (g/serving) optional        public NutritionFacts(int servingSize,int servings) &#123;        this(servingSize, servings, 0);    &#125;        public NutritionFacts(int servingSize, int servings,int calories)&#123;        this(servingSize, servings, calories, 0);    &#125;        public NutritionFacts(int servingSize, int servings,int calories,int fat)&#123;        this(servingSize, servings, calories,fat,0);    &#125;        public NutritionFacts(int servingSize, int servings,int calories,int fat,int sodium) &#123;        this(servingSize, servings, calories, fat, sodium, 0);    &#125;    public NutritionFacts(int servingSize, int servings,int calories, int fat, int sodium,int carbohydrate) &#123;        this.servingSize = servingSize;        this.servings = servings;        this.calories = calories;        this.fat = fat;        this.sodium sodium;        this.carbohydrate = carbohydrate;    &#125;&#125;\n当你想要创建实例的时候,就利用参数列表最短的构造器,但该列表中包含了要设置的所有参数：\nNutritionFacts cocaCola =new NutritionFacts(240,8,100,0,35,27);\n\n这个构造器调用通常需要许多你本不想设置的参数,但还是不得不为它们传递值。在这个例子中,我们给fat传递了一个值为0。如果”仅仅”是这6个参数,看起来还不算太糟糕,问题是随着参数数目的增加,它很快就失去了控制。\n简而言之,重叠构造器模式可行,但是当有许多参数的时候,客户端代码会很难编写,并且仍然较难以阅读。如果读者想知道那些值是什么意思,必须很仔细地数着这些参数来探个究竟。一长串类型相同的参数会导致一些微妙的错误。如果客户端不小心颠倒了其中两个参数的顺序,编译器也不会出错,但是程序在运行时会出现错误的行为(详见第51条)。\n遇到许多可选的构造器参数的时候,还有第二种代替办法,即JavaBeans模式,在这种模式下,先调用一个无参构造器来创建对象,然后再调用setter方法来设置每个必要的参数,以及每个相关的可选参数：\n// JavaBeans Pattern - allows inconsistency,mandates mutabilitypublic class NutritionFacts &#123;    // Parameters initialized to default values (if any)    private int servingSize = -1; // Required; no default value    private int servings = -1;// Required; no default valueprivate int calories =0;    private int fat = 0;    private int sodium = 0;    private int carbohydrate = 0;    public NutritionFacts() &#123;&#125;    //Setters    public void setServingSize(int val) &#123;servingSize = val;&#125;    public void s setServings(int val) &#123;servings = val;&#125;    public void setCalories(int val) &#123;calories = val;&#125;    public void s setFat(int val) &#123;fat = val;&#125;    public void s setSodium(int val) &#123;sodium = val;&#125;    public void setCarbohydrate(int val) &#123; carbohydrate = val;&#125;&#125;\n\n这种模式弥补了重叠构造器模式的不足。说得明白一点,就是创建实例很容易,这样产生的代码读起来也很容易：\nNutritionFacts cocaCola = new NutritionFacts();cocaCola.setServingSize(240);cocaCola.setServings(8);cocaCola.setCalories(100);cocaCola.setSodium(35);cocaCola.setCarbohydrate(27);\n\n遗憾的是,JavaBeans模式自身有着很严重的缺点。因为构造过程被分到了几个调用中,在构造过程中JavaBean可能处于不一致的状态。类无法仅仅通过检验构造器参数的有效性来保证一致性。试图使用处于不一致状态的对象将会导致失败,这种失败与包含错误的代码大相径庭,因此调试起来十分困难。**与此相关的另一点不足在于,JavaBeans 模式使得把类做成不可变的可能性不复存在(详见第17条),**这就需要程序员付出额外的努力来确保它的线程安全。\n当对象的构造完成,并且不允许在冻结之前使用时,通过手工”冻结”对象可以弥补这些不足,但是这种方式十分笨拙,在实践中很少使用。此外,它甚至会在运行时导致错误,因为编译器无法确保程序员会在使用之前先调用对象上的freeze方法进行冻结。\n幸运的是,还有第三种替代方法,它既能保证像重叠构造器模式那样的安全性,也能保证像JavaBeans 模式那么好的可读性。这就是建造者(Builder)模式[Gamma95]的一种形式。它不直接生成想要的对象,而是让客户端利用所有必要的参数调用构造器(或者静态工厂),得到一个 builder 对象。然后客户端在builder 对象上调用类似于 setter 的方法,来设置每个相关的可选参数。最后,客户端调用无参的buila方法来生成通常是不可变的对象。这个 builder 通常是它构建的类的静态成员类(详见第 24 条)。下面就是它的示例:\n//Builder Patternpublic class NutritionFacts &#123;    private final int servingSize;    private final int servings;    private final int calories;    private final int fat;    private final int sodium;    private final int carbohydrate;        public static class Builder&#123;        // Required parameters        private final int servingSize;        private final int servings;        // Optional parameters - initialized to default values        private int calories =0;        private int fat =0;        private int sodium =0;        private int carbohydrate =0;        public Builder(int servingSize, int servings) &#123;            this.servingSize = servingSize;            this.servings = servings;        &#125;        public Builder calories(int val)&#123;            calories = val;             return this;        &#125;        public Builder fat(int val)&#123;            fat =val;             return this;        &#125;        public Builder sodium(int val)&#123;            sodium = val;            return this;        &#125;        public Builder carbohydrate(int val)&#123;            carbohydrate = val;            return this;        &#125;        public NutritionFacts build() &#123;            return new NutritionFacts(this);        &#125;    &#125;        private NutritionFacts(Builder builder) &#123;        servingSize = builder.servingSize;        servings builder.servings;        calories builder.calories;        fat =b builder.fat;        sodium = builder.sodium;        carbohydrate = builder.carbohydrate;    &#125;&#125;\n\n注意NutritionFacts是不可变的,所有的默认参数值都单独放在一个地方。builder的设值方法返回 builder 本身,以便把调用链接起来,得到一个流式的 API。下面就是其客户端代码：\nNutritionFacts cocaCola = new NutritionFacts.Builder(240, 8)    .calories(100).sodium(35).carbohydrate(27).build();\n\n这样的客户端代码很容易编写,更为重要的是易于阅读。Builder模式模拟了具名的可选参数,就像Python 和 Scala 编程语言中的一样。\n为了简洁起见,示例中省略了有效性检查。要想尽快侦测到无效的参数,可以在builder 的构造器和方法中检查参数的有效性。查看不可变量,包括 build方法调用的构造器中的多个参数。为了确保这些不变量免受攻击,从builder复制完参数之后,要检查对象域(详见第50条)。如果检查失败,就抛出IllegalArgumentException(详见第72条),其中的详细信息会说明哪些参数是无效的(详见第75条)。\nBuilder模式也适用于类层次结构。使用平行层次结构的builder时,各自嵌套在相应的类中。抽象类有抽象的 builder,具体类有具体的 builder。假设用类层次根部的一个抽象类表示各式各样的比萨：\n// Builder pattern for class hierarchiespublic abstract class Pizza &#123;    public enum Topping &#123; HAM, MUSHROOM, ONION, PEPPER, SAUSAGE &#125;    final Set&lt;Topping&gt; toppings;    abstract static class Builder&lt;T extends Builder&lt;T&gt;&gt;&#123;        EnumSet&lt;Topping&gt; toppings = EnumSet.noneOf(Topping.class) ;        public T addTopping(Topping topping) &#123;            toppings.add(Objects.requireNonNull(topping));            return selfO;            &#125;            abstract Pizza build();            //Subclasses must override this method to return&quot;this&quot;            protected abstract T self();            Pizza(Builder&lt;?&gt; builder) &#123;toppings = builder.toppings.clone(); // See Item 50            &#125;    &#125;\n\n注意,Pizza.Builder 的类型是泛型(generic type),带有一个递归类型参数(recursivetype parameter),详见第 30 条。它和抽象的 self 方法一样,允许在子类中适当地进行方法链接,不需要转换类型。这个针对 Java 缺乏 self类型的解决方案,被称作模拟的 self 类型(simulated self-type)。\n这里有两个具体的 Pizza 子类,其中一个表示经典纽约风味的比萨,另一个表示馅料内置的半月型(calzone)比萨。前者需要一个尺寸参数,后者则要你指定酱汁应该内置还是外置：\npublic class NyPizza extends Pizza &#123;    public enum Size &#123; SMALL,MEDIUM,LARGE &#125;    private final Size size;    public static class Builder extends Pizza.Builder&lt;Builder&gt;&#123;        private final Size size;        public Builder(Size size) &#123;            this.size = Objects.requireNonNull(size);        &#125;        @Override         public NyPizza build() &#123;            return new NyPizza(this);        &#125;        @Override         protected Builder self() &#123;return this;&#125;    &#125;    private NyPizza(Builder builder) &#123;        super(builder);        size = builder.size;    &#125;&#125;    public class Calzone extends Pizza &#123;        private final boolean sauceInside;            public static class Builder extends Pizza.Builder&lt;Builder&gt; &#123;        private boolean sauceInside = false; // Default        public Builder sauceInside() &#123;            sauceInside = true;            return this;        &#125;        @Override         public Calzone build() &#123;            return new Calzone(this);        &#125;        @Override         protected Builder self() &#123;            return this;        &#125;    &#125;    private Calzone(Builder builder) &#123;        super(builder);        sauceInside = builder.sauceInside;    &#125;&#125;\n\n注意,每个子类的构建器中的buila方法,都声明返回正确的子类：NyPizza.Builder的build方法返回NyPizza,而 Calzone.Builder中 的则返回Calzone。在该方法中,子类方法声明返回超级类中声明的返回类型的子类型,这被称作协变返回类型(covariant return type)。它允许客户端无须转换类型就能使用这些构建器。\n为了简洁起见,下列客户端代码示例假设是在枚举常量上静态导人:\nNyPizza pizza = new NyPizza.Builder(SMALL)            .addTopping(SAUSAGE)             .addTopping(ONION)             .build() ;Calzone calzone = new Calzone.Builder()            .addTopping(HAM)             .sauceInside()             .build() ;\n\n与构造器相比,builder 的微略优势在于,它可以有多个可变(varargs)参数。因为builder是利用单独的方法来设置每一个参数。此外,构造器还可以将多次调用某一个方法而传人的参数集中到一个域中,如前面的调用了两次 addTopping 方法的代码所示。\nBuilder模式十分灵活,可以利用单个builder构建多个对象。builder的参数可以在调用build方法来创建对象期间进行调整,也可以随着不同的对象而改变。builder 可以自动填充某些域,例如每次创建对象时自动增加序列号。\nBuilder模式的确也有它自身的不足。为了创建对象,必须先创建它的构建器。虽然创建这个构建器的开销在实践中可能不那么明显,但是在某些十分注重性能的情况下,可能就成问题了。Builder模式还比重叠构造器模式更加冗长,因此它只在有很多参数的时候才使用,比如4个或者更多个参数。但是记住,将来你可能需要添加参数。如果一开始就使用构造器或者静态工厂,等到类需要多个参数时才添加构造器,就会无法控制,那些过时的构造器或者静态工厂显得十分不协调。因此,通常最好一开始就使用构建器。\n简而言之,如果类的构造器或者静态工厂中具有多个参数,设计这种类时,Builder模式就是一种不错的选择,特别是当大多数参数都是可选或者类型相同的时候。与使用重叠构造器模式相比,使用Builder模式的客户端代码将更易于阅读和编写,构建器也比JavaBeans更加安全。\n第3条：用私有构造器或者枚举类型强化Singleton属性Singleton是指仅仅被实例化一次的类[Gamma95]。Singleton 通常被用来代表一个无状态的对象,如函数(详见第 24 条),或者那些本质上唯一的系统组件。**使类成为 Singleton会使它的客户端测试变得十分困难,**因为不可能给 Singleton 替换模拟实现,除非实现一个充当其类型的接口。\n实现 Singleton 有两种常见的方法。这两种方法都要保持构造器为私有的,并导出公有的静态成员,以便允许客户端能够访问该类的唯一实例。在第一种方法中,公有静态成员是个final域：\n//Singleton with public final fieldpublic class Elvis&#123;    public static final Elvis INSTANCE = new Elvis();    private Elvis() &#123; ... &#125;    public void leaveTheBuilding() &#123; ...&#125;&#125;\n\n私有构造器仅被调用一次,用来实例化公有的静态 final域Elvis.INSTANCE。由于缺少公有的或者受保护的构造器,所以保证了 Elvis 的全局唯一性：一旦 Elvis 类被实例化,将只会存在一个Elvis 实例,不多也不少。客户端的任何行为都不会改变这一点,但要提醒一点：享有特权的客户端可以借助AccessibleObject.setAccessible方法,通过反射机制(详见第65条)调用私有构造器。如果需要抵御这种攻击,可以修改构造器,让它在被要求创建第二个实例的时候抛出异常。\n在实现Singleton的第二种方法中,公有的成员是个静态工厂方法：\n// Singleton with static factorypublic class Elvis &#123;    private static final Elvis INSTANCE = new Elvis();    private Elvis() &#123; ...&#125;    public static Elvis getInstance() &#123; return INSTANCE;&#125;    public void leaveTheBuilding() &#123; ... &#125;&#125;\n\n对于静态方法 Elvis.getInstance 的所有调用,都会返回同一个对象引用,所以,永远不会创建其他的 Elvis 实例(上述提醒依然适用)。\n公有域方法的主要优势在于, API很清楚地表明了这个类是一个Singleton ： 公有的静态域是final 的,所以该域总是包含相同的对象引用。 第二个优势在于它更简单。\n静态工厂方法的优势之一在于,它提供了灵活性：在不改变其API的前提下,我们可以改变该类是否应该为 Singleton 的想法。工厂方法返回该类的唯一实例,但是,它很容易被修改,比如改成为每个调用该方法的线程返回一个唯一的实例。第二个优势是,如果应用程序需要,可以编写一个泛型Singleton工厂(generic singleton factory)(详见第30条)。使用静态工厂的最后一个优势是,可以通过方法引用(methodreference)作为提供者,比如Elvis：:instance 就是一个 Supplier。除非满足以上任意一种优势,否则还是优先考虑公有域(public-field)的方法。\n为了将利用上述方法实现的 Singleton 类变成是可序列化的(Serializable)(详见第 12章),仅仅在声明中加上 implements Serializable是不够的。为了维护并保证 Singleton,必须声明所有实例域都是瞬时(transient)的,并提供一个readResolve 方法(详见第 89条)。否则,每次反序列化一个序列化的实例时,都会创建一个新的实例,比如,在我们的例子中,会导致”假冒的Elvis”。为了防止发生这种情况,要在Elvis 类中加入如下 readResolve 方法:\n//readResolve method topreserve singleton propertyprivate Object readResolve()&#123;    //Return the one true Elvis and let the garbage collector    //take care of the Elvisimpersonator.    return INSTANCE;&#125;\n\n实现 Singleton 的第三种方法是声明一个包含单个元素的枚举类型:\n//Enum singleton-the preferred approachpublic enum Elvis &#123;    INSTANCE;        public void leaveTheBuilding() &#123;...&#125;&#125;\n\n这种方法在功能上与公有域方法相似,但更加简洁,无偿地提供了序列化机制,绝对防止多次实例化,即使是在面对复杂的序列化或者反射攻击的时候。虽然这种方法还没有广泛采用,但是单元素的枚举类型经常成为实现Singleton 的最佳方法。注意,如果 Singleton必须扩展一个超类,而不是扩展 Enum 的时候,则不宜使用这个方法(虽然可以声明枚举去实现接口)。\n第4条：通过私有构造器强化不可实例化的能力有时可能需要编写只包含静态方法和静态域的类。这些类的名声很不好,因为有些人在面向对象的语言中滥用这样的类来编写过程化的程序,但它们也确实有特别的用处。我们可以利用这种类,以java.lang.Math 或者java.util.Arrays 的方式,把基本类型的值或者数组类型上的相关方法组织起来。我们也可以通过java.util.Collections的方式,把实现特定接口的对象上的静态方法,包括工厂方法(详见第1条)组织起来。(从Java8开始,也可以把这些方法放进接口中,假定这是你自已编写的接口可以进行修改。)最后,还可以利用这种类把final类上的方法组织起来,因为不能把它们放在子类中。\n这样的工具类(utilityclass)不希望被实例化,因为实例化对它没有任何意义。然而,在缺少显式构造器的情况下,编译器会自动提供一个公有的、无参的缺省构造器(defaultconstructor)。对于用户而言,这个构造器与其他的构造器没有任何区别。在已发行的API中常常可以看到一些被无意识地实例化的类。\n企图通过将类做成抽象类来强制该类不可被实例化是行不通的。该类可以被子类化,并且该子类也可以被实例化。这样做甚至会误导用户,以为这种类是专门为了继承而设计的(详见第19条)。然而,有一些简单的习惯用法可以确保类不可被实例化。由于只有当类不包含显式的构造器时,编译器才会生成缺省的构造器,因此只要让这个类包含一个私有构造器,它就不能被实例化：\n//Noninstantiableutility classpublic class UtilityClass&#123;    //Suppress default constructor for noninstantiability    private UtilityClass() &#123;    // throw new AssertionError();// Remainder omitted    &#125;    ... // Remainder omitted&#125;\n\n由于显式的构造器是私有的,所以不可以在该类的外部访问它。AssertionError 不是必需的,但是它可以避免不小心在类的内部调用构造器。它保证该类在任何情况下都不会被实例化。这种习惯用法有点违背直觉,好像构造器就是专门设计成不能被调用一样。因此,明智的做法就是在代码中增加一条注释,如上所示。\n这种习惯用法也有副作用,它使得一个类不能被子类化。所有的构造器都必须显式或隐式地调用超类(superclass)构造器,在这种情形下,子类就没有可访问的超类构造器可调用了。\n第5条：优先考虑依赖注人来引用资源有许多类会依赖一个或多个底层的资源。例如,拼写检查器需要依赖词典。因此,像下面这样把类实现为静态工具类的做法并不少见(详见第4条)：\n// Inappropriate use of static utility -inflexible &amp; untestable!public class SpellChecker &#123;    private static final Lexicon dictionary = ...;    private SpellChecker() &#123;&#125; // Noninstantiable    public static boolean isValid(String word) &#123;...&#125;    public static List&lt;String&gt; suggestions(String typo) &#123; ...&#125;&#125;\n\n同样地,将这些类实现为 Singleton 的做法也并不少见(详见第3条):\n// Inappropriate use of singleton - inflexible &amp; untestable!public class SpellChecker &#123;    private final Lexicon dictionary = ...;    private SpellChecker(...) &#123;&#125;    public static INSTANCE = new SpellChecker(...);    public boolean isValid(String word) &#123; ...&#125;    public List&lt;String&gt; suggestions(String typo)&#123;...&#125;&#125;\n\n以上两种方法都不理想,因为它们都是假定只有一本词典可用。实际上,每一种语言都有自己的词典,特殊词汇还要使用特殊的词典。此外,可能还需要用特殊的词典进行测试。因此假定用一本词典就能满足所有需求,这简直是痴心妄想\n建议尝试用 SpellChecker 来支持多词典,即在现有的拼写检查器中,设 dictionary域为 nonfinal,并添加一个方法用它来修改词典,但是这样的设置会显得很笨拙、容易出错,并且无法并行工作。静态工具类和 Singleton 类不适合于需要引用底层资源的类。\n这里需要的是能够支持类的多个实例（在本例中是指 SpellChecker）,每一个实例都使用客户端指定的资源(在本例中是指词典)。满足该需求的最简单的模式是,当创建一个新的实例时,就将该资源传到构造器中。这是依赖注入(dependency injection)的一种形式:词典(dictionary)是拼写检查器的一个依赖(dependency),在创建拼写检查器时就将词典注入(injected)其中。\n//Dependency injection provides flexibility and testabilitypublic class SpellChecker &#123;    private final Lexicon dictionary;    public SpellChecker(Lexicon dictionary)&#123;        this.dictionary = Objects.requireNonNull(dictionary);    &#125;    public boolean isValid(String word) &#123;...&#125;    public List&lt;String&gt;suggestions(String typo)&#123;...&#125;&#125;\n\n依赖注人模式就是这么简单,因此许多程序员使用多年,却不知道它还有名字呢。虽然这个拼写检查器的范例中只有一个资源(词典),但是依赖注人却适用于任意数量的资源,以及任意的依赖形式。依赖注人的对象资源具有不可变性(详见第17条),因此多个客户端可以共享依赖对象(假设客户端们想要的是同一个底层资源)。依赖注入也同样适用于构造器、静态工厂(详见第1条)和构建器(详见第2条)。\n这个程序模式的另一种有用的变体是,将资源工厂(factory)传给构造器。工厂是可以被重复调用来创建类型实例的一个对象。这类工厂具体表现为工厂方法(FactoryMethod)模式[Gamma95]。在Java 8中增加的接口 Supplier,最适合用于表示工厂。带有 Supplier的方法,通常应该限制输人工厂的类型参数使用有限制的通配符类型(bounded wildcard type),详见第 31条,以便客户端能够传入一个工厂,来创建指定类型的任意子类型。例如,下面是一个生产马赛克的方法,它利用客户端提供的工厂来生产每一片马赛克：\nMosaic create(Supplier&lt;? extends Tile&gt; tileFactory)&#123;...&#125;\n\n虽然依赖注人极大地提升了灵活性和可测试性,但它会导致大型项目凌乱不堪,因为它通常包含上千个依赖。不过这种凌乱用一个依赖注入框架(dependencyinjectionframework)便可以终结,如Dagger[Dagger]、Guice[Guice]或者 Spring[Spring]。这些框架的用法超出了本书的讨论范畴,但是,请注意：设计成手动依赖注人的 API,一般都适用于这些框架。\n总而言之,不要用 Singleton 和静态工具类来实现依赖一个或多个底层资源的类,且该资源的行为会影响到该类的行为；也不要直接用这个类来创建这些资源。而应该将这些资源或者工厂传给构造器(或者静态工厂,或者构建器),通过它们来创建类。这个实践就被称作依赖注人,它极大地提升了类的灵活性、可重用性和可测试性。\n第6条：避免创建不必要的对象一般来说,最好能重用单个对象,而不是在每次需要的时候就创建一个相同功能的新对象。重用方式既快速,又流行。如果对象是不可变的(immutable)(详见第 17条),它就始终可以被重用。\n作为一个极端的反面例子,看看下面的语句:\nStrings=new String(&quot;bikini&quot;);// DoN&#x27;T Do THIS！\n\n该语句每次被执行的时候都创建一个新的 String 实例,但是这些创建对象的动作全都是不必要的。传递给 String 构造器的参数(“bikini”)本身就是一个 String 实例,功能方面等同于构造器创建的所有对象。如果这种用法是在一个循环中,或者是在一个被频繁调用的方法中,就会创建出成千上万不必要的 String 实例。\n改进后的版本如下所示：\nString S = &quot;bikini&quot;;\n\n这个版本只用了一个 String 实例,而不是每次执行的时候都创建一个新的实例。而且,它可以保证,对于所有在同一台虚拟机中运行的代码,只要它们包含相同的字符串字面常量,该对象就会被重用[JLS,3.10.5]。\n对于同时提供了静态工厂方法(static factory method)(详见第1条)和构造器的不可变类,通常优先使用静态工厂方法而不是构造器,以避免创建不必要的对象。例如,静态工厂方法Boolean.valueOf(String)几乎总是优先于构造器Boolean(String),注意构造器Boolean(String)在Java 9中已经被废弃了。构造器在每次被调用的时候都会创建一个新的对象,而静态工厂方法则从来不要求这样做,实际上也不会这样做。除了重用不可变的对象之外,也可以重用那些已知不会被修改的可变对象。\n有些对象创建的成本比其他对象要高得多。如果重复地需要这类”昂贵的对象”,建议将它缓存下来重用。遗憾的是,在创建这种对象的时候,并非总是那么显而易见。假设想要编写一个方法,用它确定一个字符串是否为一个有效的罗马数字。下面介绍一种最容易的方法,使用一个正则表达式：\n// Performance can be greatly improved!static boolean isRomanNumeral(String s) &#123;    return s.matches(&quot;^(?=.)M*(C[MD] ID?C&#123;0,3&#125;)&quot;+ &quot;(x[Cl]1L?x&#123;0,3&#125;) (I[XV] IV?I&#123;0,3&#125;)$&quot;);&#125;\n\n这个实现的问题在于它依赖 String.matches 方法。虽然 String.matches 方法最易于查看一个字符串是否与正则表达式相匹配,但并不适合在注重性能的情形中重复使用。问题在于,它在内部为正则表达式创建了一个 Pattern 实例,却只用了一次,之后就可以进行垃圾回收了。创建Pattern 实例的成本很高,因为需要将正则表达式编译成一个有限状态机(finite state machine)。\n为了提升性能,应该显式地将正则表达式编译成一个 Pattern 实例(不可变),让它成为类初始化的一部分,并将它缓存起来,每当调用isRomanNumeral方法的时候就重用同一个实例：\n//Reusing expensive object for improved performancepublic class RomanNumerals&#123;    private static final Pattern ROMAN=Pattern.compile(&quot;A(?=.)M*(C[MD]1D？C&#123;0,3&#125;)&quot;+ &quot;(X[CL] 1L?X&#123;0,3&#125;) (I[XV] IV?I&#123;0,3&#125;)$&quot;) ;    static boolean isRomanNumeral(String s) &#123;        return ROMAN.matcher(s).matches();    &#125;&#125;\n\n改进后的isRomanNumeral方法如果被频繁地调用,会显示出明显的性能优势。在我的机器上,原来的版本在一个8字符的输入字符串上花了1.1μs,而改进后的版本只花了0.17μs,速度快了6.5倍。除了提高性能之外,可以说代码也更清晰了。将不可见的Pattern实例做成 final 静态域时,可以给它起个名字,这样会比正则表达式本身更有可读性。\n如果包含改进后的isRomanNumeral方法的类被初始化了,但是该方法没有被调用,那就没必要初始化 ROMAN域。通过在isRomanNumeral方法第一次被调用的时候延迟初始化(lazily initializing)(详见第83 条)这个域,有可能消除这个不必要的初始化工作,但是不建议这样做。正如延迟初始化中常见的情况一样,这样做会使方法的实现更加复杂,从而无法将性能显著提高到超过已经达到的水平(详见第67条)。\n如果一个对象是不变的,那么它显然能够被安全地重用,但其他有些情形则并不总是指这样一个对象：它把功能委托给一个后备对象(backing object),从而为后备对象提供一个可以替代的接口。由于适配器除了后备对象之外,没有其他的状态信息,所以针对某个给定对象的特定适配器而言,它不需要创建多个适配器实例。\n例如,Map 接口的keySet 方法返回该 Map 对象的 Set 视图,其中包含该 Map 中所有的键(key)。乍看之下,好像每次调用keySet都应该创建一个新的 Set实例,但是,对于一个给定的 Map 对象,实际上每次调用 keySet 都返回同样的 Set 实例。虽然被返回的 Set实例一般是可改变的,但是所有返回的对象在功能上是等同的：当其中一个返回对象发生变化的时候,所有其他的返回对象也要发生变化,因为它们是由同一个Map实例支撑的。虽然创建keySet 视图对象的多个实例并无害处,却是没有必要,也没有好处的。\n装箱基本类型(Boxed Primitive Type)混用,按需要自动装箱和拆箱。自动装箱使得基本类型和装箱基本类型之间的差别变得模糊起来,但是并没有完全消除。它们在语义上还有着微妙的差别,在性能上也有着比较明显的差别(详见第61条)。请看下面的程序,它计算所有int 正整数值的总和。为此,程序必须使用long 算法,因为 int 不够大,无法容纳所有int正整数值的总和:\n//Hideously slow！Can you spot the object creation?private static long sum()&#123;    Long sum=OL;    for(long i= 0;i&lt;=Integer.MAX_VALUE;i++)        sumn+=i;&#125;\n\n这段程序算出的答案是正确的,但是比实际情况要更慢一些,只因为打错了一个字符。变量 sum 被声明成 Long 而不是 long,意味着程序构造了大约 2^31个多余的Long 实例(大约每次往Long sum 中增加 long时构造一个实例)。将 sum 的声明从Long 改成long,在我的机器上使运行时间从6.3秒减少到了0.59秒。结论很明显：要优先使用基本类型而不是装箱基本类型,要当心无意识的自动装箱。\n不要错误地认为本条目所介绍的内容暗示着”创建对象的代价非常昂贵,我们应该要尽可能地避免创建对象”。相反,由于小对象的构造器只做很少量的显式工作,所以小对象的创建和回收动作是非常廉价的,特别是在现代的JIVM实现上更是如此。通过创建附加的对象,提升程序的清晰性、简洁性和功能性,这通常是件好事。\n反之,通过维护自己的对象池(object pool)来避免创建对象并不是一种好的做法,除非池中的对象是非常重量级的。正确使用对象池的典型对象示例就是数据库连接池。建立数据库连接的代价是非常昂贵的,因此重用这些对象非常有意义。而且,数据库的许可可能限制你只能使用一定数量的连接。但是,一般而言,维护自己的对象池必定会把代码弄得很乱,同时增加内存占用(footprint),并且还会损害性能。现代的JVM实现具有高度优化的垃圾回收器,其性能很容易就会超过轻量级对象池的性能。\n与本条目对应的是第50条中有关”保护性拷贝”(defensive copying)的内容。本条目提及”当你应该重用现有对象的时候,请不要创建新的对象”,而第50条则说”当你应该创建新对象的时候,请不要重用现有的对象”。注意,在提倡使用保护性拷贝的时候,因重用对象而付出的代价要远远大于因创建重复对象而付出的代价。必要时如果没能实施保护性拷贝,将会导致潜在的Bug和安全漏洞；而不必要地创建对象则只会影响程序的风格和性能。\n第7条：消除过期的对象引用当你从手工管理内存的语言(比如C或C++)转换到具有垃圾回收功能的比如Java语言时,程序员的工作会变得更加容易,因为当你用完了对象之后,它们会被自动回收。当你第一次经历对象回收功能的时候,会觉得这简直有点不可思议。它很容易给你留下这样的印象,认为自己不再需要考虑内存管理的事情了,其实不然。\n请看下面这个简单的栈实现的例子：\n//Can you spot the &quot;memoryleak&quot;?public class Stack &#123;    private Object[] elements;    private int size = 0;    private static final int DEFAULT_INITIAL_CAPACITY = 16;    public Stack() &#123;        elements = new Object[DEFAULT_INITIAL_CAPACITY];    &#125;    public void push(Object e)&#123;        ensureCapacity();        elements[size++] = e;    &#125;    public Object pop()&#123;        if(size == 0)            throw new EmptyStackException();        return elements[--size];    &#125;    /**     * Ensure space for at least one more element,roughly     * *doubling the capacity each time thearray needs to grow.    */    private void ensureCapacity() &#123;        if (elements.length == size)            elements = Arrays.copyOf(elements,2 * size + 1);    &#125;&#125;\n\n这段程序（它的泛型版本请见第29条）中并没有很明显的错误。 无论如何测试,它都会成功地通过每一项测试,但是这个程序中隐藏着一个问题。 不严格地讲,这段程序有一个”内存泄漏”,随着垃圾回收器活动的增加,或者由于内存占用的不断增加,程序性能的降低会逐渐表现出来。 在极端的情况下,这种内存泄漏会导致磁盘交换（DiskPaging）,甚至导致程序失败（OutOfMemoryError 错误）,但是这种失败情形相对比较少见。\n那么,程序中哪里发生了内存泄漏呢？如果一个栈先是增长,然后再收缩,那么,从栈中弹出来的对象将不会被当作垃圾回收,即使使用栈的程序不再引用这些对象,它们也不会被回收。这是因为栈内部维护着对这些对象的过期引用(obsolete reference)。所谓的过期引用,是指永远也不会再被解除的引用。在本例中,凡是在 elements 数组的”活动部分”(active portion)之外的任何引用都是过期的。活动部分是指 elements 中下标小于 size 的那些元素。\n在支持垃圾回收的语言中,内存泄漏是很隐蔽的(称这类内存泄漏为”无意识的对象保持”(unintentional object retention)更为恰当)。如果一个对象引用被无意识地保留起来了,象。即使只有少量的几个对象引用被无意识地保留下来,也会有许许多多的对象被排除在垃圾回收机制之外,从而对性能造成潜在的重大影响。\n这类问题的修复方法很简单：一旦对象引用已经过期,只需清空这些引用即可。对于上述例子中的 Stack 类而言,只要一个单元被弹出栈,指向它的引用就过期了。pop 方法的修订版本如下所示:\npublic Object pop()&#123;    if(size==0) throw new EmptyStackException();    Object result=elements[--size];    elements[size] = null;// Eliminate obsolete reference    return result;&#125;\n\n清空过期引用的另一个好处是,如果它们以后又被错误地解除引用,程序就会立即抛出 NullPointerException 异常,而不是悄悄地错误运行下去。尽快地检测出程序中的错误总是有益的。\n当程序员第一次被类似这样的问题困扰的时候,他们往往会过分小心：对于每一个对象引用,一旦程序不再用到它,就把它清空。其实这样做既没必要,也不是我们所期望的,因为这样做会把程序代码弄得很乱。清空对象引用应该是一种例外,而不是一种规范行为。消除过期引用最好的方法是让包含该引用的变量结束其生命周期。如果你是在最紧凑的作用域范围内定义每一个变量(详见第57条),这种情形就会自然而然地发生。\n那么,何时应该清空引用呢？Stack类的哪方面特性使它易于遭受内存泄漏的影响呢?简而言之,问题在于,Stack类自己管理内存。存储池(storage pool)包含了elements 数组(对象引用单元,而不是对象本身)的元素。数组活动区域(同前面的定义)中的元素是已分配的(allocated),而数组其余部分的元素则是自由的(free)。但是垃圾回收器并不知道这一点；对于垃圾回收器而言,elements 数组中的所有对象引用都同等有效。只有程序员知道数组的非活动部分是不重要的。程序员可以把这个情况告知垃圾回收器,做法很简单：一旦数组元素变成了非活动部分的一部分,程序员就手工清空这些数组元素。\n一般来说,只要类是自己管理内存,程序员就应该警惕内存泄漏问题。一旦元素被释放掉,则该元素中包含的任何对象引用都应该被清空。\n内存泄漏的另一个常见来源是缓存。一旦你把对象引用放到缓存中,它就很容易被遗忘掉,从而使得它不再有用之后很长一段时间内仍然留在缓存中。对于这个问题,有几种可能的解决方案。如果你正好要实现这样的缓存：只要在缓存之外存在对某个项的键的引用,该项就有意义,那么就可以用WeakHashMap 代表缓存；当缓存中的项过期之后,它们就会自动被删除。记住只有当所要的缓存项的生命周期是由该键的外部引用而不是由值决定时,WeakHashMap 才有用处。\n的推移,其中的项会变得越来越没有价值。在这种情况下,缓存应该时不时地清除掉没用的项。这项清除工作可以由一个后台线程(可能是ScheduledThreadPoolExecutor)来完成,或者也可以在给缓存添加新条目的时候顺便进行清理。LinkedHashMap 类利用它的 removeEldestEntry方法可以很容易地实现后一种方案。对于更加复杂的缓存,必须直接使用java.lang.ref。\n内存泄漏的第三个常见来源是监听器和其他回调。如果你实现了一个API,客户端在这个API中注册回调,却没有显式地取消注册,那么除非你采取某些动作,否则它们就会不断地堆积起来。确保回调立即被当作垃圾回收的最佳方法是只保存它们的弱引用(weakreference),例如,只将它们保存成 WeakHa shMap 中的键。\n由于内存泄漏通常不会表现成明显的失败,所以它们可以在一个系统中存在很多年。往往只有通过仔细检查代码,或者借助于 Heap 剖析工具(Heap Profiler)才能发现内存泄漏问题。因此,如果能够在内存泄漏发生之前就知道如何预测此类问题,并阻止它们发生,那是最好不过的了。\n第8条：避免使用终结方法和清除方法终结方法(finalizer)通常是不可预测的,也是很危险的,一般情况下是不必要的。使用终结方法会导致行为不稳定、性能降低,以及可移植性问题。当然,终结方法也有其可用之处,我们将在本条目的最后再做介绍；但是根据经验,应该避免使用终结方法。在Java 9中用清除方法(cleaner)代替了终结方法。清除方法没有终结方法那么危险,但仍然是不可预测、运行缓慢,一般情况下也是不必要的。\n在C++中,析构器是回收一个对象所占用资源的常规方法,是构造器所必需的对应物。在Java 中,当一个对象变得不可到达的时候,垃圾回收器会回收与该对象相关联的存储空间,并不需要程序员做专门的工作。C++的析构器也可以被用来回收其他的非内存资源。而在Java 中,一般用trY-finally 块来完成类似的工作(详见第9 条)。\n终结方法和清除方法的缺点在于不能保证会被及时执行[JLS,12.6]。从一个对象变得不可到达开始,到它的终结方法被执行,所花费的这段时间是任意长的。这意味着,注重时间(time-critical)的任务不应该由终结方法或者清除方法来完成。例如,用终结方法或者清的资源。如果系统无法及时运行终结方法或者清除方法就会导致大量的文件仍然保留在打开状态,于是当一个程序再也不能打开文件的时候,它可能会运行失败。\n及时地执行终结方法和清除方法正是垃圾回收算法的一个主要功能,这种算法在不同的JVM实现中会大相径庭。如果程序依赖于终结方法或者清除方法被执行的时间点,那么这个程序的行为在不同的JM中运行的表现可能就会截然不同。一个程序在你测试用的JVM平台上运行得非常好,而在你最重要顾客的JVM平台上却根本无法运行,这是完全有可能的。\n延迟终结过程并不只是一个理论问题。在很少见的情况下,为类提供终结方法,可能会随意地延迟其实例的回收过程。一位同事最近在调试一个长期运行的GUI应用程序的时候,该应用程序莫名其妙地出现 OutOfMemoryError 错误而死掉。分析表明,该应用程序死掉的时候,其终结方法队列中有数千个图形对象正在等待被终结和回收。遗憾的是,终结方法线程的优先级比该应用程序的其他线程的优先级要低得多,所以,图形对象的终结速度达不到它们进人队列的速度。Java 语言规范并不保证哪个线程将会执行终结方法,所以,除了不使用终结方法之外,并没有很轻便的办法能够避免这样的问题。在这方面,清除方法比终结方法稍好一些,因为类的设计者可以控制自己的清除线程,但清除方法仍然在后台运行,处于垃圾回收器的控制之下,因此不能确保及时清除。\nJava语言规范不仅不保证终结方法或者清除方法会被及时地执行,而且根本就不保证它们会被执行。当一个程序终止的时候,某些已经无法访问的对象上的终结方法却根本没有被执行,这是完全有可能的。结论是：永远不应该依赖终结方法或者清除方法来更新重要的持久状态。例如,依赖终结方法或者清除方法来释放共享资源(比如数据库)上的永久锁,这很容易让整个分布式系统跨掉。\n不要被 System.gc 和 System.runFinalization 这两个方法所诱惑,它们确实增加了终结方法或者清除方法被执行的机会,但是它们并不保证终结方法或者清除方法一定会被执行。唯一声称保证它们会被执行的两个方法是 System.runFinalizersOnExit,及其臭名昭著的李生兄弟 Runtime.runFinalizersOnExit。这两个方法都有致命的缺陷,并且已经被废弃很久了[ThreadStop]。\n使用终结方法的另一个问题是：如果忽略在终结过程中被抛出来的未被捕获的异常,该对象的终结过程也会终止[JLS,12.6]。未被捕获的异常会使对象处于破坏的状态(corruptstate),如果另一个线程企图使用这种被破坏的对象,则可能发生任何不确定的行为。正常情况下,未被捕获的异常将会使线程终止,并打印出栈轨迹(Stack Trace),但是,如果异常发生在终结方法之中,则不会如此,甚至连警告都不会打印出来。清除方法没有这个问题,因为使用清除方法的一个类库在控制它的线程。\n使用终结方法和清除方法有一个非常严重的性能损失。在我的机器上,创建一个简单的AutoCloseable对象,用try-with-resources将它关闭,再让垃圾回收器将它回收,完成这些工作花费的时间大约为 12ns。增加一个终结方法使时间增加到了550ns。换句话说,用终结方法创建和销毁对象慢了大约50倍。这主要是因为终结方法阻止了有效的垃圾回收。如果用清除方法来清除类的所有实例,它的速度比终结方法会稍微快一些(在我的机器上大约是每个实例花 500ns),但如果只是把清除方法作为一道安全网(safety net),下面将会介绍,那么清除方法的速度还会更快一些。在这种情况下,创建、清除和销毁对象,在我的机器上花了大约66ns,这意味着,如果没有使用它,为了确保安全网多花了5倍(而不是50倍)的代价。\n终结方法有一个严重的安全问题：它们为终结方法攻击(finalizer attack)打开了类的大门。终结方法攻击背后的思想很简单：如果从构造器或者它的序列化对等体(readobject和 readResolve方法,详见第 12章)抛出异常,恶意子类的终结方法就可以在构造了一部分的应该已经半途天折的对象上运行。这个终结方法会将对该对象的引用记录在一个静态域中,阻止它被垃圾回收。一旦记录到异常的对象,就可以轻松地在这个对象上调用任何原本永远不允许在这里出现的方法。从构造器抛出的异常,应该足以防止对象继续存在；有了终结方法的存在,这一点就做不到了。这种攻击可能造成致命的后果。final类不会受到终结方法攻击,因为没有人能够编写出 final 类的恶意子类。为了防止非final 类受到终结方法攻击,要编写一个空的final的finalize方法。\n那么,如果类的对象中封装的资源(例如文件或者线程)确实需要终止,应该怎么做才能不用编写终结方法或者清除方法呢？只需让类实现AutoCloseable,并要求其客户端终止,即使遇到异常也是如此(详见第9条)。值得提及的一个细节是,该实例必须记录效”。如果这些方法是在对象已经终止之后被调用,其他的方法就必须检查这个域,并抛出IllegalStateException异常。\n那么终结方法和清除方法有什么好处呢？它们有两种合法用途。第一种用途是,当资源的所有者忘记调用它的close 方法时,终结方法或者清除方法可以充当”安全网”。虽然这样做并不能保证终结方法或者清除方法会被及时地运行,但是在客户端无法正常结束操作的情况下,迟一点释放资源总比永远不释放要好。如果考虑编写这样的安全网终结方法,就要认真考虑清楚,这种保护是否值得付出这样的代价。有些 Java 类(如 FileInputStream、FileOutputStream、ThreadPoolExecutor 和java.sql.Connection)都具有能充当安全网的终结方法。\n清除方法的第二种合理用途与对象的本地对等体(native peer)有关。本地对等体是一个本地(非 Java 的)对象(native object),普通对象通过本地方法(native method)委托给一个本地对象。因为本地对等体不是一个普通对象,所以垃圾回收器不会知道它,当它的Java 对等体被回收的时候,它不会被回收。如果本地对等体没有关键资源,并且性能也可以接受的话,那么清除方法或者终结方法正是执行这项任务最合适的工具。如果本地对等体拥有必须被及时终止的资源,或者性能无法接受,那么该类就应该具有一个 close 方法,如前所述。\n清除方法的使用有一定的技巧。下面以一个简单的 Room 类为例。假设房间在收回之前必须进行清除。Room 类实现了 AutoCloseable；它利用清除方法自动清除安全网的过程只不过是一个实现细节。与终结方法不同的是,清除方法不会污染类的公有API:\n//Anauto closeable class using a cleaner as a safety netpublicclass Room implements AutoCloseable&#123;    private static final Cleaner cleaner = Cleaner.create();    // Resource that requires cleaning.Must not refer to Room!    private static class State implements Runnable &#123;        int numJunkPiles;// Number of junk piles in this room                State(int numJunkPiles)&#123;            this.numJunkPiles = numJunkPiles;        &#125;                //Invoked by close method or cleaner        @Override public void run()&#123;            System.out.println(&quot;Cleaning room&quot;);            numJunkPiles = 0;        &#125;    &#125;        // The state of this room,shared with our cleanable    private final State state;                // Ourcleanable.Cleans theroom when it&#x27;s eligible for gc    private final Cleaner.Cleanable cleanable;                public Room(int numJunkPiles) &#123;        state = new State(numJunkPiles);        cleanable = cleaner.register(this, state);    &#125;    @Override public void closeO&#123;cleanable.clean();&#125;&#125;\n\n内嵌的静态类 State 保存清除方法清除房间所需的资源。在这个例子中,就是 num-JunkPiles 域,表示房间的杂乱度。更现实地说,它可以是final的long,包含一个指向本地对等体的指针。State 实现了 Runnable 接口,它的 run 方法最多被 Cleanable调用一次,后者是我们在 Room 构造器中用清除器注册 State 实例时获得的。以下两种情况之一会触发 run 方法的调用：通常是通过调用 Room 的 close 方法触发的,后者又调用了Cleanable 的清除方法。如果到了 Room实例应该被垃圾回收时,客户端还没有调用close 方法,清除方法就会(希望如此)调用 State 的 run 方法。\n关键是 State 实例没有引l用它的Room 实例。如果它引l用了,会造成循环,阻止 Room实例被垃圾回收(以及防止被自动清除)。因此 State必须是一个静态的嵌套类,因为非静态的嵌套类包含了对其外围实例的引l用(详见第 24条)。同样地,也不建议使用lambda,因为它们很容易捕捉到对外围对象的引用。\n如前所述,Room 的清除方法只用作安全网。如果客户端将所有的 Room 实例化都包在 try-with-resource 块中,将永远不会请求到自动清除。用下面这个表现良好的客户端代码示范一下:\npublic class Adult &#123;    public static void main (String [] args) &#123;         try (Room myRoom = new Room(7))&#123;            System.out.println(&quot;Goodbye&quot;);        &#125;    &#125;&#125;\n\n正如所期待的一样,运行 Adult 程序会打印出 Goodbye,接着是Cleaning room。但是下面这个表现糟糕的程序又如何呢？哪一个将永远不会清除它的房间？\npublic class Teenager&#123;    public static void main(String[]args)&#123;        new Room(99);        System.out.println(&quot;Peace out&quot;);    &#125;&#125;\n\n你可能期望打印出Peaceout,然后是Cleaning room,但是在我的机器上,它没有打印出 Cleaning room,就退出程序了。这就是我们之前提到过的不可预见性。Cleaner 规范指出：”清除方法在 System.exit期间的行为是与实现相关的。不确保清除动作是否会被调用。”虽然规范没有指明,其实对于正常的程序退出也是如此。在我的机器上,只要在Teenager 的main方法上添加代码行 System.gc(),就足以让它在退出之前打印出 Cleaning room,但是不能保证在你的机器上也能看到相同的行为。\n总而言之,除非是作为安全网,或者是为了终止非关键的本地资源,否则请不要使用清除方法,对于在Java 9之前的发行版本,则尽量不要使用终结方法。若使用了终结方法或者清除方法,则要注意它的不确定性和性能后果。\n第9条：try-with-resources优先于try-finallyJava 类库中包括许多必须通过调用 close 方法来手工关闭的资源。例如 InputStream、OutputStream和java.sql.Connection。客户端经常会忽略资源的关闭,造成严重的性能后果也就可想而知了。虽然这其中的许多资源都是用终结方法作为安全网,但是效果并不理想 (详见第8条)。\n根据经验,trY-finally语句是确保资源会被适时关闭的最佳方法,就算发生异常或者返回也一样：\n//try-finally-No longer the best way to close resources！static String firstLineOfFile(String path) throws IOException &#123;    BufferedReader br = new BufferedReader(new FileReader(path)) ;    try&#123;        return br.readLineO;    &#125; finally &#123;        br.close;    &#125;&#125;\n\n这看起来好像也不算太坏,但是如果再添加第二个资源,就会一团糟了：\n//try-finally isugly when used withmore than oneresource!static void copy(String src,String dst) throws IoException &#123;    InputStream in = new FileInputStream(src);    try &#123;        OutputStream out = new FileOutputStream(dst);        try &#123;            byte[] buf = new byte[BUFFER_SIZE];            int n;            while ((n = in.read(buf)) &gt;= 0)                out.write(buf, O, n);        &#125; finally &#123;            out.close();        &#125;    &#125; finally &#123;            in.close();    &#125;&#125;\n\n这可能令人有点难以置信,不过就算优秀的程序员也会经常犯这样的错误。起先,我曾经在《JavaPuzzlers》[Bloch05]第88页犯过这个错误,时隔多年竟然没有人发现。事实上,在 2007 年,close 方法在 Java 类库中有 2&#x2F;3 都用错了。\n即便用trY-finally语句正确地关闭了资源,如前两段代码范例所示,它也存在着些许不足。因为在try块和 finally块中的代码,都会抛出异常。例如,在firstLineOfFile方法中,如果底层的物理设备异常,那么调用readLine 就会抛出异常,基于同样的原因,调用 close 也会出现异常。在这种情况下,第二个异常完全抹除了第一个异常。在异常堆栈轨迹中,完全没有关于第一个异常的记录,这在现实的系统中会导致调试变得非常复杂,因为通常需要看到第一个异常才能诊断出问题何在。虽然可以通过编写代码来禁止第二个异常,保留第一个异常,但事实上没有人会这么做,因为实现起来太烦琐了。\n当Java 7引|人 try-with-resources 语句时[JLS,14.20.3],所有这些问题一下子就全部解决了。要使用这个构造的资源,必须先实现 AutoCloseable 接口,其中包含了单个返回 void 的close 方法。Java 类库与第三方类库中的许多类和接口,现在都实现或扩展了AutoCloseable接口。如果编写了一个类,它代表的是必须被关闭的资源,那么这个类也应该实现AutoCloseable。\n以下就是使用 try-with-resources 的第一个范例:\n//try-with-resources -the the best way to close resources!static String firstLineOfFile(String path) throws IOException &#123;    try (BufferedReader br = new BufferedReader(new FileReader(path))) &#123;        return br.readLine();    &#125;&#125;\n\n以下是使用 try-with-resources 的第二个范例:\n// try-with-resources on multiple resources - short and sweetstatic void copy(String src, String dst) throws IOException &#123;    try (InputStream  in = new FileInputStream(src);    OutputStream out = new FileOutputStream(dst)) &#123;        byte[] buf = new byte[BUFFER_SIZE];        int n;        while ((n = in.read(buf)) &gt;= 0)        out.write(buf, O, n);    &#125;&#125;\n\n使用 try-with-resources 不仅使代码变得更简洁易懂,也更容易进行诊断。以first-LineOfFile 方法为例,如果调用 readLine 和(不可见的)close 方法都抛出异常,后一个异常就会被禁止,以保留第一个异常。事实上,为了保留你想要看到的那个异常,即便多个异常都可以被禁止。这些被禁止的异常并不是简单地被抛弃了,而是会被打印在堆栈轨迹中,并注明它们是被禁止的异常。通过编程调用 getSuppressed 方法还可以访问到它们,getsuppressed 方法也已经添加在 Java 7的 Throwable 中了。\n在 try-with-resources 语句中还可以使用catch子句,就像在平时的try-finally语句中一样。这样既可以处理异常,又不需要再套用一层代码。下面举一个稍费了点心思的范例,这个 firstLineOfFile 方法没有抛出异常,但是如果它无法打开文件,或者无法从中读取,就会返回一个默认值:\n//try-with-resources with a catch clausestatic String firstLineOfFile(String path, String defaultVal)&#123;    try (BufferedReader br = new BufferedReader(new FileReader(path))) &#123;        return br.readLine();    &#125;catch (IOException e)&#123;        return defaultVal;    &#125;&#125;\n\n结论很明显：在处理必须关闭的资源时,始终要优先考虑用 try-with-resources,而不是用try-finally。这样得到的代码将更加简洁、清晰,产生的异常也更有价值。有了 try-with-resources 语句,在使用必须关闭的资源时,就能更轻松地正确编写代码了。实践证明,这个用try-finally是不可能做到的。\n第三章 对于所有对象都通用的方法尽管 Object 是一个具体类,但设计它主要是为了扩展。它所有的非 final方法(equals、hashCode、toString、clone 和finalize)都有明确的通用约定(general contract)因为它们设计成是要被覆盖(override)的。任何一个类,它在覆盖这些方法的时候,都有责任遵守这些通用约定；如果不能做到这一点,其他依赖于这些约定的类(例如HashMap和HashSet)就无法结合该类一起正常运作。\n本章将讲述何时以及如何覆盖这些非 final的 Object 方法。本章不再讨论 finalize方法,因为第8条已经讨论过这个方法了。而Comparable.compareTo虽然不是Object方法,但是本章也将对它进行讨论,因为它具有类似的特征。\n第10条：覆盖equals时请遵守通用约定覆盖équals方法看起来似乎很简单,但是有许多覆盖方式会导致错误,并且后果非常严重。最容易避免这类问题的办法就是不覆盖équals方法,在这种情况下,类的每个实例都只与它自身相等。如果满足了以下任何一个条件,这就正是所期望的结果：\n\n类的每个实例本质上都是唯一的。 对于代表活动实体而不是值（value）的类来说确实如此,例如 Thread。Object 提供的equals 实现对于这些类来说正是正确的行为。\n\n类没有必要提供”没有必要提供”逻辑相等”(logical equality)的测试功能。例如,java.util.regex.Pattern 可以覆盖 equals,以检查两个 Pattern 实例是否代表同一个正则表达式,但是设计者并不认为客户需要或者期望这样的功能。在这类情况之下,从 Object 继承得到的 equals 实现已经足够了。\n\n超类已经覆盖了equals,超类的行为对于这个类也是合适的。例如,大多数的Set 实现都从 AbstractSet 继承 equals 实现,List 实现从 AbstractList 继承 equals 实现,Map实现从 AbstractMap 继承equals 实现。\n\n类是私有的,或者是包级私有的,可以确定它的equals 方法永远不会被调用。如果你非常想要规避风险,可以覆盖équals方法,以确保它不会被意外调用：\n\n\n@Override public boolean equals(Object o)&#123;    throw new AssertionError();// Method is never &#125;\n\n那么,什么时候应该覆盖equals 方法呢？如果类具有自己特有的”逻辑相等”(logicalequality)概念(不同于对象等同的概念),而且超类还没有覆盖equals。这通常属于”值类”(value class)的情形。值类仅仅是一个表示值的类,例如Integer 或者 String。程序员在利用équals方法来比较值对象的引用时,希望知道它们在逻辑上是否相等,而不是想了解它们是否指向同一个对象。为了满足程序员的要求,不仅必须覆盖 équals 方法,而且这样做也使得这个类的实例可以被用作映射表(map)的键(key),或者集合(set)的元素,使映射或者集合表现出预期的行为。\n有一种”值类”不需要覆盖equals方法,即用实例受控(详见第1条)确保”每个值至多只存在一个对象”的类。枚举类型(详见第34条)就属于这种类。对于这样的类而言,逻辑相同与对象等同是一回事,因此 Object 的 équals 方法等同于逻辑意义上的equals方法。\n在覆盖équals方法的时候,必须要遵守它的通用约定。下面是约定的内容,来自Object的规范。\nequals 方法实现了等价关系(equivalence relation),其属性如下:\n\n自反性(reflexive)：对于任何非 null的引l用值×,X.equals(x)必须返回true。\n对称性(symmetric)：对于任何非 null 的引用值×和y,当且仅当y.equals(x)返回true时,x.equals(y)必须返回true。\n传递性(transitive)：对于任何非 null 的引l用值x、Y和 z,如果x.equals(y)返回true,并且.equals(z)也返回true,那么α.equals(z)也必须返回true。\n一致性(consistent)：对于任何非 null 的引用值x和Y,只要 equals 的比较操作在对象中所用的信息没有被修改,多次调用α.equals(y)就会一致地返回true,或者一致地返回false。\n对于任何非 null 的弓l用值×,X.equals(null)必须返回false。\n\n除非你对数学特别感兴趣,否则这些规定看起来可能有点让人感到恐惧,但是绝对不要忽视这些规定！如果违反了,就会发现程序将会表现得不正常,甚至崩溃,而且很难找到失败的根源。 用John Donne 的话说,没有哪个类是孤立的。 一个类的实例通常会被频繁地传递给另一个类的实例。 有许多类,包括所有的集合类（collection class）在内,都依赖于传递给它们的对象是否遵守了 equals 约定。递给它们的对象是否遵守了équals约定。\n现在你已经知道了违反équals约定有多么可怕,下面将更细致地讨论这些约定。值得欣慰的是,这些约定虽然看起来很吓人,实际上并不十分复杂。一旦理解了这些约定,要遵守它们并不困难。\n那么什么是等价关系呢？不严格地说,它是一个操作符,将一组元素划分到其元素与另一个元素等价的分组中。这些分组被称作等价类(equivalence class)。从用户的角度来看,对于有用的equals方法,每个等价类中的所有元素都必须是可交换的。现在我们按照顺序逐一查看以下5个要求。\n\n自反性(Reflexivity)—第一个要求仅仅说明对象必须等于其自身。很难想象会无意识地违反这一条。假如违背了这一条,然后把该类的实例添加到集合中,该集合的 contains方法将果断地告诉你,该集合不包含你刚刚添加的实例。\n\n对称性(Symmetry)—第二个要求是说,任何两个对象对于”它们是否相等”的问题都必须保持一致。与第一个要求不同,若无意中违反这一条,这种情形倒是不难想象。例如下面的类,它实现了一个区分大小写的字符串。字符串由toString 保存,但在equals操作中被忽略。\n\n\n// Broken - violates symmetry!public final class CaseInsensitiveString &#123;    private final String s;    public CaseInsensitiveString(String s) &#123;        this.s = Objects.requireNonNull(s);    &#125;        // Broken-violates symmetry!    @Override public boolean equals(Object o)&#123;        if (o instanceof CaseInsensitiveString)             return s.equalsIgnoreCase(                ((CaseInsensitiveString) o).s);            if(oinstanceof String)// One-wayinteroperability！            return s.equalsIgnoreCase((String) o);        return false;        &#125;        ...// Remainder omitted&#125;\n\n在这个类中,équals 方法的意图非常好,它企图与普通的字符串对象进行互操作。假设我们有一个不区分大小写的字符串和一个普通的字符串：\nCaseInsensitiveString cis = new CaseInsensitiveString(&quot;Polish&quot;);String s = &quot;polish&quot;;\n\n不出所料,cis.equals(s)返回true。问题在于,虽然CaseInsensitiveString类中的 equals 方法知道普通的字符串对象,但是,String 类中的 equals方法却并不知道不区分大小写的字符串。因此,s.equals(cis)返回false,显然违反了对称性。假设你把不区分大小写的字符串对象放到一个集合中：\nList&lt;CaseInsensitiveString&gt;list =new ArrayList&lt;&gt;();list.add(cis);\n\n此时list.contains(s)会返回什么结果呢？没人知道。在当前的OpenJDK实现中,它碰巧返回false,但这只是这个特定实现得出的结果而已。在其他的实现中,它有可能返回true,或者抛出一个运行时异常。一旦违反了 equals 约定,当其他对象面对你的对象时,你完全不知道这些对象的行为会怎么样。\n为了解决这个问题,只需把企图与 String互操作的这段代码从 équals 方法中去掉就可以了。这样做之后,就可以重构该方法,使它变成一条单独的返回语句：\n@Override public boolean equals(object o)&#123;    return o instanceof CaseInsensitiveString &amp;&amp;((CaseInsensitiveString) o).s.equalsIgnoreCase(s);&#125;\n\n\n传递性(Transitivity)一 -equals 约定的第三个要求是,如果一个对象等于第二个对象,而第二个对象又等于第三个对象,则第一个对象一定等于第三个对象。同样地,无意识地违反这条规则的情形也不难想象。用子类举个例子。假设它将一个新的值组件(valuecomponent)添加到了超类中。换句话说,子类增加的信息会影响équals 的比较结果。我们首先以一个简单的不可变的二维整数型Point类作为开始：\n\npublic class Point&#123;    private final int x;    private final int y;    public Point(int x,int y)&#123;        this.x=x;        this.y =y;    &#125;        @Override public boolean equals(Object o)&#123;        if (!(o instanceof Point))return false;        Point p = (Point)o;returnp.x==x&amp;&amp;p.y y//Remainder omitted    &#125;    ... //非卖品,仅供非商业用途或交流学习使用&#125;\n\n假设你想要扩展这个类,为一个点添加颜色信息：\npublic class ColorPoint extends Point&#123;    private final Color color;public ColorPoint(int x,int y,Color color)&#123;        super(x, y);this.color = color;//Remainder omitted    &#125;&#125;\n\nequals 方法会是什么样的呢？如果完全不提供 equals 方法,而是直接从 Point 继承过来,在équals 做比较的时候颜色信息就被忽略掉了。虽然这样做不会违反 équals约定,但很明显这是无法接受的。假设编写了一个équals 方法,只有当它的参数是另一个有色点,并且具有同样的位置和颜色时,它才会返回true:\n//Brolen-violatessymmetry！@Override public boolean equals(Object o)&#123;    if (!(o instanceof ColorPoint))        return false;    return super.equals(o) &amp;&amp; ((ColorPoint) o).color == color;&#125;\n\n这个方法的问题在于,在比较普通点和有色点,以及相反的情形时,可能会得到不同的结果。前一种比较忽略了颜色信息,而后一种比较则总是返回false,因为参数的类型不正确。为了直观地说明问题所在,我们创建一个普通点和一个有色点：\nPoint p=new Point(1,2);ColorPoint cp = new ColorPoint(1,2,Color.RED);\n\n然后,p.equals(cp)返回true,cp.equals(p)则返回false。你可以做这样的尝试来修正这个问题,让ColorPoint.equals 在进行”混合比较”时忽略颜色信息：\n//Brolen-violates transitivity！@Override public boolean equals(Object o)&#123;    if (!(o instanceof Point))return false;    //If o is a normal Point,do a color-blind comparison    if (!(o instanceof ColorPoint))return o.equals(this);        //oisaColorPoint;do afullcomparison    return super.equals(o)&amp;&amp;((ColorPoint)o).color==color;&#125;\n\n这种方法确实提供了对称性,但是却牺牲了传递性：\nColorPoint pl = new ColorPoint(1,2,Color.RED);Point p2 =new Point(l,2);ColorPoint p3 = new ColorPoint(1,2,Color.BLUE);\n\n此时,pl.equals(p2)和p2.equals(p3)都返回true,但是pl.equals(p3)则返回false,很显然这违反了传递性。前两种比较不考虑颜色信息(“色盲”),而第三种比较则考虑了颜色信息。\n此外,这种方法还可能导致无限递归问题：假设 Point 有两个子类,如ColorPoint和 SmellPoint,它们各自都带有这种 equals方法。那么对 myColorPoint.equals(mySmellPoint)的调用将会抛出 StackOverflowError异常。\n那该怎么解决呢？事实上,这是面向对象语言中关于等价关系的一个基本问题。我们无法在扩展可实例化的类的同时,既增加新的值组件,同时又保留eguals约定,除非愿意放弃面向对象的抽象所带来的优势。\n你可能听说过,在 equals 方法中用 getClass 测试代替 instanceof 测试,可以扩展可实例化的类和增加新的值组件,同时保留équals 约定：\n//Broken -violates Liskov substitution principle (page 43)@Override public boolean equals(Object o) &#123;    if(o ==nu11 || o.getClass() !=getClass())        return false;    Point p=(Point)o;    return p.x==x&amp;&amp;p.y=y;&#125;\n\n这段程序只有当对象具有相同的实现类时,才能使对象等同。虽然这样也不算太糟糕,但结果却是无法接受的：Point子类的实例仍然是一个 Point,它仍然需要发挥作用,但是如果采用了这种方法,它就无法完成任务！假设我们要编写一个方法,以检验某个点是否处在单位圆中。下面是可以采用的其中一种方法：\n// Initialize unitCircle to contain allPoints on the unit circleprivate static final Set&lt;Point&gt; unitCircle=Set.of(        new Point(1,0),new Point( 0,1),        new Point(-1,0),new Point(0,-1));public static boolean onUnitCircle(Point p)&#123;    return unitCircle.contains(p);&#125;\n\n虽然这可能不是实现这种功能的最快方式,不过它的效果很好。但是假设你通过某种不添加值组件的方式扩展了Point,例如让它的构造器记录创建了多少个实例:\npublic class CounterPoint extends Point&#123;    private static final AtomicInteger counter=new AtomicInteger();        public CounterPoint(int ×,int y)&#123;        super(x, y);        counter.incrementAndGetO;    &#125;    public static int numberCreated() &#123;        return counter.get();    &#125;&#125;\n\n里氏替换原则(Liskov substitution principle)认为,一个类型的任何重要属性也将适用于它的子类型,因此为该类型编写的任何方法,在它的子类型上也应该同样运行得很好[Liskov87]。针对上述Point的子类(如CounterPoint)仍然是Point,并且必须发挥作用的例子,这个就是它的正式语句。但是假设我们将 CounterPoint 实例传给了 onUnitCircle方法。如果 Point类使用了基于 getClass 的 equals方法,无论 CounterPoint实例的x和y值是什么,onUnitCircle方法都会返回 false。这是因为像 onUnitCircle 方法所用的HashSet这样的集合,利用equals方法检验包含条件,没有任何CounterPoint实例与任何 Point 对应。但是,如果在 Point 上使用适当的基于 instanceof 的 equals 方法,当遇到 CounterPoint 时,相同的 onUnitCircle 方法就会工作得很好。\n虽然没有一种令人满意的办法可以既扩展不可实例化的类,又增加值组件,但还是有一种不错的权宜之计：遵从第18条”复合优先于继承”的建议。我们不再让ColorPoint扩展Point,而是在ColorPoint 中加人一个私有的Point域,以及一个公有的视图(view)方法(详见第6条),此方法返回一个与该有色点处在相同位置的普通Point对象：\n//Adds a valuecomponent withoutviolating theequals contractpublic class ColorPoint&#123;    private final Point point;    private final Color color;    public ColorPoinit(int x,int y.Color color)&#123;        point = new Point(x,y);        this.color =Objects.requireNonNull(color);    &#125;    /**    * Returns the point-view of this color point.    */    public Point asPoint() &#123;        return point;    &#125;    @Override public boolean equals(Object o)&#123;        if (!(o instanceof ColorPoint))return false;        ColorPoint cp = (ColorPoint) o;        return cp.point.equals(point) &amp;&amp; cp.color.equals(color);    &#125;    ...    // Remainder omitted&#125;\n\n在 Java平台类库中,有一些类扩展了可实例化的类,并添加了新的值组件。例如,java.sql.Timestamp 对java.util.Date进行了扩展,并增加了 nanoseconds 域。Times-tamp 的 equals 实现确实违反了对称性,如果 Timestamp 和 Date 对象用于同一个集合中,或者以其他方式被混合在一起,则会引起不正确的行为。Timestamp 类有一个免责声明,告诫程序员不要混合使用 Date 和Timestamp 对象。只要你不把它们混合在一起,就不会有麻烦,除此之外没有其他的措施可以防止你这么做,而且结果导致的错误将很难调试。Timestamp 类的这种行为是个错误,不值得仿效。\n注意,你可以在一个抽象(abstract)类的子类中增加新的值组件且不违反equals 约定。对于根据第 23 条的建议而得到的那种类层次结构来说,这一点非常重要。例如,你可能有一个抽象的 Shape类,它没有任何值组件,Circle子类添加了一个 radius 域,Rectangle 子类添加了 length 和 width 域。只要不可能直接创建超类的实例,前面所述的种种问题就都不会发生。\n\n一致性(Consistency)—equals 约定的第四个要求是,如果两个对象相等,它们就必须始终保持相等,除非它们中有一个对象(或者两个都)被修改了。换句话说,可变对象在不同的时候可以与不同的对象相等,而不可变对象则不会这样。当你在写一个类的时候,应该仔细考虑它是否应该是不可变的(详见第 17条)。如果认为它应该是不可变的,就必须保证équals方法满足这样的限制条件：相等的对象永远相等,不相等的对象永远不相等。\n\n无论类是否是不可变的,都不要使équals 方法依赖于不可靠的资源。如果违反了这条禁令,要想满足一致性的要求就十分困难了。例如,java.net.URL的equals方法依赖于对URL中主机IP地址的比较。将一个主机名转变成IP地址可能需要访问网络,随着时间的推移,就不能确保会产生相同的结果,即有可能IP地址发生了改变。这样会导致URL équals 方法违反 equals 约定,在实践中有可能引l发一些问题。URL équals 方法的行为是一个大错误并且不应被模仿。遗憾的是,因为兼容性的要求,这一行为无法被改变。为了避免发生这种问题,equals方法应该对驻留在内存中的对象执行确定性的计算。\n\n非空性(Non-nulity)—最后一个要求没有正式名称,我姑且称它为”非空性”,意思是指所有的对象都不能等于null。尽管很难想象在什么情况下o.equals(null)调用会意外地返回 true,但是意外抛出 NullPointerException 异常的情形却不难想象。通用约定不允许抛出 NullPointerException 异常。许多类的equals 方法都通过一个显式的 null 测试来防止这种情况：\n\n@Override public boolean equals(Object o)&#123;    if(o ==nu11) return false;&#125;\n\n这项测试是不必要的。为了测试其参数的等同性,équals方法必须先把参数转换成适当的类型,以便可以调用它的访问方法,或者访问它的域。在进行转换之前,équals 方法必须使用 instanceof 操作符,检查其参数的类型是否正确：\n@Override public boolean equals(Object o)&#123;    if (!(o instanceof MyType))return false;    MyType mt =(MyType)o;    ...&#125;\n\n如果漏掉了这一步的类型检查,并且传递给équals方法的参数又是错误的类型,那么equals方法将会抛出 ClassCastException异常,这就违反了equals约定。但是,如果 instanceof 的第一个操作数为 null,那么,不管第二个操作数是哪种类型,instanceof 操作符都指定应该返回false[JLS,15.20.2]。因此,如果把 null 传给equals 方法,类型检查就会返回 false,所以不需要显式的 null 检查。\n结合所有这些要求,得出了以下实现高质量équals 方法的诀窍:\n\n使用&#x3D;&#x3D;操作符检查”参数是否为这个对象的引用”。如果是,则返回true。这只不过是一种性能优化,如果比较操作有可能很昂贵,就值得这么做。\n\n使用 instanceof 操作符检查”参数是否为正确的类型”。如果不是,则返回 false。一般说来,所谓”正确的类型”是指equals方法所在的那个类。某些情况下,是指该类所实现的某个接口。如果类实现的接口改进了équals 约定,允许在实现了该接口的类之间进行比较,那么就使用接口。集合接口如 Set、List、Map 和Map.Entr具有这样的特性。\n\n把参数转换成正确的类型。 因为转换之前进行过且stanceof测试,所以确保会成功。\n\n对于该类中的每个”关键”（ significant ）域,检查参数中的域是否与该对象中对应的域相匹配。如果这些测试全部成功,则返回true；否则返回 false。如果第 2 步中的类型是个接口,就必须通过接口方法访问参数中的域；如果该类型是个类,也许就能够直接访问参数中的域,这要取决于它们的可访问性。\n\n\n对于既不是float 也不是 double 类型的基本类型域,可以使用&#x3D;&#x3D;操作符进行比较;对于对象引用域,可以递归地调用equals方法；对于float域,可以使用静态Float.compare(float,float)方法;对于 double 域,则使用 Double.compare(double, double)。对 float 和 double 域进行特殊的处理是有必要的,因为存在着 Float.NaN、-0.Of 以及类似的 double 常量；详细信息请参考 JLS 15.21.1 或者 Float.equals 的文档。虽然可以用静态方法 Float.equals 和 Double.equals 对 float 和 double域进行比较,但是每次比较都要进行自动装箱,这会导致性能下降。对于数组域,则要把以上这些指导原则应用到每一个元素上。如果数组域中的每个元素都很重要,就可以使用其中一个Arrays.equals 方法。\n有些对象引用域包含 null可能是合法的,所以,为了避免可能导致NullPointerException 异常,则使用静态方法 Objects.equals(Object,Object)来检查这类域的等同性。\n对于有些类,比如前面提到的CaseInsensitiveString类,域的比较要比简单的等同性测试复杂得多。如果是这种情况,可能希望保存该域的一个”范式”canonical精确比较。这种方法对于不可变类(详见第17条)是最为合适的；如果对象可能发生变化,就必须使其范式保持最新。\n域的比较顺序可能会影响équals方法的性能。为了获得最佳的性能,应该最先比较最有可能不一致的域,或者是开销最低的域,最理想的情况是两个条件同时满足的域。不应该比较那些不属于对象逻辑状态的域,例如用于同步操作的Lock域。也不需要比较衍生域能提高 équals 方法的性能。如果衍生域代表了整个对象的综合描述,比较这个域可以节省在比较失败时去比较实际数据所需要的开销。例如,假设有一个 Polygon 类,并缓存了该面积。如果两个多边形有着不同的面积,就没有必要去比较它们的边和顶点。\n在编写完 equals 方法之后,应该问自己三个问题：它是否是对称的、传递的、一致的？并且不要只是自问,还要编写单元测试来检验这些特性,除非用AutoValue(后面会讲到)生成équals 方法,在这种情况下就可以放心地省略测试。如果答案是否定的,就要找出原因,再相应地修改 equals 方法的代码。当然,équals 方法也必须满足其他两个特性(自反性和非空性),但是这两种特性通常会自动满足。\n根据上面的诀窍构建equals方法的具体例子,请看下面这个简单的PhoneNumber类：\n// Class with a typical equals methodpublic final class PhoneNumber &#123;    private final short areaCode,prefix, lineNum;    public PhoneNumber(int areaCode,int prefix,int lineNum)&#123;        this.areaCode = rangeCheck(areaCode, 999,&quot;area code&quot;);        this.prefix = rangeCheck(prefix, 999,&quot;prefix&quot;);        this.lineNum m = rangeCheck(lineNum, 9999, &quot;line num&quot;);    &#125;        private static short rangeCheck(int val,int max, String arg)&#123;        if (val &lt; 0 ll val &gt;max)            throw new IllegalArgumentException(arg + &quot;:&quot;+ val);        return (short) val;    &#125;            @Override public boolean equals(Object o)&#123;        if (o ==this)            return true;        if (!(o instanceof PhoneNumber))            return false;        PhoneNumber pn = (PhoneNumber)o;        return pn.lineNum ==lineNum &amp;&amp; pn.prefix == prefix&amp;&amp; pn.areaCode == areaCode;    &#125;    ...// Remainder omitted&#125;\n\n下面是最后的一些告诫：\n\n覆盖equals时总要覆盖hashCode(详见第11条)。\n\n不要企图让 équals 方法过于智能。如果只是简单地测试域中的值是否相等,则不难做到遵守 équals 约定。如果想过度地去寻求各种等价关系,则很容易陷人麻烦之中。把任何一种别名形式考虑到等价的范围内,往往不会是个好主意。例如,File类不应该试图把指向同一个文件的符号链接(symbolic link)当作相等的对象来看待。所幸 File 类没有这样做。\n\n不要将 equals 声明中的 object 对象替换为其他的类型。程序员编写出下面这样的equals 方法并不鲜见,这会使程序员花上数个小时都搞不清为什么它不能正常工作:\n// Broken-parameter type must beObject!public boolean equals(MyClass o) &#123;    ...&#125;\n\n问题在于,这个方法并没有覆盖(override)Object.equals,因为它的参数应该是Object 类型,相反,它重载(overload)了Object.equals(详见第 52条)。在正常接受的,因为会导致子类中的 Override 注解产生错误的正值,带来错误的安全感。\n@Override注解的用法一致,就如本条目中所示,可以防止犯这种错误(详见第40条)。这个équals方法不能编译,错误消息会告诉你到底哪里出了问题：\n//Still broken,but won&#x27;t compile@Override publicboolean equals(MyClass o)&#123;    ...&#125;\n\n编写和测试equals(及hashCode)方法都是十分烦琐的,得到的代码也很琐碎。代替手工编写和测试这些方法的最佳途径,是使用Google开源的AutoValue框架,它会自动替你生成这些方法,通过类中的单个注解就能触发。在大多数情况下,AutoValue 生成的方法本质上与你亲自编写的方法是一样的。\nIDE也有工具可以生成equals 和hashCode方法,但得到的源代码比使用Auto-Value的更加冗长,可读性也更差,它无法自动追踪类中的变化,因此需要进行测试。也就是说,让IDE 生成 equals(及 hashCode)方法,通常优于手工实现它们,因为IDE 不会犯粗心的错误,但是程序员会犯错。\n总而言之,不要轻易覆盖équals方法,除非迫不得已。因为在许多情况下,从object 处继承的实现正是你想要的。如果覆盖équals,一定要比较这个类的所有关键域,并且查看它们是否遵守 équals 合约的所有五个条款。\n第11条：覆盖equals时总要覆盖hashCode在每个覆盖了equals 方法的类中,都必须覆盖hashCode 方法。如果不这样做的话,就会违反 hashCode 的通用约定,从而导致该类无法结合所有基于散列的集合一起正常运作,这类集合包括 HashMap 和 HashSet。下面是约定的内容,摘自 Object 规范:\n\n在应用程序的执行期间,只要对象的 équals 方法的比较操作所用到的信息没有被修改,那么对同一个对象的多次调用,hashCode方法都必须始终返回同一个值。在一个应用程序与另一个程序的执行过程中,执行hashCode方法所返回的值可以不一致。\n\n如果两个对象根据équals(Object)方法比较是相等的,那么调用这两个对象中的hashCode方法都必须产生同样的整数结果。\n\n如果两个对象根据équals(Object)方法比较是不相等的,那么调用这两个对象序员应该知道,给不相等的对象产生截然不同的整数结果,有可能提高散列表(hashtable)的性能。\n\n\n因没有覆盖hashCode而违反的关键约定是第二条：相等的对象必须具有相等的散列码(hash code)。根据类的 équals 方法,两个截然不同的实例在逻辑上有可能是相等的,但是根据 Object 类的 hashCode 方法,它们仅仅是两个没有任何共同之处的对象。因此,对象的 hashCode 方法返回两个看起来是随机的整数,而不是根据第二个约定所要求的那样,返回两个相等的整数。\n假设在HashMap中用第10条中出现过的PhoneNumber类的实例作为键：\nMap&lt;PhoneNumber, String&gt; m = new HashMap&lt;&gt;();m.put(new PhoneNumber(707, 867, 5309),&quot;Jenny&quot;);\n\n此时,你可能期望m.get(newPhoneNumber(707,867,5309))会返回”Jenny”,但它实际上返回的是 null。注意,这里涉及两个 PhoneNumber 实例：第一个被插入 HashMap中,第二个实例与第一个相等,用于从Map 中根据 PhoneNumber 去获取用户名字。由于PhoneNumber 类没有覆盖hashCode 方法,从而导致两个相等的实例具有不相等的散列码,违反了hashCode 的约定。因此,put方法把电话号码对象存放在一个散列桶(hashbucket)中,get方法却在另一个散列桶中查找这个电话号码。即使这两个实例正好被放到同一个散列桶中,get方法也必定会返回 null,因为 HashMap 有一项优化,可以将与每个项相关联的散列码缓存起来,如果散列码不匹配,也就不再去检验对象的等同性。\n修正这个问题非常简单,只需为PhoneNumber类提供一个适当的 hashCode方法即可。那么,hashCode方法应该是什么样的呢？编写一个合法但并不好用的 hashCode 方法没有任何价值。例如,下面这个方法总是合法的,但是它永远都不应该被正式使用：\n//The worst possiblelegal hashCode implementation-never use!@Override public int hashCode() &#123;return 42;&#125;\n\n上面这个hashCode 方法是合法的,因为它确保了相等的对象总是具有同样的散列码。但它也极为恶劣,因为它使得每个对象都具有同样的散列码。因此,每个对象都被映射到同一个散列桶中,使散列表退化为链表(linked list)。它使得本该线性时间运行的程序变成了以平方级时间在运行。对于规模很大的散列表而言,这会关系到散列表能否正常工作。\n一个好的散列函数通常倾向于”为不相等的对象产生不相等的散列码”。这正是hashCode 约定中第三条的含义。理想情况下,散列函数应该把集合中不相等的实例均匀地分布到所有可能的int值上。要想完全达到这种理想的情形是非常困难的。幸运的是,相对接近这种理想情形则并不太困难。下面给出一种简单的解决办法：\n\n声明一个 int 变量并命名为 result,将它初始化为对象中第一个关键域的散列码c,如步骤 2.a 中计算所示(如第 10条所述,关键域是指影响 equals 比较的域)。\n\n对象中剩下的每一个关键域f都完成以下步骤：\n\n为该域计算 int 类型的散列码 c:\n\n如果该域是基本类型,则计算 Type.hashCode(f),这里的 Type 是装箱基本类型的类,与f 的类型相对应。\n如果该域是一个对象引用,并且该类的 equals 方法通过递归地调用 equals的方式来比较这个域,则同样为这个域递归地调用 hashCode。如果需要更复杂的比较,则为这个域计算一个”范式”(canonicalrepresentation),然后针对这个范式调用hashCode。如果这个域的值为 null,则返回O(或者其他某个常数,但通常是0)。\n如果该域是一个数组,则要把每一个元素当作单独的域来处理。也就是说,递归地应用上述规则,对每个重要的元素计算一个散列码,然后根据步骤2.b中的做法把这些散列值组合起来。如果数组域中没有重要的元素,可以使用一个常量,但最好不要用0。如果数组域中的所有元素都很重要,可以使用Arrays.hashCode 方法。\n\n\n按照下面的公式,把步骤 2.a 中计算得到的散列码c 合并到 result 中:\n result = 31 * result + C;\n\n\n返回result。\n\n\n写完了hashCode 方法之后,问问自己”相等的实例是否都具有相等的散列码”。要编写单元测试来验证你的推断(除非利用AutoValue 生成 equals 和hashCode方法,这样你就可以放心地省略这些测试)。如果相等的实例有着不相等的散列码,则要找出原因,并修正错误。\n在散列码的计算过程中,可以把衍生域(derived field)排除在外。换句话说,如果一个域的值可以根据参与计算的其他域值计算出来,则可以把这样的域排除在外。必须排除equals 比较计算中没有用到的任何域,否则很有可能违反 hashCode 约定的第二条。\n步骤2.b中的乘法部分使得散列值依赖于域的顺序,如果一个类包含多个相似的域,这样的乘法运算就会产生一个更好的散列函数。例如,如果 String 散列函数省略了这个乘法部分,那么只是字母顺序不同的所有字符串将都会有相同的散列码。之所以选择31,是因为它是一个奇素数。如果乘数是偶数,并且乘法溢出的话,信息就会丢失,因为与2相乘等价于移位运算。使用素数的好处并不很明显,但是习惯上都使用素数来计算散列结果。31有个很好的特性,即用移位和减法来代替乘法,可以得到更好的性能：31＊i&#x3D;&#x3D;(i〈&lt; 5)－i。现代的虚拟机可以自动完成这种优化。\n现在我们要把上述解决办法用到 PhoneNumber类中:\n// Typical hashCode method@Override public int hashCodeO &#123;    int result = Short.hashCode(areaCode);    result = 31 * result + Short.hashCode(prefix);    result = 31 * result + Short.hashCode(lineNum);    return result;&#125;\n\n因为这个方法返回的结果是一个简单、确定的计算结果,它的输人只是PhoneNumber对于 PhoneNumber 的 hashCode 实现而言,上面这个方法是非常合理的,相当于 Java 平台类库中的实现。它的做法非常简单,也相当快捷,恰当地把不相等的电话号码分散到不同的散列桶中。\n虽然本条目中前面给出的hashCode 实现方法能够获得相当好的散列函数,但它们并不是最先进的。它们的质量堪比Java 平台类库的值类型中提供的散列函数,这些方法对于绝大多数应用程序而言已经足够了。如果执意想让散列函数尽可能地不会造成冲突,请参阅Guava’s com.google.common.hash.Hashing [Guava]。\nObjects 类有一个静态方法,它带有任意数量的对象,并为它们返回一个散列码。这过的解决方案编写出来的相比,它的质量是与之相当的。遗憾的是,运行速度更慢一些,因为它们会引发数组的创建,以便传人数目可变的参数,如果参数中有基本类型,还需要装箱和拆箱。建议只将这类散列函数用于不太注重性能的情况。下面就是用这种方法为PhoneNumber 编写的散列函数:\n// One-line hashCode method - mediocre performance@Override public int hashCode() &#123;    return Objects.hash(lineNum,prefix,areaCode);&#125;\n\n如果一个类是不可变的,并且计算散列码的开销也比较大,就应该考虑把散列码缓存在对象内部,而不是每次请求的时候都重新计算散列码。如果你觉得这种类型的大多数对象会被用作散列键(hash keys),就应该在创建实例的时候计算散列码。否则,可以选择”延迟初始化”(lazily initialize)散列码,即一直到hashCode 被第一次调用的时候才初始化(见第 83条)。虽然我们的 PhoneNumber 类不值得这样处理,但是可以通过它来说明这种方法该如何实现。注意hashCode 域的初始值(在本例中是O)一般不能成为创建的实例的散列码:\n//hashCode method with lazily initialized cached hash codeprivate int hashCode;// Automatically initialized to 0@Override public int hashCode()&#123;    int result = hashCode;    if(result ==0)&#123;        result = Short.hashCode(areaCode);        result = 31 * result + Short.hashCode(prefix);        result = 31 * result + Short.hashCode(lineNum);        hashCode =result;    &#125;    return result;&#125;\n\n不要试图从散列码计算中排除掉一个对象的关键域来提高性能。虽然这样得到的散列函数运行起来可能更快,但是它的效果不见得会好,可能会导致散列表慢到根本无法使用。特别是在实践中,散列函数可能面临大量的实例,在你选择忽略的区域之中,这些实例仍然区别非常大。如果是这样,散列函数就会把所有这些实例映射到极少数的散列码上,原本应该以线性级时间运行的程序,将会以平方级的时间运行。\n这不只是一个理论问题。在Java 2 发行版本之前,一个 String 散列函数最多只能使用 16个字符,若长度少于16个字符就计算所有的字符,否则就从第一个字符开始,在整个函数正好表现出了这里所提到的病态行为。\n不要对hashCode方法的返回值做出具体的规定,因此客户端无法理所当然地依赖它；这样可以为修改提供灵活性。Java 类库中的许多类,比如 String 和Integer,都可以把它们的 hashCode 方法返回的确切值规定为该实例值的一个函数。一般来说,这并不是个好主意,因为这样做严格地限制了在未来的版本中改进散列函数的能力。如果没有规定散列函数的细节,那么当你发现了它的内部缺陷时,或者发现了更好的散列函数时,就可以在后面的发行版本中修正它。\n总而言之,每当覆盖 equals 方法时都必须覆盖 hashCode,否则程序将无法正确运行。hashCode 方法必须遵守 Object 规定的通用约定,并且必须完成一定的工作,将不相等的散列码分配给不相等的实例。这个很容易实现,但是如果不想那么费力,也可以使用前文建议的解决方法。如第 10条所述,AutoValue 框架提供了很好的替代方法,可以不必手工编写 equals 和hashCode 方法,并且现在的集成开发环境IDE 也提供了类似的部分功能。\n第12条：始终要覆盖toString虽然 Object 提供了toString 方法的一个实现,但它返回的字符串通常并不是类的用户所期望看到的。它包含类的名称,以及一个”@”符号,接着是散列码的无符号十六进制表示法,例如 PhoneNumber@163b91。toString 的通用约定指出,被返回的字符串应该是一个”简洁的但信息丰富,并且易于阅读的表达形式”。尽管有人认为PhoneNumber@163b91算得上是简洁和易于阅读了,但是与707-867-5309比较起来,它还算不上是信息丰富的。toString 约定进一步指出,”建议所有的子类都覆盖这个方法。”这是一个很好的建议,真的！\n遵守toString 约定并不像遵守equals和hashCode 的约定(见第10条和第 1l条)那么重要,但是,提供好的toString实现可以使类用起来更加舒适,使用了这个类的系统也更易于调试。当对象被传递给 println、printf、字符串联操作符(+)以及 assert,或者被调试器打印出来时,toString 方法会被自动调用。即使你永远不调用对象的toString方法,但是其他人也许可能需要。例如,带有对象引用的一个组件,在它记录的错误消息中,可能包含该对象的字符串表示法。如果你没有覆盖toString,这条消息可能就毫无用处。\n如果为 PhoneNumber 提供了好的toString 方法,那么要产生有用的诊断消息会非常容易：\nSystem.out.println(&quot;Failed to connect to &quot; + phoneNumber);\n不管是否覆盖了toString 方法,程序员都将以这种方式来产生诊断消息,但是如果没有覆盖toString 方法,产生的消息将难以理解。提供好的toString 方法,不仅有益于这个类的实例,同样也有益于那些包含这些实例的引用的对象,特别是集合对象。打印Map时会看到消息{Jenny&#x3D;PhoneNumber@163b91}或{Jenny&#x3D;707-867-5309},你更愿意看到哪一个？\n**在实际应用中,toString方法应该返回对象中包含的所有值得关注的信息,**例如上述电话号码例子那样。如果对象太大,或者对象中包含的状态信息难以用字符串来表达,这样做就有点不切实际。在这种情况下,toString 应该返回一个摘要信息,例如”Manhattanresidential phone directory(1487536 listings)” 或者 “Thread[main, 5,main]”。理想情况下,字符串应该是自描述的(self-explanatory)。(Thread 例子不满足这样的要求。)如果对象的字符串表示法中没有包含对象的所有必要信息,测试失败时得到的报告将会像下面这样：\nAssertion failure: expected &#123;abc,123&#125;,but was &#123;abc,123&#125;\n在实现toString 的时候,必须要做出一个很重要的决定：是否在文档中指定返回值的格式。对于值类(value class),比如电话号码类、矩阵类,建议这么做。指定格式的好处是,它可以被用作一种标准的、明确的、适合人阅读的对象表示法。这种表示法可以用于输入和输出,以及用在永久适合人类阅读的数据对象中,例如CSV文档。如果你指定了格式,通常最好再提供一个相匹配的静态工厂或者构造器,以便程序员可以很容易地在对象及其字符串表示法之间来回转换。Java平台类库中的许多值类都采用了这种做法,包括BigInteger、BigDecimal 和绝大多数的基本类型包装类(boxed primitive class)。\n指定toString 返回值的格式也有不足之处：如果这个类已经被广泛使用,一旦指定格式,就必须始终如一地坚持这种格式。程序员将会编写出相应的代码来解析这种字符串表示法、产生字符串表示法,以及把字符串表示法嵌人持久的数据中。如果将来的发行版本中改变了这种表示法,就会破坏他们的代码和数据,他们当然会抱怨。如果不指定格式,就可以保留灵活性,便于在将来的发行版本中增加信息,或者改进格式。\n无论是否决定指定格式,都应该在文档中明确地表明你的意图。如果要指定格式,则应该严格地这样去做。例如,下面是第 11 条中 PhoneNumber 类的toString 方法:\n\n如果你决定不指定格式,那么文档注释部分也应该有如下所示的指示信息：\n/** * Returns a brief description of this potion.The exact details * of the rep resentation are unspecified and subject to change, * but the following may be regarded as typical: *  * &quot;[Potion #9: type=love, smell=turpentine, look=india ink]&#x27; */ @Override public String toStringO &#123;...&#125;\n\n对于那些依赖于格式的细节进行编程或者产生永久数据的程序员,在读到这段注释之后,一旦格式被改变,则只能自己承担后果。\n无论是否指定格式,都为toString返回值中包含的所有信息提供一种可以通过编程访问之的途径。例如,PhoneNumber 类应该包含针对 area code、prefix 和 line number 的访问方法。如果不这么做,就会迫使需要这些信息的程序员不得不自己去解析这些字符串。除了降低了程序的性能,使得程序员们去做这些不必要的工作之外,这个解析过程也很容易出错,会导致系统不稳定,如果格式发生变化,还会导致系统崩溃。如果没有提供这些访问方法,即使你已经指明了字符串的格式是会变化的,这个字符串格式也成了事实上的API。\n在静态工具类(详见第4条)中编写toString方法是没有意义的。也不要在大多数枚举类型(详见第34条)中编写toString方法,因为Java 已经为你提供了非常完美的方法。但是,在所有其子类共享通用字符串表示法的抽象类中,一定要编写一个toString方法。例如,大多数集合实现中的toString方法都是继承自抽象的集合类。\n在第10条中讨论过的Google公司开源的AutoValue工具,会替你生成toString方但是并不特定于该类的意义(meaning)。因此,比如对于上述 PhoneNumber 类就不适合用自动生成的toString方法(因为电话号码有标准的字符串表示法),但是我们的Potion类就非常适合。也就是说,自动生成的toString 方法要远远优先于继承自 Object 的方法,因为它无法告诉你任何关于对象值的信息。\n总而言之,要在你编写的每一个可实例化的类中覆盖Object 的toString实现,除非已经在超类中这么做了。这样会使类使用起来更加舒适,也更易于调试。toString 方法应该以美观的格式返回一个关于对象的简洁、有用的描述。\n第13条：谨慎地覆盖cloneCloneable 接口的目的是作为对象的一个mixin接口(mixin interface) (详见第 20条),表明这样的对象允许克隆(clone)。遗憾的是,它并没有成功地达到这个目的。它的主要缺陷在于缺少一个 clone 方法,而 Object 的 clone 方法是受保护的。如果不借助于反射(reflection)(详见第 65条),就不能仅仅因为一个对象实现了Cloneable,就调用clone方法。即使是反射调用也可能会失败,因为不能保证该对象一定具有可访问的clone 方法。尽管存在这样或那样的缺陷,这项设施仍然被广泛使用,因此值得我们进一步了解。本条目将告诉你如何实现一个行为良好的clone 方法,并讨论何时适合这样做,同时也简单地讨论了其他的可替代做法。\n既然Cloneable 接口并没有包含任何方法,那么它到底有什么作用呢？它决定了 Object中受保护的 clone 方法实现的行为：如果一个类实现了Cloneable,Object 的 clone这是接口的一种极端非典型的用法,也不值得仿效。通常情况下,实现接口是为了表明类可以为它的客户做些什么。然而,对于Cloneable接口,它改变了超类中受保护的方法的行为。\n虽然规范中没有明确指出,事实上,实现Cloneable接口的类是为了提供一个功能适当的公有的 clone 方法。为了达到这个目的,类及其所有超类都必须遵守一个相当复杂的、不可实施的,并且基本上没有文档说明的协议。由此得到一种语言之外的(extralinguistic)机制：它无须调用构造器就可以创建对象。\nclone 方法的通用约定是非常弱的,下面是来自 Object 规范中的约定内容:\n创建和返回该对象的一个拷贝。这个”拷贝”的精确含义取决于该对象的类。一般的含义是,对于任何对象X,表达式\nx.clone() != x\n\n将会返回结果true,并且表达式\nx.clone().getClass( == x.getClass()\n\n将会返回结果true,但这些都不是绝对的要求。虽然通常情况下,表达式\nx.clone().equals(x)\n将会返回结果true,但是,这也不是一个绝对的要求。\n按照约定,这个方法返回的对象应该通过调用 super.clone 获得。如果类及其超类(Object除外)遵守这一约定,那么：\nx.clone().getClass() == x.getClass()\n\n按照约定,返回的对象应该不依赖于被克隆的对象。为了成功地实现这种独立性,可能需要在 super.clone 返回对象之前,修改对象的一个或更多个域。\n这种机制大体上类似于自动的构造器调用链,只不过它不是强制要求的：如果类的clone方法返回的实例不是通过调用 super.clone 方法获得,而是通过调用构造器获得,编译器就不会发出警告,但是该类的子类调用了super.clone方法,得到的对象就会拥有错误的类,并阻止了clone 方法的子类正常工作。如果 final类覆盖了clone 方法,那么这个约定可以被安全地忽略,因为没有子类需要担心它。如果 fi nal类的 clone 方法没有调用 super.clone 方法,这个类就没有理由去实现Cloneable 接口了,因为它不依赖于Object 克隆实现的行为。\n假设你希望在一个类中实现 Cloneable 接口,并且它的超类都提供了行为良好的 clone方法。首先,调用 super.clone 方法。由此得到的对象将是原始对象功能完整的克隆(clone)。在这个类中声明的域将等同于被克隆对象中相应的域。如果每个域包含一个基本类型的值,或者包含一个指向不可变对象的引用,那么被返回的对象则可能正是你所需要的对象,在这种情况下不需要再做进一步处理。例如,第11条中的 PhoneNumber 类正是如此,但要注意,不可变的类永远都不应该提供clone 方法,因为它只会激发不必要的克隆。因此,PhoneNumber的clone方法应该是这样的：\n//Clonemethodforclass withnoreferencestomutablestate@Override public PhoneNumber clone() &#123;    try &#123;        return (PhoneNumber) super.clone;    &#125; catch (CloneNotSupportedException e) &#123;        throw new AssertionError();// Can&#x27;t happen    &#125;&#125;\n\n为了让这个方法生效,应该修改 PhoneNumber 的类声明为实现Cloneable接口。虽然Object的clone方法返回的是Object,但这个clone方法返回的却是PhoneNumber。这么做是合法的,也是我们所期望的,因为 Java 支持协变返回类型(covariant return type)。换句话说,目前覆盖方法的返回类型可以是被覆盖方法的返回类型的子类了。这样在客户端中就不必进行转换了。我们必须在返回结果之前,先将 super.clone 从 Object转换成PhoneNumber,当然这种转换是一定会成功的。\n对 super.clone 方法的调用应当包含在一个try-catch 块中。这是因为Object声明其clone 方法抛出 CloneNotSupportedException,这是一个受检异常(checkedexception)。由于 PhoneNumber实现了Cloneable 接口,我们知道调用 super.clone方法一定会成功。对于这个样板代码的需求表明,CloneNotSupportedException 应该还没有被检查到(详见第71条)。\n如果对象中包含的域引用了可变的对象,使用上述这种简单的clone实现可能会导致灾难性的后果。例如第7条中的 Stack类:\npublic class Stack &#123;    private Object[] elements;    private int size = 0;    private Static final int DEFAULT_INITIAL_CAPACITY = 16;    public Stack() &#123;        this.elements = new Object[DEFAULT_INITIAL_CAPACITY];    &#125;    public void push(Object e) &#123;        ensureCapacity();        elements[size++] = e;    &#125;    public Object pop()&#123;        if (size == 0)            throw new EmptyStackException();        Object result =elements[--size];        elements[size]= null;        // Eliminate obsolete reference        return result;    &#125;    //Ensure space for at least one more element    private void ensureCapacity() &#123;        if (elements.length == size)elements =Arrays.copyOf(elements,2 * size + 1);    &#125;&#125;\n假设你希望把这个类做成可克隆的(cloneable)。如果它的clone 方法仅仅返回 super.clone(),这样得到的 Stack 实例,在其 size 域中具有正确的值,但是它的elements域将引用与原始Stack实例相同的数组。修改原始的实例会破坏被克隆对象中的约束条件,反之亦然。很快你就会发现,这个程序将产生毫无意义的结果,或者抛出Nu11-PointerException 异常。\n如果调用 Stack类中唯一的构造器,这种情况就永远不会发生。实际上,clone 方法就是另一个构造器；必须确保它不会伤害到原始的对象,并确保正确地创建被克隆对象中的约束条件(invariant)。为了使 Stack类中的clone 方法正常工作,它必须要拷贝栈的内部信息。最容易的做法是,在elements 数组中递归地调用 clone:\n// Clone method for class with references to mutable state@Override public Stack clone() &#123;    try &#123;        Stack result = (Stack) super.clone();        result.elements = elements.clone();        return result;    &#125;catch (CloneNotSupportedException e) &#123;        throw new AssertionError();    &#125;&#125;\n\n注意,我们不一定要将elements.clone()的结果转换成 Object[]。在数组上调用clone 返回的数组,其编译时的类型与被克隆数组的类型相同。这是复制数组的最佳习惯做法。事实上,数组是clone 方法唯一吸引l人的用法。\n还要注意如果 elements 域是 final 的,上述方案就不能正常工作,因为 clone 方法是被禁止给 final 域赋新值的。这是个根本的问题：就像序列化一样,**Cloneable 架构与引用可变对象的final域的正常用法是不相兼容的,**除非在原始对象和克隆对象之间可以安全地共享此可变对象。为了使类成为可克隆的,可能有必要从某些域中去掉 final 修饰符。它的内部数据包含一个散列桶数组,每个散列桶都指向”键－值”对链表的第一项。出于性能方面的考虑,该类实现了它自己的轻量级单向链表,而没有使用Java 内部的java.util.LinkedList:\npublic class HashTable implements Cloneable &#123;    private Entry[] buckets =...;    private static class Entry &#123;        final Object key;        Object value;        Entry next;        Entry(Object key,Object value,Entry next) &#123;            this.key =key;this.value = value;this.next =next;        &#125;    &#125;        ...    // Remainder omitted&#125;\n\n假设你仅仅递归地克隆这个散列桶数组,就像我们对 Stack类所做的那样：\n//Broken clone method-results in shared mutable state!@Override public HashTable clone()&#123;    try&#123;        HashTable result = (HashTable) super.clone();        result.buckets = buckets.clone();        return result;    &#125; catch (CloneNotSupportedException e) &#123;        throw new AssertionError();    &#125;&#125;\n\n虽然被克隆对象有它自己的散列桶数组,但是,这个数组引用的链表与原始对象是一样的,从而很容易引起克隆对象和原始对象中不确定的行为。为了修正这个问题,必须单独地拷贝并组成每个桶的链表。下面是一种常见的做法：\n//Recursive clone method for class with complex mutable statepublic class HashTable implements Cloneable &#123;    private Entry[] buckets =...;    private static class Entry &#123;        final Object key;        Object value;        Entry next;        Entry(Object key,Object value,Entry next)&#123;            this.key =key;            this.value = value;            this.next = next;        &#125;        // Recursively copy the linked list headed by this Entry        Entry deepCopy()&#123;            return new Entry(key, value,next == null ? null : next.deepCopy());        &#125;    &#125;&#125;@Override public HashTable clone() &#123;    try&#123;        HashTable result = (HashTable) super.clone();        result.buckets = new Entry[buckets.length];        for (int i = 0;i &lt; buckets.length;i++)            if (buckets[i] != null)                result.buckets[i]= buckets[i].deepCopy() ;            return result;    &#125;catch (CloneNotSupportedException e) &#123;            throw new AssertionErrorO;    &#125;    ...// Remainder omitted&#125;\n\n私有类HashTable.Entry 被加强了,它支持一个”深度拷贝”(deep copy)方法。HashTable上的clone 方法分配了一个大小适中的、新的buckets 数组,并且遍历原始的buckets 数组,对每一个非空散列桶进行深度拷贝。Entry类中的深度拷贝方法递归地调用它自身,以便拷贝整个链表(它是链表的头节点)。虽然这种方法很灵活,如果散列桶不是很长,也会工作得很好,但是,这样克隆一个链表并不是一种好办法,因为针对列表中的每个元素,它都要消耗一段栈空间。如果链表比较长,这很容易导致栈溢出。为了避免发生这种情况,你可以在deepCopy方法中用迭代(iteration)代替递归(recursion):\n// Iteratively copy the linked list headed by this EntryEntry deepCopy()&#123;    Entry result = new Entry(key,value, next);    for (Entry p = result; p.next != null; p = p.next)        p.next = new Entry(p.next.key, p.next.value, p.next.next);        return result;&#125;\n\n克隆复杂对象的最后一种办法是,先调用 super.clone 方法,然后把结果对象中的所有域都设置成它们的初始状态(initial state),然后调用高层(higher-level)的方法来重新产生对象的状态。在我们的HashTable例子中,buckets 域将被初始化为一个新的散列桶数组,然后,对于正在被克隆的散列表中的每一个键－值映射,都调用put(keY,value)方法(上面没有给出其代码)。这种做法往往会产生一个简单、合理且相当优美的方法”快。虽然这种方法干脆利落,但它与整个Cloneable架构是对立的,因为它完全抛弃了 Cloneable 架构基础的逐域对象复制的机制。\n像构造器一样,clone方法也不应该在构造的过程中,调用可以覆盖的方法(详见第19条)。如果clone 调用了一个在子类中被覆盖的方法,那么在该方法所在的子类有机会修正它在克隆对象中的状态之前,该方法就会先被执行,这样很有可能会导致克隆对象和原始对象之间的不一致。因此,上一段中讨论到的 put(keY,Value)方法要么应是final的,要么应是私有的。(如果是私有的,它应该算是非 final公有方法的”辅助方法”。)\nObject的clone方法被声明为可抛出 CloneNotSupportedException异常,但是,覆盖版本的 clone 方法可以忽略这个声明。公有的 clone 方法应该省略throws 声明,因为不会抛出受检异常的方法使用起来更加轻松(详见第71条)。\n为继承(详见第19条)设计类有两种选择,但是无论选择其中的哪一种方法,这个类可以使子类具有实现或不实现cloneable接口的自由,就仿佛它们直接扩展了Object一样。或者,也可以选择不去实现一个有效的clone方法,并防止子类去实现它,只需要提供下列退化了的clone实现即可:\n//clone method for extendable class not supporting Cloneable@Override protected final Object clone() throws CloneNotSupportedException &#123;    throw  new CloneNotSupportedException();&#125;\n\n还有一点值得注意。如果你编写线程安c全的类准备实现Cloneable接口,要记住它的clone 方法必须得到严格的同步,就像任何其他方法一样(详见第 78 条)。Object的 clone 方法没有同步,即使很满意可能也必须编写同步的 clone 方法来调用 super.clone(),即实现 synchronized clone()方法。\n简而言之,所有实现了 Cloneable 接口的类都应该覆盖 clone 方法,并且是公有的方法,它的返回类型为类本身。该方法应该先调用 super.clone 方法,然后修正任何需要修正的域。一般情况下,这意味着要拷贝任何包含内部”深层结构”的可变对象,并用指向新对象的引用代替原来指向这些对象的引用。虽然,这些内部拷贝操作往往可以通过递归地调用clone 来完成,但这通常并不是最佳方法。如果该类只包含基本类型的域,或者指向不可变对象的引用,那么多半的情况是没有域需要修正。这条规则也有例外。例如,代表序列号或其他唯一ID值的域,不管这些域是基本类型还是不可变的,它们也都需要被修正。\n真的有必要这么复杂吗？很少有这种必要。如果你扩展一个实现了Cloneable接口的类,那么你除了实现一个行为良好的clone 方法外,没有别的选择。否则,最好提供某些其他的途径来代替对象拷贝。**对象拷贝的更好的办法是提供一个拷贝构造器(copyconstructor)或拷贝工厂(copy factory)**。拷贝构造器只是一个构造器,它唯一的参数类型是包含该构造器的类,例如：\n//Copy constructorpublic Yum(Yum yum) &#123; ... &#125;;\n\n拷贝工厂是类似于拷贝构造器的静态工厂(详见第1条)：\n//Copyfactorypublic static Yum newInstance(Yum yum) &#123; ...&#125;;\n\n拷贝构造器的做法,及其静态工厂方法的变形,都比 Cloneable&#x2F;clone 方法具有更多的优势：它们不依赖于某一种很有风险的、语言之外的对象创建机制；它们不要求遵守尚未制定好文档的规范；它们不会与final域的正常使用发生冲突；它们不会抛出不必要的受检异常；它们不需要进行类型转换。\n甚至,拷贝构造器或者拷贝工厂可以带一个参数,参数类型是该类所实现的接口。例如,按照惯例所有通用集合实现都提供了一个拷贝构造器,其参数类型为Collection 或者Map接口。基于接口的拷贝构造器和拷贝工厂(更准确的叫法应该是转换构造器(conversionconstructor)和转换工厂(conversion factory)),允许客户选择拷贝的实现类型,而不是强迫客户接受原始的实现类型。例如,假设你有一个HashSet:S,并且希望把它拷贝成一个TreeSet。clone 方法无法提供这样的功能,但是用转换构造器很容易实现：newTreeSet&lt;&gt;(s)。\n既然所有的问题都与Cloneable接口有关,新的接口就不应该扩展这个接口,新的这个应该被视同性能优化,留到少数必要的情况下才使用(详见第67条)。总之,复制功能最好由构造器或者工厂提供。这条规则最绝对的例外是数组,最好利用clone 方法复制数组。\n第14条：考虑实现Comparable接口与本章中讨论的其他方法不同,compareTo 方法并没有在 Object类中声明。相反,它是Comparable接口中唯一的方法。compareTo方法不但允许进行简单的等同性比较,而且允许执行顺序比较,除此之外,它与 Object 的equals 方法具有相似的特征,它还是个泛型(generic)。类实现了Comparable接口,就表明它的实例具有内在的排序关系(natural ordering)。为实现Comparable 接口的对象数组进行排序就这么简单:\nArrays.sort(a) ;\n对存储在集合中的Comparable对象进行搜索、计算极限值以及自动维护也同样简单。例如,下面的程序依赖于实现了Comparable接口的 String 类,它去掉了命令行参数列表中的重复参数,并按字母顺序打印出来：\npublic class WordList&#123;    public static void main(String[] args) &#123;        Set&lt;String&gt; s = new TreeSet&lt;&gt;();        Collections.addAll(s, args);        System.out.println(s) ;    &#125;&#125;\n\n一旦类实现了Comparable 接口,它就可以跟许多泛型算法(generic algorithm)以及依赖于该接口的集合实现(collection implementation)进行协作。你付出很小的努力就可以获得非常强大的功能。事实上,Java平台类库中的所有值类(value classes),以及所有的枚举类型(详见第 34条)都实现了Comparable 接口。如果你正在编写一个值类,它具有非常明显的内在排序关系,比如按字母顺序、按数值顺序或者按年代顺序,那你就应该坚决考虑实现Comparable接口:\npublic interface Comparable&lt;T&gt;&#123;    int compareTo(T t);&#125;\n\ncompareTo 方法的通用约定与 equals 方法的约定相似:\n将这个对象与指定的对象进行比较。当该对象小于、等于或大于指定对象的时候,比较,则抛出 ClassCastException 异常。\n在下面的说明中,符号sgn(expression)表示数学中的signum 函数,它根据表达式(expression)的值为负值、零和正值,分别返回-1、0或1。\n\n实现者必须确保所有的x和y 都满足 sgn(x.compareTo(y))&#x3D;&#x3D;-sgn(y.com-pareTo(x))。(这也暗示着,当且仅当y.compareTo(x)抛出异常时,x.com-pareTo(y)才必须抛出异常。)\n\n实现者还必须确保这个比较关系是可传递的：(x.compareTo(y)&gt;O&amp;&amp;y.compareTo(z)&gt;0)暗示着x.compareTo(z)&gt;0。\n\n最后,实现者必须确保x.compareTo(y)&#x3D;&#x3D;O暗示着所有的z 都满足 sgn(α.compareTo(z))&#x3D;&#x3D; sgn(y.compareTo(z))。\n\n强烈建议(x.compare To (y) &#x3D;&#x3D; 0) &#x3D;&#x3D; (x. equals (y)）,但这并非绝对必要。一般说来,任何实现了Comparable接口的类,若违反了这个条件,都应该明确予以说明。推荐使用这样的说法：”注意：该类具有内在的排序功能,但是与equals 不一致。”\n\n\n千万不要被上述约定中的数学关系所迷惑。如同équals 约定(详见第10条)一样,compareTo约定并没有看起来那么复杂。与equals方法不同的是,它对所有的对象强行施加了一种通用的等同关系,compareTo不能跨越不同类型的对象进行比较：在比较不同类型的对象时,compareTo可以抛出ClassCastException异常。通常,这正是compareTo 在这种情况下应该做的事情。合约确实允许进行跨类型之间的比较,这一般是在被比较对象实现的接口中进行定义。\n就好像违反了hashCode约定的类会破坏其他依赖于散列的类一样,违反compareTo约定的类也会破坏其他依赖于比较关系的类。依赖于比较关系的类包括有序集合类Tree-Set 和TreeMap,以及工具类Collections 和Arrays,它们内部包含有搜索和排序算法。\n现在我们来回顾一下compareTo 约定中的条款。 第一条指出,如果颠倒了两个对象引用之间的比较方向,就会发生下面的情况：如果第一个对象小于第二个对象,则第二个对象一定大于第一个对象；如果第一个对象等于第二个对象,则第二个对象一定等于第一个对象；如果第一个对象大于第二个对象,则第二个对象一定小于第一个对象。第二条指出,如果一个对象大于第二个对象,并且第二个对象又大于第三个对象,那么第一个对象一定大于第三个对象。最后一条指出,在比较时被认为相等的所有对象,它们跟别的对象做比较时一定会产生同样的结果。\n这三个条款的一个直接结果是,由 compareTo方法施加的等同性测试,也必须遵守相同于équals约定所施加的限制条件：自反性、对称性和传递性。因此,下面的告诫也同样适用：无法在用新的值组件扩展可实例化的类时,同时保持compareTo 约定,除非愿意放弃面向对象的抽象优势(详见第10条)。针对equals的权宜之计也同样适用于展这个类；而是要编写一个不相关的类,其中包含第一个类的一个实例。然后提供一个”视图”(view)方法返回这个实例。这样既可以让你自由地在第二个类上实现compareTo方法,同时也允许它的客户端在必要的时候,把第二个类的实例视同第一个类的实例。\ncompareTo约定的最后一段是一条强烈的建议,而不是真正的规则,它只是说明了compareTo方法施加的等同性测试,在通常情况下应该返回与équals方法同样的结果。如果遵守了这一条,那么由 compareTo方法所施加的顺序关系就被认为与 équals一致。如果违反了这条规则,顺序关系就被认为与 équals 不一致。如果一个类的 compareTo方法施加了一个与 équals 方法不一致的顺序关系,它仍然能够正常工作,但是如果一个(Collection、Set或Map)的通用约定。因为对于这些接口的通用约定是按照equals方法来定义的,但是有序集合使用了由 compareTo方法而不是équals 方法所施加的等同性测试。尽管出现这种情况不会造成灾难性的后果,但是应该有所了解。\n例如,以 BigDecimal 类为例,它的 compareTo 方法与equals 不一致。如果你创建了一个空的 HashSet实例,并且添加 new BigDecimal(“1.O”)和 new BigDecimal(“1.00”),这个集合就将包含两个元素,因为新增到集合中的两个BigDecimal实例,通过equals方法来比较时是不相等的。然而,如果你使用TreeSet而不是HashSet来执行同样的过程,集合中将只包含一个元素,因为这两个BigDecimal实例在通过compareTo 方法进行比较时是相等的。(详情请参阅 BigDecimal 的文档。)\n编写compareTo方法与编写equals方法非常相似,但也存在几处重大的差别。因为Comparable接口是参数化的,而且comparable方法是静态的类型,因此不必进行类型检查,也不必对它的参数进行类型转换。如果参数的类型不合适,这个调用甚至无法编译。如果参数为 null,这个调用应该抛出 NullPointerException 异常,并且一旦该方法试图访问它的成员时就应该抛出异常。\nCompareTo方法中域的比较是顺序的比较,而不是等同性的比较。比较对象引用域可以通过递归地调用 compareTo方法来实现。如果一个域并没有实现Comparable接口,或者你需要使用一个非标准的排序关系,就可以使用一个显式的 Comparator 来代替。或者编写自己的比较器,或者使用已有的比较器,例如针对第10条中的CaseInsensitive-String类的这个compareTo方法使用一个已有的比较器：\n//Single-field Comparable with object reference fieldpublic final class CaseInsensitiveStringimplements Comparable&lt;CaseInsensitiveString&gt; &#123;    public int compareTo(CaseInsensitiveString cis) &#123;        return String.CASE_INSENSITIVE_ORDER.compare(s, cis.s);    &#125;    ...// Remainder omitted&#125;\n\n注意 CaseInsensitiveString类实现了 Comparable接口。这意味着 CaseInsensitiveString引用只能与另一个CaseInsensitiveString引用进行比较。在声明类去实现Comparable 接口时,这是常用的模式。\n本书的前两个版本建议compareTo方法可以利用关系操作符&lt;和》去比较整数型基本类型的域,用静态方法 Double.compare 和 Float.compare 去比较浮点基本类型域。在Java 7版本中,已经在Java 的所有装箱基本类型的类中增加了静态的compare方法。在compareTo方法中使用关系操作符&lt;和&gt;是非常烦琐的,并且容易出错,因此不再建议使用。\n如果一个类有多个关键域,那么,按什么样的顺序来比较这些域是非常关键的。你必须从最关键的域开始,逐步进行到所有的重要域。如果某个域的比较产生了非零的结果(零代表相等),则整个比较操作结束,并返回该结果。如果最关键的域是相等的,则进一步比较次关键的域,以此类推。如果所有的域都是相等的,则对象就是相等的,并返回零。下面通过第11条中的PhoneNumber 类的compareTo方法来说明这种方法:\n//Multiple-field Comparable with primitive fieldspublic int compareTo(PhoneNumber pn) &#123;    int result = Short.compare(areaCode, pn.areaCode);    if(result==0)&#123;        result = Short.compare(prefix, pn.prefix) ;        if(result==0)            result = Short.compare(lineNum, pn.lineNum) ;    &#125;    return result;&#125;\n\n在 Java 8中,Comparator接口配置了一组比较器构造方法(comparator constructionmethods),使得比较器的构造工作变得非常流畅。之后,按照Comparable接口的要求,这些比较器可以用来实现一个compareTo方法。许多程序员都喜欢这种方法的简洁性,虽然它要付出一定的性能成本：在我的机器上,PhoneNumber实例的数组排序的速度慢了大约10%。在使用这个方法时,为了简洁起见,可以考虑使用Java 的静态导入(static import)设施,通过静态比较器构造方法的简单的名称就可以对它们进行引用。下面是使用这个方法之后 PhoneNumber 的 compareTo 方法:\n// Comparable with comparator construction methodsprivate static final Comparator&lt;PhoneNumber&gt; COMPARATOR =comparingInt((PhoneNumber pn) -&gt; pn.areaCode).thenComparingInt(pn -&gt; pn.prefix). thenComparingInt(pn -&gt; pn.lineNum) ;public int compareTo(PhoneNumber pn)&#123;    return COMPARATOR.compare(this, pn);&#125;\n\n这个实现利用两个比较构造方法,在初始化类的时候构建了一个比较器。第一个是comparingInt。这是一个静态方法,带有一个键提取器函数(key extractor function),它将一个对象引用映射到一个类型为int的键上,并根据这个键返回一个对实例进行排序的比较器。在上一个例子中,ComparingInt带有一个lambda(),它从PhoneNumber提取区号,并返回一个按区号对电话号码进行排序的Comparator。注意,lambda显式定义了其输入参数(PhoneNumber pn)的类型。事实证明,在这种情况下,Java 的类型推导还没有强大到足以为自己找出类型,因此我们不得不帮助它直接进行指定,以使程序能够成功地进行编译。\n如果两个电话号码的区号相同,就需要进一步细化比较,这正是第二个比较器构造方类型为int 的键提取器函数,它会返回一个最先运用原始比较器的比较器,然后利用提取到的键继续比较。还可以随意地叠加多个thenComparingInt调用,并按词典顺序进行排序。在上述例子中,叠加了两个thenComparingInt 调用,按照第二个键为前缀且第三个键为行数的顺序进行排序。注意,并不一定要指定传人thenComparingInt 调用的键提取器函数的参数类型：Java 的类型推导十分智能,它足以为自己找出正确的类型。\nComparator 类具备全套的构造方法。对于基本类型 long 和 double 都有对应的 com-Number 例子中的 short。double 版本也可以用于 float。这样便涵盖了所有的 Java 数字型基本类型。\n对象引用类型也有比较器构造方法。静态方法 comparing 有两个重载。一个带有键提取器,使用键的内在排序关系。第二个既带有键提取器,还带有要用在被提取的键上的比较器。这个名为thenComparing 的实例方法有三个重载。一个重载只带一个比较器,并用它提供次级顺序。第二个重载只带一个键提取器,并利用键的内在排序关系作为次级顺序。最后一个重载既带有键提取器,又带有要在被提取的键上使用的比较器。\ncompareTo或者compare方法偶尔也会依赖于两个值之间的区别,即如果第一个值小于第二个值,则为负；如果两个值相等,则为零；如果第一个值大于第二个值,则为正。下面举个例子：\n// BROKEN difference-based comparator - violates transitivity! static Comparator ＜Object&gt; hashCodeOrder ＝ new Comparator&lt;&gt;（）&#123;    public int compara(Object o1, Object o2)&#123;        return o1.hashCode () - o2 .hashCode () ;     &#125;&#125;;\n千万不要使用这个方法。它很容易造成整数溢出,同时违反IEEE 754浮点算术标准[JLS 15.20.1,15.21.1]。甚至,与利用本条目讲到的方法编写的那些方法相比,最终得到的方法并没有明显变快。因此,要么使用一个静态方法 compare:\n// Comparator based on static compare methodstatic Comparator&lt;Object&gt; hashCodeOrder = new Comparator&lt;&gt;() &#123;    public int compare(Object ol,0bject o2) &#123;        return Integer.compare(o1.hashCode(), o2.hashCode());    &#125;&#125;;\n\n要么使用一个比较器构造方法：\n//Comparator basedon Comparator construction methodstatic Comparator&lt;Object&gt; hashCodeOrder =Comparator.comparingInt(o -&gt; o.hashCode());\n\n总而言之,每当实现一个对排序敏感的类时,都应该让这个类实现Comparable接口,以便其实例可以轻松地被分类、搜索,以及用在基于比较的集合中。每当在com-pareTo方法的实现中比较域值时,都要避免使用&lt;和&gt;操作符,而应该在装箱基本类型的类中使用静态的compare方法,或者在Comparator接口中使用比较器构造方法。\n第四章 类和接口类和接口是 Java 编程语言的核心,它们也是 Java 语言的基本抽象单元。Java 语言提供了许多强大的基本元素,供程序员用来设计类和接口。本章阐述的一些指导原则,可以帮助你更好地利用这些元素,设计出更加有用、健壮和灵活的类和接口。\n第15条：使类和成员的可访问性最小化区分一个组件设计得好不好,唯一重要的因素在于,它对于外部的其他组件而言,是否隐藏了其内部数据和其他实现细节。设计良好的组件会隐藏所有的实现细节,把API与块的内部工作情况。这个概念被称为信息隐藏(informationhiding)或封装(encapsulation),是软件设计的基本原则之一[Parnas72]。\n信息隐藏之所以非常重要有许多原因,其中大多是因为：它可以有效地解除组成系统的各组件之间的耦合关系,即解耦(decouple),使得这些组件可以独立地开发、测试、优化、使用、理解和修改。因为这些组件可以并行开发,所以加快了系统开发的速度。同时减轻了维护的负担,程序员可以更快地理解这些组件,并且在调试它们的时候不影响其他的组件。虽然信息隐藏本身无论是对内还是对外都不会带来更好的性能,但是可以有效地调节性能：一旦完成一个系统,并通过剖析确定了哪些组件影响了系统的性能(详见第67条),那些组件就可以被进一步优化,而不会影响到其他组件的正确性。信息隐藏提高了软件的可重用性,因为组件之间并不紧密相连,除了开发这些模块所使用的环境之外,它们在其他的环境中往往也很有用。最后,信息隐藏也降低了构建大型系统的风险,因为即使整个系统不可用,这些独立的组件仍有可能是可用的。\nJava 提供了许多机制(facility)来协助信息隐藏。访问控制(access control)机制[JLS6.6]决定了类、接口和成员的可访问性(accessibility)。实体的可访问性是由该实体声明所在的位置,以及该实体声明中所出现的访问修饰符(private、protected 和public)共同决定的。正确地使用这些修饰符对于实现信息隐藏是非常关键的。\n规则很简单：尽可能地使每个类或者成员不被外界访问。换句话说,应该使用与你正在编写的软件的对应功能相一致的、尽可能最小的访问级别。\n对于顶层的(非嵌套的)类和接口,只有两种可能的访问级别：包级私有的(package-private)和公有的(public)。如果你用 public 修饰符声明了顶层类或者接口,那它就是公有的；否则,它将是包级私有的。如果类或者接口能够被做成包级私有的,它就应该被做成包级私有。通过把类或者接口做成包级私有,它实际上成了这个包的实现的一部分,而不是该包导出的API的一部分,在以后的发行版本中,可以对它进行修改、替换或者删除,而无须担心会影响到现有的客户端程序。如果把它做成公有的,你就有责任永远支持它,以保持它们的兼容性。\n如果一个包级私有的顶层类(或者接口)只是在某一个类的内部被用到,就应该考虑使它成为唯一使用它的那个类的私有嵌套类(详见第24条)。这样可以将它的可访问范围从包中的所有类缩小到使用它的那个类。然而,降低不必要公有类的可访问性,比降低包级私有的顶层类的可访问性重要得多：因为公有类是包的API的一部分,而包级私有的顶层类则已经是这个包的实现的一部分。\n对于成员(域、方法、嵌套类和嵌套接口)有四种可能的访问级别,下面按照可访问性的递增顺序罗列出来：\n\n私有的(private)一只有在声明该成员的顶层类内部才可以访问这个成员。\n\n包级私有的 (package-private) 一一声明该成员的包内部的任何类都可以访问这个成员。从技术上讲,它被称为”缺省”(default)访问级别,如果没有为成员指定访问修饰符,就采用这个访问级别(当然,接口成员除外,它们默认的访问级别是公有的)。\n\n\n-受保护的(protected)一声明该成员的类的子类可以访问这个成员(但有一些限制[JLS,6.6.2]),并且声明该成员的包内部的任何类也可以访问这个成员。\n\n公有的(public)一在任何地方都可以访问该成员。\n\n当你仔细地设计了类的公有API之后,可能觉得应该把所有其他的成员都变成私有的。其实,只有当同一个包内的另一个类真正需要访问一个成员的时候,你才应该删除private 修饰符,使该成员变成包级私有的。如果你发现自己经常要做这样的事情,就应该重新检查系统设计,看看是否另一种分解方案所得到的类,与其他类之间的耦合度会更小。也就是说,私有成员和包级私有成员都是一个类的实现中的一部分,一般不会影响导出的 API。然而,如果这个类实现了 Serializable 接口(详见第 86 条和第 87 条),这些域就有可能会被”泄漏”（leak）到导出的 API 中。\n对于公有类的成员,当访问级别从包级私有变成保护级别时,会大大增强可访问性。受保护的成员是类的导出的API的一部分,必须永远得到支持。导出的类的受保护成员也代表了该类对于某个实现细节的公开承诺(详见第19条)。应该尽量少用受保护的成员。\n有一条规则限制了降低方法的可访问性的能力。如果方法覆盖了超类中的一个方法,子类中的访问级别就不允许低于超类中的访问级别[JLS,8.4.8.3]。这样可以确保任何可使用超类的实例的地方也都可以使用子类的实例(里氏替换原则,详见第10条)。如果违反了这条规则,那么当你试图编译该子类的时候,编译器就会产生一条错误消息。这条规则有一个特例：如果一个类实现了一个接口,那么接口中所有的方法在这个类中也都必须被声明为公有的。\n为了便于测试代码,你可以试着使类、接口或者成员变得更容易访问。这么做在一定程度上来说是好的。为了测试而将一个公有类的私有成员变成包级私有的,这还可以接受,但是要将访问级别提高到超过它,这就无法接受了。换句话说,不能为了测试,而将类、接口或者成员变成包的导出的API的一部分。幸运的是,也没有必要这么做,因为可以让测试作为被测试的包的一部分来运行,从而能够访问它的包级私有的元素。\n公有类的实例域决不能是公有的(详见第16条)。如果实例域是非final的,或者是一个指向可变对象的final引用,那么一旦使这个域成为公有的,就等于放弃了对存储在这个域中的值进行限制的能力；这意味着,你也放弃了强制这个域不可变的能力。同时,当这个域被修改的时候,你也失去了对它采取任何行动的能力。因此,包含公有可变域的类通常并不是线程安全的。即使域是final的,并且引用不可变的对象,但当把这个域变成公有的时候,也就放弃了”切换到一种新的内部数据表示法”的灵活性。\n这条建议也同样适用于静态域,只是有一种情况例外。假设常量构成了类提供的整个抽象中的一部分,可以通过公有的静态final域来暴露这些常量。按惯例,这种域的名称由大写字母组成,单词之间用下划线隔开(详见第68条)。很重要的一点是,这些域要么包含基本类型的值,要么包含指向不可变对象的引用(详见第17条)。如果final域包含可变对象的引用,它便具有非final域的所有缺点。虽然引用本身不能被修改,但是它所引用的对象却可以被修改,这会导致灾难性的后果。\n注意,长度非零的数组总是可变的,所以让类具有公有的静态final数组域,或者返回这种域的访问方法,这是错误的。如果类具有这样的域或者访问方法,客户端将能够修改数组中的内容。这是安全漏洞的一个常见根源：\n//Potential security hole！public static final Thing[] VALUES = &#123; ... &#125;;\n要注意,许多IDE产生的访问方法会返回指向私有数组域的引用,正好导致了这个问题。修正这个问题有两种方法。可以使公有数组变成私有的,并增加一个公有的不可变列表：\nprivate static final Thing[] PRIVATE_VALUES=&#123;... &#125;;public static final List&lt;Thing&gt; VALUES =Collections.unmodifiableList(Arrays.asList(PRIVATE_VALUES)) ;\n\n另一种方法是,也可以使数组变成私有的,并添加一个公有方法,它返回私有数组的一个拷贝：\nprivate static final Thing[] PRIVATE_VALUES = &#123; ... &#125;;public static final Thing[]  values() &#123;    return PRIVATE_VALUES.clone();&#125;\n\n要在这两种方法之间做出选择,得考虑客户端可能怎么处理这个结果。哪种返回类型会更加方便？哪种会得到更好的性能？\n从Java 9开始,又新增了两种隐式访问级别,作为模块系统(module system)的一部分。一个模块就是一组包,就像一个包就是一组类一样。模块可以通过其模块声明(moduledeclaration)中的导出声明(export declaration)显式地导出它的一部分包(按照惯例,这包含在名为 module-info.java 的源文件中)。模块中未被导出的包在模块之外是不可访问的；在模块内部,可访问性不受导出声明的影响。使用模块系统可以在模块内部的包之间共享类,不用让它们对全世界都可见。未导出的包中公有类的公有成员和受保护的成员都提高了两个隐式访问级别,这是正常的公有和受保护级别在模块内部的对等体(intramodular analogues) 。 对于这种共享的需求相对罕见,经常通过在包内部重新安排类来解决。\n与四个主访问级别不同的是,这两个基于模块的级别主要提供咨询。如果把模块的JAR文件放在应用程序的类路径下,而不是放在模块路径下,模块中的包就会恢复其非模块的行为：无论包是否通过模块导出,这些包中公有类的所有公有的和受保护的成员将都有正常的可访问性[Reinhold,1.2]。严格执行新引l人的访问级别的一个示例是JDK本身：Java类库中未导出的包在其模块之外确实是不可访问的。\n对于传统的Java 程序员来说,不仅由受限工具的模块提供了访问保护,而且在本质上主要也是提供咨询。为了利用模块的这一特性,必须将包集中到模块中,并在模块声明中显式地表明其所有的依赖关系,重新安排代码结构树,从模块内部采取特殊的动作调解对于非模块化的包的任何访问[Reinhold,3]。现在说模块将在 JDK本身之外获得广泛的使用,还为时过早。同时,似乎最好不用它们,除非你的需求非常迫切。\n总而言之,应该始终尽可能(合理)地降低程序元素的可访问性。在仔细地设计了一个最小的公有API之后,应该防止把任何散乱的类、接口或者成员变成API的一部分。除了公有静态 final域的特殊情形之外(此时它们充当常量),公有类都不应该包含公有域,并且要确保公有静态final域所引用的对象都是不可变的。\n第16条：要在公有类而非公有域中使用访问方法有时候,可能需要编写一些退化类,它们没有什么作用,只是用来集中实例域：\n//Degenerate classes like thisshouldnot bepublic!class Point &#123;    public double x;    public double y;&#125;\n\n由于这种类的数据域是可以被直接访问的,这些类没有提供封装(encapsulation)的功能(详见第15条)。如果不改变API,就无法改变它的数据表示法,也无法强加任何约束条件；当域被访问的时候,无法采取任何辅助的行动。坚持面向对象编程的程序员对这种类深恶痛绝,认为应该用包含私有域和公有访问方法(getter)的类代替。对于可变的类来说,应该用公有设值方法(setter)的类代替：\n//Encapsulation of data by access or methods and mutatorsclass Point &#123;    private double x;    private double y;    public Point(double x,double y)&#123;        this.x = x;        this.y = y;    &#125;    public double getX() &#123; return x;&#125;    public double getY()&#123;return y;&#125;    public void setX(double x)&#123; this.x=x;&#125;    public void setY(double y) &#123; this.y = y; &#125;&#125;\n\n毫无疑问,说到公有类的时候,坚持面向对象编程思想的看法是正确的：如果类可以在它所在的包之外进行访问,就提供访问方法,以保留将来改变该类的内部表示法的灵活性。如果公有类暴露了它的数据域,要想在将来改变其内部表示法是不可能的,因为公有类的客户端代码已经遍布各处了。\n然而,如果类是包级私有的,或者是私有的嵌套类,直接暴露它的数据域并没有本质的错误————假设这些数据域确实描述了该类所提供的抽象。无论是在类定义中,还是在使用该类的客户端代码中,这种方法比访问方法的做法更不容易产生视觉混乱。虽然客户端代码与该类的内部表示法紧密相连,但是这些代码被限定在包含该类的包中。如有必要,也可以不改变包之外的任何代码,而只改变内部数据表示法。在私有嵌套类的情况下,改变的作用范围被进一步限制在外围类中。\nJava平台类库中有几个类违反了”公有类不应该直接暴露数据域”的告诫。显著的例子包括java.awt 包中的Point类和 Dimension 类。它们是不值得仿效的例子,相反,这些类应该被当作反面的警告示例。正如第 67条所述,决定暴露 Dimension 类的内部数据造成了严重的性能问题,而且这个问题至今依然存在。\n让公有类直接暴露域虽然从来都不是种好办法,但是如果域是不可变的,这种做法的危害就比较小一些。如果不改变类的API,就无法改变这种类的表示法,当域被读取的时示一个有效的时间：\n//Public class withexposedimmutable fields-questionablepublic final class Time &#123;    private static final int HOURS_PER_DAY =24;    private Static final int MINUTES_PER_HOUR = 60;        public final int hour;    public final int minute;        public Time(int hour,int minute) &#123;        if (hour &lt; 0 丨l hour &gt;= HOURS_PER_DAY)            throw new IllegalArgumentException(&quot;Hour: &quot; + hour);        if (minute &lt; 0 Il minute &gt;= MINUTES_PER_HOUR)            throw new IllegalArgumentException(&quot;Min: &quot; + minute);            this.hour = hour;            this.minute = minute;    &#125;    ..// Remainder omitted&#125;\n\n简而言之,公有类永远都不应该暴露可变的域。虽然还是有问题,但是让公有类暴露不可变的域,其危害相对来说比较小。但有时候会需要用包级私有的或者私有的嵌套类来暴露域,无论这个类是可变的还是不可变的。\n第17条：使可变性最小化不可变类是指其实例不能被修改的类。每个实例中包含的所有信息都必须在创建该实例的时候就提供,并在对象的整个生命周期(lifetime)内固定不变。Java平台类库中包含许多不可变的类,其中有 String、基本类型的包装类、BigInteger 和 BigDecimal。存在不可变的类有许多理由：不可变的类比可变类更加易于设计、实现和使用。它们不容易出错,且更加安全。\n为了使类成为不可变,要遵循下面五条规则：\n\n不要提供任何会修改对象状态的方法(也称为设值方法)。\n\n保证类不会被扩展。这样可以防止粗心或者恶意的子类假装对象的状态已经改变,从而破坏该类的不可变行为。为了防止子类化,一般做法是声明这个类成为 final的,但是后面我们还会讨论到其他的做法。\n\n声明所有的域都是final 的。通过系统的强制方式可以清楚地表明你的意图。而且,如就必须确保正确的行为,正如内存模型(memorymodel)中所述[JLS,17.5；Goetz0616]。\n\n声明所有的域都为私有的。这样可以防止客户端获得访问被域引用的可变对象的权限,并防止客户端直接修改这些对象。虽然从技术上讲,允许不可变的类具有公有的 final域,只要这些域包含基本类型的值或者指向不可变对象的引用,但是不建议这样做,因为这样会使得在以后的版本中无法再改变内部的表示法(详见第 15条和第 16 条)。\n\n确保对于任何可变组件的互斥访问。如果类具有指向可变对象的域,则必须确保该类的客户端无法获得指向这些对象的引用。并且,永远不要用客户端提供的对象引用来初始化这样的域,也不要从任何访问方法(accessor)中返回该对象引用。在构造器、访问方法和readObject方法(详见第88条)中请使用保护性拷贝(defensivecopy)技术(详见第50条)。\n\n\n前面条目中的许多例子都是不可变的,其中一个例子是第 11条中的 PhoneNumber,它针对每个属性都有访问方法(accessor),但是没有对应的设值方法(mutator)。下面是个稍微复杂一点的例子:\n//Immutablecomplex numberclasspublic final class Complex &#123;    private final double re;    private final double im;    public Complex(double re, double im) &#123;        this.re = re;        this.im = im;    &#125;    public double realPart() &#123;        return re;    &#125;    public double imaginaryPart() &#123;         return im;    &#125;    public Complex plus(Complex c) &#123;        return new Complex(re + c.re, im + c.im);    &#125;    public Complex minus(Complex c) &#123;        return new Complex(re - c.re, im - c.im);    &#125;    public Complex times(Complex c) &#123;        return new Complex(re * C.re -i im *c.im,re*c.im+im *c.re);    &#125;    public Complex dividedBy(Complex c) &#123;        double tmp = c.re * c.re + c.im * c.im;        return new Complex((re * c.re + im * c.im) / tmp,(im * c.re - re * c.im) / tmp);    &#125;    @Override public boolean equals(Object o) &#123;        if (o == this)return true;        if (!(o instanceof Complex))return false;        Complex C = (Complex) o;        // See page 47 to find out why we use compare instead of ==        return Double.compare(c.re, re) == 0&amp;&amp; Double.compare(c.im, im) == 0;    &#125;    @Override public int hashCode()&#123;        return 31 * Double.hashCode(re) + Double.hashCode(im) ;    &#125;    @Overridepublic String toString()&#123;        return&quot;(&quot; + re + &quot;+ &quot;+ im + &quot;i)&quot;;    &#125;&#125;\n\n这个类表示一个复数(complex number,具有实部和虚部)。除了标准的 Object方法之外,它还提供了针对实部和虚部的访问方法,以及4种基本的算术运算：加法、减法、乘法和除法。注意这些算术运算如何创建并返回新的Complex实例,而不是修改这个实例。大多数重要的不可变类都使用了这种模式。它被称为函数的(functional)方法,因为这些方法返回了一个函数的结果,这些函数对操作数进行运算但并不修改它。与之相对应的更常见的是过程的(procedural)或者命令式的(imperative)方法,使用这些方法时,将一个过程作用在它们的操作数上,会导致它的状态发生改变。注意,这些方法名称都是介词(如plus),而不是动词(如 add)。这是为了强调该方法不会改变对象的值。BigInteger类和BigDecimal类由于没有遵守这一命名习惯,就导致了许多用法错误。\n如果你对函数方式的做法还不太熟悉,可能会觉得它显得不太自然,但是它带来了不可变性,具有许多优点。不可变对象比较简单。不可变对象可以只有一种状态,即被创建时的状态。如果你能够确保所有的构造器都建立了这个类的约束关系,就可以确保这些约束关系在整个生命周期内永远不再发生变化,你和使用这个类的程序员都无须再做额外的工作来维护这些约束关系。另一方面,可变的对象可以有任意复杂的状态空间。如果文档中没有为设值方法所执行的状态转换提供精确的描述,要可靠地使用可变类是非常困难的,甚至是不可能的。\n不可变对象本质上是线程安全的,它们不要求同步。当多个线程并发访问这样的对象时,它们不会遭到破坏。这无疑是获得线程安全最容易的办法。实际上,没有任何线程会注意到其他线程对于不可变对象的影响。所以,不可变对象可以被自由地共享。不可变类应该充分利用这种优势,鼓励客户端尽可能地重用现有的实例。要做到这一点,一个很简便的办法就是：对于频繁用到的值,为它们提供公有的静态 final常量。例如,Complex类有可能会提供下面的常量：\npublic static final Complex ZERO = new Complex(0, 0);public static final Complex ONE = new Complex(1, 0);public static final Complex I = new Complex(0,1);\n\n这种方法可以被进一步扩展。不可变的类可以提供一些静态工厂(详见第1条),它们例。所有基本类型的包装类和BigInteger 都有这样的静态工厂。使用这样的静态工厂也使得客户端之间可以共享现有的实例,而不用创建新的实例,从而降低内存占用和垃圾回收的成本。在设计新的类时,选择用静态工厂代替公有的构造器可以让你以后有添加缓存的灵活性,而不必影响客户端。\n“不可变对象可以被自由地共享”导致的结果是,永远也不需要进行保护性拷贝(defensive copy) (详见第 50 条)。 实际上,你根本无须做任何拷贝,因为这些拷贝始终等于原始的对象。因此,你不需要,也不应该为不可变的类提供clone 方法或者拷贝构造器(详见第13条)。这一点在Java 平台的早期并不好理解,所以 String 类仍然具有拷贝构造器,但是应该尽量少用它(详见第6条)。\n不仅可以共享不可变对象,甚至也可以共享它们的内部信息。例如,BigInteger类内部使用了符号数值表示法。符号用一个 int 类型的值来表示,数值则用一个 int 数组表示。negate 方法产生一个新的 BigInteger,其中数值是一样的,符号则是相反的。它\n不可变对象为其他对象提供了大量的构件,无论是可变的还是不可变的对象。如果知道一个复杂对象内部的组件对象不会改变,要维护它的不变性约束是比较容易的。这条原则的一种特例在于,不可变对象构成了大量的映射键(mapkey)和集合元素(setelement)；一旦不可变对象进人到映射(map)或者集合(set)中,尽管这破坏了映射或者集合的不变性约束,但是也不用担心它们的值会发生变化。\n不可变对象无偿地提供了失败的原子性(详见第76条)。它们的状态永远不变,因此不存在临时不一致的可能性。\n不可变类真正唯一的缺点是,对于每个不同的值都需要一个单独的对象。创建这些对象的代价可能很高,特别是大型的对象。例如,假设你有一个上百万位的 BigInteger,想要改变它的低位：\nBigInteger moby =....;moby =moby.flipBit(0):\n\nflipBit方法创建了一个新的BigInteger实例,也有上百万位长,它与原来的对象只差一位不同。这项操作所消耗的时间和空间与BigInteger 的成正比。我们拿它与java.util.BitSet进行比较。与BigInteger类似,BitSet代表一个任意长度的位序列,但是与BigInteger不同的是,BitSet是可变的。BitSet类提供了一个方法,允许在固定时间(constant time)内改变此”百万位”实例中单个位的状态：\nBitSet moby = ...;moby.flip(0) ;\n如果你执行一个多步骤的操作,并且每个步骤都会产生一个新的对象,除了最后的结果之外,其他的对象最终都会被丢弃,此时性能问题就会显露出来。处理这种问题有两种办法。第一种办法,先猜测一下经常会用到哪些多步骤的操作,然后将它们作为基本类型提供。如果某个多步骤操作已经作为基本类型提供,不可变的类就无须在每个步骤单独创建一个对象。不可变的类在内部可以更加灵活。例如,BigInteger有一个包级私有的可变”配套类”(companing class),它的用途是加速诸如”模指数”(modular exponentiation)这样的困难工作。\n如果能够精确地预测出客户端将要在不可变的类上执行哪些复杂的多阶段操作,这种包级私有的可变配套类的方法就可以工作得很好。如果无法预测,最好的办法是提供一个公有的可变配套类。在Java平台类库中,这种方法的主要例子是 String类,它的可变配套类是 StringBuilder(及其已经被废弃的祖先 StringBuffer)。\n现在你已经知道了如何构建不可变的类,并且了解了不可变性的优点和缺点,现在我们来讨论其他的一些设计方案。前面提到过,为了确保不可变性,类绝对不允许自身被子类化。除了”使类成为final的”这种方法之外,还有另外一种更加灵活的办法可以做到这一点。不可变的类变成final的另一种办法就是,让类的所有构造器都变成私有的或者包级私有的,并添加公有的静态工厂(static factory)来代替公有的构造器(详见第1条)。为了具体说明这种方法,下面以 Complex 为例,看看如何使用这种方法:\n//Immutable classwith staticfactories instead of constructorspublic class Complex &#123;    private final double re;    private final double im;    private Complex(double re,double im) &#123;        this.re = re;        this.im = im;    &#125;    public staticComplex valueOf(doublere,doubleim)&#123;        return new Complex(re, im);    &#125;    ...// Remainderunchanged&#125;\n\n这种方法虽然并不常用,但它通常是最好的替代方法。它最灵活,因为它允许使用多个包级私有的实现类。对于处在包外部的客户端而言,不可变的类实际上是final的,因为不可能对来自另一个包的类、缺少公有的或受保护的构造器的类进行扩展。除了允许多个实现类的灵活性之外,这种方法还使得有可能通过改善静态工厂的对象缓存能力,在后续的发行版本中改进该类的性能。\n当BigInteger 和BigDecimal刚被编写出来的时候,对于”不可变的类必须为final”的说法还没有得到广泛的理解,所以它们的所有方法都有可能被覆盖。遗憾的是,为了保持向后兼容,这个问题一直无法得以修正。如果你在编写一个类,它的安全性依赖于来自不可信客户端的 BigInteger 或者BigDecimal参数的不可变性,就必须进行检查,以确定这个参数是否为”真正的”BigInteger 或者BigDecimal,而不是不可信任子类的实例。如果是后者,就必须在假设它可能是可变的前提下对它进行保护性拷贝(详见第50条):\npublic static BigInteger safeInstance(BigInteger val)&#123;    return val.getClass() == BigInteger.class ?        val : new BigInteger(val.toByteArray());&#125;\n\n本条开头关于不可变类的诸多规则指出,没有方法会修改对象,并且它的所有域都必须是final的。实际上,这些规则比真正的要求更强硬了一点,为了提高性能可以有所放松。事实上应该是这样：没有一个方法能够对对象的状态产生外部可见(extermallyvisible)的改变。然而,许多不可变的类拥有一个或者多个非 final的域,它们在第一次被请求执行这些计算的时候,把一些开销昂贵的计算结果缓存在这些域中。如果将来再次请求同样的计算,就直接返回这些缓存的值,从而节约了重新计算所需要的开销。这种技巧可以很好地工作,因为对象是不可变的,它的不可变性保证了这些计算如果被再次执行,就会产生同样的结果。\n例如,PhoneNumber类的hashCode方法(详见第 11条)在第一次被调用的时候,计算出散列码,然后把它缓存起来,以备将来被再次调用时使用。这种方法是延迟初始化(lazy initialization)(详见第 83 条)的一个例子,String 类也用到了。\n有关序列化功能的一条告诫有必要在这里提出来。如果你选择让自己的不可变类实现Serializable接口,并且它包含一个或者多个指向可变对象的域,就必须提供一个显式的readobject 或者 readResolve 方法,或者使用 ObjectOutputStream.writeUnshared和 ObjectInputStream.readUnshared方法,即便默认的序列化形式是可以接受的,也是如此。否则,攻击者可能从不可变的类创建可变的实例。关于这个话题的详情请参见第88条。\n总之,坚决不要为每个 get方法编写一个相应的 set方法。除非有很好的理由要让类成为可变的类,否则它就应该是不可变的。不可变的类有许多优点,唯一的缺点是在特定的情况下存在潜在的性能问题。你应该总是使一些小的值对象,比如PhoneNumber和Complex,成为不可变的。(在Java平台类库中,有几个类如java.util.Date和java.awt.Point,它们本应该是不可变的,但实际上却不是。)你也应该认真考虑把一些较大的值对象做成不可变的,例如 String 和BigInteger。只有当你确认有必要实现令人满意的性能时(详见第67条),才应该为不可变的类提供公有的可变配套类。\n对于某些类而言,其不可变性是不切实际的。如果类不能被做成不可变的,仍然应该尽可能地限制它的可变性。降低对象可以存在的状态数,可以更容易地分析该对象的行为,同时降低出错的可能性。因此,除非有令人信服的理由使域变成非final的,否则让每个域都是 final的。结合这条的建议和第15 条的建议,你自然倾向于：除非有令人信服的理由要使域变成是非final的,否则要使每个域都是privatefinal的。\n构造器应该创建完全初始化的对象,并建立起所有的约束关系。不要在构造器或者静态工厂之外再提供公有的初始化方法,除非有令人信服的理由必须这么做。同样地,也不应该提供”重新初始化”方法(它使得对象可以被重用,就好像这个对象是由另一不同的初始状态构造出来的一样)。与所增加的复杂性相比,”重新初始化”方法通常并没有带来太多的性能优势。\n通过CountDownLatch类的例子可以说明这些原则。它是可变的,但是它的状态空间被有意地设计得非常小。比如创建一个实例,只使用一次,它的任务就完成了：一旦定时器的计数达到零,就不能重用了。\n最后值得注意的一点与本条目中的Complex类有关。这个例子只是被用来演示不可变性的,它不是一个工业强度的复数实现。它对复数乘法和除法使用标准的计算公式,会进行不正确的四舍五人,并且对复数NaN和无穷大也没有提供很好的语义[Kahan91,Smith62,Thomas94]。\n第18条：复合优先于继承继承(inheritance)是实现代码重用的有力手段,但它并非永远是完成这项工作的最佳工具。使用不当会导致软件变得很脆弱。在包的内部使用继承是非常安全的,在那里子类和超类的实现都处在同一个程序员的控制之下。对于专门为了继承而设计并且具有很好的文档说明的类来说(详见第19条),使用继承也是非常安全的。然而,对普通的具体类(concreteclass)进行跨越包边界的继承,则是非常危险的。提示一下,本书使用”继承”一词,含义是实现继承(当一个类扩展另一个类的时候)。本条目中讨论的问题并不适用于接口继承(当一个类实现一个接口的时候,或者当一个接口扩展另一个接口的时候)。\n**与方法调用不同的是,继承打破了封装性[Snyder86]**。换句话说,子类依赖于其超类中特定功能的实现细节。超类的实现有可能会随着发行版本的不同而有所变化,如果真的发生了变化,子类可能会遭到破坏,即使它的代码完全没有改变。因而,子类必须要跟着其超类的更新而演变,除非超类是专门为了扩展而设计的,并且具有很好的文档说明。\n为了说明得更加具体一点,我们假设有一个程序使用了HashSet。为了调优该程序的性能,需要查询HashSet,看一看自从它被创建以来添加了多少个元素(不要与它当前的元素数目混淆起来,它会随着元素的删除而递减)。为了提供这种功能,我们得编写一个HashSet变体,定义记录试图插人的元素的数量 addCount,并针对该计数值导出一个访问方法。HashSet 类包含两个可以增加元素的方法：add 和 addAll,因此这两个方法都要被覆盖：\n// Rroken -Inappropriate use of inheritance!public class InstrumentedHashSet&lt;E&gt;extends HashSet&lt;E&gt;&#123;    // The number of attempted element insertions    private int addCount =0;    public InstrumentedHashSet()&#123;&#125;    public InstrumentedHashSet(int initCap, float loadFactor)&#123;        super(initCap, loadFactor);    &#125;    @Override public boolean add(E e)&#123;        addCount++;        return super.add(e);    &#125;    @Override public boolean addAll(Collection&lt;?extends E&gt; c) &#123;        addCount += c.sizeO;        return super.addAll(c);    &#125;    public int getAddCount() &#123;        return addCount;    &#125;&#125;\n这个类看起来非常合理,但是它并不能正常工作。 假设我们创建了一个实例,并利用addAll 方法添加了三个元素。顺便提一句,注意我们利用静态工厂方法 List.of 创建了一个列表,该方法是在 Java 9 中增加的。如果使用较早的版本,则用 Arrays.asList 代替:\nInstrumentedHashSet&lt;String&gt; s = new InstrumentedHashSet&lt;&gt;();s.addAll(List.of(&quot;Snap&quot;, &quot;Crackle&quot;, &quot;Pop&quot;));\n\n此时我们期望 getAddCount方法能返回3,但是实际上它返回的是6。哪里出错了呢？在HashSet的内部,addAll方法是基于它的 add方法来实现的,即使HashSet的文档中并没有说明这样的实现细节,这也是合理的。InstrumentedHashSet中的addAll方法首先给 addCount 增加3,然后利用 supper.addAll 来调用 HashSet 的addAll实现。然后又依次调用到被 InstrumentedHashSet 覆盖了的 add方法,每个元素调用一次。这三次调用又分别给 addCount 加了 1,所以总共增加了6：通过 addAll方法增加的每个元素都被计算了两次。\n我们只要去掉被覆盖的addAll方法,就可以”修正”这个子类。虽然这样得到的类可以正常工作,但是它的功能正确性则需要依赖于这样的事实：HashSet 的 addAll方法是在它的 add方法上实现的。这种”自用性”(self-use)是实现细节,不是承诺,不能保证在Java平台的所有实现中都保持不变,不能保证随着发行版本的不同而不发生变化。因此,这样得到的InstrumentedHashSet类将是非常脆弱的。\n稍微好一点的做法是,覆盖 addAll方法来遍历指定的集合,为每个元素调用一次add 方法。这样做可以保证得到正确的结果,不管 HashSet 的 addAll方法是否在 add方法的基础上实现,因为 HashSet 的 addAll 实现将不会再被调用到。然而,这项技术并没有解决所有的问题,它相当于重新实现了超类的方法,这些超类的方法可能是自用的,也可能不是,这种方法很困难,也非常耗时,容易出错,并且可能降低性能。此外,这样做并不总是可行的,因为无法访问对于子类来说是私有的域,所以有些方法就无法实现。\n导致子类脆弱的一个相关的原因是,它们的超类在后续的发行版本中可以获得新的方法。假设一个程序的安全性依赖于这样的事实：所有被插人某个集合中的元素都满足某个先决条件。下面的做法就可以确保这一点：对集合进行子类化,并覆盖所有能够添加元素的方法,以便确保在加人每个元素之前它是满足这个先决条件的。如果在后续的发行版本中,超类中没有增加能插入元素的新方法,这种做法就可以正常工作。然而,一旦超类增加了这样的新方法,则很可能仅仅由于调用了这个未被子类覆盖的新方法,而将”非法的”元素添加到子类的实例中。这不是一个纯粹的理论问题。在把 Hashtable 和Vector加人到CollectionsFramework中的时候,就修正了几个这类性质的安全漏洞。\n上面这两个问题都来源于覆盖(overriding)方法。你可能会认为在扩展一个类的时候,仅仅增加新的方法,而不覆盖现有的方法是安全的。虽然这种扩展方式比较安全一些,但是也并非完全没有风险。如果超类在后续的发行版本中获得了一个新的方法,并且不幸的是,你给子类提供了一个签名相同但返回类型不同的方法,那么这样的子类将无法通过编译[JLS,8.4.8.3]。如果给子类提供的方法带有与新的超类方法完全相同的签名和返回类型,实际上就覆盖了超类中的方法,因此又回到了上述两个问题。此外,你的方法是否能够遵守新的超类方法的约定,这也是很值得怀疑的,因为当你在编写子类方法的时候,这个约定压根还没有面世。\n幸运的是,有一种办法可以避免前面提到的所有问题。即不扩展现有的类,而是在新的类中增加一个私有域,它引用现有类的一个实例。这种设计被称为”复合”(composition),因为现有的类变成了新类的一个组件。新类中的每个实例方法都可以调用被包含的现有类实例中对应的方法,并返回它的结果。这被称为转发(forwarding),新类中的方法被称为转发方法(forwarding method)。这样得到的类将会非常稳固,它不依赖于现有类的实现细节。即使现有的类添加了新的方法,也不会影响新的类。为了进行更具体的说明,请看下面的例子,它用复合／转发的方法来代替 InstrumentedHashSet 类。注意这个实现分为两部分：类本身和可重用的转发类(forwarding class),其中包含了所有的转发方法,没有任何其他的方法：\n//Wrapper class -uses composition in place of inheritancepublic class InstrumentedSet&lt;E&gt; extends ForwardingSet&lt;E&gt;&#123;    private int addCount = 0;    public InstrumentedSet(Set&lt;E&gt; s) &#123;        super(s);    &#125;    @Override public boolean add(E e)&#123;        addCount++;        return super.add(e);    &#125;    @Override public boolean addAll(Collection&lt;? extends E&gt; c)&#123;        addCount += c.size();        return super.addAll(c);    &#125;    public int getAddCount() &#123;        return addCount;    &#125;&#125;//Reusable forwarding classpublic class ForwardingSet&lt;E&gt; implements Set&lt;E&gt;&#123;    private final Set&lt;E&gt; s;    public ForwardingSet(Set&lt;E&gt; s) &#123; this.s= S;&#125;    public void clear() &#123;s.clear();&#125;    public boolean contains(Object o) &#123;return s.contains(o);&#125;    public boolean isEmpty() &#123;return s.isEmpty();&#125;    public int size() &#123;return s.size();&#125;    public Iterator&lt;E&gt; iterator() &#123;return s.iterator();&#125;    public boolean add(E e)&#123; return s.add(e);&#125;    public boolean remove(Object o) &#123; return s.remove(o);&#125;    public boolean containsAll(Collection&lt;?&gt; c)&#123; return s.containsAll(c);&#125;    public boolean addAll(Collection&lt;? extends E&gt; c)&#123;return s.addAll(c);&#125;    public boolean removeAll(Collection&lt;?&gt; c)&#123; return s.removeAll(c);&#125;    public boolean retainAll(Collection&lt;?&gt; c)&#123;return s.retainAll(c);&#125;    public Object[] toArray() &#123; return s.toArrayO;&#125;    public &lt;T&gt; T[] toArray(T[] a) &#123;return s.toArray(a);&#125;    @Override public boolean equals(Object o)&#123; return s.equals(o);&#125;    @Override public int hashCode() &#123; return s.hashCode();&#125;    @Override public String toString() &#123; return s.toStringO;&#125;&#125;\n\nSet接口的存在使得InstrumentedSet类的设计成为可能,因为 Set接口保存了HashSet类的功能特性。除了获得健壮性之外,这种设计也带来了更多的灵活性。InstrumentedSet类实现了 Set接口,并且拥有单个构造器,它的参数也是Set类型。从本质上讲,这个类把一个Set转变成了另一个 Set,同时增加了计数的功能。前面提到的基于继承的方法只适用于单个具体的类,并且对于超类中所支持的每个构造器都要求有一)实现,并且可以结合任何先前存在的构造器一起工作:\nSet&lt;Instant&gt; times = new InstrumentedSet&lt;&gt;(new TreeSet&lt;&gt;(cmp));Set&lt;E&gt; s = new InstrumentedSet&lt;&gt;(new HashSet&lt;&gt;(INIT_CAPACITY));\n\nInstrumentedSet 类甚至也可以用来临时替换一个原本没有计数特性的 Set 实例\nstatic void walk(Set&lt;Dog&gt; dogs) &#123;     InstrumentedSet&lt;Dog&gt; iDogs = new InstrumentedSet&lt;&gt;(dogs);    ...// Within this method use iDogs instead of dogs&#125;\n\n因为每一个InstrumentedSet 实例都把另一个 Set 实例包装起来了,所以 Instru-mentedSet 类被称为包装类(wrapper class)。这也正是Decorator(修饰者)模式[Gamma95],因为 InstrumentedSet 类对一个集合进行了修饰,为它增加了计数特性。有时复合和转发的结合也被宽松地称为”委托”(delegation)。从技术的角度而言,这不是委托,除非包装对象把自身传递给被包装的对象[Lieberman86；Gamma95]。\n包装类几乎没有什么缺点。需要注意的一点是,包装类不适合用于回调框架(callbackframework)；在回调框架中,对象把自身的引引用传递给其他的对象,用于后续的调用(“回调”)。因为被包装起来的对象并不知道它外面的包装对象,所以它传递一个指向自身的引用(this),回调时避开了外面的包装对象。这被称为 SELF 问题[Lieberman86]。有些人担心转发方法调用所带来的性能影响,或者包装对象导致的内存占用。在实践中,这两者都不会造成很大的影响。编写转发方法倒是有点琐碎,但是只需要给每个接口编写一次构造器,转发类则可以通过包含接口的包提供。例如,Guava 就为所有的集合接口提供了转发类[ Guava ]。\n只有当子类真正是超类的子类型(subtype)时,才适合用继承。换句话说,对于两个类A 和B,只有当两者之间确实存在”is-a”关系的时候,类B才应该扩展类A。如果你打算让类B扩展类A,就应该问问自己：每个B确实也是A吗？如果你不能够确定这个问题的答案是肯定的,那么B就不应该扩展A。如果答案是否定的,通常情况下,B应该包含A的一个私有实例,并且暴露一个较小的、较简单的 API：A本质上不是B的一部分,只是它的实现细节而已。\n在Java 平台类库中,有许多明显违反这条原则的地方。例如,栈(stack)并不是向量(vector),所以 Stack 不应该扩展Vector。同样地,属性列表也不是散列表,所以Properties 不应该扩展 Hashtable。在这两种情况下,复合模式才是恰当的。\n如果在适合使用复合的地方使用了继承,则会不必要地暴露实现细节。这样得到的API会把你限制在原始的实现上,永远限定了类的性能。更为严重的是,由于暴露了内部的细节,客户端就有可能直接访问这些内部细节。这样至少会导致语义上的混淆。例如,如果p指向 Properties实例,那么p·getProperty(key)就有可能产生与p·get(key)不同的结果：前一个方法考虑了默认的属性表,而后一个方法则继承自 Hashtable,没有考虑默认的属性列表。最严重的是,客户有可能直接修改超类,从而破坏子类的约束条件。在Properties 的情形中,设计者的目标是只允许字符串作为键(key)和值(value),但是直接访问底层的Hashtable就允许违反这种约束条件。一旦违反了约束条件,就不可能再使用Properties API 的其他部分(load 和 store)了。等到发现这个问题时,要改正它已经太晚了,因为客户端依赖于使用非字符串的键和值了。\n在决定使用继承而不是复合之前,还应该问自己最后一组问题。对于你正试图扩展的机制会把超类API中的所有缺陷传播到子类中,而复合则允许设计新的API来隐藏这些缺陷。\n简而言之,继承的功能非常强大,但是也存在诸多问题,因为它违背了封装原则。只有当子类和超类之间确实存在子类型关系时,使用继承才是恰当的。即便如此,如果子类和超类处在不同的包中,并且超类并不是为了继承而设计的,那么继承将会导致脆弱性(fragility)。为了避免这种脆弱性,可以用复合和转发机制来代替继承,尤其是当存在适当的接口可以实现包装类的时候。包装类不仅比子类更加健壮,而且功能也更加强大。\n第19条：要么设计继承并提供文档说明,要么禁止继承第18条提醒过我们：对于不是为了继承而设计并且没有文档说明的”外来”类进行子类化是多么危险。那么对于专门为了继承而设计并且具有良好文档说明的类而言,这又意味着什么呢?\n首先,该类的文档必须精确地描述覆盖每个方法所带来的影响。换句话说,该类必须有文档说明它可覆盖(overridable)的方法的自用性(self-use)。对于每个公有的或受保护的方法或者构造器,它的文档必须指明该方法或者构造器调用了哪些可覆盖的方法,是以什么顺序调用的,每个调用的结果又是如何影响后续处理过程的(所谓可覆盖(overridable)的方法,是指非final 的、公有的或受保护的)。更广义地说,即类必须在文档中说明,在哪些情况下它会调用可覆盖的方法。例如,后台的线程或者静态的初始化器(initializer)可能会调用这样的方法。\n述信息。这段描述信息是规范的一个特殊部分,写着：”Implementation Requirements”(实现要求·…..··),它由Javadoc 标签@implSpec生成。这段话描述了该方法的内部工作情况。下面举个例子,摘自java.util.AbstractCollection 的规范:\npublic boolean remove(Object o)\n\n(如果这个集合中存在指定的元素,就从中删除该指定元素中的单个实例(这是项可选的操作)。更广义地说,即如果集合中包含一个或者多个这样的元素é,就从中删除掉一个,如Objects.equals(o,e)。如果集合中包含指定的元素,就返回true(如果调用的结果改变了集合,也是一样)。\n实现要求：该实现遍历整个集合来查找指定的元素。如果它找到该元素,将会利用迭代器的 remove 方法将之从集合中删除。注意,如果由该集合的 iterator 方法返回的迭代器没有实现 remove 方法,该实现就会抛出 UnsupportedOperationException。)\n这份文档清楚地说明了,覆盖 iterator 方法将会影响 remove 方法的行为。而且,它确切地描述了 iterator 方法返回的 Iterator 的行为将会怎样影响 remove方法的行为。与此相反的是,在第 18条的情形中,程序员在子类化 HashSet 的时候,无法说明覆盖 add 方法是否会影响 addAll 方法的行为。\n关于程序文档有句格言：好的API文档应该描述一个给定的方法做了什么工作,而不是描述它是如何做到的。那么,上面这种做法是否违背了这句格言呢？是的,它确实违背了！这正是继承破坏了封装性所带来的不幸后果。所以,为了设计一个类的文档,以便它能够被安全地子类化,你必须描述清楚那些有可能未定义的实现细节。\n@implSpec 标签是在Java 8 中增加的,在 Java 9 中得到了广泛应用。这个标签应该是默认可用的,但是到Java 9,Javadoc 工具仍然把它忽略,除非传入命令行参数：-tag”apiNote:a:API Note:”\n为了继承而进行的设计不仅仅涉及自用模式的文档设计。为了使程序员能够编写出更加有效的子类,而无须承受不必要的痛苦,类必须以精心挑选的受保护的(protected)方法的形式,提供适当的钩子(hook),以便进入其内部工作中。这种形式也可以是罕见的实例,或者受保护的域。例如,以java.util.AbstractList 中的 removeRange 方法为例:\nprotected void removeRange(int fromIndex, int toIndex)\n\n(从列表中删除所有索引处于fromIndex(含)和toIndex(不含)之间的元素。将所有符合条件的元素移到左边(减小它们索引l)。这一调用将从 ArrayList 中删除从 toIndex 到 fromIndex 之间的元素。(如果toIndex &#x3D;&#x3D; fromIndex,这项操作就无效。)\n这个方法是通过clear 操作在这个列表及其子列表中调用的。覆盖这个方法来利用列表实现的内部信息,可以充分地改善这个列表及其子列表中的clear操作的性能。\n实现要求：这项实现获得了一个处在 fromIndex 之前的列表迭代器,并依次地重复调用ListIterator.next 和ListIterator.remove,直到整个范围都被移除为止。注意：如果ListIterator.remove需要线性的时间,该实现就需要平方级的时间。\n参数：\n\nfromIndex要移除的第一个元素的索引l。\ntoIndex要移除的最后一个元素之后的索引。)\n\n这个方法对于List实现的最终用户并没有意义。提供该方法的唯一目的在于,使子类更易于提供针对子列表(sublist)的快速clear方法。如果没有removeRange方法,当在子列表(sublist)上调用clear方法时,子类将不得不用平方级的时间来完成它的工作。否则,就得重新编写整个subList机制—这可不是一件容易的事情！\n因此,当你为了继承而设计类的时候,如何决定应该暴露哪些受保护的方法或者域呢？遗憾的是,并没有什么神奇的法则可供你使用。你所能做到的最佳途径就是努力思考,发挥最好的想象,然后编写一些子类进行测试。你应该尽可能地少暴露受保护的成员,因为每个方法或者域都代表了一项关于实现细节的承诺。另一方面,你又不能暴露得太少,因为漏掉的受保护方法可能会导致这个类无法被真正用于继承。\n对于为了继承而设计的类,唯一的测试方法就是编写子类。如果遗漏了关键的受保护成员,尝试编写子类就会使遗漏所带来的痛苦变得更加明显。相反,如果编写了多个子类,并且无一使用受保护的成员,或许就应该把它做成私有的。经验表明,3个子类通常就足以测试一个可扩展的类。除了超类的程序设计者之外,都需要编写一个或者多个这种子类。\n在为了继承而设计有可能被广泛使用的类时,必须要意识到,对于文档中所说明的自用模式(self-use pattern),以及对于其受保护方法和域中所隐含的实现策略,你实际上已经做出了永久的承诺。这些承诺使得你在后续的版本中提高这个类的性能或者增加新功能都变得非常困难,甚至不可能。因此,必须在发布类之前先编写子类对类进行测试。\n还要注意,因继承而需要的特殊文档会打乱正常的文档信息,正常的文档信息是被设计用来让程序员可以创建该类的实例,并调用类中的方法。在编写本书之时,几乎还没有适当的工具或者注释规范,能够把”普通的API文档”与”专门针对实现子类的程序员的信息”区分开。\n为了允许继承,类还必须遵守其他一些约束。**构造器决不能调用可被覆盖的方法,**无论是直接调用还是间接调用。如果违反了这条规则,很有可能导致程序失败。超类的构造器在子类的构造器之前运行,所以,子类中覆盖版本的方法将会在子类的构造器运行之前先被调用。如果该覆盖版本的方法依赖于子类构造器所执行的任何初始化工作,该方法将不会如预期般执行。为了更加直观地说明这一点,下面举个例子,其中有个类违反了这条规则：\npublic class Super &#123;    //Broken-constructorinvokesanoverridablemethod    public Super() &#123;        overrideMe();    &#125;    public void overrideMe()&#123;&#125;&#125;\n\n下面的子类覆盖了方法 overrideMe,Super 唯一的构造器就错误地调用了这个方法:\npublic final class Sub extends Super&#123;    // Blank final,set by constructor    private final Instant instant;    Sub() &#123;instant = Instant.now();&#125;    //Overridingmethodinvokedbysuperclassconstructor    @Override public void overrideMe()&#123;        System.out.println(instant) ;    &#125;    public static void main(String[] args) &#123;        Sub sub = new Sub();sub.overrideMe () ;    &#125;&#125;\n\n你可能会期待这个程序会打印两次日期,但是它第一次打印出的是null,因为 over-rideMe 方法被 Super 构造器调用的时候,构造器 Sub 还没有机会初始化 instant 域。注意,这个程序观察到的 final 域处于两种不同的状态。还要注意,如果 overrideMe 已经调用了 instant 中的任何方法,当 Super 构造器调用 overrideMe 的时候,调用就会抛出 NullPointerException 异常。如果该程序没有抛出 NullPointerException异常,唯一的原因就在于 println 方法可以容忍 null 参数。\n注意,通过构造器调用私有的方法、final方法和静态方法是安全的,这些都不是可以被覆盖的方法。\n如果类是为了继承而设计的,无论实现这其中的哪个接口通常都不是个好主意,因为它们把一些实质性的负担转嫁到了扩展这个类的程序员身上。然而,你还是可以采取一些特殊的手段,允许子类实现这些接口,无须强迫子类的程序员去承受这些负担。第13条和第86 条中会讲解这些特殊的手段。\n如果你决定在一个为了继承而设计的类中实现 Cloneable 或者 Serializable接口,就应该意识到,因为 clone 和 readobject 方法在行为上非常类似于构造器,所以类似的限制规则也是适用的：无论是clone 还是readObject,都不可以调用可覆盖的方法,不管是以直接还是间接的方式。对于 readObject 方法,覆盖的方法将在子类的状态被反序列化(deserialized)之前先被运行；而对于clone 方法,覆盖的方法则是在子类的clone 方法有机会修正被克隆对象的状态之前先被运行。无论哪种情形,都不可避免地将导致程序失败。在clone 方法的情形中,这种失败可能会同时损害到原始的对象以及被克隆的对象本身。例如,如果覆盖版本的方法假设它正在修改对象深层结构的克隆对象的备份,就会发生这种情况,但是该备份还没有完成。\n最后,如果你决定在一个为了继承而设计的类中实现 Serializable 接口,并且该类有一个 readResolve 或者 writeReplace 方法,就必须使 readResolve 或者 write-Replace 成为受保护的方法,而不是私有的方法。如果这些方法是私有的,那么子类将会不声不响地忽略掉这两个方法。这正是”为了允许继承,而把实现细节变成一个类的API的一部分”的另一种情形。\n到现在为止,结论应该很明显了：为了继承而设计类,对这个类会有一些实质性的限制。这并不是很轻松就可以承诺的决定。在某些情况下,这样的决定很明显是正确的,比如抽象类,包括接口的骨架实现(skeletal implementation)(详见第 20 条)。但是,在另外一些情况下,这样的决定却很明显是错误的,比如不可变类(详见第17条)。\n但是,对于普通的具体类应该怎么办呢？它们既不是final的,也不是为了子类化而设计和编写文档的,所以这种状况很危险。每次对这种类进行修改,从这个类扩展得到的客户类就有可能遭到破坏。这不仅仅是个理论问题。对于一个并非为了继承而设计的非final具体类,在修改了它的内部实现之后,接收到与子类化相关的错误报告也并不少见。\n这个问题的最佳解决方案是,对于那些并非为了安全地进行子类化而设计和编写文档的类,要禁止子类化。有两种办法可以禁止子类化。比较容易的办法是把这个类声明为final的。另一种办法是把所有的构造器都变成私有的,或者包级私有的,并增加一些公有的静态工厂来替代构造器。后一种办法在第17条中讨论过,它为内部使用子类提供了灵活性。这两种办法都是可以接受的。\n这条建议可能会引来争议,因为许多程序员已经习惯于对普通的具体类进行子类化,以便增加新的功能设施,比如仪表功能(如计数显示等)、通知机制或者同步功能,或者为了限制原有类中的功能。如果类实现了某个能够反映其本质的接口,比如 Set、List 或者Map,就不应该为了禁止子类化而感到后悔。第18条中介绍的包装类(wrapperclass)模式还提供了另一种更好的办法,让继承机制实现更多的功能。\n如果具体的类没有实现标准的接口,那么禁止继承可能会给某些程序员带来不便。如果你认为必须允许从这样的类继承,一种合理的办法是确保这个类永远不会调用它的任何可覆盖的方法,并在文档中说明这一点。换句话说,完全消除这个类中可覆盖方法的自用特他任何方法的行为。\n你可以机械地消除类中可覆盖方法的自用特性,而不改变它的行为。将每个可覆盖方法的代码体移到一个私有的”辅助方法”(helper method)中,并且让每个可覆盖的方法调用它的私有辅助方法。然后用”直接调用可覆盖方法的私有辅助方法”来代替”可覆盖方法的每个自用调用”。\n简而言之,专门为了继承而设计类是一件很辛苦的工作。你必须建立文档说明其所有的自用模式,并且一旦建立了文档,在这个类的整个生命周期中都必须遵守。如果没有做到,子类就会依赖超类的实现细节,如果超类的实现发生了变化,它就有可能遭到破坏。为了允许其他人能编写出高效的子类,还你必须导出一个或者多个受保护的方法。除非知道真正需要子类,否则最好通过将类声明为final,或者确保没有可访问的构造器来禁止类被继承。\n第20条：接口优于抽象类Java 提供了两种机制,可以用来定义允许多个实现的类型：接口和抽象类。自从Java 8为继承引l入了缺省方法(default method),这两种机制都允许为某些实例方法提供实现。主要的区别在于,为了实现由抽象类定义的类型,类必须成为抽象类的一个子类。因为Java只允许单继承,所以用抽象类作为类型定义受到了限制。任何定义了所有必要的方法并遵守通用约定的类,都允许实现一个接口,无论这个类是处在类层次结构中的什么位置。\n现有的类可以很容易被更新,以实现新的接口。如果这些方法尚不存在,你所需要做的就只是增加必要的方法,然后在类的声明中增加一个 implements子句。例如,当Comparable、Iterable 和 Autocloseable 接口被引l人 Java 平台时,更新了许多现有的类,以实现这些接口。一般来说,无法更新现有的类来扩展新的抽象类。如果你希望两个类扩展同一个抽象类,就必须把抽象类放到类型层次(type hierarchy)的高处,这样它就成了那两个类的一个祖先。遗憾的是,这样做会间接地伤害到类层次,迫使这个公共祖先的所有后代类都扩展这个新的抽象类,无论它对于这些后代类是否合适。\n接口是定义 mixin(混合类型)的理想选择。不严格地讲,mixin 类型是指：类除了实现它的”基本类型”之外,还可以实现这个 mixin 类型,以表明它提供了某些可供选择的行为。例如,Comparable是一个mixin接口,它允许类表明它的实例可以与其他的可相互比较的对象进行排序。这样的接口之所以被称为 mixin,是因为它允许任选的功能可被混合到类型的主要功能中。抽象类不能被用于定义mixin,同样也是因为它们不能被更新到现有的类中：类不可能有一个以上的父类,类层次结构中也没有适当的地方来插入mixin。\n接口允许构造非层次结构的类型框架。类型层次对于组织某些事物是非常合适的,但是其他事物并不能被整齐地组织成一个严格的层次结构。例如,假设我们有一个接口代表一个singer(歌唱家),另一个接口代表一个songwriter(作曲家)：\npublic interface Singer&#123;    AudioClip sing(Song s);&#125;public interface Songwriter&#123;    Song compose(int chartPosition);&#125;在现实生活中,有些歌唱家本身也是作曲家。因为我们使用了接口而不是抽象类来定义这些类型,所以对于单个类而言,它同时实现 Singer 和 Songwriter 是完全允许的。实际上,我们可以定义第三个接口,它同时扩展 Singer 和 Songwriter,并添加一些适合于这种组合的新方法：```javapublic interface SingerSongwriter extends Singer, Songwriter &#123;    AudioClip strum();    void actSensitive();&#125;\n\n也许并非总是需要这种灵活性,但是一旦这样做了,接口可就成了救世主。另外一种做法是编写一个臃肿(bloated)的类层次,对于每一种要被支持的属性组合,都包含一个单独的类。如果在整个类型系统中有n个属性,那么就必须支持2”种可能的组合。这种现象被称为”组合爆炸”(combinatorial explosion)。类层次臃肿会导致类也臃肿,这些类包含许多方法,并且这些方法只是在参数的类型上有所不同而已,因为类层次中没有任何类型体现了公共的行为特征。\n通过第18条中介绍的包装类(wrapper class)模式,接口使得安全地增强类的功能成为可能。如果使用抽象类来定义类型,那么程序员除了使用继承的手段来增加功能,再没有其他的选择了。这样得到的类与包装类相比,功能更差,也更加脆弱。\n当一个接口方法根据其他接口方法有了明显的实现时,可以考虑以缺省方法的形式为程序员提供实现协助。关于这种方法的范例,请参考第 21条中的 removeIf 方法。如果提供了缺省方法,要确保利用Javadoc 标签@implSpec 建立文档(详见第 19条)。\n通过缺省方法可以提供的实现协助是有限的。虽然许多接口都定义了object方法的行为,如équals 和hashCode,但是不允许给它们提供缺省方法。而且接口中不允许包含实例域或者非公有的静态成员(私有的静态方法除外)。最后一点,无法给不受你控制的接口添加缺省方法。\n但是,通过对接口提供一个抽象的骨架实现(skeletalimplementation)类,可以把接口和抽象类的优点结合起来。接口负责定义类型,或许还提供一些缺省方法,而骨架实现类则负责实现除基本类型接口方法之外,剩下的非基本类型接口方法。扩展骨架实现占了实现接口之外的大部分工作。这就是模板方法(TemplateMethod)模式[Gamma95]。\n按照惯例,骨架实现类被称为 AbstractInterface,这里的Interface 是指所实现的接口的名字。例如,Collections Framework 为每个重要的集合接口都提供了一个骨架实现,包括AbstractCollection、AbstractSet、AbstractList 和 AbstractMap。将 它们称作 SkeletalCollection、 SkeletalSet、SkeletalList 和 SkeletalMap 也是有道理的,但是现在Abstract 的用法已经根深蒂固。 如果设计得当,骨架实现(无论是单独一个抽象类,还是接口中唯一包含的缺省方法)可以使程序员非常容易地提供他们自已的接口实现。例如,下面是一个静态工厂方法,除AbstractList之外,它还包含了一个完整的、功能全面的 List实现:\n//Concreteimplementationbuiltatopskeletalimplementationstatic List&lt;Integer&gt; intArrayAsList(int[] a) &#123;    Objects.requireNonNull(a) ;    // The diamond operator is only legal here in Java 9 and later    // If you&#x27;re using an earlier release,specify &lt;Integer&gt;    return new AbstractList&lt;&gt;() &#123;        @Override public Integer get(int i)&#123;            return a[i]; // Autoboxing (Item 6)        &#125;        @Override public Integer set(int i,Integer val) &#123;            int oldVal = a[i];            a[i] =val； //Auto-unboxing            return oldVal;// Autoboxing        &#125;        @Override public int size() &#123;            return a.length;        &#125;    &#125;;&#125;\n如果想知道一个List实现应该为你完成哪些工作,这个例子就充分演示了骨架实现的强大功能。顺便提一下,这个例子是个Adapter[Gamma95],它允许将 int数组看作Integer 实例的列表。由于在 int 值和 Integer 实例之间来回转换需要开销,它的性能不会很好。注意,这个实现采用了匿名类(anonymous class)的形式(详见第 24条)。\n骨架实现类的美妙之处在于,它们为抽象类提供了实现上的帮助,但又不强加”抽象类被用作类型定义时”所特有的严格限制。对于接口的大多数实现来讲,扩展骨架实现类是个很显然的选择,但并不是必须的。如果预置的类无法扩展骨架实现类,这个类始终能手工实现这个接口。同时,这个类本身仍然受益于接口中出现的任何缺省方法。此外,骨架实现类仍然有助于接口的实现。实现了这个接口的类可以把对于接口方法的调用转发到一个内部私有类的实例上,这个内部私有类扩展了骨架实现类。这种方法被称作模拟多重继承(simulated multiple inheritance),它与第18 条中讨论过的包装类模式密切相关。这项技术具有多重继承的绝大多数优点,同时又避免了相应的缺陷。\n编写骨架实现类相对比较简单,只是过程有点乏味。首先,必须认真研究接口,并确定哪些方法是最为基本的,其他的方法则可以根据它们来实现。这些基本方法将成为骨架实现类中的抽象方法。接下来,在接口中为所有可以在基本方法之上直接实现的方法提供缺省方法,但要记住,不能为 Object 方法(如 equals 和 hashCode)提供缺省方法。如果基本方法和缺省方法覆盖了接口,你的任务就完成了,不需要骨架实现类了。否则,就要编写一个类,声明实现接口,并实现所有剩下的接口方法。这个类中可以包含任何非公有的域,以及适合该任务的任何方法。\n以 Map.Entry接口为例,举个简单的例子。明显的基本方法是 getKey、getValue和(可选的)setValue。接口定义了equals 和hashCode 的行为,并且有一个明显的toString 实现。由于不允许给 Object 方法提供缺省实现,因此所有实现都放在骨架实现类中：\n//Skeletal implementation classpublic abstract class AbstractMapEntry&lt;k,V&gt;implements Map.Entry&lt;K,V&gt;&#123;    //Entries ina modifiablemap must overridethis method    @Override public V setValue(V value)&#123;        throw new UnsupportedOperationException();    &#125;    //Implements thegeneralcontract of Map.Entry.equals    @Override public boolean equals(Object o)&#123;        if(o== this)return true;        if (!(o instanceof Map.Entry))return false;        Map.Entry&lt;?,?&gt;e =(Map.Entry)o;        return Objects.equals(e.getKey(), getKey())            &amp;&amp;Objects.equals(e.getValue(), getValue());    &#125;    // Implements thegeneralcontract of Map.Entry.hashCode    @Override public int hashCode() &#123;        return Objects.hashCode(getKeyO)^ Objects.hashCode(getValue());    &#125;    @Override public String toString() &#123;        return getKey() + &quot;=&quot; + getValue();     &#125;&#125;\n注意,这个骨架实现不能在Map.Entry接口中实现,也不能作为子接口,因为不允许缺省方法覆盖 Object 方法,如 equals、hashCode 和toString。\n因为骨架实现类是为了继承的目的而设计的,所以应该遵从第19条中介绍的所有关于设计和文档的指导原则。为了简洁起见,上面例子中的文档注释部分被省略掉了,但是对于骨架实现类而言,好的文档绝对是非常必要的,无论它是否在接口或者单独的抽象类中包含了缺省方法。\n骨架实现上有个小小的不同,就是简单实现(simple implementation),AbstractMap,SimpleEntry就是个例子。简单实现就像骨架实现一样,这是因为它实现了接口,并且是为了继承而设计的,但是区别在于它不是抽象的：它是最简单的可能的有效实现。你可以原封不动地使用,也可以看情况将它子类化。\n总而言之,接口通常是定义允许多个实现的类型的最佳途径。如果你导出了一个重要的接口,就应该坚决考虑同时提供骨架实现类。而且,还应该尽可能地通过缺省方法在接口中提供骨架实现,以便接口的所有实现类都能使用。也就是说,对于接口的限制,通常也限制了骨架实现会采用的抽象类的形式。\n第21条：为后代设计接口在Java 8发行之前,如果不破坏现有的实现,是不可能给接口添加方法的。如果给某个接口添加了一个新的方法,一般来说,现有的实现中是没有这个方法的,因此就会导致编译错误。在Java 8中,增加了缺省方法(default method)构造[JLS9.4],目的就是允许给现有的接口添加方法。但是给现有接口添加新方法还是充满风险的。\n没有实现默认方法的所有类使用的。虽然Java中增加了缺省方法之后,可以给现有接口添加方法了,但是并不能确保这些方法在之前存在的实现中都能良好运行。因为这些默认的方法是被”注人”到现有实现中的,它们的实现者并不知道,也没有许可。在Java8之前,编写这些实现时,是默认它们的接口永远不需要任何新方法的。\nJava8在核心集合接口中增加了许多新的缺省方法,主要是为了便于使用lambda(详见第6章)。Java类库的缺省方法是高品质的通用实现,它们在大多数情况下都能正常使用。但是, 并非每一个可能的实现的所有变体,始终都可以编写出一个缺省方法。\n比如,以 removeIf 方法为例,它在 Java 8 中被添加到了 Collection 接口。这个方法用来移除所有元素,并用一个 boolean 函数(或者断言)返回true。缺省实现指定用其迭代器来遍历集合,在每个元素上调用断言(predicate),并利用迭代器的remove 方法移除断言返回值为 true 的元素。其声明大致如下:\n//Default method added to the Collection interface in Java 8default boolean removeIf(Predicate&lt;? super E&gt; filter)&#123;    Objects.requireNonNull(filter);    boolean result = false;    for (Iterator&lt;E&gt; it= iterator();it.hasNext();)&#123;        if(filter.test(it.next())) &#123;            it.remove();            result = true;        &#125;    &#125;    return result;&#125;\n\n这是适用于 removeIf方法的最佳通用实现,但遗憾的是,它在某些现实的Collection实现中会出错。比如,以 org.apache.commons.collections4.Collection.Synch-ronizedCollection 为例,这个类来自 Apache Commons 类库,类似于 java.util 中的静态工厂Collections.SynchronizedCollection。Apache版本额外提供了利用客户端提供的对象(而不是用集合)进行锁定的功能。换句话说,它是一个包装类(详见第18条),它的所有方法在委托给包装集合之前,都在锁定对象上进行了同步。\nApache 版本的 SynchronizedCollection 类依然有人维护,但是到编写本书之时,它也没有取代 removeIf 方法。如果这个类与Java 8结合使用,将会继承 removeIf 的缺省实现,它不会(实际上也无法)保持这个类的基本承诺：围绕着每一个方法调用执行自动同步。缺省实现压根不知道同步这回事,也无权访问包含该锁定对象的域。如果客户在SynchronizedCollection 实例上调用removeIf方法,同时另一个线程对该集合进行修改,就会导致ConcurrentModificationException 或者其他异常行为。\n为了避免在类似的 Java平台类库实现中发生这种异常,如 Collections.synchronizedCollection返回的包私有类,JDK维护人员必须覆盖默认的 removeIf实现,以及像它一样的其他方法,以便在调用缺省实现之前执行必要的同步。不属于Java平台组成部分的预先存在的集合实现,过去无法做出与接口变化相类似的改变,现在有些已经可以做到了。\n有了缺省方法,接口的现有实现就不会出现编译时没有报错或警告,运行时却失败的情况。这个问题虽然并非普遍,但也不是孤立的意外事件。Java8在集合接口中添加的许多方法是极易受影响的,有些现有实现已知将会受到影响。\n建议尽量避免利用缺省方法在现有接口上添加新的方法,除非有特殊需要,但就算在那样的情况下也应该慎重考虑：缺省的方法实现是否会破坏现有的接口实现。然而,在创建接口的时候,用缺省方法提供标准的方法实现是非常方便的,它简化了实现接口的任务(详见第20条)。\n还要注意的是,缺省方法不支持从接口中删除方法,也不支持修改现有方法的签名。对接口进行这些修改肯定会破坏现有的客户端代码。\n结论很明显：尽管缺省方法现在已经是Java平台的组成部分,但谨慎设计接口仍然是至关重要的。虽然缺省方法可以在现有接口上添加方法,但这么做还是存在着很大的风险。就算接口中只有细微的缺陷都可能永远给用户带来不愉快；假如接口有严重的缺陷,则可能摧毁包含它的API。\n因此,在发布程序之前,测试每一个新的接口就显得尤其重要。程序员应该以不同的方法实现每一个接口。最起码不应少于三种实现。编写多个客户端程序,利用每个新接口的实例来执行不同的任务,这一点也同样重要。这些步骤对确保每个接口都能满足其既定的所有用途起到了很大的帮助。它还有助于在接口发布之前及时发现其中的缺陷,使你依然能够轻松地把它们纠正过来。或许接口程序发布之后也能纠正,但是千万别指望它啦！\n第22条：接口只用于定义类型当类实现接口时,接口就充当可以引I用这个类的实例的类型(type)。因此,类实现了接口,就表明客户端可以对这个类的实例实施某些动作。为了任何其他目的而定义接口是不恰当的。\n有一种接口被称为常量接口(constant interface),它不满足上面的条件。这种接口不包含任何方法,它只包含静态的final域,每个域都导出一个常量。使用这些常量的类实现这个接口,以避免用类名来修饰常量名。下面举个例子：\n// Constant interface antipattern -do not use！public interface PhysicalConstants &#123;    // Avogadro&#x27;s number (1/mo1)    static final double AVOGADROS_NUMBER = 6.022_140_857e23;        // Boltzmann constant (J/K)    static fina1 doub1e BOLTZMANN_CONSTANT= 1.380_648_52e-23;        // Mass of the electron (kg)    static final double ELECTRON_MASS = 9.109_383_56e-31;&#125;\n\n常量接口模式是对接口的不良使用。类在内部使用某些常量,这纯粹是实现细节。实现常量接口会导致把这样的实现细节泄露到该类的导出 API中。类实现常量接口对于该类的用户而言并没有什么价值。实际上,这样做反而会使他们更加糊涂。更糟糕的是,它代表了一种承诺：如果在将来的发行版本中,这个类被修改了,它不再需要使用这些常量了,它依然必须实现这个接口,以确保二进制兼容性。如果非final类实现了常量接口,它的所有子类的命名空间也会被接口中的常量所”污染”。\n在Java平台类库中有几个常量接口,例如java.io.ObjectStreamConstants。这些接口应该被认为是反面的典型,不值得效仿。\n如果要导出常量,可以有几种合理的选择方案。如果这些常量与某个现有的类或者接口紧密相关,就应该把这些常量添加到这个类或者接口中。例如,在Java平台类库中所有的数值包装类,如Integer 和 Double,都导出了 MIN_VALUE 和 MAX_VALUE 常量。如果这些常量最好被看作枚举类型的成员,就应该用枚举类型(enum type)(详见第 34条)来导出这些常量。否则,应该使用不可实例化的工具类(utility class)(详见第 4条)来导出这些常量。下面的例子是前面的 PhysicalConstants 例子的工具类翻版:\n//Constantutilityclasspackage com.effectivejava.science;public class PhysicalConstants &#123;    private PhysicalConstants() &#123;&#125; // Prevents instantiation    public static final double AVOGADROS_NUMBER = 6.022_140_857e23;    public static final double BOLTZMANN_CONST = 1.380_648_52e-23;    public static final double ELECTRON_MASS = 9.109_383_56e-31;&#125;\n注意,有时候会在数字的字面量中使用下划线(_)。从Java 7开始,下划线的使用已经合法了,它对数字字面量的值没有影响,如果使用得当,还可以极大地提升它们的可读性。如果其中包含五个或五个以上连续的数字,无论是浮点还是定点,都要考虑在数字的字面量中添加下划线。对于基数为10的字面量,无论是整数还是浮点,都应该用下划线把数字隔成每三位一组,表示一千的正负倍数。\n工具类通常要求客户端要用类名来修饰这些常量名,例如 PhysicalConstants.AVO-GADROS_NUMBER。如果大量利用工具类导出的常量,可以通过利用静态导入(static import)机制,避免用类名来修饰常量名：\n// Use of static import to avoid qualifying constantsimport static com.effectivejava.science.PhysicalConstants.*;public class Test &#123;    double atoms(double mols) &#123;        return AVOGADROS_NUMBER * mols;    &#125;    ...    // Many more uses of PhysicalConstants justify static import&#125;\n\n简而言之,接口应该只被用来定义类型,它们不应该被用来导出常量。\n第23条：类层次优于标签类有时可能会遇到带有两种甚至更多种风格的实例的类,并包含表示实例风格的标签(tag)域。例如,以下面这个类为例,它能够表示圆形或者矩形:\n//Tagged class-vastly inferior to a class hierarchy！class Figure &#123;    enum Shape &#123; RECTANGLE,CIRCLE &#125;;    // Tag field - the shape of this figure    final Shape shape;        // These fields are used only if shape is RECTANGLE    double length;    double width;        // This field is used only if shape is CIRCLE    double radius;        // Constructor for circle    Figure(double radius) &#123;        shape = Shape.CIRCLE;        this.radius = radius;    &#125;    // Constructor for rectangle    Figure(double length,double width) &#123;        shape = Shape.RECTANGLE;        this.length = length;        this.width = width;    &#125;    double area()&#123;        switch(shape) &#123;            case RECTANGLE:                return length * width;            case CIRCLE:                return Math.PI *(radius * radius);            default:                throw new AssertionError(shape);        &#125;    &#125;&#125;\n\n这种标签类(tagged class)有许多缺点。它们中充斥着样板代码,包括枚举声明、标签域以及条件语句。由于多个实现乱七八糟地挤在单个类中,破坏了可读性。由于实例承担着属于其他风格的不相关的域,因此内存占用也增加了。域不能做成final的,除非构造器初始化了不相关的域,产生了更多的样板代码。构造器必须不借助编译器来设置标签域,并初始化正确的数据域：如果初始化了错误的域,程序就会在运行时失败。无法给标签类添加风格,除非可以修改它的源文件。如果一定要添加风格,就必须记得给每个条件语句都添加一个条件,否则类就会在运行时失败。最后,实例的数据类型没有提供任何关于其风格的线索。一句话,标签类过于长、容易出错,并且效率低下。\n幸运的是,面向对象的语言(如Java)提供了其他更好的方法来定义能表示多种风格对象的单个数据类型：子类型化(subtyping)。标签类正是对类层次的一种简单的仿效。\n为了将标签类转变成类层次,首先要为标签类中的每个方法都定义一个包含抽象方法的抽象类,标签类的行为依赖于标签值。在 Figure 类中,只有一个这样的方法：area。这个抽象类是类层次的根(root)。如果还有其他的方法其行为不依赖于标签的值,就把这样的方法放在这个类中。同样地,如果所有的方法都用到了某些数据域,就应该把它们放在这个类中。在Figure 类中,不存在这种类型独立的方法或者数据域。\n接下来,为每种原始标签类都定义根类的具体子类。在前面的例子中,这样的类型有两个：圆形(circle)和矩形(rectangle)。在每个子类中都包含特定于该类型的数据域。在我们的示例中,radius 是特定于圆形的,length 和 width 是特定于矩形的。同时在每个子类中还包括针对根类中每个抽象方法的相应实现。以下是与原始的Figure类相对应的类层次：\n//Class hierarchy replacement for a tagged class abstract class Figure&#123;    abstract double area();&#125;class Circle extends Figure &#123;    final double radius;    Circle(double radius) &#123; this.radius = radius;&#125;    @Override double area() &#123; return Math.PI*(radius *radius);&#125;&#125;class Rectangle extends Figure  &#123;    final double length;    final double width;        Rectangle(double length, double width) &#123;        this.length = length;        this.width = width;    &#125;        @Override double area() &#123; return length * width; &#125;&#125;\n\n这个类层次纠正了前面提到过的标签类的所有缺点。这段代码简单且清楚,不包含在原来的版本中见到的所有样板代码。每个类型的实现都配有自己的类,这些类都没有受到不相关数据域的拖累。所有的域都是final的。编译器确保每个类的构造器都初始化它的数据域,对于根类中声明的每个抽象方法都确保有一个实现。这样就杜绝了由于遗漏 switch case而导致运行时失败的可能性。多名程序员可以独立地扩展层次结构,并且不用访问根类的源代码就能相互操作。每种类型都有一种相关的独立的数据类型,允许程序员指明变量的类型,限制变量,并将参数输人到特殊的类型。\n类层次的另一个好处在于,它们可以用来反映类型之间本质上的层次关系,有助于增强灵活性,并有助于更好地进行编译时类型检查。假设上述例子中的标签类也允许表达正方形。类层次可以反映出正方形是一种特殊的矩形这一事实(假设两者都是不可变的):\nclass Square extends Rectangle &#123;    Square(double side)&#123;        super(side, side);    &#125;&#125;\n\n注意,上述层次中的域被直接访问,而不是通过访问方法访问。这是为了简洁起见,如果层次结构是公有的(详见第16条),则不允许这样做。\n简而言之,标签类很少有适用的时候。当你想要编写一个包含显式标签域的类时,应该考虑一下,这个标签是否可以取消,这个类是否可以用类层次来代替。当你遇到一个包含标签域的现有类时,就要考虑将它重构到一个层次结构中去。\n第24条：静态成员类优于非静态成员类嵌套类(nested class)是指定义在另一个类的内部的类。嵌套类存在的目的应该只是为它的外围类(enclosing class)提供服务。如果嵌套类将来可能会用于其他的某个环境中,它就应该是顶层类(top-levelclass)。嵌套类有四种：静态成员类(static member class)、非静态成员类(nonstatic member class)、匿名类(anonymous class)和局部类(local class)。除了第一种之外,其他三种都称为内部类(inner class)。本条目将告诉你什么时候应该使用哪种嵌套类,以及这样做的原因。\n静态成员类是最简单的一种嵌套类。最好把它看作是普通的类,只是碰巧被声明在另一个类的内部而已,它可以访问外围类的所有成员,包括那些声明为私有的成员。静态成员类是外围类的一个静态成员,与其他的静态成员一样,也遵守同样的可访问性规则。如果它被声明为私有的,它就只能在外围类的内部才可以被访问,等等。\n静态成员类的一种常见用法是作为公有的辅助类,只有与它的外部类一起使用才有意义。例如,以枚举为例,它描述了计算器支持的各种操作(详见第 34条)。Operation 枚举应该是Calculator类的公有静态成员类,之后Calculator类的客户端就可以用诸如 Calculator.Operation.PLUS 和 Calculator.Operation.MINUS 这样的名称来引引用这些操作。\n从语法上讲,静态成员类和非静态成员类之间唯一的区别是,静态成员类的声明中包含修饰符 static。尽管它们的语法非常相似,但是这两种嵌套类有很大的不同。非静态成员类的每个实例都隐含地与外围类的一个外围实例(enclosing instance)相关联。在非静态成员类的实例方法内部,可以调用外围实例上的方法,或者利用修饰过的 this(qualifiedthis)构造获得外围实例的引I用[JLS,15.8.4]。如果嵌套类的实例可以在它外围类的实例之外独立存在,这个嵌套类就必须是静态成员类：在没有外围实例的情况下,要想创建非静态成员类的实例是不可能的。\n当非静态成员类的实例被创建的时候,它和外围实例之间的关联关系也随之被建立起来；而且,这种关联关系以后不能被修改。通常情况下,当在外围类的某个实例方法的内部调用非静态成员类的构造器时,这种关联关系被自动建立起来。使用表达式énclosing-Instance.newMemberClass(args)来手工建立这种关联关系也是有可能的,但是很少使用。正如你所预料的那样,这种关联关系需要消耗非静态成员类实例的空间,并且会增加构造的时间开销。\n非静态成员类的一种常见用法是定义一个Adapter[Gamma95],它允许外部类的实例被看作是另一个不相关的类的实例。例如,Map 接口的实现往往使用非静态成员类来实现它们的集合视图(collection view),这些集合视图是由 Map 的keySet、entrySet 和values方法返回的。同样地,诸如 Set 和List这种集合接口的实现往往也使用非静态成员类来实现它们的迭代器(iterator):\n//Typical use of a nonstatic member class public class MySet&lt;E&gt; extends AbstractSet&lt;E&gt;&#123;    ...// Bulk of the class omitted    @Override public Iterator&lt;E&gt; iterator()&#123;        return new MyIterator();    &#125;    private class MyIterator implements Iterator&lt;E&gt;&#123;        ...    &#125;&#125;\n\n**如果声明成员类不要求访问外围实例,就要始终把修饰符static放在它的声明中,**使它成为静态成员类,而不是非静态成员类。如果省略了static 修饰符,则每个实例都将包含一个额外的指向外围对象的引用。如前所述,保存这份引用要消耗时间和空间,并且会导致外围实例在符合垃圾回收(详见第7条)时却仍然得以保留。由此造成的内存泄漏可能是灾难性的。但是常常难以发现,因为这个引用是不可见的。\n私有静态成员类的一种常见用法是代表外围类所代表的对象的组件。以Map实例为例,它把键(key)和值(value)关联起来。许多Map 实现的内部都有一个Entry对象,对应于Map 中的每个键-值对。虽然每个entry都与一个Map关联,但是éntrY上的方法(getKeY、getValue 和 setValue)并不需要访问该Map。因此,使用非静态成员类来表示éntry是很浪费的：私有的静态成员类是最佳的选择。如果不小心漏掉了éntry声明中的 static 修饰符,该Map 仍然可以工作,但是每个 éntry中将会包含一个指向该Map 的引用,这样就浪费了空间和时间。\n如果相关的类是导出类的公有或受保护的成员,毫无疑问,在静态和非静态成员类之间做出正确的选择是非常重要的。在这种情况下,该成员类就是导出的API元素,在后续的发行版本中,如果不违反向后兼容性,就无法从非静态成员类变为静态成员类。\n顾名思义,匿名类是没有名字的。它不是外围类的一个成员。它并不与其他的成员一起被声明,而是在使用的同时被声明和实例化。匿名类可以出现在代码中任何允许存在表达式的地方。当且仅当匿名类出现在非静态的环境中时,它才有外围实例。但是即使它们出现在静态的环境中,也不可能拥有任何静态成员,而是拥有常数变量(constant variable),常数变量是final基本类型,或者被初始化成常量表达式[JLS,4.12.4]的字符串域。\n匿名类的运用受到诸多的限制。除了在它们被声明的时候之外,是无法将它们实例化的。不能执行instanceof测试,或者做任何需要命名类的其他事情。无法声明一个匿名类来实现多个接口,或者扩展一个类,并同时扩展类和实现接口。除了从超类型中继承得到之外,匿名类的客户端无法调用任何成员。由于匿名类出现在表达式中,它们必须保持简短(大约10行或者更少),否则会影响程序的可读性。\n在Java 中增加lambda(详见第6章)之前,匿名类是动态地创建小型函数对象(functionobject)和过程对象(process object)的最佳方式,但是现在会优先选择 lambda(详见第 42条)。匿名类的另一种常见用法是在静态工厂方法的内部(参见第 20条中的intArrayAsList方法)。\n局部类是四种嵌套类中使用最少的类。在任何”可以声明局部变量”的地方,都可以声明局部类,并且局部类也遵守同样的作用域规则。局部类与其他三种嵌套类中的每一种都有一些共同的属性。与成员类一样,局部类有名字,可以被重复使用。与匿名类一样,只有当局部类是在非静态环境中定义的时候,才有外围实例,它们也不能包含静态成员。与匿名类一样,它们必须非常简短,以便不会影响可读性。\n总而言之,共有四种不同的嵌套类,每一种都有自己的用途。如果一个嵌套类需要在单个方法之外仍然是可见的,或者它太长了,不适合放在方法内部,就应该使用成员类。如果成员类的每个实例都需要一个指向其外围实例的引用,就要把成员类做成非静态的；否则,就做成静态的。假设这个嵌套类属于一个方法的内部,如果你只需要在一个地方创建实例,并且已经有了一个预置的类型可以说明这个类的特征,就要把它做成匿名类；否则,就做成局部类。\n第25条：限制源文件为单个顶级类虽然Java 编译器允许在一个源文件中定义多个顶级类,但这么做并没有什么好处,只会带来巨大的风险。因为在一个源文件中定义多个顶级类,可能导致给一个类提供多个定义。哪一个定义会被用到,取决于源文件被传给编译器的顺序。\n为了更具体地说明,下面举个例子,这个源文件中只包含一个Main类,它将引用另外两个顶级类(Utensil 和 Dessert)的成员:\npublic class Main &#123;    public static void main(String[] args) &#123;        System.out.println(Utensil.NAME + Dessert.NAME);    &#125;&#125;\n现在假设你在一个名为 Utensil.java 的源文件中同时定义了 Utensil 和 Dessert:\n// Two classes defined in one file.Don&#x27;t ever do this!class Utensil &#123;    static final String NAME = &quot;pan&quot;;&#125;class Dessert &#123;    static final String NAME =&quot;cake&quot;;&#125;\n当然,主程序会打印出”pancake”。现在假设你不小心在另一个名为 Dessert.java 的源文件中也定义了同样的两个类：\n//Twoclassesdefinedinonefile.Don&#x27;teverdothis！class Utensil &#123;    static final String NAME = &quot;pot&quot;;&#125;class Dessert &#123;    static final String NAME = &quot;pie&quot;;&#125;\n\n如果你侥幸是用命令javac Main.javaDessert.java 来编译程序,那么编译就会失败,此时编译器会提醒你定义了多个Utensil 和 Dessert类。这是因为编译器会先编译Main.java,当它看到Utensil的引I用(在 Dessert引用之前),就会在Utensil.javajava 时,也会去查找该文件,结果会遇到Utensil 和 Dessert这两个定义。\n如果用命令 javac Main.java 或者 javac Main.java Utensil.java 编译程序,结果将如同你还没有编写 Dessert.java 文件一样,输出 pancake。但如果是用命令javacDessert.java Main.java 编译程序,就会输出 potpie。程序的行为受源文件被传给编译器的顺序影响,这显然是让人无法接受的。\n这个问题的修正方法很简单,只要把顶级类(在本例中是指Utensil 和 Dessert)分别放入独立的源文件即可。如果一定要把多个顶级类放进一个源文件中,就要考虑使用静态成员类(详见第 24条),以此代替将这两个类分到独立源文件中去。如果这些类服从于另一个类,那么将它们做成静态成员类通常比较好,因为这样增强了代码的可读性,如果将这些类声明为私有的(详见第15条),还可以使它们减少被读取的概率。以下就是做成静态成员类的范例：\n// Static member classes instead of multiple top-level classespublic class Test &#123;    public static void main(String[] args) &#123;        System.out.println(Utensil.NAME + Dessert.NAME) ;    &#125;    private static class Utensil &#123;        static final String NAME =&quot;pan&quot;;    &#125;    private static class Dessert &#123;        static final String NAME = &quot;cake&quot;;    &#125;&#125;\n\n结论显而易见：永远不要把多个顶级类或者接口放在一个源文件中。遵循这个规则可以确保编译时一个类不会有多个定义。这么做反过来也能确保编译产生的类文件,以及程序结果的行为,都不会受到源文件被传给编译器时的顺序的影响。\n第五章 泛型从Java 5开始,泛型(generic)已经成了Java 编程语言的一部分。在没有泛型之前,从集合中读取到的每一个对象都必须进行转换。如果有人不小心插入了类型错误的对象,在运行时的转换处理就会出错。有了泛型之后,你可以告诉编译器每个集合中接受哪些对象类型。编译器自动为你的插人进行转换,并在编译时告知是否插入了类型错误的对象。这样可以使程序更加安全,也更加清楚,但是要享有这些优势(不限于集合)有一定的难度。本章就是教你如何最大限度地享有这些优势,又能使整个过程尽可能简单化。\n第26条：请不要使用原生态类型首先介绍一些术语。声明中具有一个或者多个类型参数(type parameter)的类或者接口,就是泛型(generic)类或者接口[JLS,8.1.2,9.1.2]。例如,List 接口就只有单个类型参数E,表示列表的元素类型。这个接口的全称是List&lt;E&gt;(读作”E的列表”),但是人们经常把它简称为 List。泛型类和接口统称为泛型(generic type)。\n每一种泛型定义一组参数化的类型(parameterized type),构成格式为：先是类或者接口的名称,接着用尖括号(&lt;&gt;)把对应于泛型形式类型参数的实际类型参数(actual type paramter)列表 ［ JLS, 4.4, 4.5 ］ 括起来。 例如, List&lt;String&gt; (读作 “字符串列表”)是一个参数化的类型,表示元素类型为 String 的列表。( String 是与形式的类型参数 E 相对应的实际类型参数。)\n最后一点,每一种泛型都定义一个原生态类型(raw type),即不带任何实际类型参数的泛型名称[ JLS,4.8]。例如,与List&lt;E&gt;相对应的原生态类型是List。原生态类型就像从类型声明中删除了所有泛型信息一样。它们的存在主要是为了与泛型出现之前的代码相兼容。\n在 Java 增加泛型之前,下面这个集合声明是值得参考的。从 Java 9开始,它依然合法,但是已经没什么参考价值了：\n//Rawcollectiontype-don&#x27;t dothis!// My stamp collection. Contains only Stamp instances.private final Collection stamps =...;\n\n如果现在使用这条声明,并且不小心将一个 coin 放进了 stamp 集合中,这一错误的插入照样得以编译和运行,不会出错(不过编译器确实会发出一条模糊的警告信息)：\n//Erroneous insertion of coininto stamp collectionstamps.add(new Coin( ... )); // Emits &quot;unchecked call&quot; warning\n\n直到从 stamp 集合中获取coin 时才会收到一条错误提示:\n// Raw iterator type - don&#x27;t do this!for (Iterator i = stamps.iterator(); i.hasNext(); )    Stamp stamp = (Stamp) i.next(); // Throws ClassCastException    stamp.cancel();\n\n如本书中经常提到的,出错之后应该尽快发现,最好是编译时就发现。在本例中,直到运行时才发现错误,已经出错很久了,而且它在代码中所处的位置,距离包含错误的这部分代码已经很远了。一旦发现ClassCastException,就必须搜索代码,查找将coin 放进 stamp 集合的方法调用。此时编译器帮不上忙,因为它无法理解这种注释:”Contains only Stamp instances”(只包含 Stamp 实例)。\n有了泛型之后,类型声明中可以包含以下信息,而不是注释：\n// Parameterized collection type - typesafeprivate final Collection&lt;Stamp&gt; stamps = ... ;\n通过这条声明,编译器知道 stamps 应该只包含 Stamp 实例,并给予保证(guarantee),假设整个代码库在编译过程中都没有发出(或者隐瞒,详见第27条)任何警告。当 stamps利用一个参数化的类型进行声明时,错误的插入会产生一条编译时的错误消息,告诉你具体是哪里出错了：\nTest.java:9:error:incompatible types:Coin cannot be convertedto StampC.add(new Coin());\n\n从集合中检索元素时,编译器会替你插入隐式的转换,并确保它们不会失败(依然假设所有代码都没有产生或者隐瞒任何编译警告)。假设不小心将coin插人stamp 集合,这显得有点牵强,但这类问题却是真实的。例如,很容易想象有人会不小心将一个BigInteger实例放进一个原本只包含BigDecimal实例的集合中。\n如上所述,使用原生态类型(没有类型参数的泛型)是合法的,但是永远不应该这么做。如果使用原生态类型,就失掉了泛型在安全性和描述性方面的所有优势。既然不应该使用原生态类型,为什么Java语言的设计者还要允许使用它们呢?这是为了提供兼容性。因为泛型出现的时候,Java平台即将进人它的第二个十年,已经存在大量没有使用泛型的Java代码。人们认为让所有这些代码保持合法,并且能够与使用泛型的新代码互用,这一点很重要。它必须合法才能将参数化类型的实例传递给那些被设计成使用普通类型的方法,反之亦然。这种需求被称作移植兼容性(MigrationCompatibility),促成了支持原生态类型,以及利用擦除(erasure)(详见第28条)实现泛型的决定。\n虽然不应该在新代码中使用像List这样的原生态类型,使用参数化的类型以允许插人任意对象(比如List&lt;Object&gt;)是可行的。原生态类型List和参数化的类型List&lt;Object&gt;之间到底有什么区别呢?不严格地说,前者逃避了泛型检查,后者则明确告知编译器,它能够持有任意类型的对象。虽然可以将 List&lt;String&gt;传递给类型List 的参数,但是不能将它传给类型List&lt;Object&gt;的参数。泛型有子类型化(subtyping)的规则,List&lt;String&gt;是原生态类型List 的一个子类型,而不是参数化类型List&lt;Object&gt;的子类型(详见第28条)。因此,如果使用像List这样的原生态类型,就会失掉类型安全性,但是如果使用像List&lt;Object&gt;这样的参数化类型,则不会。\n为了更具体地进行说明,请参考下面的程序：\n// Fails at runtime - unsafeAdd method uses a raw type (List)!public static void main(String[] args) &#123;    List&lt;String&gt; strings = new ArrayList&lt;&gt;();    unsafeAdd(strings, Integer.value0f(42));    String s = strings.get(0);// Has compiler-generated cast&#125;private static void unsafeAdd(List list, Object o) &#123;    list.add(o) ;&#125;\n\n这段程序可以进行编译,但是因为它使用了原生态类型List,你会收到一条警告:\nTest.java:10: warning: [unchecked] unchecked call to add(E) as a member of the raw type Listlist.add(o) ;\n\n实际上,如果运行这段程序,在程序试图将 strings.get(O)的调用结果 Integer转换成 String 时,你会收到一个ClassCastException异常。这是一个编译器生成的转换,因此一般保证会成功,但是我们在这个例子中忽略了一条编译器警告,为此付出了代价。\n如果在 unsafeAdd 声明中用参数化类型List&lt;Object&gt;代替原生态类型List,并试着重新编译这段程序,会发现它无法再进行编译了,并发出以下错误消息：\nTest.java:5: error: incompatible types: List&lt;String&gt; cannot beconverted to List&lt;object&gt;    unsafeAdd(strings, Integer.value0f(42));\n\n在不确定或者不在乎集合中的元素类型的情况下,你也许会使用原生态类型。例如,假设想要编写一个方法,它有两个集合,并从中返回它们共有元素的数量。如果你对泛型还不熟悉,可以参考以下方式来编写这种方法：\n//Useofraw typeforunknown elementtype-don&#x27;tdothis！static int numElementsInCommon(Set sl,Set s2) &#123;    int result=0;    for (Object ol : s1)        if (s2.contains(o1))            result++;        return result;&#125;\n\n这个方法可行,但它使用了原生态类型,这是很危险的。安全的替代做法是使用无限类型参数,就可以用一个问号代替。例如,泛型 Set&lt;E&gt;的无限制通配符类型为 Set&lt;?&gt;numElementsInCommon方法使用了无限制通配符类型时的情形:\n//Usesunboundedwildcard type-typesafeandflexiblestatic int numElementsInCommon(Set&lt;?&gt; sl,Set&lt;?&gt; s2) &#123;...&#125;\n用了吗?这一点不需要赘述,但通配符类型是安全的,原生态类型则不安全。由于可以将任何元素放进使用原生态类型的集合中,因此很容易破坏该集合的类型约束条件(如之前范例中所示的unsafeAdd方法);但不能将任何元素(除了null之外)放到collection&lt;?&gt;中。如果尝试这么做,将会产生一条像这样的编译时错误消息：\nWildCard.java:13: error: incompatible types: String cannot beconverted to CAP#1        C.add(&quot;verboten&quot;);    whereCAP#lisafreshtype-variable:        CAP#1 extends Object from capture of?\n\n这样的错误消息显然无法令人满意,但是编译器已经尽到了它的职责,防止你破坏集合的类型约束条件。你不仅无法将任何元素(除了null之外)放进Collection&lt;?&gt;中,而且根本无法猜测你会得到哪种类型的对象。要是无法接受这些限制,就可以使用泛型方法(详见第30条)或者有限制的通配符类型(详见第31条)。\n不要使用原生态类型,这条规则有几个小小的例外。必须在类文字(class literal)中使用原生态类型。规范不允许使用参数化类型(虽然允许数组类型和基本类型)[ JLS,15.8.2]。换句话说,List.class、String[].class 和 int.class 都合法,但是List&lt;String&gt;.class 和List&lt;?&gt;.class 则不合法。\n这条规则的第二个例外与 instanceof 操作符有关。由于泛型信息可以在运行时被擦除,因此在参数化类型而非无限制通配符类型上使用 instanceof 操作符是非法的。用无限制通配符类型代替原生态类型,对 instanceof 操作符的行为不会产生任何影响。在这种情况下,尖括号(&lt;&gt;)和问号(?)就显得多余了。下面是利用泛型来使用 instanceof操作符的首选方法：\n// Legitimate use of raw type instanceof operatorif (o instanceof Set)&#123; //Raw type    Set&lt;?&gt;s=(Set&lt;?&gt;)o; // wildcard type    ...&#125;\n\n注意,一旦确定这个是个 Set,就必须将它转换成通配符类型 Set&lt;?&gt;,而不是转换成原生态类型 Set。这是个受检的(checked)转换,因此不会导致编译时警告。\n总而言之,使用原生态类型会在运行时导致异常,因此不要使用。原生态类型只是为了与引入泛型之前的遗留代码进行兼容和互用而提供的。让我们做个快速的回顾：Set&lt;Object&gt;是个参数化类型,表示可以包含任何对象类型的一个集合；Set&lt;?&gt;则是一个通配符类型,表示只能包含某种未知对象类型的一个集合；Set是一个原生态类型,它脱离了泛型系统。前两种是安全的,最后一种不安全。\n为便于参考,在下表中概括了本条目中所介绍的术语(及本章后续条目中将要介绍的一些术语):\n\n第27条：消除非受检的警告用泛型编程时会遇到许多编译器警告：非受检转换警告(unchecked cast warning)、非受检方法调用警告、非受检参数化可变参数类型警告(unchecked parameterized vararg type warning),以及非受检转换警告(unchecked conversion warning)。 当你越来越熟悉泛型之后,遇到的警告也会越来越少,但是不要期待一开始用泛型编写代码就可以正确地进行编译。\n有许多非受检警告很容易消除。例如,假设意外地编写了这样一个声明：\nSet&lt;Lark&gt; exaltation = new HashSet();\n\n编译器会细致地提醒你哪里出错了:\nVenery.java:4: warning: [unchecked] unchecked conversion    Set&lt;Lark&gt; exaltation = new HashSet();        required: Set&lt;Lark&gt;    found: HashSet\n\n你就可以纠正所显示的错误,消除警告。注意,不必真正去指定类型参数,只需要用在Java7中开始引入的菱形操作符(diamondoperator)(&lt;&gt;)将它括起来即可。随后编译器就会推测出正确的实际类型参数(在本例中是Lark):\nSet&lt;Lark&gt; exaltation = new HashSet&lt;&gt;();\n有些警告非常难以消除。本章主要介绍这种警告示例。当你遇到需要进行一番思考的警告时,要坚持住！要尽可能地消除每一个非受检警告。如果消除了所有警告,就可以确保代码是类型安全的,这是一件很好的事情。这意味着不会在运行时出现Class-Cast-Exception 异常,你会更加自信自己的程序可以实现预期的功能。\n如果无法消除警告,同时可以证明引起警告的代码是类型安全的,(只有在这种情况下)才可以用一个@SuppressWarnings(“unchecked”)注解来禁止这条警告。如果在禁止警告之前没有先证实代码是类型安全的,那就只是给你自己一种错误的安全感而已。代码在编译的时候可能没有出现任何警告,但它在运行时仍然会抛出 ClassCastException异常。但是如果忽略(而不是禁止)明知道是安全的非受检警告,那么当新出现一条真正有问题的警告时,你也不会注意到。新出现的警告就会淹没在所有的错误警告声当中。\nSuppressWarnings 注解可以用在任何粒度的级别中,从单独的局部变量声明到整个类都可以。应该始终在尽可能小的范围内使用SuppressWarnings 注解。它通常是个变量声明,或是非常简短的方法或构造器。永远不要在整个类上使用 SuppressWarnings,这么做可能会掩盖重要的警告。\n如果你发现自已在长度不止一行的方法或者构造器中使用了 SuppressWarnings 注解,可以将它移到一个局部变量的声明中。虽然你必须声明一个新的局部变量,不过这么做还是值得的。例如,看看 ArrayList 类当中的toArray方法:\npublic &lt;T&gt;T[]toArray(T[]a)&#123;    if (a.length &lt; size)        return (T[]) Arrays.copyOf(elements, size, a.getClass());        System.arraycopy(elements, 0, a, 0, size);        if (a.length &gt; size)            a[size] = null;        return a;&#125;\n\n如果编译ArrayList,该方法就会产生成这条警告：\nArrayList.java:305: warning: [unchecked] unchecked cast    return (T[]) Arrays.copyOf(elements, size, a.getClass());        required: T[]    found: Object[]\n将 SuppressWarnings 注解放在 return 语句中是合法的,因为它不是声明[ JLS,9.7]。你可以试着将注解放在整个方法上,但是在实践中千万不要这么做,而是应该声明一个局部变量来保存返回值,并注解其声明,像这样：\n// Adding local variable to reduce scope of @SuppressWarningspublic&lt;T&gt;T[]toArray(T[] a)&#123;    if (a.length &lt; size)&#123;        // Thiscastis correct because the arraywe&#x27;recreating        //is of the same type as the one passed in,which is T[].        @SuppressWarnings(&quot;unchecked&quot;) T[] result =(T[]) Arrays.copyOf(elements, size, a.getClass());        return result;    &#125;    System.arraycopy(elements, 0, a, 0, size);    if (a.length &gt; size)        a[size] = null;    return a;&#125;\n\n这个方法可以正确地编译,禁止非受检警告的范围也会减到最小。\n每当使用 SuppressWarnings(&quot;unchecked&quot;)注解时,都要添加一条注释,说明为什么这么做是安全的。这样可以帮助其他人理解代码,更重要的是,可以尽量减少其他人修改代码后导致计算不安全的概率。如果你觉得这种注释很难编写,就要多加思考。最终你会发现非受检操作是非常不安全的。\n总而言之,非受检警告很重要,不要忽略它们。每一条警告都表示可能在运行时抛出ClassCastException 异常。要尽最大的努力消除这些警告。如果无法消除非受检警告,同时可以证明引起警告的代码是类型安全的,就可以在尽可能小的范围内使用@Suppress-\n第28条：列表优于数组数组与泛型相比,有两个重要的不同点。首先,数组是协变的(covariant)。这个词听起来有点吓人,其实只是表示如果 Sub 为 Super 的子类型,那么数组类型 Sub[]就是Super[]的子类型。相反,泛型则是可变的(invariant)：对于任意两个不同的类型Type1类型[JLS,4.10；Naftalin07,2.5]。你可能认为,这意味着泛型是有缺陷的,但实际上可以说数组才是有缺陷的。下面的代码片段是合法的：\n// Fails at runtime!Object[] objectArray = new Long[1];objectArray[0]=&quot;I don&#x27;t fit in&quot;;// Throws ArrayStoreException\n但下面这段代码则不合法：\n//Won&#x27;tcompile!List&lt;Object&gt; ol = new ArrayList&lt;Long&gt;(); // Incompatible types ol.add(&quot;I don&#x27;t fit in&quot;);\n\n这其中无论哪一种方法,都不能将 String放进Long容器中,但是利用数组,你会在运行时才发现所犯的错误；而利用列表,则可以在编译时就发现错误。 我们当然希望在编译时就发现错误。\n数组与泛型之间的第二大区别在于,数组是具体化的(reified)[JLS,4.7]。因此数组会在运行时知道和强化它们的元素类型。如上所述,如果企图将 String 保存到Long数组中,就会得到一个ArrayStoreException异常。相比之下,泛型则是通过擦除(erasure)[JLS,4.6]来实现的。这意味着,泛型只在编译时强化它们的类型信息,并在运行时丢弃(或者擦除)它们的元素类型信息。擦除就是使泛型可以与没有使用泛型的代码随意进行互用(详见第 26 条),以确保在Java5中平滑过渡到泛型。\n由于上述这些根本的区别,因此数组和泛型不能很好地混合使用。例如,创建泛型、参数化类型或者类型参数的数组是非法的。这些数组创建表达式没有一个是合法的：newList&lt;E&gt;[]、new List&lt;String&gt;[] 和 new E[]。这些在编译时都会导致一个泛型数组创建(generic array creation)错误。\n为什么创建泛型数组是非法的?因为它不是类型安全的。要是它合法,编译器在其他正确的程序中发生的转换就会在运行时失败,并出现一个ClassCastException 异常。这就违背了泛型系统提供的基本保证,\n为了更具体地对此进行说明,以下面的代码片段为例：\n// Why generic array creation is illegal - won&#x27;t compile!List&lt;String&gt;[] stringLists = new List&lt;String&gt;[i];// (1)List&lt;Integer&gt; intList = List.of(42); //(2)Object[] objects = stringLists; // (3)objects[o] = intList; //(4)String s = stringLists[0].get(0); // (5)\n我们假设第1行是合法的,它创建了一个泛型数组。 第2行创建并初始化了一个包含单个元素的List&lt;Integer&gt;。第3行将List&lt;String&gt;数组保存到一个Object 数组变量中,这是合法的,因为数组是协变的。第 4行将 List&lt;Integer&gt;保存到 Object 数组里唯一的元素中,这是可以的,因为泛型是通过擦除实现的：List&lt;Integer&gt;实例的运行时类型只是List,List&lt;String&gt;[] 实例的运行时类型则是List[],因此这种安排不会产生 ArrayStoreException异常。但现在我们有麻烦了。我们将一个List&lt;Integer&gt;实例保存到了原本声明只包含List&lt;String&gt;实例的数组中。在第5行中,我们从这个数组里唯一的列表中获取了唯一的元素。编译器自动地将获取到的元素转换成 String,但它是一个Integer,因此,我们在运行时得到了一个ClassCastException 异常。为了防止出现这种情况,(创建泛型数组的)第1行必须产生一条编译时错误。\n从技术的角度来说,像E、List&lt;E&gt;和List&lt;String&gt;这样的类型应称作不可具体化的(nonreifiable)类型[JLS,4.7]。直观地说,不可具体化的(non-reifiable)类型是指其运行时表示法包含的信息比它的编译时表示法包含的信息更少的类型。唯一可具体化的(reifiable)参数化类型是无限制的通配符类型,如List&lt;?&gt;和Map&lt;?,?&gt;(详见第 26条)。虽然不常用,但是创建无限制通配类型的数组是合法的。\n禁止创建泛型数组可能有点讨厌。例如,这表明泛型一般不可能返回它的元素类型数组(部分解决方案请见第33条)。这也意味着在结合使用可变参数(varargs)方法(详见第53条)和泛型时会出现令人费解的警告。这是由于每当调用可变参数方法时,就会创建一个数组来存放varargs 参数。如果这个数组的元素类型不是可具体化的(reifialbe),就会得到一条警告。利用 SafeVarargs 注解可以解决这个问题(详见第 32 条)。\n当你得到泛型数组创建错误时,最好的解决办法通常是优先使用集合类型List&lt;E&gt;,而不是数组类型E[]。这样可能会损失一些性能或者简洁性,但是换回的却是更高的类型安全性和互用性。\n例如,假设要通过构造器编写一个带有集合的Chooser类和一个方法,并用该方法返回在集合中随机选择的一个元素。根据传给构造器的集合类型,可以用chooser充当游戏用的色子、魔术8球(一种卡片棋牌类游戏),或者一个蒙特卡罗模拟的数据源。下面是一个没有使用泛型的简单实现：\n//Chooser-a class badly in need of generics！public class Chooser &#123;    private final Object[]choiceArray;    public Chooser(Collection choices)&#123;        choiceArray = choices.toArray();    &#125;    public Object choose()&#123;        Random rnd = ThreadLocalRandom.current();        return choiceArray[rnd.nextInt(choiceArray.length)];    &#125;&#125;\n\n要使用这个类,必须将 choose 方法的返回值,从 Object 转换成每次调用该方法时想要的类型,如果搞错类型,转换就会在运行时失败。牢记第29条的建议,努力将Chooser 修改成泛型,修改部分如粗体所示:\n//A first cut at making Chooser generic- won&#x27;t compilepublic class Chooser&lt;T&gt;&#123;    private final T[] choiceArray;    public Chooser(Collection&lt;T&gt;choices)&#123;        choiceArray = choices.toArray();//choose method unchanged    &#125;    // choose method unchanged&#125;\n\n如果试着编译这个类,将会得到以下错误消息：\nChooser.java:9: error: incompatible types: Object[] cannot beconverted to T[]    choiceArray = choices.toArray();    where T is a type-variable:        T extends Object declared in class Chooser\n\n你可能会说：这没什么大不了的,我可以把 Object 数组转换成数组：\nchoiceArray = (T[]) choices.toArray();\n\n这样做的确消除了错误消息,但是现在得到了一条警告：\nChooser.java:9: warning: [unchecked] unchecked cast        choiceArray = (T[]) choices.toArray();    required: T[], found: Object[]    where T is a type-variable:T extends Object declared in class Chooser\n\n编译器告诉你,它无法在运行时检查转换的安全性,因为程序在运行时还不知道T是什么一记住,元素类型信息会在运行时从泛型中被擦除。这段程序可以运行吗?可以,但是编译器无法证明这一点。你可以亲自证明,只要将证据放在注释中,用一条注解禁止警告,但是最好能消除造成警告的根源(详见第 27条)。\n要消除未受检的转换警告,必须选择用列表代替数组。下面是编译时没有出错或者警告的Chooser类版本:\n// List-based Chooser - typesafepublic class Chooser&lt;T&gt; &#123;    private final List&lt;T&gt; choiceList;    public Chooser(Collection&lt;T&gt; choices) &#123;        choiceList = new ArrayList&lt;&gt;(choices);    &#125;    public T choose() &#123;        Random rnd = ThreadLocalRandom.current();        return choiceList.get(rnd.nextInt(choiceList.size()));    &#125;&#125;\n这个版本的代码稍微冗长一点,运行速度可能也会慢一点,但是在运行时不会得到ClassCastException 异常,为此也值了。\n总而言之,数组和泛型有着截然不同的类型规则。数组是协变且可以具体化的；泛型是不可变的且可以被擦除的。因此,数组提供了运行时的类型安全,但是没有编译时的类型安全,反之,对于泛型也一样。一般来说,数组和泛型不能很好地混合使用。如果你发现自已将它们混合起来使用,并且得到了编译时错误或者警告,你的第一反应就应该是用列表代替数组。\n第29条：优先考虑泛型一般来说,将集合声明参数化,以及使用JDK所提供的泛型方法,这些都不太困难。编写自己的泛型会比较困难一些,但是值得花些时间去学习如何编写。\n以第7条中简单的(玩具)堆栈实现为例：\n// Object-based collection - a prime candidate for genericspublic class Stack &#123;    private Object[] elements;    private int size = 0;    private Static final int DEFAULT_INITIAL_CAPACITY = 16;    public Stack()&#123;        elements = new Object[DEFAULT_INITIAL_CAPACITY];    &#125;    public void push(object e) &#123;        ensureCapacity();        elements[size++]= e;    &#125;    public Object pop()&#123;        if (size == 0)throw new EmptyStackException();        Object result=elements[--size];        elements[size] = null; // Eliminate obsolete reference         return result;    &#125;    public boolean isEmpty() &#123;        return size == 0;    &#125;    private void ensureCapacity() &#123;        if (elements.length == size)            elements = Arrays.copyOf(elements, 2 * size + 1);    &#125;&#125;\n\n这个类应该先被参数化,但是它没有,我们可以在后面将它泛型化(generify)。换句话说,可以将它参数化,而又不破坏原来非参数化版本的客户端代码。也就是说,客户端必须转换从堆栈里弹出的对象,以及可能在运行时失败的那些转换。将类泛型化的第一步是在它的声明中添加一个或者多个类型参数。在这个例子中有一个类型参数,它表示堆栈的元素类型,这个参数的名称通常为E(详见第68条)。\n下一步是用相应的类型参数替换所有的 Object类型,然后试着编译最终的程序:\n//Initialattempt togenerifyStack-won&#x27;tcompile！public class Stack&lt;E&gt;&#123;    private E[] elements;    private int size =0;    private Static final int DEFAULT_INITIAL_CAPACITY = 16;    public Stack()&#123;        elements = new E[DEFAULT_INITIAL_CAPACITY];    &#125;    publ ic void push(E e) &#123;        ensureCapacity();        elements[size++]=e;    &#125;    public E pop()&#123;        if (size ==0)            throw new EmptyStackException();            E result=elements[--size];            elements[size]=null;// Eliminate obsolete reference            return result;        &#125;        ...//nochanges in isEmpty or ensureCapacity&#125;\n\n通常,你将至少得到一个错误提示或警告,这个类也不例外。幸运的是,这个类只产生一个错误,内容如下:\nStack.java:8: generic array creation    elements = new E[DEFAULT_INITIAL_CAPACITY];\n\n如第 28 条中所述,你不能创建不可具体化的(non-reifiable)类型的数组,如E。每当编写用数组支持的泛型时,都会出现这个问题。解决这个问题有两种方法。第一种,直接绕过创建泛型数组的禁令：创建一个Objéct的数组,并将它转换成泛型数组类型。现在错误是消除了,但是编译器会产生一条警告。这种用法是合法的,但(整体上而言)不是类型安全的：\nStack.java:8: warning: [unchecked] unchecked castfound: Object[],required:E[]    elements = (E[]) neW Object[DEFAULT_INITIAL_CAPACITY];\n\n编译器不可能证明你的程序是类型安全的,但是你可以。你自己必须确保未受检的转换不会危及程序的类型安全性。相关的数组(即elements 变量)保存在一个私有的域中,永远不会被返回到客户端,或者传给任何其他方法。这个数组中保存的唯一元素,是传给push 方法的那些元素,它们的类型为E,因此未受检的转换不会有任何危害。\n一旦你证明了未受检的转换是安全的,就要在尽可能小的范围中禁止警告(详见第27条)。在这种情况下,构造器只包含未受检的数组创建,因此可以在整个构造器中禁止这条警告。通过增加一条注解 @SuppressWarnings 来完成禁止,Stack 能够正确无误地进行编译,你就可以使用它了,无须显式的转换,也无须担心会出现ClassCastException 异常:\n// The elements array will contain only E instances from push(E).// This is sufficient to ensure type safety,but the runtime//type of the array won&#x27;t be E[];it will always be Object[]！@SuppressWarnings(&quot;unchecked&quot;)public Stack()&#123;    elements =(E[]) new Object[DEFAULT_INITIAL_CAPACITY];&#125;\n\n消除 Stack 中泛型数组创建错误的第二种方法是,将 elements 域的类型从 E[] 改为 Object[]。这么做会得到一条不同的错误：\nStack.java:19: incompatible typesfound:Object,required:E    E result = elements[--size];\n\n通过把从数组中获取到的元素由Object转换成E,可以将这条错误变成一条警告：\nStack.java:19: warning:[unchecked] unchecked castfound:Object,required:E    E result =(E) elements[--size];\n\n由于E是一个不可具体化的(non-reifiable)类型,编译器无法在运行时检验转换。你还是可以自己证实未受检的转换是安全的,因此可以禁止该警告。根据第 27条的建议,我们只要在包含未受检转换的任务上禁止警告,而不是在整个pop方法上禁止就可以了,方法如下:\n//Appropriate suppression ofuncheckedwarningpublicE pop()&#123;    if(size==0)throw new EmptyStackException();        //push requires elements to be of type E,so cast is correct    @SuppressWarnings(&quot;unchecked&quot;) E result =(E) elements[--size];        elements[size]=null;// Eliminate obsolete reference    return result;&#125;\n\n这两种消除泛型数组创建的方法,各有所长。第一种方法的可读性更强：数组被声明为E[]类型清楚地表明它只包含E实例。它也更加简洁：在一个典型的泛型类中,可以在代码中的多个地方读取到该数组；第一种方法只需要转换一次(创建数组的时候),而第二种方法则是每次读取一个数组元素时都需要转换一次。因此,第一种方法优先,在实践中也更常用。但是,它会导致堆污染(heap pollution),详见第 32 条：数组的运行时类型与它的编译时类型不匹配(除非E正好是Object)。这使得有些程序员会觉得很不舒服,因而选择第二种方案,虽然堆污染在这种情况下并没有什么危害。\n下面的程序示范了泛型 Stack类的使用方法。程序以倒序的方式打印出它的命令行参数,并转换成大写字母。如果要在从堆栈中弹出的元素上调用 String 的toUpperCase方法,并不需要显式的转换,并且确保自动生成的转换会成功：\n// Little program to exercise our generic Stackpublic static void main(String[] args) &#123;    Stack&lt;String&gt; stack = new Stack&lt;&gt;();    for (String arg : args)        stack.push(arg);    while (!stack.isEmpty())        System.out.println(stack.pop().toupperCase());&#125;\n\n看来上述的示例与第 28 条相矛盾了,第 28 条鼓励优先使用列表而非数组。实际上不可能总是或者总想在泛型中使用列表。Java 并不是生来就支持列表,因此有些泛型如 ArrayList,必须在数组上实现。为了提升性能,其他泛型如 HashMap 也在数组上实现。\n绝大多数泛型就像我们的 Stack示例一样,因为它们的类型参数没有限制：你可以创建 Stack&lt;Object&gt;、Stack&lt;int[]&gt;、Stack&lt;List&lt;String&gt;&gt;,或者任何其他对象引用类型的 Stack。注意不能创建基本类型的 Stack：企图创建 Stack&lt;int&gt;或者 Stack&lt;double&gt;会产生一个编译时错误。这是Java 泛型系统的一个基本局限性。你可以通过使用基本包装类型(boxed primitive type)来避开这条限制(详见第61条)。\n有一些泛型限制了可允许的类型参数值。例如,以java.util.concurrent.Delay-Queue 为例,其声明内容如下:\nclass DelayQueue&lt;E extends Delayed&gt;implements BlockingQueue&lt;E&gt;\n类型参数列表(&lt;EextendsDelayed&gt;)要求实际的类型参数E 必须是java.util.con-的元素上利用 Delayed 方法,无须显式的转换,也没有出现ClassCastException 的风险。类型参数E被称作有限制的类型参数(bounded type parameter)。注意,子类型关系确定了,每个类型都是它自身的子类型[JLS,4.10],因此创建 DelayQueue&lt;Delayed&gt;是合法的。\n总而言之,使用泛型比使用需要在客户端代码中进行转换的类型来得更加安全,也更加容易。在设计新类型的时候,要确保它们不需要这种转换就可以使用。这通常意味着要把类做成是泛型的。只要时间允许,就把现有的类型都泛型化。这对于这些类型的新用户来说会变得更加轻松,又不会破坏现有的客户端(详见第26条)。\n第30条：优先考虑泛型方法正如类可以从泛型中受益一般,方法也一样。静态工具方法尤其适合于泛型化。Co1le-\n编写泛型方法与编写泛型类型相类似。例如下面这个方法,它返回两个集合的联合：\n//Uses raw types-unacceptable! (Item 26)public static Set union(Set sl, Set s2) &#123;    Set result = new HashSet(s1);    result.addA1l(s2);    return result;&#125;\n\n这个方法可以编译,但是有两条警告：\nUnion.java:5: warning: [unchecked] unchecked call toHashSet(Collection&lt;? extends E&gt;) as a member of raw type HashSet    Set result = new HashSet(sl);Union.java:6: warning: [unchecked] unchecked call toaddAll(Collection&lt;?extends E&gt;)as a member of raw type Set    result.addA1l(s2) ;\n\n为了修正这些警告,使方法变成是类型安全的,要将方法声明修改为声明一个类型参数(type parameter),表示这三个集合的元素类型(两个参数和一个返回值),并在方法中使用类型参数。声明类型参数的类型参数列表,处在方法的修饰符及其返回值之间。在这个示例中,类型参数列表为&lt;E&gt;,返回类型为 Set&lt;E&gt;。类型参数的命名惯例与泛型方法以及泛型的相同(详见第 29条和第68条):\n//Genericmethodpublic static &lt;E&gt;Set&lt;E&gt; union(Set&lt;E&gt;sl,Set&lt;E&gt;s2)&#123;    Set&lt;E&gt; result = new HashSet&lt;&gt;(s1);    result.addA1l(s2);    return result;&#125;\n\n至少对于简单的泛型方法而言,就是这么回事了。现在该方法编译时不会产生任何警告,并提供了类型安全性,也更容易使用。以下是一个执行该方法的简单程序。程序中不包含转换,编译时不会有错误或者警告：\n//Simpleprogramtoexercisegenericmethodpublic static void main(String[]  args) &#123;    Set&lt;String&gt; guys = Set.of(&quot;Tom&quot;, &quot;Dick&quot;, &quot;Harry&quot;);    Set&lt;String&gt; stooges = Set.of(&quot;Larry&quot;,&quot;Moe&quot;, &quot;Curly&quot;);    Set&lt;String&gt; aflCio = union(guys, stooges);    System.out.println(aflCio);&#125;\n\n运行这段程序时,会打印出[Moe,Harry,Tom,Curly,Larry,Dick]。(元素的输出顺序是独立于实现的。)\nunion 方法的局限性在于三个集合的类型(两个输入参数和一个返回值)必须完全相同。利用有限制的通配符类型(bounded wildcard type)可以使方法变得更加灵活(详见第 31条)。\n有时可能需要创建一个不可变但又适用于许多不同类型的对象。由于泛型是通过擦除(详见第28条)实现的,可以给所有必要的类型参数使用单个对象,但是需要编写一个静态工厂方法,让它重复地给每个必要的类型参数分发对象。这种模式称作泛型单例工厂(generic singleton factory),常用于函数对象(详见第 42 条),如Collections.reverse-Order,有时也用于像 Collections.emptySet 这样的集合。\n假设要编写一个恒等函数(identity function)分发器。类库中提供了Function.identity,因此不需要自己编写(详见第59条),但是自己编写也很有意义。如果在每次需要的时候都重新创建一个,这样会很浪费,因为它是无状态的(stateless)。如果 Java 泛型被具体化了,每个类型都需要一个恒等函数,但是它们被擦除后,就只需要一个泛型单例。请看以下示例：\n// Generic singleton factory pattern private static UnaryOperator&lt;Object&gt; IDENTITY_FN = (t) -&gt; t;@SuppressWarnings(&quot;unchecked&quot;)public static &lt;T&gt; UnaryOperator&lt;T&gt; identityFunction() &#123;    return (UnaryOperator&lt;T&gt;) IDENTITY_FN;&#125;\nIDENTITY_FN 转换成(UnaryFunction&lt;T&gt;),产生了一条未受检的转换警告,因为UnaryFunction&lt;Object&gt;对于每个T来说并非都是个UnaryFunction&lt;T&gt;。但是恒等函数很特殊：它返回未被修改的参数,因此我们知道无论T的值是什么,用它作为 Unary-Function&lt;T&gt;都是类型安全的。因此,我们可以放心地禁止由这个转换所产生的未受检转换警告。一旦禁止,代码在编译时就不会出现任何错误或者警告。\n下面是一个范例程序,它利用泛型单例作为 UnaryFunction&lt;String&gt;和Unary-Function&lt;Number&gt;。像往常一样,它不包含转换,编译时没有出现错误或者警告：\n//Sampleprogramto exercisegenericsingletonpublic static void main(String[]  args) &#123;    String[] strings =&#123; &quot;jute&quot;, &quot;hemp&quot;,&quot;nylon&quot; &#125;;    UnaryOperator&lt;String&gt; sameString = identityFunction();    for (String s : strings)        System.out.println(sameString.apply(s));        Number[] numbers =&#123;1,2.0,3L &#125;;    UnaryOperator ＜Number＞ sarneNumber ＝ identityFunction();     for (Number n : numbers)        System.out.println(sameNumber.apply(n)) ;&#125;\n\n虽然相对少见,但是通过某个包含该类型参数本身的表达式来限制类型参数是允许的。这就是递归类型限制(recursive type bound)。递归类型限制最普遍的用途与Comparable接口有关,它定义类型的自然顺序(详见第14条)。这个接口的内容如下:\npublic interface Comparable&lt;T&gt; &#123;    int compareTo(T o);&#125;\n\n类型参数 T定义的类型,可以与实现 Comparable&lt;T&gt;的类型的元素进行比较。实际上,几乎所有的类型都只能与它们自身的类型的元素相比较。例如 String 实现Comparable&lt;String&gt;,Integer 实现 Comparable&lt;Integer&gt;等等。\n有许多方法都带有一个实现Comparable 接口的元素列表,为了对列表进行排序,并在其中进行搜索,计算出它的最小值或者最大值,等等。要完成这其中的任何一项操作,都要求列表中的每个元素能够与列表中的每个其他元素相比较,换句话说,列表的元素可以互相比较(mutually comparable)。下面是如何表达这种约束条件的一个示例：\n//Using arecursive typebound to express mutualcomparabilitypublic static &lt;E extends Comparable&lt;E&gt;&gt;E max(Collection&lt;E&gt;c);\n类型限制&lt;E extends Comparable&lt;?&gt;&gt;,可以读作”针对可以与自身进行比较的每个类型E”,这与互比性的概念或多或少有些一致。\n下面的方法就带有上述声明。它根据元素的自然顺序计算列表的最大值,编译时没有出现错误或者警告：\n// Returns max value ina collection-uses recursive type boundpublic static &lt;E extends Comparable&lt;E&gt;&gt;E max(Collection&lt;E&gt; c)&#123;    if (c.isEmpty())        throw new IllegalArgumentException(&quot;Empty collection&quot;);        E result =null;        for(E e:c)            if(result == nu1l || e.compareTo(result)&gt;0)                result =Objects.requireNonNull(e);                return result;&#125;\n\n注意,如果列表为空,这个方法就会抛出 IllegalArgumentException 异常。更好的替代做法是返回一个Optional&lt;E&gt;(详见第55条)。\n递归类型限制可能比这个要复杂得多,但幸运的是,这种情况并不经常发生。如果你理解了这种习惯用法和它的通配符变量(详见第31 条),以及模拟自类型(simulated self-type)习惯用法(详见第 2条),就能够处理在实践中遇到的许多递归类型限制了。\n总而言之,泛型方法就像泛型一样,使用起来比要求客户端转换输人参数并返回值的方法来得更加安全,也更加容易。就像类型一样,你应该确保方法不用转换就能使用,这通常意味着要将它们泛型化。并且就像类型一样,还应该将现有的方法泛型化,使新用户使用起来更加轻松,且不会破坏现有的客户端(详见第26条)。\n第31条：利用有限制通配符来提升API的灵活性如第 28 条所述,参数化类型是不变的(invariant)。换句话说,对于任何两个截然不同的类虽然List&lt;String&gt;不是List&lt;Object&gt;的子类型,这与直觉相悖,但是实际上很有意义。你可以将任何对象放进一个List&lt;Object&gt;中,却只能将字符串放进List&lt;String&gt;中。由于List&lt;String&gt;不能像List&lt;Object&gt;能做任何事情,它不是一个子类型(详见第10条)。\n有时候,我们需要的灵活性要比不变类型所能提供的更多。比如第 29条中的堆栈。提醒一下,下面就是它的公共API:\npublic class Stack&lt;E&gt;&#123;    public Stack();    public void push(E e);    public E pop();    public boolean isEmpty();&#125;\n\n假设我们想要增加一个方法,让它按顺序将一系列的元素全部放到堆栈中。第一次尝试如下:\n// pushAll method without wildcard type - deficient!public void pushAll(Iterable&lt;E&gt; src)&#123;    for (E e: src)        push(e) ;&#125;\n\n这个方法编译时正确无误,但是并非尽如人意。如果 Iterable 的 src 元素类型与堆栈的完全匹配,就没有问题。但是假如有一个Stack&lt;Number&gt;,并且调用了push(intVal),这里的intVal就是Integer类型。这是可以的,因为 Integer是Number 的一个子类型。因此从逻辑上来说,下面这个方法应该可行：\nStack&lt;Number&gt; numberStack = new Stack&lt;&gt;();Iterable&lt;Integer&gt; integers = ... ;numberStack.pushAll(integers) ;\n\n但是,如果尝试这么做,就会得到下面的错误消息,因为参数化类型是不可变的：\nStackTest.java:7: error: incompatible types: Iterable&lt;Integer&gt;cannot be converted to Iterable&lt;Number&gt;numberStack.pushAll(integers) ;\n\n幸运的是,有一种解决办法。Java提供了一种特殊的参数化类型,称作有限制的通配符类型(bounded wildcard type),它可以处理类似的情况。pushAll 的输人参数类型不应该,Iterable&lt;?extends E&gt;正是这个意思。(使用关键字 extends 有些误导：回忆一下第29条中的说法,确定了子类型(subtype)后,每个类型便都是自身的子类型,即便它没有将自身扩展。)我们修改一下pushAll来使用这个类型：\n//wildcard type for a parameter that serves as an E producerpublic void pushAll(Iterable&lt;?extends E&gt;src)&#123;    for (E e : src)    push(e) ;&#125;\n\n修改之后,不仅 Stack 可以正确无误地编译,没有通过初始的 pushAll 声明进行编译的客户端代码也一样可以。因为 Stack及其客户端正确无误地进行了编译,你就知道一切都是类型安全的了。\n现在假设想要编写一个 pushAll 方法,使之与 popAll 方法相呼应。popAll方法从堆栈中弹出每个元素,并将这些元素添加到指定的集合中。初次尝试编写的 popAll方法可能像下面这样：\n//popAll method without wildcard type-deficient！public void popAll(Collection&lt;E&gt; dst)&#123;    while (!isEmpty())        dst.add(pop()) ;&#125;\n此外,如果目标集合的元素类型与堆栈的完全匹配,这段代码编译时还是会正确无误,并且运行良好。但是,也并不意味着尽如人意。假设你有一个 Stack&lt;Number&gt;和Object类型的变量。如果从堆栈中弹出一个元素,并将它保存在该变量中,它的编译和运行都不会出错,那你为何不能也这么做呢?\nStack&lt;Number&gt; numberStack = new Stack&lt;Number&gt;();Collection&lt;Object&gt; objects = ... ;numberStack.popAl1(objects) ;\n\n如果试着用上述的 popA1l版本编译这段客户端代码,就会得到一个非常类似于第一次用pushAll时所得到的错误：Collection&lt;Object&gt;不是Collection&lt;Number&gt;的子类型。这一次通配符类型同样提供了一种解决办法。POpA11的输人参数类型不应该为”E的集合”,而应该为”E的某种超类的集合”(这里的超类是确定的,因此E是它自身的一个超类型[JLS,4.10])。仍有一个通配符类型正符合此意：Collection&lt;?superE&gt;。让我们修改 popAll来使用它:\n//Wildcard type for parameter that serves as an E consumerpublic void popAll(Collection&lt;? super E&gt; dst)&#123;    while (!isEmpty())        dst.add(pop());&#125;\n\n做了这个变动之后,Stack 和客户端代码就都可以正确无误地编译了。\n结论很明显：为了获得最大限度的灵活性,要在表示生产者或者消费者的输入参数上使用通配符类型。如果某个输入参数既是生产者,又是消费者,那么通配符类型对你就没有什么好处了：因为你需要的是严格的类型匹配,这是不用任何通配符而得到的。\n下面的助记符便于让你记住要使用哪种通配符类型：\nPECS 表示 producer-extends,consumer-super。\n换句话说,如果参数化类型表示一个生产者T,就使用&lt;?extends T&gt;；如果它表示一个消费者T,就使用&lt;?super T&gt;。在我们的 Stack 示例中,pushAll 的 src 参数产生 E实例供 Stack使用,因此 src 相应的类型为Iterable&lt;? extends E&gt;；popAll的 dst 参数通过 Stack 消费E 实例,因此 dst 相应的类型为 Collection&lt;? super E&gt;。PECS 这个助记符突出了使用通配符类型的基本原则。Naftalin 和 Wadler 称之为 Get and PutPrinciple [Naftalin07, 2.4]。\n记住这个助记符,下面我们来看一些之前的条目中提到过的方法声明。第 28条中的reduce方法就有这条声明：\npublic Chooser(Collection&lt;T&gt; choices)\n\n这个构造器只用 choices 集合来生成类型T的值(并把它们保存起来供后续使用),因此它的声明应该使用一个éxtends T的通配符类型。得到的构造器声明如下:\n// Wildcard type for parameter that serves as an T producerpublic Chooser(Collection&lt;? extends T&gt; choices)\n这一变化实际上有什么区别吗?事实上,的确有区别。假设你有一个List&lt;Integer&gt;,想通过Function&lt;Number&gt;把它简化。它不能通过初始声明进行编译,但是一旦添加了有限制的通配符类型,就可以进行编译了。\n现在让我们看看第 30 条中的 union 方法。声明如下:\npublic static&lt;E&gt; Set&lt;E&gt;union(Set&lt;E&gt; sl,Set&lt;E&gt; s2)\n\ns1 和 s2 这两个参数都是生产者E,因此根据 PECS 助记符,这个声明应该是:\npublic static &lt;E&gt; Set&lt;E&gt; union(Set&lt;? extends E&gt; sl,Set&lt;? extends E&gt; s2)\n注意返回类型仍然是 Set&lt;E&gt;。不要用通配符类型作为返回类型。除了为用户提供额外的灵活性之外,它还会强制用户在客户端代码中使用通配符类型。修改了声明之后,这段代码就能正确编译了：\nSet&lt;Integer&gt; integers = Set.of(1,3,5);Set&lt;Double&gt; doubles = Set.of(2.0,4.0,6.0);Set&lt;Number&gt; numbers = union(integers, doubles);\n\n如果使用得当,通配符类型对于类的用户来说几乎是无形的。它们使方法能够接受它们应该接受的参数,并拒绝那些应该拒绝的参数。如果类的用户必须考虑通配符类型,类的API或许就会出错。\n在Java8之前,类型推导(type inference)规则还不够智能,它无法处理上述代码片段,还需要编译器使用通过上下文指定的返回类型(或者目标类型)来推断E的类型。前面出现过的 union 调用的目标类型是 Set&lt;Number&gt;。如果试着在较早的 Java 版本中编译这个代码片段(使用 Set.of 工厂相应的替代方法),将会得到一条像下面这样冗长、繁复的错误消息:\nUnion.java:14: error: incompatible types    Set&lt;Number&gt; numbers = union(integers, doubles) ;        required:Set&lt;Number&gt;    found:Set&lt;INT#1&gt;    where INT#l,INT#2 are intersection types:        INT#1 extends Number,Comparable&lt;? extends INT#2&gt;        INT#2 extends Number,Comparable&lt;?&gt;\n\n幸运的是,有一种办法可以处理这种错误。如果编译器不能推断出正确的类型,始终可以通过一个显式的类型参数(explicit type parameter)[JLS,15.12]来告诉它要使用哪种类型。甚至在Java 8中引人目标类型之前,这种情况不经常发生,这是好事,因为显式的类型参数不太优雅。增加了这个显式的类型参数之后,这个代码片段在Java 8之前的版本中也能正确无误地进行编译了：\n// Explicit type parameter - required prior to Java 8Set&lt;Number&gt; numbers = Union.&lt;Number&gt;union(integers, doubles) ;\n\n接下来,我们把注意力转向第 30条中的 max方法。以下是初始的声明：\npublic static &lt;T extends Comparable&lt;T&gt;&gt; T max(List&lt;T&gt; list)\n\n下面是修改过的使用通配符类型的声明：\npublic static &lt;T extends Comparable&lt;? super T&gt;&gt; T max(List&lt;? extends T&gt; list)\n\n为了从初始声明中得到修改后的版本,要应用PECS转换两次。最直接的是运用到参数list。它产生 T实例,因此将类型从 List&lt;T&gt;改成List&lt;?extends T&gt;。更灵活的是运用到类型参数T。这是我们第一次见到将通配符运用到类型参数。最初T被指定用来扩展Comparable&lt;T&gt;,但是 T的 comparable 消费T实例(并产生表示顺序关系的整值)。因comparable 始终是消费者,因此使用时始终应该是 Comparable&lt;? super T&gt;优先于Comparable&lt;T&gt;。对于comparator 接口也一样,因此使用时始终应该是Comparator&lt;?super T&gt;优先于 Comparator&lt;T&gt;。\n修改过的 max声明可能是整本书中最复杂的方法声明了。所增加的复杂代码真的起作用了么?是的,起作用了。下面是一个简单的列表示例,在初始的声明中不允许这样,修改过的版本则可以：\nList&lt;ScheduledFuture&lt;?&gt;&gt; scheduledFutures = ...;\n不能将初始方法声明运用到这个列表的原因在于,java.util.concurrent.Scheduled-Future 没有实现Comparable&lt;ScheduledFuture&gt;接口。相反,它是扩展 Comparable&lt;Delayed&gt;接口的 Delayed接口的子接口。换句话说,ScheduleFuture实例并非只能与其他 ScheduledFuture实例相比较；它可以与任何 Delayed实例相比较,这就足以导致初始声明时就会被拒绝。更通俗地说,需要用通配符支持那些不直接实现Comparable(或者Comparator)而是扩展实现了该接口的类型。\n还有一个与通配符有关的话题值得探讨。类型参数和通配符之间具有双重性,许多方法都可以利用其中一个或者另一个进行声明。例如,下面是可能的两种静态方法声明,来交换列表中的两个被索引的项目。第一个使用无限制的类型参数(详见第30条),第二个使用无限制的通配符：\n//Twopossibledeclarationsfortheswapmethodpublic static &lt;E&gt; void swap(List&lt;E&gt; list, int i, int j);public static void swap(List&lt;?&gt; list,int i,int j);\n\n你更喜欢这两种声明中的哪一种呢?为什么?在公共API中,第二种更好一些,因为它更简单。将它传到一个列表中(任何列表)方法就会交换被索引的元素。不用担心类型参数。一般来说,如果类型参数只在方法声明中出现一次,就可以用通配符取代它。如果是无限制的类型参数,就用无限制的通配符取代它；如果是有限制的类型参数,就用有限制的通配符取代它。\n将第二种声明用于swap方法会有一个问题。下面这个简单的实现不能编译：\npublic static void swap(List&lt;?&gt; list,int i,int j) &#123;    list.set(i, list.set(j, list.get(i)));&#125;\n\n试着编译时会产生这条没有什么用处的错误消息：\nSwap.java:5: error: incompatible types: Object cannot beconverted to CAP#1    list.set(i,list.set(j,list.get(i)));        where CAP#1 is a fresh type-variable:        CAP#l extends Object from capture of ?\n\n不能将元素放回到刚刚从中取出的列表中,这似乎不太对劲。问题在于List的类型为List&lt;?&gt;,你不能把 null 之外的任何值放到List&lt;?&gt;中。幸运的是,有一种方式可以实现这个方法,无须求助于不安全的转换或者原生态类型(raw type)。这种想法就是编写一个私有的辅助方法来捕捉通配符类型。为了捕捉类型,辅助方法必须是一个泛型方法,像下面这样：\npublic static void swap(List&lt;?&gt; list,int i,int j)&#123;    swapHelper(list, i, j);&#125;//Privatehelpermethodforwildcardcaptureprivate static &lt;E&gt; void swapHelper(List&lt;E&gt; list, int i,int j) &#123;    list.set(i,list.set(j, list.get(i)));&#125;\n\nswapHelper方法知道 list是一个List&lt;E&gt;。因此,它知道从这个列表中取出的任何值均为 E 类型,并且知道将 E类型的任何值放进列表都是安全的。Swap 这个有些费解的实现编译起来却是正确无误的。它允许我们导出 swap这个比较好的基于通配符的声明,同时在内部利用更加复杂的泛型方法。Swap方法的客户端不一定要面对更加复杂的swapHelper声明,但是它们的确从中受益。值得一提的是,辅助方法中拥有的签名,正是我们在公有方法中因为它过于复杂而抛弃的。\n总而言之,在API中使用通配符类型虽然比较需要技巧,但是会使API变得灵活得多。如果编写的是将被广泛使用的类库,则一定要适当地利用通配符类型。记住基本的原则：producer-extends,consumer-super(PECS)。还要记住所有的 comparable 和comparator都是消费者。\n第32条：谨慎并用泛型和可变参数可变参数(vararg)方法(详见第53条)和泛型都是在Java5中就有了,因此你可能会期待它们可以良好地相互作用；遗憾的是,它们不能。可变参数的作用在于让客户端能够将可变数量的参数传给方法,但这是个技术露底(leaky abstration)：当调用一个可变参数方法时,会创建一个数组用来存放可变参数；这个数组应该是一个实现细节,它是可见的。因此,当可变参数有泛型或者参数化类型时,编译警告信息就会产生混乱。\n回顾一下第28条,非具体化(non-reifiable)类型是指其运行时代码信息比编译时少,并且显然所有的泛型和参数类型都是非具体化的。如果一个方法声明其可变参数为non-reifiable类型,编译器就会在声明中产生一条警告。如果方法是在类型为non-reifiable的可变参数上调用,编译器也会在调用时发出一条警告信息。这个警告信息类似于：\nwarning: [unchecked] Possible heap pollution from    parameterized vararg type List&lt;String&gt;\n当一个参数化类型的变量指向一个不是该类型的对象时,会产生堆污染(heap pollution)[JLS,4.12.2]。它导致编辑器的自动生成转换失败,破坏了泛型系统的基本保证。\n举个例子。下面的代码是对第28条中的代码片段稍加修改而得：\n//Mixing generics andvarargscanviolate type safety！static void dangerous(List&lt;String&gt;... stringLists) &#123;    List&lt;Integer&gt; intList = List.of(42);    Object[] objects = stringLists;objects[0] = intList; //Heap pollution    String s = stringLists[0].get(0); // ClassCastExceptionException&#125;\n这个方法没有可见的转换,但是在调用一个或者多个参数时会抛出 ClassCast Except工on 异常。 上述最后一行代码中有一个不可见的转换,这是由编译器生成的。这个转换失败证明类型安全已经受到了危及,因此将值保存在泛型可变参数数组参数中是不安全的。\n这个例子引出了一个有趣的问题：为什么显式创建泛型数组是非法的,用泛型可变参数声明方法却是合法的呢?换句话说,为什么之前展示的方法只产生一条警告,而第28条中的代码片段却产生一个错误呢?答案在于,带有泛型可变参数或者参数化类型的方法在实践中用处很大,因此Java语言的设计者选择容忍这一矛盾的存在。事实上,Java类库导出了好几个这样的方法,包括Arrays.asList(T.．.a)、Collections.addAll(Collection&lt;? super T&gt; C, T...elements), 以及EnumSet.of(E first,E．·．rest)。与前面提到的危险方法不一样,这些类库方法是类型安全的。\n在Java 7之前,带泛型可变参数的方法的设计者,对于在调用处出错的警告信息一点办法也没有。这使得这些API使用起来非常不愉快。用户必须忍受这些警告,要么最好在每处调用点都通过@SuppressWarnings(&quot;unchecked&quot;)注解来消除警告(详见第27条)。这么做过于烦琐,而且影响可读性,并且掩盖了反映实际问题的警告。\n在Java 7中,增加了 SafeVarargs 注解,它让带泛型 vararg 参数的方法的设计者能够自动禁止客户端的警告。本质上,SafeVarargs 注解是通过方法的设计者做出承诺,声明这是类型安全的。作为对于该承诺的交换,编译器同意不再向该方法的用户发出警告说这些调用可能不安全。\n重要的是,不要随意用@SafeVarargs 对方法进行注解,除非它真正是安全的。那么它凭什么确保安全呢?回顾一下,泛型数组是在调用方法的时候创建的,用来保存可变参数。如果该方法没有在数组中保存任何值,也不允许对数组的引用转义(这可能导致不被信任的代码访问数组),那么它就是安全的。换句话说,如果可变参数数组只用来将数量可变的参数从调用程序传到方法(毕竟这才是可变参数的目的),那么该方法就是安全的。\n值得注意的是,从来不在可变参数的数组中保存任何值,这可能破坏类型安全性。以下面的泛型可变参数方法为例,它返回了一个包含其参数的数组。乍看之下,这似乎是一个方便的小工具：\n//UNSAFE - Exposes a reference to its generic parameter array! static &lt;T&gt; T[] toArray(T... args) &#123;     return args &#125;\n\n这个方法只是返回其可变参数数组,看起来没什么危险,但它实际上很危险！这个数组的类型,是由传到方法的参数的编译时类型来决定的,编译器没有足够的信息去做准确的决定。因为该方法返回其可变参数数组,它会将堆污染传到调用堆栈上。\n下面举个具体的例子。这是一个泛型方法,它带有三个类型为T的参数,并返回一个包含两个(随机选择的)参数的数组：\nstatic &lt;T&gt; T[] pickTwo(T a,T b,T c)&#123;    switch(ThreadLoca1Random.current().nextInt(3)) &#123;        case 0: return toArray(a, b);        case 1: return toArray(a, c);        case 2: return toArray(b, c);    &#125;    throw new AssertionError();// Can&#x27;t get here&#125;\n\n这个方法本身并没有危险,也不会产生警告,除非它调用了带有泛型可变参数的toArray方法。\n在编译这个方法时,编译器会产生代码,创建一个可变参数数组,并将两个T实例传到toArray。这些代码配置了一个类型为 Object[]的数组,这是确保能够保存这些实例的最具体的类型,无论在调用时给 pickTwo传递什么类型的对象都没问题。toArray方法只是将这个数组返回给 pickTwo,反过来也将它返回给其调用程序,因此 pickTwo 始终都会返回一个类型为 Object[] 的数组。\n现在以下面的 main 方法为例,练习一下 pickTwo 的用法:\npublic static void main(String[]  args) &#123;    String[] attributes = pickTwo(&quot;Good&quot;, &quot;Fast&quot;, &quot;Cheap&quot;);&#125;\n\n这个方法压根没有任何问题,因此编译时不会产生任何警告。但是在运行的时候,它会抛出一个ClassCastException,虽然它看起来并没有包括任何的可见的转换。你看不到的是,编译器在pickTwo 返回的值上产生了一个隐藏的 String[] 转换。但转换失败了,这是因为从实际导致堆污染(toArray)的方法处移除了两个级别,可变参数数组在实际的参数存入之后没有进行修改。\n这个范例是为了告诉大家,**允许另一个方法访问一个泛型可变参数数组是不安全的,**有两种情况例外：将数组传给另一个用 @SafeVarargs 正确注解过的可变参数方法是安全的,将数组传给只计算数组内容部分函数的非可变参数方法也是安全的。\n这里有一个安全使用泛型可变参数的典型范例。这个方法中带有一个任意数量参数的列表,并按顺序返回包含输人清单中所有元素的唯一列表。由于该方法用@SafeVarargs注解过,因此在声明处或者调用处都不会产生任何警告：\n//Safe method with a generic, varargs parameter@SafeVarargsstatic &lt;T&gt;List&lt;T&gt; flatten(List&lt;? extends T&gt;...lists)&#123;    List&lt;T&gt; result = new ArrayList&lt;&gt;();    for (List&lt;? extends T&gt; list : lists)        result.addAll(list) ;    return result;&#125;\n\n确定何时应该使用 SafeVarargs 注解的规则很简单：对于每一个带有泛型可变参数或者参数化类型的方法,都要用@SafeVarargs 进行注解,这样它的用户就不用承受那些无谓的、令人困惑的编译警报了。这意味着应该永远都不要编写像dangerous或者toArray这类不安全的可变参数方法。每当编译器警告你控制的某个带泛型可变参数的方法可能形成堆污染,就应该检查该方法是否安全。这里先提个醒,泛型可变参数方法在下列条件下是安全的：\n\n它没有在可变参数数组中保存任何值。\n它没有对不被信任的代码开放该数组(或者其克隆程序)。\n\n以上两个条件只要有任何一条被破坏,就要立即修正它。\n注意,SafeVarargs 注解只能用在无法被覆盖的方法上,因为它不能确保每个可能的覆盖方法都是安全的。在Java 8 中,该注解只在静态方法和 final实例方法中才是合法的;在Java9中,它在私有的实例方法上也合法了。\n如果不想使用 SafeVarargs 注解,也可以采用第 28 条的建议,用一个List参数代替可变参数(这是一个伪装数组)。下面举例说明这个办法在flatten 方法上的运用。注意,此处只对参数声明做了修改：\n// List as a typesafe alternative to a generic varargs parameterstatic&lt;T&gt;List&lt;T&gt;flatten(List&lt;List&lt;? extends T&gt;&gt;lists)&#123;    List&lt;T&gt; result = new ArrayList&lt;&gt;();    for (List&lt;? extends T&gt; list : lists)        result.addAll(list);    return result;&#125;\n\n随后,这个方法就可以结合静态工厂方法List.of一起使用了,允许使用数量可变的参数。注意,使用该方法的前提是用 @SafeVarargs 对List.of 声明进行了注解:\naudience = flatten(List.of(friends, romans, countrymen));\n这种做法的优势在于编译器可以证明该方法是类型安全的。你不必再通过Safe-Varargs 注解来证明它的安全性,也不必担心自己是否错误地认定它是安全的。其缺点在于客户端代码有点烦琐,运行起来速度会慢一些。\n这一技巧也适用于无法编写出安全的可变参数方法的情况,比如本条之前提到的toArray方法。其List 对应的是 List.of 方法,因此我们不必编写；Java 类库的设计者已经替我们完成了。因此pickTwo 方法就变成了下面这样:\nstatic &lt;T&gt; List&lt;T&gt; pickTwo(T a,T b, T c) &#123;    switch(rnd.nextInt(3)) &#123;        case 0: return List.of(a, b);        case 1: return List.of(a, c);        case 2:return List.of(b,c);    &#125;    throw newAssertionError();&#125;\nmain方法变成了下面这样:\npublic static void main(String[] args) &#123;    List&lt;String&gt; attributes = pickTwo(&quot;Good&quot;, &quot;Fast&quot;, &quot;Cheap&quot;);&#125;\n\n这样得到的代码就是类型安全的,因为它只使用泛型,没有用到数组。\n总而言之,可变参数和泛型不能良好地合作,这是因为可变参数设施是构建在顶级数组之上的一个技术露底,泛型数组有不同的类型规则。虽然泛型可变参数不是类型安全的,但它们是合法的。如果选择编写带有泛型(或者参数化)可变参数的方法,首先要确保该方法是类型安全的,然后用@SafeVarargs对它进行注解,这样使用起来就不会出现不愉快的情况了。\n第33条：优先考虑类型安全的异构容器泛型最常用于集合,如 Set&lt;E&gt;和 Map&lt;K,V&gt;,以及单个元素的容器,如 Thread-Local&lt;T&gt;和 AtomicReference&lt;T&gt;。在所有这些用法中,它都充当被参数化了的容器。这样就限制每个容器只能有固定数目的类型参数。一般来说,这种情况正是你想要的。一个Set只有一个类型参数,表示它的元素类型；一个Map 有两个类型参数,表示它的键和值类型。\n但是,有时候你会需要更多的灵活性。例如,数据库的行可以有任意数量的列,如果能以类型安全的方式访问所有列就好了。幸运的是,有一种方法可以很容易地做到这一点。这种方法就是将键(key)进行参数化而不是将容器(container)参数化。然后将参数化的键提交给容器来插人或者获取值。用泛型系统来确保值的类型与它的键相符。\n下面简单地示范一下这种方法：以 Favorites 类为例,它允许其客户端从任意数量的其他类中,保存并获取一个”最喜爱”的实例。Class对象充当参数化键的部分。之所以可以这样,是因为类Class被泛型化了。类的类型从字面上来看不再只是简单的Class,而是Class&lt;T&gt;。例如,String.class 属于 Class&lt;String&gt;类型,Integer.class属于Class&lt;Integer&gt;类型。当一个类的字面被用在方法中,来传达编译时和运行时的类型信息时,就被称作类型令牌(type token)[Brancha04]。\nFavorites类的API很简单。它看起来就像一个简单的映射,除了键(而不是映射)被参数化之外。客户端在设置和获取最喜爱的实例时提交Class 对象。下面就是这个API:\n// Typesafe heterogeneous container pattern - APIpublic class Favorites &#123;    public &lt;T&gt; void putFavorite(Class&lt;T&gt; type, T instance) ;    public &lt;T&gt; T getFavorite(Class&lt;T&gt; type) ;&#125;\n\n下面是一个示例程序,检验一下 Favorites 类,它将保存、获取并打印一个最喜爱的 String、Integer 和 Class 实例:\n// Typesafe heterogeneous container pattern - clientpublic static void main(String[] args) &#123;    Favorites f = new Favorites();    f.putFavorite(String.class, &quot;Java&quot;);    f.putFavorite(Integer.class, Oxcafebabe);    f.putFavorite(Class.class, Favorites.class);    String favoriteString = f.getFavorite(String.class);    int favoriteInteger = f.getFavorite(Integer.class);    Class&lt;?&gt; favoriteClass = f.getFavorite(Class.class);    System.out.printf(&quot;%s %x %s%n&quot;, favoriteString,favoriteInteger, favoriteClass.getName());&#125;\n\n正如所料,这段程序打印出的是Java Cafebabe Favorites。注意,有时Java 的printf方法与C语言中的不同,C语言中使用\\n 的地方,在Java 中应该使用%n。这个n 会产生适用于特定平台的行分隔符,在许多平台上是\\n,但是并非所有平台都是如此。\nFavorites 实例是类型安全(typesafe)的：当你向它请求 String 的时候,它从来不会返回一个Integer 给你。同时它也是异构的(heterogeneous)：不像普通的映射,它的所有键都是不同类型的。因此,我们将 Favorites 称作类型安全的异构容器(typesafeheterogeneous container) 。\nFavorites 的实现小得出奇。它的完整实现如下：\n//Typesafe heterogeneous container pattern-implementationpublic class Favorites &#123;    private Map&lt;Class&lt;?&gt;,Object&gt; favorites = new HashMap&lt;&gt;();    public &lt;T&gt; void putFavorite(Class&lt;T&gt; type,T instance)&#123;        favorites.put(Objects.requireNonNull(type), instance);    &#125;    public &lt;T&gt;T getFavorite(Class&lt;T&gt; type)&#123;        return type.cast(favorites.get(type));    &#125;&#125;\n\n这里面发生了一些微妙的事情。每个 Favorites 实例都得到一个称作 favorites 的私有 Map&lt;Class&lt;?&gt;,Object&gt;的支持。你可能认为由于无限制通配符类型的关系,将不能把任何东西放进这个Map 中,但事实正好相反。要注意的是通配符类型是嵌套的：它不是属于通配符类型的Map 的类型,而是它的键的类型。由此可见,每个键都可以有一个不同的参数化类型：一个可以是Class&lt;String&gt;,接下来是Class&lt;Integer&gt;等。异构就是从这里来的。\n第二件要注意的事情是,favorites Map 的值类型只是 Object。换句话说,Map 并不能保证键和值之间的类型关系,即不能保证每个值都为它的健所表示的类型(通俗地说,就是指键与值的类型并不相同一译者注)。事实上,Java 的类型系统还没有强大到足以表达这一点。但我们知道这是事实,并在获取 faVorite 的时候利用了这一点。\nputFavorite 方法的实现很简单：它只是把(从指定的 Class 对象到指定的 favo-rite实例)一个映射放到favorites 中。如前所述,这是放弃了键和值之间的”类型联系”,因此无法知道这个值是键的一个实例。但是没关系,因为 getFavorites 方法能够并且的确重新建立了这种联系。\ngetFavorite方法的实现比 putFavorite 的更难一些。它先从 favorites 映射中获得与指定Class对象相对应的值。这正是要返回的对象引l用,但它的编译时类型是错误的。它的类型只是 Object(favorites 映射的值类型),我们需要返回一个 T。因此,getFavorite 方法的实现利用 Class 的 cast 方法,将对象引l用动态地转换(dynamicallycast)成了Class对象所表示的类型。\ncast方法是Java 的转换操作符的动态模拟。它只检验它的参数是否为 Class 对象所表示的类型的实例。如果是,就返回参数；否则就抛出 ClassCastException 异常。我们知道 getFavorite 中的 cast调用永远不会抛出 ClassCastException 异常,并假设客户端代码正确无误地进行了编译。也就是说,我们知道 faVorites 映射中的值会始终与键的类型相匹配。\n假设cast方法只返回它的参数,那它能为我们做什么呢?cast方法的签名充分利用了Class 类被泛型化的这个事实。它的返回类型是 Class 对象的类型参数:\npublic class Class&lt;T&gt;&#123;    T cast(Object obj);&#125;\n\n这正是 getFavorite 方法所需要的,也正是让我们不必借助于未受检地转换成 T 就能确保 Favorites 类型安全的东西。\nFavorites类有两种局限性值得注意。首先,恶意的客户端可以很轻松地破坏Favorites 实例的类型安全,只要以它的原生态形式(raw form)使用 Class对象。但会造成客户端代码在编译时产生未受检的警告。这与一般的集合实现,如 HashSet 和 HashMap并没有什么区别。你可以很容易地利用原生态类型HashSet(详见第 26 条)将 String 放进HashSet&lt;Integer&gt;中。也就是说,如果愿意付出一点点代价,就可以拥有运行时的类型安全。确保 Favorites 永远不违背它的类型约束条件的方式是,让putFavorite 方法检验 instance 是否真的是type 所表示的类型的实例。只需使用一个动态的转换,如下代码所示：\n//Achieving runtime typesafetywithadynamic castpublic &lt;T&gt; void putFavorite(Class&lt;T&gt; type, T instance)&#123;    favorites.put(type, type.cast(instance));&#125;\n\njava.util.Collections 中有一些集合包装类采用了同样的技巧。它们称作 checked-Set、checkedList、checkedMap,诸如此类。除了一个集合(或者映射)之外,它们的静态工厂还采用一个(或者两个)Class 对象。静态工厂属于泛型方法,确保 Class对象和集合的编译时类型相匹配。包装类给它们所封装的集合增加了具体化。例如,如果有人试图将 Coin 放进你的 Collection&lt;Stamp&gt;,包装类就会在运行时抛出 ClassCast-Exception异常。用这些包装类在混有泛型和原生态类型的应用程序中追溯”是谁把错误的类型元素添加到了集合中”很有帮助。\nFavorites 类的第二种局限性在于它不能用在不可具体化的(non-reifiable)类型中(详见第 28 条)。换句话说,你可以保存最喜爱的 String 或者 String[],但不能保存最喜爱的List&lt;String&gt;。如果试图保存最喜爱的List&lt;String&gt;,程序就不能进行编译。原因在于你无法为List&lt;String&gt;获得一个Class 对象：List&lt;String&gt;.Class是个语法错误,这也是件好事。List&lt;String&gt;和List&lt;Integer&gt;共用一个 Class 对象,即List.class。如果从”类型的字面”(type literal)上来看,List&lt;String&gt;.class 和List&lt;Integer&gt;.class 是合法的,并返回了相同的对象引l用,这会破坏 Favorites 对象的内部结构。对于这种局限性,还没有完全令人满意的解决办法。\nFavorites 使用的类型令牌(type token)是无限制的：getFavorite 和putFavorite接受任何Class对象。有时可能需要限制那些可以传给方法的类型。这可以通过有限制的类型令牌(bounded type token)来实现,它只是一个类型令牌,利用有限制类型参数(详见第 30条)或者有限制通配符(详见第31条),来限制可以表示的类型。\n注解API(详见第39条)广泛利用了有限制的类型令牌。例如,这是一个在运行时读取注解的方法。这个方法来自 AnnotatedElement 接口,它通过表示类、方法、域及其他程序元素的反射类型来实现：\npublic &lt;T extends Annotation&gt;T getAnnotation(Class&lt;T&gt; annotationType);\n参数annotationType是一个表示注解类型的有限制的类型令牌。如果元素有这种类型的注解,该方法就将它返回；如果没有,则返回 null。被注解的元素本质上是个类型安全的异构容器,容器的键属于注解类型。\n的方法,例如 getAnnotation。你可以将对象转换成 Class&lt;?extends Annotation&gt;,但是这种转换是非受检的,因此会产生一条编译时警告(详见第27条)。幸运的是,类Class 提供了一个安全(且动态)地执行这种转换的实例方法。该方法称作 asSubclass,它将调用它的Class 对象转换成用其参数表示的类的一个子类。如果转换成功,该方法返回它的参数；如果失败,则抛出 ClassCastException 异常。\n下面示范如何利用 as Subclass 方法在编译时读取类型未知的注解。这个方法编译时没有出现错误或者警告：\n//UseofasSubclasstosafelycasttoaboundedtypetokenstatic Annotation getAnnotation(AnnotatedElement element,String annotationTypeName) &#123;    Class&lt;?&gt; annotationType = null; // Unbounded type token    try&#123;        annotationType = Class.forName(annotationTypeName) ;    &#125;catch (Exception ex)&#123;        throw new IllegalArgumentException(ex);    &#125;    return element.getAnnotation(annotationType.asSubclass(Annotation.class));&#125;\n总而言之,集合API说明了泛型的一般用法,限制每个容器只能有固定数目的类型参数。你可以通过将类型参数放在键上而不是容器上来避开这一限制。对于这种类型安全的异构容器,可以用Class 对象作为键。以这种方式使用的Class 对象称作类型令牌。你也可以使用定制的键类型。例如,用一个 DatabaseRow 类型表示一个数据库行(容器),用泛型 Column &lt;T&gt;作为它的键。\n第六章 枚举和注解Java 支持两种特殊用途的引引用类型：一种是类,称作枚举类型(enum type)；一种是接口,称作注解类型(annotation type)。本章将讨论这两个新类型的最佳使用实践。\n第34条：用enum代替int常量枚举类型(enum type)是指由一组固定的常量组成合法值的类型,例如一年中的季节、太阳系中的行星或者一副牌中的花色。在Java 编程语言引人枚举类型之前,通常是用一组int 常量来表示枚举类型,其中每一个int 常量表示枚举类型的一个成员：\n//Theintenumpattern-severelydeficient！public Static final int APPLE_FUJI =0;public Static final int APPLE_PIPPIN =1;public static final int APPLE_GRANNY_SMITH = 2;public static final int ORANGE_NAVEL = 0;public static final int ORANGE_TEMPLE = 1;public Static final int ORANGE_BLOOD= 2;\n\n这种方法称作int枚举模式(int enum pattern),它存在着很多不足。int枚举模式不具有类型安全性,也几乎没有描述性可言。例如你将 apple 传到想要 orange 的方法中,编译器也不会发出警告,还会用 &#x3D;&#x3D;操作符对 apple 与 orange 进行比较,甚至更糟糕:\n// Tasty citrus flavored applesauce!int i =(APPLE_FUJI - ORANGE_TEMPLE)/ APPLE_PIPPIN;\n注意每个 apple 常量的名称都以 APPLE_作为前缀,每个 orange 常量的名称则都以ORANGE_作为前缀。这是因为 Java 没有为 int 枚举组提供命名空间。当两个int 枚举组具有相同的命名常量时,前缀可以防止名称发生冲突,如使用ELEMENT_MERCURY和PLANET_MERCURY避免名称冲突。\n采用int枚举模式的程序是十分脆弱的。因为 int枚举是编译时常量(constantvariable)的值发生了变化,客户端必须重新编译。如果没有重新编译,客户端程序还是可以运行,不过其行为已经不再准确。\n很难将int 枚举常量转换成可打印的字符串。就算将这种常量打印出来,或者从调试器中将它显示出来,你所见到的也只是一个数字,这几乎没有什么用处。当需要遍历一个int枚举模式中的所有常量,以及获得int 枚举数组的大小时,在 int 枚举模式中,几乎不存在可靠的方式。\n这种模式还有一种变体,它使用的是 String 常量,而不是 int 常量。这样的变体被称作 String 枚举模式(String enum pattern),同样也不是我们期望的。它虽然为这些常量提供了可打印的字符串,但是会导致初级用户直接把字符串常量硬编码到客户端代码中,而不是使用对应的常量字段(field)名。一旦这样的硬编码字符串常量中包含书写错误,在编译时不会被检测到,但是在运行的时候却会报错。而且它会导致性能问题,因为它依赖于字符串的比较操作。\n幸运的是,Java 提供了另一种替代的解决方案,可以避免 int 和 String 枚举模式的缺点,并提供更多的好处。这就是枚举类型(enum type)[JLS,8.9]。下面以最简单的形式演示了这种模式：\npublic enum Apple&#123; FUJI,PIPPIN,GRANNY_SMITH &#125;public enum Orange &#123; NAVEL,TEMPLE,BLOOD &#125;\n\n表面上看来,这些枚举类型与其他语言中的没有什么两样,例如C、C++和C#,但是实际上并非如此。Java的枚举类型是功能十分齐全的类,其功能比其他语言中的对应类强大得多,Java的枚举本质上是int值。\n出一个实例。枚举类型没有可以访问的构造器,所以它是真正的final类。客户端不能创建枚举类型的实例,也不能对它进行扩展,因此不存在实例,而只存在声明过的枚举常量。换句话说,枚举类型是实例受控的(详见第6页)。它们是单例(Singleton)(详见第3条)的泛型化,本质上是单元素的枚举。\n枚举类型保证了编译时的类型安全。例如声明参数的类型为Apple,它就能保证传到该参数上的任何非空的对象引用一定属于三个有效的Apple值之一,而其他任何试图传递类型错误的值都会导致编译时错误,就像试图将某种枚举类型的表达式赋给另一种枚举类型的变量,或者试图利用&#x3D;&#x3D;操作符比较不同枚举类型的值都会导致编译时错误。\n包含同名常量的多个枚举类型可以在一个系统中和平共处,因为每个类型都有自己的命名空间。你可以增加或者重新排列枚举类型中的常量,而无须重新编译它的客户端代码,因为导出常量的域在枚举类型和它的客户端之间提供了一个隔离层：常量值并没有被编译到客户端代码中,而是在 int 枚举模式之中。最终,可以通过调用toString 方法,将枚举转换成可打印的字符串。\n除了完善 int 枚举模式的不足之外,枚举类型还允许添加任意的方法和域,并实现任意的接口。它们提供了所有 Object方法(详见第3章)的高级实现,实现了Comparable(详见第14条)和 Serializable接口(详见第 12章),并针对枚举类型的可任意改变性设计了序列化方式。\n那么我们为什么要向枚举类型中添加方法或者域呢？首先,可能是想将数据与它的常量关联起来。例如,一个能够返回水果颜色或者返回水果图片的方法,对于我们的 Apple和range类型就很有必要。你可以利用任何适当的方法来增强枚举类型。枚举类型可以先作为枚举常量的一个简单集合,随着时间的推移再演变成为全功能的抽象。\n举个有关枚举类型的例子,比如太阳系中的8颗行星。每颗行星都有质量和半径,通过这两个属性可以计算出它的表面重力。从而给定物体的质量,进而计算出一个物体在行星表面上的重量。下面就是这个枚举。每个枚举常量后面括号中的数值就是传递给构造器的参数。在这个例子中,它们就是行星的质量和半径：\n//Enum typewithdataand behaviorpublic enum Planet &#123;    MERCURY(3.302e+23, 2.439e6),    VENUS (4.869e+24,6.052e6),    EARTH (5.975e+24, 6.378e6),    MARS (6.419e+23, 3.393e6),    JUPITER(1.899e+27, 7.149e7),    SATURN (5.685e+26, 6.027e7),    URANUS (8.683e+25,2.556e7),    NEPTUNE(1.024e+26, 2.477e7);    private final double mass; // In kilograms    private final double radius; // In meters    private final double surfaceGravity; // In m / s^2    // Universal gravitational constant in m^3 / kg s^2    private static final double G = 6.67300E-11;    // Constructor    Planet(double mass, double radius) &#123;        this.mass = mass;        this.radius = radius;        surfaceGravity = G * mass / (radius * radius);    &#125;    public double mass() &#123; return mass;&#125;    public double radius() &#123;return radius;&#125;    public double surfaceGravity() &#123; return surfaceGravity;&#125;    public double surfaceWeight(double mass) &#123;return mass * surfaceGravity; // F = ma    &#125;&#125;\n编写一个像 Planet 这样的枚举类型并不难。为了将数据与枚举常量关联起来,得声明实例域,并编写一个带有数据并将数据保存在域中的构造器。枚举天生就是不可变的,因此所有的域都应该为 final的(详见第17条)。它们可以是公有的,但最好将它们做成私有的,并提供公有的访问方法(详见第16 条)。在 Planet这个示例中,构造器还计算和保存表面重力,但这正是一种优化。每当 surfaceWeight 方法用到重力时,都会根据质量和半径重新计算,并返回它在该常量所表示的行星上的重量。\n虽然 Planet 枚举很简单,但它的功能强大得出奇。下面是一个简短的程序,根据某个物体在地球上的重量(以任何单位),打印出一张很棒的表格,显示出该物体在所有8颗行星上的重量 (用相同的单位)：\npublic class WeightTable &#123;    public static void main(String[] args) &#123;        double earthWeight = Double.parseDouble(args[0]);        double mass = earthWeight / Planet.EARTH.surfaceGravity();        for (Planet p : Planet.values())            System.out.printf(&quot;Weight on %s is %f%n&quot;,p, p.surfaceWeight(mass));    &#125;&#125;\n\n注意就像所有的枚举一样,Planet有一个静态的values方法,按照声明顺序返回它的值数组。toString 方法返回每个枚举值的声明名称,使得 println 和 printf 的打印变得更加容易。如果你不满意这种字符串表示法,可以通过覆盖toString方法对它进行修改。下面就是带命令行参数为 185来运行这个小小的 WeightTable程序(没有覆盖toString方法)时的结果：\nWeight on MERCURY is 69.912739Weight on VENUS is 167.434436Weight on EARTH is 185.000000Weight on MARS is 70.226739Weight on JUPITER is 467.990696Weight on SATURN is 197.120111Weight on URANUS is 167.398264Weight on NEPTUNE is 210.208751\n\n直到 2006 年,即Java 中增加了枚举的两年之后,当时冥王星Pluto 还属于行星。这引发出一个问题：当把一个元素从一个枚举类型中移除时,会发生什么情况呢？答案是：没有引l用该元素的任何客户端程序都会继续正常工作。因此,我们的 WeightTable程序只会打印出一个少了一行的表格而已。对于引l用了被删除元素(如本例中是指 Planet.Pluto)的客户端程序又如何呢？如果重新编译客户端程序,就会失败,并在引用被删除行星的那一条出现一条错误消息；如果没有重新编译客户端代码,在运行时就会在这一行抛出一个异常。这是你能期待的最佳行为了,远比使用int枚举模式时要好得多。\n有些与枚举常量相关的行为,可能只会用在枚举类型的定义类或者所在的包中,那么这些方法最好被实现成私有的或者包级私有的。于是每个枚举常量都带有一组隐藏的行为,这使得枚举类型的类或者所在的包能够运作得很好,像其他的类一样,除非要将枚举方法导出至它的客户端,否则都应该声明为私有的,或者声明为包级私有的(详见第 15条)。\n如果一个枚举具有普遍适用性,它就应该成为一个顶层类(top-level class)；如果它只是被用在一个特定的顶层类中,它就应该成为该顶层类的一个成员类(详见第24条)。例如,java.math.RoundingMode 枚举表示十进制小数的舍人模式(rounding mode)。这些舍人模式被用于BigDecimal类,但是它们却不属于BigDecimal类的一个抽象。通过使 RoundingMode 变成一个顶层类,库的设计者鼓励任何需要舍人模式的程序员重用这个枚举,从而增强API之间的一致性。\nPlanet示例中所示的方法对于大多数枚举类型来说就足够了,但有时候我们会需要更多的方法。每个Planet常量关联了不同的数据,但你有时需要将不同的行为(behavior)与每个常量关联起来。例如,假设你在编写一个枚举类型,来表示计算器的四大基本操作(即加减乘除),你想要提供一个方法来执行每个常量所表示的算术运算。有一种方法是通过启用枚举的值来实现：\n// Enum type that switches on its own value- questionablepublic enum Operation &#123;    PLUS,MINUS,TIMES,DIVIDE;    //Do the arithmetic operation represented by this constant    public double apply(double x, double y) &#123;        switch(this) &#123;            case PLUS: return x + y;            case MINUS: return x - y;            case TIMES: return x * y;            case DIVIDE: return x / y;        &#125;        throw new AssertionError(&quot;Unknown op: &quot; + this);    &#125;&#125;\n\n这段代码能用,但是不太好看。如果没有throw语句,它就不能进行编译,虽然从技术角度来看代码的结束部分是可以执行到的,但是实际上是不可能执行到这行代码的[JLS,14.21]。更糟糕的是,这段代码很脆弱。如果你添加了新的枚举常量,却忘记给switch 添加相应的条件,枚举仍然可以编译,但是当你试图运用新的运算时,就会运行失败。\n幸运的是,有一种更好的方法可以将不同的行为与每个枚举常量关联起来：在枚举类型中声明一个抽象的 apply方法,并在特定于常量的类主体(constant-specific class body)中,用具体的方法覆盖每个常量的抽象 apply方法。这种方法被称作特定于常量的方法实现 (constant-specific method implementation):\n// Enum type with constant-specific method implementationspublic enum Operation &#123;    PLUS &#123;public double apply(double x, double y)&#123;return x + y;&#125;&#125;,    MINUS &#123;public double apply(double x, double y)&#123;return x - y;&#125;&#125;,    DIVIDE&#123;public double apply(double x, double y)&#123;return x / y;&#125;&#125;;    public abstract double apply(double x, double y);&#125;\n\n如果给Operation 的第二种版本添加新的常量,你就不可能会忘记提供apply方法,因为该方法紧跟在每个常量声明之后。即使你真的忘记了,编译器也会提醒你,因为枚举类型中的抽象方法必须被它的所有常量中的具体方法所覆盖。\n特定于常量的方法实现可以与特定于常量的数据结合起来。例如,下面的 Operation覆盖了toString方法以返回通常与该操作关联的符号：\n// Enum type with constant-specific class bodies and datapublic enum Operation &#123;    PLUS(&quot;+&quot;)&#123;        public double apply(double x,double y)&#123; return x + y;&#125;    &#125;    MINUS(&quot;-&quot;) &#123;        public double apply(double x, double y) &#123; return x - y; &#125;    &#125;    TIMES(&quot;*&quot;)&#123;        public double apply(double x,double y) &#123; return x * y;&#125;    &#125;    DIVIDE(&quot;/&quot;)&#123;public double apply(double ×, double y) &#123; return x / y; &#125;    &#125;;        private final String symbol;    Operation(String symbol) &#123; this.symbol = Symbol;&#125;    @Override public String toStringO &#123; return symbol;&#125;    public abstract double apply(double x,double y);&#125;\n上述的toString 实现使得打印算术表达式变得非常容易,如下小程序所示：\npublic static void main(String[] args)&#123;    double x = Double.parseDouble(args[0]);    double y = Double.parseDouble(args[1]);    for (Operation op : Operation.values())        System.out.printf(&quot;%f %s %f = %f%n&quot;x,op,y, op.apply(x,y));&#125;\n用2和4作为命令行参数来运行这段程序,会输出：\n2.000000 + 4.000000 = 6.0000002.000000 - 4.000000 =-2.0000002.000000 * 4.000000 = 8.0000002.000000 / 4.000000 = 0.500000\n枚举类型有一个自动产生的valueOf(String)方法,它将常量的名字转变成常量本身。如果在枚举类型中覆盖toString,要考虑编写一个 fromString 方法,将定制的字符串表示法变回相应的枚举。下列代码(适当地改变了类型名称)可以为任何枚举完成这一技巧,只要每个常量都有一个独特的字符串表示法：\n//Implementing a fromString methodonanenumtypeprivate static final Map&lt;String, Operation&gt; stringToEnum =    Stream.of(values()).collect(toMap(Object::toString,e-&gt; e));        // Returns Operation for string,if any    public static Optional&lt;Operation&gt; fromString(String symbol)&#123;        return Optional.ofNullable(stringToEnum.get(symbol));    &#125;\n注意,在枚举常量被创建之后,Operation 常量从静态代码块中被放人到了 string-ToEnum 的映射中。前面的代码在values()方法返回的数组上使用流(见第 7章);在Java 8之前,我们将创建一个空的散列映射并遍历 values 数组,将字符串到枚举的映射插人到映射中,当然,如果你愿意,现在仍然可以这么做。但是,试图使每个常量都从自己的构造器将自身放入到映射中是不起作用的。它会导致编译时错误,这是好事,因为如果这是合法的,可能会引发NullPointerException 异常。除了编译时常量域(见第34 条)之外,枚举构造器不可以访问枚举的静态域。这一限制是有必要的,因为构造器运行的时候,这些静态域还没有被初始化。这条限制有一个特例：枚举常量无法通过其构造器访问另一个构造器。\n还要注意返回 Optional的 fromString 方法。它用该方法表明：传入的字符串并不代表一项有效的操作,并强制客户端面对这种可能性(详见第55条)。\n特定于常量的方法实现有一个美中不足的地方,它们使得在枚举常量中共享代码变得更加困难了。例如,考虑用一个枚举表示薪资包中的工作天数。这个枚举有一个方法,根据给定的某工人的基本工资(按小时)以及当天的工作时间,来计算他当天的报酬。在五个工作日中,超过正常八小时的工作时间都会产生加班工资；在节假日中,所有工作都产生加班工资。利用 switch 语句,很容易通过将多个case标签分别应用到两个代码片段中,来完成这一计算：\n//Enum that switches on itsvalue to sharecode-questionableenum PayrollDay &#123;MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY,SATURDAY, SUNDAY;private Static final int MINS_PER_SHIFT=8 * 60;int pay(int minutesWorked,int payRate)&#123;    int basePay= minutesWorked * payRate;    int overtimePay;switch(this)&#123;        case SATURDAY:case SUNDAY:// Weekend            overtimePay =basePay / 2;            break;        default://Weekday            overtimePay = minutesWorked &lt;= MINS_PER_SHIFT ?            0:(minutesWorked-MINS_PER_SHIFT)*payRate/ 2;    &#125;    return basePay + overtimePay;    &#125;&#125;\n\n不可否认,这段代码十分简洁,但是从维护的角度来看,它非常危险。假设将一个元素添加到该枚举中,或许是一个表示假期天数的特殊值,但是忘记给 switch 语句添加相应的\n为了利用特定于常量的方法实现安全地执行工资计算,你可能必须重复计算每个常量的加班工资,或者将计算移到两个辅助方法中(一个用来计算工作日,一个用来计算节假日),并从每个常量调用相应的辅助方法。任何一种方法都会产生相当数量的样板代码,这会降低可读性,并增加了出错的概率。\n通过用计算工作日加班工资的具体方法来代替 PayrollDay 中抽象的overtimePaY方法,可以减少样板代码。这样,就只有节假日必须覆盖该方法了。但是这样也有着与switch 语句一样的不足：如果又增加了一天而没有覆盖 overtimePay方法,就会悄悄地延续工作日的计算。\n我们真正想要的就是每当添加一个枚举常量时,就强制选择一种加班报酬策略。幸运的是,有一种很好的方法可以实现这一点。这种想法就是将加班工资计算移到一个私有的嵌套枚举中,将这个策略枚举(strategyenum)的实例传到PayrollDay枚举的构造器中。之后 PayrollDay 枚举将加班工资计算委托给策略枚举,PayrollDay 中就不需要 switch语句或者特定于常量的方法实现了。虽然这种模式没有 switch 语句那么简洁,但更加安全,也更加灵活:\n// The strategy enum patternenum PayrollDay &#123;    MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY,SATURDAY(PayType.WEEKEND), SUNDAY(PayType.WEEKEND) ;    private final PayType payType;    PayrollDay(PayType payType)&#123;         this.payType = payType;    &#125;    PayrollDay() &#123; this(PayType.WEEKDAY);&#125;// Default        int pay(int minutesWorked, int payRate) &#123;        return payType.pay(minutesWorked, payRate);    &#125;        // The strategy enum type    private enum PayType &#123;        WEEKDAY&#123;            int overtimePay(int minsWorked, int payRate) &#123;                return minsWorked &lt;= MINS_PER_SHIFT ? 0 :(minsWorked - MINS_PER_SHIFT) * payRate / 2;            &#125;        &#125;,        WEEKEND&#123;            int overtimePay(int minsWorked, int payRate) &#123;                return minsWorked * payRate / 2;            &#125;        &#125;;                abstract int overtimePay(int mins, int payRate);        private static final int MINS_PER_SHIFT = 8 * 60;                int pay(int minsWorked,int payRate)&#123;            int basePay = minsWorked * payRate;            return basePay + overtimePay(minsWorked, payRate);        &#125;    &#125;&#125;\n\n如果枚举中的switch语句不是在枚举中实现特定于常量的行为的一种很好的选择,那么它们还有什么用处呢？枚举中的switch语句适合于给外部的枚举类型增加特定于常量的行为。 例如,假设Operation 枚举不受你的控制,你希望它有一个实例方法来返回每个运算的反运算。你可以用下列静态方法模拟这种效果:\n//Switch on an enumto simulateamissing methodpublic static Operation inverse(Operation op)&#123;    switch(op) &#123;        case PLUS: return Operation.MINUS;        case MINUS:  return Operation.PLUS;        case TIMES: return Operation.DIVIDE;        case DIVIDE: return Operation.TIMES;                default:throw new AssertionError(&quot;Unknown op:&quot;+ op);    &#125;&#125;\n\n如果一个方法不属于枚举类型,也应该在你所能控制的枚举类型上使用这种方法。这种方法有点用处,但是通常还不值得将它包含到枚举类型中去。\n一般来说,枚举通常在性能上与 int 常量相当。与 int 常量相比,枚举有个小小的性能缺点,即装载和初始化枚举时会需要空间和时间的成本,但在实践中几乎注意不到这个问题。\n那么什么时候应该使用枚举呢？每当需要一组固定常量,并且在编译时就知道其成员的时候,就应该使用枚举。当然,这包括”天然的枚举类型”,例如行星、一周的天数以及棋子的数目等。但它也包括你在编译时就知道其所有可能值的其他集合,例如菜单的选项、操作代码以及命令行标记等。枚举类型中的常量集并不一定要始终保持不变。专门设计枚举特性是考虑到枚举类型的二进制兼容演变。\n总而言之,与int常量相比,枚举类型的优势是不言而喻的。枚举的可读性更好,也更加安全,功能更加强大。许多枚举都不需要显式的构造器或者成员,但许多其他枚举则受益于属性与每个常量的关联以及其行为受该属性影响的方法。只有极少数的枚举受益于将多种行为与单个方法关联。在这种相对少见的情况下,特定于常量的方法要优先于启用自有值的枚举。如果多个(但非所有)枚举常量同时共享相同的行为,则要考虑策略枚举。\n第35条：用实例域代替序数许多枚举天生就与一个单独的 int值相关联。所有的枚举都有一个ordinal方法,它返回每个枚举常量在类型中的数字位置。你可以试着从序数中得到关联的int值：\n//Abuseofordinaltoderiveanassociatedvalue-DoN&#x27;TDoTHISpublic enum Ensemble &#123;    SOLO,DUET,TRIO,QUARTET,QUINTET,SEXTET,SEPTET,OCTET,NONET, DECTET;    public int numberOfMusicians() &#123;        return ordinal() + 1;    &#125;&#125;\n\n虽然这个枚举工作得不错,但是维护起来就像一场噩梦。如果常量进行重新排序,number-OfMusicians 方法就会遭到破坏。如果要再添加一个与已经用过的 int 值关联的枚举常量,就没那么走运了。例如,给双四重奏(double quartet)添加一个常量,它就像个八重奏一样,是由8位演奏家组成,但是没有办法做到。\n而且,要是没有给所有这些 int 值添加常量,也无法给某个 int 值添加常量。例如,假设想要添加一个常量表示三四重奏(triple quartet),它由 12 位演奏家组成。对于由 11 位演奏家组成的合奏曲并没有标准的术语,因此只好给没有用过的int 值(11)添加一个虚拟(dummy)常量。这么做顶多就是不太好看。如果有许多 int 值都是从未用过的,可就不切实际了。\n幸运的是,有一种很简单的方法可以解决这些问题。永远不要根据枚举的序数导出与它关联的值,而是要将它保存在一个实例域中：\npublic enum Ensemble &#123;    SOLO(1),DUET(2),TRIO(3),QUARTET(4),QUINTET(5),SEXTET(6),SEPTET(7),OCTET(8),DOUBLE_QUARTET(8),NONET(9),DECTET(10), TRIPLE_QUARTET(12);    private final int numberOfMusicians;    Ensemble(int size) &#123;         this.numberOfMusicians = size;    &#125;    public int numberOfMusicians() &#123; return numberOfMusicians;&#125;&#125;\n\nEnum 规范中谈及ordinal方法时写道：”大多数程序员都不需要这个方法。它是设计用于像EnumSet和EnumMap这种基于枚举的通用数据结构的。”除非你在编写的是这种数据结构,否则最好完全避免使用 ordinal 方法。\n第36条：用EnumSet代替位域如果一个枚举类型的元素主要用在集合中,一般就使用int枚举模式(详见第 34条),比如将2的不同倍数赋予每个常量：\n//Bit field enumerationconstants-OBSOLETE!public class Text &#123;    public static final int STYLE_BOLD = 1 &lt;&lt; 0;  //1    public static final int STYLE_ITALIC = 1 &lt;&lt; 1; //2    public Static final int STYLE_UNDERLINE = 1 &lt;&lt; 2  //4    public static final int STYLE_STRIKETHROUGH = 1 &lt;&lt; 3; //8    // //Parameteris bitwise ORof zeroormoreSTYLE_constants    public void applyStyles(int styles)&#123;...&#125;&#125;\n\n这种表示法让你用OR 位运算将几个常量合并到一个集合中,称作位域(bit field)：\ntext.applyStyles(STYLE_BOLD I STYLE_ITALIC);\n\n位域表示法也允许利用位操作,有效地执行像union(联合)和intersection(交集)这样的集合操作。但位域具有int 枚举常量的所有缺点,甚至更多。当位域以数字形式打印时,翻译位域比翻译简单的int枚举常量要困难得多。要遍历位域表示的所有元素也没有很容易的方法。最后一点,在编写API的时候,就必须先预测最多需要多少位,同时还要给位域选择对应的类型(一般是 int 或者 1ong)。一旦选择好类型,在没有修改 API的情况下,将不能超出其位宽度(如 32位或者64位)。\n有些程序员虽然更倾向于使用枚举而非 int 常量,但是他们在需要传递多组常量集时,仍然倾向于使用位域。其实没有理由这么做,因为还有更好的替代方法。jaVa.util包提Set接口,提供了丰富的功能、类型安全性,以及可以从任何其他 Set实现中得到的互用性。但是在内部具体的实现上,每个EnumSet内容都表示为位矢量。如果底层的枚举类型有64个或者更少的元素(大多如此)整个EnumSet就使用单个long 来表示,因此它的性能比得上位域的性能。批处理操作,如 removeAll 和 retainAll,都是利用位算法来实现的,就像手工替位域实现的那样。但是可以避免手工位操作时容易出现的错误以及丑陋的代码,因为EnumSet替你完成了这项艰巨的工作。\n下面是前一个范例改成用枚举代替位域之后的代码,它更加简短、更加清楚,也更加安全：\n//EnumSet-amodernreplacementforbitfieldspublic class Text&#123;    public enum Style &#123; BOLD,ITALIC, UNDERLINE,STRIKETHROUGH &#125;        // Any Set could be passed in,but EnumSet is clearly best    public void applyStyles(Set&lt;Style&gt; styles)&#123;...&#125;&#125;\n\n下面是将EnumSet 实例传递给 applyStyles 方法的客户端代码。 EnumSet 提供了丰富的静态工厂来轻松创建集合,其中一个如下代码所示：\ntext.applyStyles(EnumSet.of(Style.BOLD,Style.ITALIC));//注意 applyStyles 方法采用的是Set&lt;Style&gt;而非EnumSet&lt;Style&gt;。\n\n虽然看起来好像所有的客户端都可以将EnumSet传到这个方法,但是最好还是接受接口类型而非接受实现类型(详见第64条)。这是考虑到可能会有特殊的客户端需要传递一些其他的 Set实现。\n总而言之,正是因为枚举类型要用在集合中,所以没有理由用位域来表示它。EnumSet类集位域的简洁和性能优势及第34条中所述的枚举类型的所有优点于一身。实际上EnumSet有个缺点,即截止 Java 9发行版本,它都无法创建不可变的 EnumSet,但是这一点很可能在即将发布的版本中得到修正。同时,可以用Collections.unmodifiableSet将EnumSet封装起来,但是简洁性和性能会受到影响。\n第37条：用EnumMap代替序数索引有时你可能会见到利用ordinal方法(详见第 35条)来索引数组或列表的代码。例如下面这个超级简化的类,用来表示一种烹饪用的香草：\nclass Plant&#123;    enum LifeCycle &#123; ANNUAL, PERENNIAL, BIENNIAL &#125;    final String name;    final LifeCycle lifeCycle;    Plant(String name,LifeCycle lifeCycle) &#123;        this.name = name;        this.lifeCycle = lifeCycle;    &#125;    @Override public String toStringO &#123;        return name;    &#125;&#125;\n\n现在假设有一个香草的数组,表示一座花园中的植物,你想要按照类型(一年生、多年生或者两年生植物)进行组织之后将这些植物列出来。如果要这么做,需要构建三个集合,每种类型一个,并且遍历整座花园,将每种香草放到相应的集合中。有些程序员会将这些集合放到一个按照类型的序数进行索引的数组中来实现这一点：\n//Using ordinal() to index into an array- DON’T DO THIS! Set&lt;Plant&gt;[] plantsByLifeCycle =(Set&lt;Plant&gt;[]) new Set[Plant. LifeCycle.values().length];for (int i= 0;i&lt; plantsByLifeCycle.length;i++)    plantsByLifeCycle[i] = new HashSet&lt;&gt;();for (Plant p : garden)    plantsByLifeCycle[p.lifeCycle.ordinalO].add(p) ;// Print the resultsfor(int i= 0;i&lt; plantsByLifeCycle.length;i++)&#123;    System.out.printf(&quot;%s: %s%n&quot;,Plant.LifeCycle.valuesO[i], plantsByLifeCycle[i]);&#125;\n\n这种方法的确可行,但是隐藏着许多问题。因为数组不能与泛型(详见第28条)兼容,程序需要进行未受检的转换,并且不能正确无误地进行编译。因为数组不知道它的索引代表着什么,你必须手工标注(label)这些索引的输出。但是这种方法最严重的问题在于,当你访问一个按照枚举的序数进行索引的数组时,使用正确的int值就是你的职责了；int不能提供枚举的类型安全。你如果使用了错误的值,程序就会悄悄地完成错误的工作,或者幸运的话,会抛出 ArrayIndexOutOfBoundException 异常。\n有一种更好的方法可以达到同样的效果。数组实际上充当着从枚举到值的映射,因此可能还要用到Map。更具体地说,有一种非常快速的Map 实现专门用于枚举键,称作java.util.EnumMap。以下就是用EnumMap改写后的程序:\n//UsinganEnumMaptoassociatedatawithanenumMap&lt;Plant.LifeCycle,Set&lt;Plant&gt;&gt;plantsByLifeCyclenew EnumMap&lt;&gt;(Plant.LifeCycle.class) ;for (Plant.LifeCycle 1c:Plant.LifeCycle.values())    plantsByLifeCycle.put(lc, new HashSet&lt;&gt;()) ;for (Plant p : garden)    plantsByLifeCycle.get(p.lifeCycle).add(p);System.out.println(plantsByLifeCycle);\n\n这段程序更简短、更清楚,也更加安全,运行速度方面可以与使用序数的程序相媲美。它没有不安全的转换；不必手工标注这些索引的输出,因为映射键知道如何将自身翻译成可打印字符串的枚举；计算数组索引时也不可能出错。EnumMap 在运行速度方面之所以能与通过序数索引的数组相媲美,正是因为EnuMap 在内部使用了这种数组。但是它对程序员隐藏了这种实现细节,集 Map 的丰富功能和类型安全与数组的快速于一身。注意 EnumMap构造器采用键类型的Class对象：这是一个有限制的类型令牌(bounded type token),它提供了运行时的泛型信息(详见第33条)。\n的最简单的代码,大量复制了上一个示例的行为：\n//Naivestream-basedapproach-unlikelytoproduceanEnumMap！System.out.println(Arrays.stream(garden)    .collect(groupingBy(p -&gt; p.lifeCycle)));\n这段代码的问题在于它选择自己的映射实现,实际上不会是一个EnumMap,因此与显式EnumMap版本的空间及时间性能并不吻合。为了解决这个问题,要使用有三种参数形式的Collectors.groupingBy方法,它允许调用者利用 mapFactory参数定义映射实现:\n//UsingastreamandanEnumMaptoassociatedatawithanenumSystem.out.println(Arrays.stream(garden)        .collect(groupingBy(p -&gt; p.lifeCycle,            ()-&gt; new EnumMap&lt;&gt;(LifeCycle.class),toSet())));\n在这样一个玩具程序中不值得进行这种优化,但是在大量使用映射的程序中就很重要了。\n一个植物生命周期都设计一个嵌套映射,基于 stream 的版本则仅当花园中包含了一种或多种植物带有该生命周期时才会设计一个嵌套映射。因此,假如花园中包含了一年生和多年生植物,但没有两年生植物,plantByLifeCycle 的数量在 EnumMap 版本中应该是三种,在基于stream 的两个版本中则都是两种。\n你还可能见到按照序数进行索引(两次)的数组的数组,该序数表示两个枚举值的映射。例如,下面这个程序就是使用这样一个数组将两个阶段映射到一个阶段过渡中(从液体到固体称作凝固,从液体到气体称作沸腾,诸如此类):\n//Using ordinal() to index array of arrays- DON ’T DO THIS! public enum Phase &#123;    SOLID, LIQUID, GAS;     public enum Transition &#123;        MELT,FREEZE,BOIL,CONDENSE,SUBLIME,DEPOSIT;        // Rows indexed by from-ordinal,cols by to-ordinal        private Static final Transition[][] TRANSITIONS =&#123;            &#123;null, MELT, SUBLIME &#125;,            &#123;FREEZE, null, BOIL &#125;,            &#123;DEPOSIT, CONDENSE,null&#125;        &#125;;        //Returnsthephasetransitionfromonephasetoanother        public static Transition from(Phase from, Phase to) &#123;            return TRANSITIONS[from.ordinalO][to.ordinalO];        &#125;    &#125;&#125;\n\n这段程序可行,看起来也比较优雅,但是事实并非如此。就像上面那个比较简单的香草花园的示例一样,编译器无法知道序数和数组索引之间的关系。如果在过渡表中出了错,或者在修改 Phase 或者 Phase.Transition 枚举类型的时候忘记将它更新,程序就会在运行时失败。这种失败的形式可能为ArrayIndexOutOfBoundsException、NullPointerException 或者(更糟糕的是)没有任何提示的错误行为。这张表的大小是阶段数的平方,即使非空项的数量比较少。\n同样,利用 EnumMap 依然可以做得更好一些。因为每个阶段过渡都是通过一对阶段枚举进行索引的,最好将这种关系表示为一个映射,这个映射的键是一个枚举(起始阶段),值为另一个映射,这第二个映射的键为第二个枚举(目标阶段),它的值为结果(阶段过渡),即形成了Map(起始阶段,Map(目标阶段,阶段过渡))这种形式。一个阶段过渡所关联的两个阶段,最好通过”数据与阶段过渡枚举之间的关系”来获取,之后用该阶段过渡枚举来初始化嵌套的EnumMap:\n//UsinganestedEnumMaptoassociatedatawithenumpairspublic enum Phase &#123;    SOLID,LIQUID,GAS;    public enum Transition &#123;        MELT(SOLID,LIQUID),         FREEZE(LIQUID,SOLID),        BOIL(LIQUID, CAS),         CONDENSE(GAS, LIQUID),        SUBLIME(SOLID, GAS),         DEPOSIT(GAS,SOLID);                private final Phase from;        private final Phase to;        Transition(Phase from,Phase to) &#123;            this.from = from;this.to = to;        &#125;        //Initialize the phase transition map        private static final Map&lt;Phase, Map&lt;Phase, Transition&gt;&gt;m =            Stream.of(values()).collect(groupingBy(t -&gt; t.from,()-&gt; new EnumMap&lt;&gt;(Phase.class),toMap(t-&gt;t.to,t-&gt;t,(x,y) -&gt; y, () -&gt; new EnumMap&lt;&gt;(Phase.class))));                    public static Transition from(Phase from, Phase to) &#123;            return m.get(from).get(to);        &#125;    &#125;&#125;\n\n初始化阶段过渡映射的代码看起来可能有点复杂。映射的类型为 Map&lt;Phasé,Map&lt;Phase,Transition&gt;&gt;,其中组成值的 Map 是由键值对目标 Phase(即第二个阶段)和Transition 组成的。这个映射的映射是利用两个集合的级联顺序进行初始化的。第一个集合按源 Phase 对过渡进行分组,第二个集合利用从目标 Phase 到过渡之间的映射创建一个 EnumMap。第二个集合中的 merge 函数((α,Y)-&gt;y)没有用到；只有当我们因为想要获得一个EnumMap而定义映射工厂时才需要用到它,同时Collectors 提供了重叠工厂。本书第 2版是利用显式迭代来初始化阶段过渡映射的。其代码更加烦琐,但是的确更易于理解。\n现在假设想要给系统添加一个新的阶段：plasma(离子)或者电离气体。只有两个过渡与这个阶段关联：电离化(ionization),它将气体变成离子；以及消电离化(deionization),将离子变成气体。为了更新基于数组的程序,必须给 Phase 添加一种新常量,给 Phase.Transition 添加两种新常量,用一种新的16个元素的版本取代原来9个元素的数组的数组。如果给数组添加的元素过多或者过少,或者元素放置不妥当,可就麻烦了：程序可以编译,但是会在运行时失败。为了更新基于 EnumMap 的版本,所要做的就是必须将 PLASMA添加到PhaSe 列表,并将IONIZE(GAS,PLASMA)和 DEIONIZE(PLASMA,GAS)添加到Phase.Transition 的列表中:\n//Adding a new phase using the nested EnumMap implementationpublic enum Phase&#123;    SOLID,LIQUID,GAS,PLASMA;    public enum Transition &#123;        MELT(SOLID,LIQUID),FREEZE(LIQUID, SOLID),        BOIL(LIQUID, GAS), CONDENSE(GAS, LIQUID),        SUBLIME(SOLID, GAS), DEPOSIT(GAS, SOLID),        IONIZE(GAS,PLASMA),DEIONIZE(PLASMA,GAS);        ...// Remainder unchanged    &#125;&#125;\n\n程序会自行处理所有其他的事情,这样就几乎没有出错的可能。从内部来看,映射的映射被实现成了数组的数组,因此在提升了清晰性、安全性和易维护性的同时,在空间或者时间上也几乎没有多余的开销。\n为了简洁起见,上述范例是用 null 表明状态没有变化(这里的to 和 from 是相等的)。这并不是好的实践,可能在运行时导致NullPointerException 异常。要给这个问题设计一个整洁、优雅的解决方案,需要高超的技巧,得到的程序会很长,贬损了本条目的主要精神。\n总而言之,最好不要用序数来索引数组,而要使用EnumMap。如果你所表示的这种关系是多维的,就使用EnumMap&lt;.··,EnumMap&lt;。．.&gt;&gt;。应用程序的程序员在一般情况下都不使用Enum.ordinal方法,仅仅在极少数情况下才会使用,因此这是一种特殊情况(详见第35条)。\n第38条：用接口模拟可扩展的枚举几乎从所有方面来看,枚举类型都优越于本书第1版中所述的类型安全枚举模式[Bloch01]。言构造的支持。换句话说,使用第1版所述的模式能够实现让一个枚举类型去扩展另一个枚举类型；利用这种语言特性,则不可能做到。这绝非偶然。枚举的可伸缩性最后证明基本上都不是什么好点子。扩展类型的元素为基本类型的实例,基本类型的实例却不是扩展类型的元素,这样很混乱。目前还没有很好的方法来枚举基本类型的所有元素及其扩展。最终,可伸缩性会导致设计和实现的许多方面变得复杂起来。\n也就是说,对于可伸缩的枚举类型而言,至少有一种具有说服力的用例,这就是操作码(operation code),也称作 opcode。操作码是指这样的枚举类型：它的元素表示在某种机器上的那些操作,例如第34条中的Operation 类型,它表示一个简单的计算器中的某些函数。有时要尽可能地让API的用户提供它们自己的操作,这样可以有效地扩展API所提供的操作集。\n幸运的是,有一种很好的方法可以利用枚举类型来实现这种效果。由于枚举类型可以通过给操作码类型和(属于接口的标准实现的)枚举定义接口来实现任意接口,基本的想法就是利用这一事实。例如,以下是第 34条中的Operation 类型的扩展版本:\n// Emulated extensible enum using an interfacepublic interface Operation &#123;    double apply(double x,double y);&#125;public enum BasicOperation implements Operation &#123;    PLUS(&quot;+&quot;)&#123;public double apply(double x, double y) &#123; return x + y; &#125;    &#125;,    MINUS(&quot;-&quot;) &#123;public double apply(double x, double y) &#123; return x - y; &#125;    &#125;,    TIMES(&quot;*&quot;)&#123;public double apply(double x,double y) &#123; return × * y;&#125;    &#125;,    DIVIDE(&quot;/&quot;)&#123;public double apply(double x,double y) &#123; return x / y; &#125;    &#125;;        private final String symbol;    BasicOperation(String symbol)&#123;this.symbol = symbol;&#125;        @Override public String toString() &#123;return symbol;    &#125;&#125;\n\n虽然枚举类型(BasicOperation)不是可扩展的,但接口类型(Operation)却是可扩展的,它是用来表示API中的操作的接口类型。你可以定义另一个枚举类型,它实现这个接口,并用这个新类型的实例代替基本类型。例如,假设你想要定义一个上述操作类型的扩展,由求幂(exponentiation)和求余(remainder)操作组成。你所要做的就是编写一个枚举类型,让它实现Operation 接口：\n//Emulatedextensionenumpublic enum Extended Operation implements Operation &#123;    EXP(&quot;^&quot;)&#123;        public double apply(double x, double y) &#123;            return Math.pow(x, y);        &#125;    &#125;,    REMAINDER(&quot;%&quot;)&#123;        public double apply(double x, double y) &#123;            return x % y;        &#125;    &#125;;    private final String symbol;    ExtendedOperation(String symbol) &#123;        this.symbol = symbol;    &#125;    @Override public String toString() &#123;        return symbol;    &#125;&#125;\n\n在可以使用基础操作的任何地方,现在都可以使用新的操作,只要API是写成采用接口类型(Operation)而非实现(BasicOperation)。注意,在枚举中,不必像在不可扩展的枚举中所做的那样,利用特定于实例的方法实现(见第 34 条)来声明抽象的 apply方法。因为抽象的方法(apply)是接口(Operation)的一部分。\n不仅可以在任何需要”基本枚举”的地方单独传递一个”扩展枚举”的实例,而且除了那些基本类型的元素之外,还可以传递完整的扩展枚举类型,并使用它的元素。例如,通过第34条的测试程序版本,体验一下上面定义过的所有扩展过的操作：\npublic static void main(String[] args) &#123;    double x = Double.parseDouble(args[0]);    double y = Double.parseDouble(args[1]);    test(ExtendedOperation.class, x, y);&#125;private static &lt;T extends Enum&lt;T&gt; &amp; Operation&gt; void test(        Class&lt;T&gt; opEnumType, double x, double y) &#123;    for (Operation op : opEnumType.getEnumConstants())        System.out.printf(&quot;%f %s %f = %f%n&quot;,x,op,y,op.apply(x,y));&#125;\n\n注意扩展过的操作类型的类的字面文字(ExtendedOperation.class)从 main 被传递给了七est方法,来描述被扩展操作的集合。这个类的字面文字充当有限制的类型令牌(bounded type token)(详见第 33条)。OpEnumType参数中公认很复杂的声明(&lt;T extends Enum&lt;T&gt;&amp;Operation&gt;Class&lt;T&gt;)确保了Class 对象既表示枚举又表示 Operation的子类型,这正是遍历元素和执行与每个元素相关联的操作时所需要的。\n第二种方法是传人一个Collection&lt;？Extends Operation&gt;,这是个有限制的通配符类型(boundedwildcard type)(详见第31条),而不是传递一个类对象：\npublic static void main(String[] args) &#123;    double x = Double.parseDouble(args[0]);    double y = Double.parseDouble(args[1]);    test(Arrays.asList(ExtendedOperation.values()), x, y);&#125;private static void test(Collection&lt;? extends Operation&gt; opSet,double x, double y) &#123;    for (Operation op : opSet)        System.out.printf(&quot;%f %s %f = %f%n&quot;x,op,y,op.apply(x,y));&#125;\n\n这样得到的代码没有那么复杂,test方法也比较灵活一些：它允许调用者将多个实现类型的操作合并到一起。另一方面,也放弃了在指定操作上使用 EnumSet(详见第 36条)和EnumMap(详见第37条)的功能。\n上面这两段程序运行时带上命令行参数4和2,都会产生如下输出：\n4.000000 ^ 2.000000 &#x3D; 16.0000004.000000 % 2.000000 &#x3D; 0.000000\n用接口模拟可伸缩枚举有个小小的不足,即无法将实现从一个枚举类型继承到另一个枚举类型。如果实现代码不依赖于任何状态,就可以将缺省实现(详见第20条)放在接口中。在上述Operation 的示例中,保存和获取与某项操作相关联的符号的逻辑代码,必须复制到 BasicOperation 和 ExtendedOperation 中。在这个例子中是可以的,因为复制的代码非常少。如果共享功能比较多,则可以将它封装在一个辅助类或者静态辅助方法中,来避免代码的复制工作。\n本条目所述的模式也在 Java 类库中得到了应用。例如,java.nio.file.LinkOption枚举类型,它同时实现了 CopyOption 和 OpenOption 接口。\n总而言之,虽然无法编写可扩展的枚举类型,却可以通过编写接口以及实现该接口的基础枚举类型来对它进行模拟。这样允许客户端编写自己的枚举(或者其他类型)来实现接口。如果API是根据接口编写的,那么在可以使用基础枚举类型的任何地方,也都可以使用这些枚举。\n第39条：注解优先于命名模式根据经验,一般使用命名模式(naming pattern)表明有些程序元素需要通过某种工具或者框架进行特殊处理。例如,在 Java 4 发行版本之前,JUnit 测试框架原本要求其用户一定要用test 作为测试方法名称的开头[Beck04]。这种方法可行,但是有几个很严重的缺点。首先,文字拼写错误会导致失败,且没有任何提示。例如,假设不小心将一个测试方法命名为tsetSafetyOverride 而不是testSafetyOverride。JUnit 3 不会提示,但也不会执行测试,造成错误的安全感。\n命名模式的第二个缺点是,无法确保它们只用于相应的程序元素上。例如,假设将某个类称作TestSafetyMechanisms,是希望JUnit3会自动地测试它所有的方法,而不管它们叫什么名称。JUnit3还是不会提示,但也同样不会执行测试。\n命名模式的第三个缺点是,它们没有提供将参数值与程序元素关联起来的好方法。例如,假设想要支持一种测试类别,它只在抛出特殊异常时才会成功。异常类型本质上是测试的一个参数。你可以利用某种具体的命名模式,将异常类型名称编码到测试方法名称中,但是这样的代码很不雅观,也很脆弱(见第62条)。编译器不知道要去检验准备命名异常的字符串是否真正命名成功。如果命名的类不存在,或者不是一个异常,你也要到试着运行测试时才会发现。\n注解[JLS,9.7]很好地解决了所有这些问题,JUnit 从 Java4开始使用。在本条目中,我们要编写自己的试验测试框架,展示一下注解的使用方法。假设想要定义一个注解类型来指定简单的测试,它们自动运行,并在抛出异常时失败。以下就是这样的一个注解类型,命名为Test:\n//Markerannotationtypedeclarationimport java.lang.annotation.*;/** * Indicatesthattheannotatedmethodis atest  * Use only on parameterless static methods */@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface Test &#123;&#125;\n\nTest 注解类型的声明就是它自身通过 Retention 和 Target 注解进行了注解。注解类型声明中的这种注解被称作元注解(meta-annotation)。@Retention(RetentionPolicy·RUNTIME)元注解表明 Test 注解在运行时也应该存在，否则测试工具就无法知道 Test 注解。@Target(ElementType.METHOD)元注解表明,Test注解只在方法声明中才是合法的：它不能运用到类声明、域声明或者其他程序元素上。\n注意Test注解声明上方的注释：”Use only on parameterless static method”(只用于无参的静态方法)。如果编译器能够强制这一限制最好,但是它做不到,除非编写一个注解处理器(annotation processor),让它来完成。关于这个主题的更多信息,请参阅javax。annotation·processing 的文档。在没有这类注解处理器的情况下,如果将 Test 注解放在实例方法的声明中,或者放在带有一个或者多个参数的方法中,测试程序还是可以编译,让测试工具在运行时来处理这个问题。\n下面就是现实应用中的Test注解,称作标记注解(marker annotation),因为它没有参数,只是”标注”被注解的元素。如果程序员拼错了Test,或者将Test 注解应用到程序元素而非方法声明,程序就无法编译:\n//Program containing marker annotationspublic class Sample&#123;    @Test public static void ml() &#123;&#125;// Test should pass    public static void m2() &#123;&#125;    @Test public static void m3() &#123; // Test should fail        throw new RuntimeException(&quot;Boom&quot;);    &#125;    public static void m4()&#123;&#125;    @Test public void m5()&#123;&#125; //INVALIDUSE:nonstaticmethod    public static void m6() &#123;&#125;    @Test public static void m7() &#123; // Test should fail        throw new RuntimeException(&quot;Crash&quot;);    &#125;    public static void m8() &#123;&#125;&#125;\n\nSample类有7个静态方法,其中 4个被注解为测试。这4个中有2个抛出了异常：m3 和m7,另外两个则没有：m1和m5。但是其中一个没有抛出异常的被注解方法：m5,是一个实例方法,因此不属于注解的有效使用。总之,Sample 包含 4项测试：一项会通过,两项会失败,另一项无效。没有用 Test 注解进行标注的另外4个方法会被测试工具忽略。\nTest 注解对 Sample 类的语义没有直接的影响。它们只负责提供信息供相关的程序使用。更一般地讲,注解永远不会改变被注解代码的语义,但是使它可以通过工具进行特殊的处理,例如像这种简单的测试运行类：\n//Programto process marker annotationsimport java.lang.reflect.*;public class RunTests &#123;    public static void main(String[] args) throws Exception &#123;        int tests = 0;        int passed = 0;        Class&lt;?&gt; testClass = Class.forName(args[0]);        for (Method m : testClass.getDeclaredMethods()) &#123;            if (m.isAnnotationPresent(Test.class)) &#123;                tests++;                try &#123;                    m.invoke(null) ;                    passed++;                &#125; catch (InvocationTargetException wrappedExc) &#123;                    Throwable exc = wrappedExc.getCause() ;                    System.out.println(m + &quot; failed: &quot; + exc);                &#125;catch (Exception exc)&#123;                    System.out.println(&quot;Invalid @Test: &quot; + m) ;                &#125;            &#125;        &#125;        System.out.printf(&quot;Passed: %d, Failed: %d%n&quot;,passed, tests - passed);    &#125;&#125;\n\n测试运行工具在命令行上使用完全匹配的类名,并通过调用 Method.invoke 反射式地运行类中所有标注了 Test 注解的方法。isAnnotationPresent 方法告知该工具要运行哪些方法。如果测试方法抛出异常,反射机制就会将它封装在 InvocationTargetException中。该工具捕捉到这个异常,并打印失败报告,包含测试方法抛出的原始异常,这些信息是通过 getCause 方法从 InvocationTargetException 中提取出来的。\n如果尝试通过反射调用测试方法时抛出InvocationTargetException之外的任何异常,表明编译时没有捕捉到Test注解的无效用法。这种用法包括实例方法的注解,或者带有一个或多个参数的方法的注解,或者不可访问的方法的注解。测试运行类中的第二个catch 块捕捉到这些 Test用法错误,并打印出相应的错误消息。下面就是 RunTests 在Sample上运行时打印的输出:\npublic static void Sample.m3() failed: RuntimeException: BoomInvalid @Test: public void Sample.m5()public static void Sample.m7() failed: RuntimeException:CrashPassed:1,Failed:3\n\n现在我们要针对只在抛出特殊异常时才成功的测试添加支持。为此需要一个新的注解类型：\n//Annotation type with a parameterimport java.lang.annotation.*;/** Indicates that the annotated method is a test method that * must throw the designated exception to succeed. */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface ExceptionTest&#123;    Class&lt;?extendsThrowable&gt;value();&#125;\n\n这个注解的参数类型是 Class&lt;？extends Throwable&gt;。这个通配符类型有些绕口。它在英语中的意思是：某个扩展 Throwable 的类的Class对象,它允许注解的用户指定任何异常(或错误)类型。这种用法是有限制的类型令牌(bounded type token)(详见第33条)的一个示例。下面就是实际应用中的这个注解。注意类名称被用作了注解参数的值：\n//Program containing annotationswith aparameterpublic class Sample2 &#123;    @ExceptionTest(ArithmeticException.class)    public static void m1() &#123;// Test should pass        int i= 0;        i=i/i;    &#125;    @ExceptionTest(ArithmeticException.class)    public static void m2() &#123; // Should fail (wrong exception)        int[] a = new int[0];        int i = a[1];    &#125;    @ExceptionTest(ArithmeticException.class)    public static void m3() &#123;&#125;// Should fail(noexception)\n\n现在我们要修改一下测试运行工具来处理新的注解。这其中包括将以下代码添加到main 方法中:\nif (m.isAnnotationPresent(ExceptionTest.class)) &#123;    tests++;    try&#123;        m.invoke(null);        System.out.printf(&quot;Test %s failed: no exception%n&quot;, m);    &#125;catch (InvocationTargetException wrappedEx) &#123;        Throwable exc = wrappedEx.getCause() ;        Class&lt;? extends Throwable&gt; excType =m.getAnnotation(ExceptionTest.class).value();        if (excType.isInstance(exc))&#123;            passed++;        &#125;else&#123;            System.out.printf(&quot;Test %s failed: expected %s, got %s%n&quot;,m, excType.getName(), exc);        &#125;    &#125;catch (Exception exc)&#123;        System.out.println(&quot;Invalid @Test: &quot; + m);    &#125;&#125;\n\n这段代码类似于用来处理Test注解的代码,但有一处不同：这段代码提取了注解参数的值,并用它检验该测试抛出的异常是否为正确的类型。没有显式的转换,因此没有出现 ClassCastException 的危险。编译过的测试程序确保它的注解参数表示的是有效的异常类型,需要提醒一点：有可能注解参数在编译时是有效的,但是表示特定异常类型的类文件在运行时却不存在。在这种希望很少出现的情况下,测试运行类会抛出 TypeNot-PresentException 异常。\n将上面的异常测试示例再深人一点,想象测试可以在抛出任何一种指定异常时都能够通过。注解机制有一种工具,使得支持这种用法变得十分容易。假设我们将 ExceptionTest注解的参数类型改成 Class 对象的一个数组：\n// Annotation type with an array parameter@Retention(RetentionPolicy.RUNTIME)@Target(ElementType .METHOD)public @interface ExceptionTest &#123;    Class&lt;? extends Exception&gt;[] value();&#125;\n\n注解中数组参数的语法十分灵活。它是进行过优化的单元素数组。使用了 Exception-Test 新版的数组参数之后,之前的所有 ExceptionTest 注解仍然有效,并产生单元素的数组。为了指定多元素的数组,要用花括号将元素包围起来,并用逗号将它们隔开：\n// Code containing an annotation with an array parameter@ExceptionTest(&#123; IndexOutOfBoundsException.class,NullPointerException.class &#125;)public static void doublyBad() &#123;    List&lt;String&gt; list = new ArrayList&lt;&gt;();    // The spec permits this method to throw either    // IndexOutOfBoundsException or NullPointerException    list.addA1l(5, nu11);&#125;\n\n修改测试运行工具来处理新的 ExceptionTest 相当简单。下面的代码代替了原来的代码：\nif (m.isAnnotationPresent(ExceptionTest.class)) &#123;    tests++:    try&#123;        m.invoke(nul1);        System.out.printf(&quot;Test %s failed: no exception%n&quot;, m);    &#125;catch (Throwable wrappedExc)&#123;        Throwable exc = wrappedExc.getCause();        int oldPassed =passed;        Class&lt;? extends Exception&gt;[] excTypes=m.getAnnotation(ExceptionTest.class).value();        for (Class&lt;? extends Exception&gt; excType :excTypes)&#123;            if (excType.isInstance(exc)) &#123;                passed++;                break;            &#125;        &#125;        if (passed == oldPassed)            System.out.printf(&quot;Test %s failed: %s %n&quot;,m,exc);    &#125;&#125;\n\n从Java8开始,还有另一种方法可以进行多值注解。它不是用一个数组参数声明一个注解类型,而是用 @Repeatable 元注解对注解的声明进行注解,表示该注解可以被重复地应用给单个元素。这个元注解只有一个参数,就是包含注解类型(containing annotationtype)的类对象,它唯一的参数是一个注解类型数组[JLS,9.6.3]。下面的注解声明就是把ExceptionTest 注解改成使用这个方法之后的版本。注意包含的注解类型必须利用适当的保留策略和目标进行注解,否则声明将无法编译：\n//Repeatableannotationtype@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)@Repeatable(ExceptionTestContainer.class)public @interface ExceptionTest&#123;    Class&lt;? extends Exception&gt; value();&#125;@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface ExceptionTestContainer &#123;    ExceptionTest[] value();&#125;\n\n下面是 doublyBad 测试方法用重复注解代替数组值注解之后的代码:\n// Code containing a repeated annotation@ExceptionTest(IndexOutOfBoundsException.class)@ExceptionTest(NullPointerException.class)public static void doublyBad() &#123;...&#125;\n\n处理可重复的注解要非常小心。重复的注解会产生一个包含注解类型的合成注解。get-AnnotationsByType方法掩盖了这个事实,可以用于访问可重复注解类型的重复和非重复的注解。但isAnnotationPresent使它变成了显式的,即重复的注解不是注解类型(而是所包含的注解类型)的一部分。如果一个元素具有某种类型的重复注解,并且用isAnnotationPresent方法检验该元素是否具有该类型的注解,会发现它没有。用这种方法检验是否存在注解类型,会导致程序默默地忽略掉重复的注解。同样地,用这种方法检验是否存在包含的注解类型,会导致程序默默地忽略掉非重复的注解。为了利用isAnnotationPresent 检测重复和非重复的注解,必须检查注解类型及其包含的注解类型。下面是 Runtests 程序改成使用 ExceptionTest 注解时有关部分的代码:\n// Processing repeatable annotationsif(m.isAnnotationPresent(ExceptionTest.class)     || m.isAnnotationPresent(ExceptionTestContainer.class))&#123;        tests++;        try&#123;            m.invoke(null);            System.out.printf(&quot;Test %s failed: no exception%n&quot;, m);        &#125; catch (Throwable wrappedExc) &#123;            Throwable exc = wrappedExc.getCause();            int oldPassed = passed;            ExceptionTest[] excTests=m.getAnnotationsByType(ExceptionTest.class);            for (ExceptionTest excTest: excTests)&#123;                if (excTest.value().isInstance(exc)) &#123;                    passed++;                    break;                &#125;            &#125;            if (passed == oldPassed)            System.out.printf(&quot;Test %s failed: %s %n&quot;, m, exc);        &#125;    &#125;\n\n加人可重复的注解,提升了源代码的可读性,逻辑上是将同一个注解类型的多个实例应用到了一个指定的程序元素。如果你觉得它们增强了源代码的可读性就使用它们,但是记住在声明和处理可重复注解的代码中会有更多的样板代码,并且处理可重复的注解容易出错。\n本条目中的测试框架只是一个试验,但它清楚地示范了注解之于命名模式的优越性。这只是揭开了注解功能的冰山一角。如果是在编写一个需要程序员给源文件添加信息的工具,就要定义一组适当的注解类型。既然有了注解,就完全没有理由再使用命名模式了。\n也就是说,除了”工具铁匠”(toolsmiths,即平台框架程序员)之外,大多数程序员都不必定义注解类型。但是所有的程序员都应该使用Java平台所提供的预定义的注解类型(详见第 40 条和第 27条)。还要考虑使用IDE 或者静态分析工具所提供的任何注解。这种注解可以提升由这些工具所提供的诊断信息的质量。但是要注意这些注解还没有标准化,因此如果变换工具或者形成标准,就有很多工作要做了。\n第40条：坚持使用Override注解Java类库中包含了几种注解类型。对于传统的程序员而言,这里面最重要的就是@Override 注解。这个注解只能用在方法声明中,它表示被注解的方法声明覆盖了超类型中的一个方法声明。如果坚持使用这个注解,可以防止一大类的非法错误。以下面的程序为例,这里的 Bigram 类表示一个双字母组或者有序的字母对:\n//Canyouspotthebug?public class Bigram &#123;    private final char first;    private final char second;    public Bigram(char first,char second) &#123;        this.first = first;        this.second = second;    &#125;    public boolean equals(Bigram b) &#123;        return b.first == first &amp;&amp; b.second == second;    &#125;    public int hashCode()&#123;        return 31 * first + second;    &#125;    public static void main(String[] args)&#123;        Set&lt;Bigram&gt; s = new HashSet&lt;&gt;();        for(int i= 0;i&lt; 10;i++)            for(char ch = &#x27;a&#x27; , ch &lt;&#x27;z&#x27; ; ch++)                s.add(new Bigram(ch, ch));        System.out.println(s.size());    &#125;&#125;\n\n主程序反复地将26个双字母组添加到集合中,每个双字母组都由两个相同的小写字母组成。随后它打印出集合的大小。你可能以为程序打印出的大小为26,因为集合不能包含重复。如果你试着运行程序,会发现它打印的不是26而是260。哪里出错了呢?\n很显然,Bigram 类的创建者原本想要覆盖equals 方法(详见第 10条),同时还记得覆盖了hashCode(详见第 11 章)。遗憾的是,不幸的程序员没能覆盖equals 方法,而是将它重载了(详见第52条)。为了覆盖Object.equals 必须定义一个参数为 Object 类型的equals 方法,但是 Bigram 类的 equals 方法的参数并不是 Object 类型,因此 Bigram类从 Object继承了equals方法。这个equals方法测试对象的同一性(identity),就像&#x3D;&#x3D;操作符一样。每个 bigram 的 10 个备份中,每一个都与其余的9个不同,因此 Object.equals认为它们不相等,这正是程序会打印出 260的原因。\n幸运的是,编译器可以帮助你发现这个错误,但是只有当你告知编译器你想要覆盖Object.equals时才行。为了做到这一点,要用@Override 标注Bigram.euqals,如下所示：\n@Override public boolean equals(Bigram b)&#123;    return b.first==first &amp;&amp; b.second==second;&#125;\n\n如果插人这个注解,并试着重新编译程序,编译器就会产生如下的错误消息：\nBigram.java:10:method does not override or implement a methodfrom a supertype    @Override public boolean equals(Bigramb)&#123;&#125;\n\n你会立即意识到哪里错了,拍拍自己的头,恍然大悟,马上用正确的来取代出错的equals 实现(详见第10条):\n@Override public boolean equals(object o)&#123;    if(!(o instanceof Bigram))        return false;    Bigram b = (Bigram) o;    return b.first ==first &amp;&amp;b.second ==second;&#125;\n\n因此,应该在你想要覆盖超类声明的每个方法声明中使用Override注解。这一规则有个小小的例外。如果你在编写一个没有标注为抽象的类,并且确信它覆盖了超类的抽象方法,在这种情况下,就不必将 Override 注解放在该方法上了。在没有声明为抽象的类中,如果没有覆盖抽象的超类方法,编译器就会发出一条错误消息。但是,你可能希望关注类中所有覆盖超类方法的方法,在这种情况下,也可以放心地标注这些方法。大多数IDE可以设置为在需要覆盖一个方法时自动插人Override 注解。\n大多数IDE 都提供了使用Override 注解的另一种理由。如果启用相应的代码检验功能,当有一个方法没有Override 注解,却覆盖了超类方法时,IDE 就会产生一条警告。如果使用了Override注解,这些警告就会提醒你警惕无意识的覆盖。这些警告补充了编译器的错误消息,后者会提醒你警惕无意识的覆盖失败。IDE和编译器可以确保你无一遗漏地覆盖任何你想要覆盖的方法。\nOverride 注解可以用在方法声明中,覆盖来自接口以及类的声明。由于缺省方法的出现,在接口方法的具体实现上使用Override,可以确保签名正确,这是一个很好的实践。如果知道接口没有缺省方法,可以选择省略接口方法的具体实现上的 Override 注解,以减少混乱。\n但是在抽象类或者接口中,还是值得标注所有你想要的方法,来覆盖超类或者超接口方法,无论它们是具体的还是抽象的。例如,Set接口没有给Collection 接口添加新方法,因此它应该在它的所有方法声明中包括Override 注解,以确保它不会意外地给Collection接口添加任何新方法。\n总而言之,如果在你想要的每个方法声明中使用Override 注解来覆盖超类声明,编译器就可以替你防止大量的错误,但有一个例外。在具体的类中,不必标注你确信覆盖了抽象方法声明的方法(虽然这么做也没有什么坏处)。\n第41条：用标记接口定义类型标记接口(marker interface)是不包含方法声明的接口,它只是指明(或者”标明”)一个类实现了具有某种属性的接口。例如,考虑 Serializable接口(详见第12章)。通过实现这个接口,类表明它的实例可以被写到ObjectOutputStream 中(或者”被序列化”)。\n你可能听说过标记注解(详见第39条)使得标记接口过时了。这种断言是不正确的。标记接口有两点胜过标记注解。首先,也是最重要的一点是,标记接口定义的类型是由被标记类的实例实现的；标记注解则没有定义这样的类型。标记接口类型的存在,允许你在编译时就能捕捉到在使用标记注解的情况下要到运行时才能捕捉到的错误。\n序列化的。ObjectoutputStream.writeObject方法将传人的对象序列化,其参数必须是可序列化的。该方法的参数类型应该为 Serializable,如果试着序列化一个不恰当的对象,(通过类型检查)在编译时就会被发现。编译时的错误侦测是标记接口的目的,但遗憾的是,ObjectOutputStream.write API并没有利用 Serializable接口的优势:其参数声明为Object类型,因此,如果尝试序列化一个不可序列化的对象,将直到程序运行时才会失败。\n标记接口胜过标记注解的另一个优点是,它们可以被更加精确地进行锁定。如果注解类型用目标 ElementType.TYPE声明,它就可以被应用于任何类或者接口。假设有一个标记它适用的接口,确保所有被标记的类型也都是该唯一接口的子类型。\nSet接口可以说就是这种有限制的标记接口(restricted marker interface)。它只适用于 Collection 子类型,但是它不会添加除了Collection 定义之外的方法。一般情况下,不把它当作是标记接口,因为它改进了几个Collection 方法的合约,包括 add、equals 和hashCode。但是很容易想象只适用于某种特殊接口的子类型的标记接口,它没有改进接口的任何方法的合约。这种标记接口可以描述整个对象的某个约束条件,或者表ObjectOutputStream 进行处理一样)。\n标记注解胜过标记接口的最大优点在于,它们是更大的注解机制的一部分。因此,标记注解在那些支持注解作为编程元素之一的框架中同样具有一致性。\n那么什么时候应该使用标记注解,什么时候应该使用标记接口呢？很显然,如果标记是应用于任何程序元素而不是类或者接口,就必须使用注解,因为只有类和接口可以用来实现或者扩展接口。如果标记只应用于类和接口,就要问问自己：我要编写一个还是多个只接受有这种标记的方法呢？如果是这种情况,就应该优先使用标记接口而非注解。这样你就可以用接口作为相关方法的参数类型,它可以真正为你提供编译时进行类型检查的好处。如果外,如果标记是广泛使用注解的框架的一个组成部分,则显然应该选择标记注解。\n总而言之,标记接口和标记注解都各有用处。如果想要定义一个任何新方法都不会与之关联的类型,标记接口就是最好的选择。如果想要标记程序元素而非类和接口,或者标记要适合于已经广泛使用了注解类型的框架，那么标记注解就是正确的选择。 如果你发现自己在编写的是目标为ElementType.TYPE的标记注解类型,就要花点时间考虑清楚,它是否真的应该为注解类型,想想标记接口是否会更加合适。\n从某种意义上说,本条目与第22条中”如果不想定义类型就不要使用接口”的说法相反。本条目最接近的意思是说：”如果想要定义类型,一定要使用接口。”\n","categories":["读书笔记"],"tags":["Java","Effective Java"]}]